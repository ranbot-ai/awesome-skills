{
  "id": "antigravity-azure-ai-ml-py",
  "name": "azure-ai-ml-py",
  "slug": "azure-ai-ml-py",
  "description": "Azure Machine Learning SDK v2 for Python. Use for ML workspaces, jobs, models, datasets, compute, and pipelines.\nTriggers: \"azure-ai-ml\", \"MLClient\", \"workspace\", \"model registry\", \"training jobs\", \"datasets\".\n",
  "category": "AI & Agents",
  "source": "antigravity",
  "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
  "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/azure-ai-ml-py",
  "content": "\n# Azure Machine Learning SDK v2 for Python\n\nClient library for managing Azure ML resources: workspaces, jobs, models, data, and compute.\n\n## Installation\n\n```bash\npip install azure-ai-ml\n```\n\n## Environment Variables\n\n```bash\nAZURE_SUBSCRIPTION_ID=<your-subscription-id>\nAZURE_RESOURCE_GROUP=<your-resource-group>\nAZURE_ML_WORKSPACE_NAME=<your-workspace-name>\n```\n\n## Authentication\n\n```python\nfrom azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\n\nml_client = MLClient(\n    credential=DefaultAzureCredential(),\n    subscription_id=os.environ[\"AZURE_SUBSCRIPTION_ID\"],\n    resource_group_name=os.environ[\"AZURE_RESOURCE_GROUP\"],\n    workspace_name=os.environ[\"AZURE_ML_WORKSPACE_NAME\"]\n)\n```\n\n### From Config File\n\n```python\nfrom azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\n\n# Uses config.json in current directory or parent\nml_client = MLClient.from_config(\n    credential=DefaultAzureCredential()\n)\n```\n\n## Workspace Management\n\n### Create Workspace\n\n```python\nfrom azure.ai.ml.entities import Workspace\n\nws = Workspace(\n    name=\"my-workspace\",\n    location=\"eastus\",\n    display_name=\"My Workspace\",\n    description=\"ML workspace for experiments\",\n    tags={\"purpose\": \"demo\"}\n)\n\nml_client.workspaces.begin_create(ws).result()\n```\n\n### List Workspaces\n\n```python\nfor ws in ml_client.workspaces.list():\n    print(f\"{ws.name}: {ws.location}\")\n```\n\n## Data Assets\n\n### Register Data\n\n```python\nfrom azure.ai.ml.entities import Data\nfrom azure.ai.ml.constants import AssetTypes\n\n# Register a file\nmy_data = Data(\n    name=\"my-dataset\",\n    version=\"1\",\n    path=\"azureml://datastores/workspaceblobstore/paths/data/train.csv\",\n    type=AssetTypes.URI_FILE,\n    description=\"Training data\"\n)\n\nml_client.data.create_or_update(my_data)\n```\n\n### Register Folder\n\n```python\nmy_data = Data(\n    name=\"my-folder-dataset\",\n    version=\"1\",\n    path=\"azureml://datastores/workspaceblobstore/paths/data/\",\n    type=AssetTypes.URI_FOLDER\n)\n\nml_client.data.create_or_update(my_data)\n```\n\n## Model Registry\n\n### Register Model\n\n```python\nfrom azure.ai.ml.entities import Model\nfrom azure.ai.ml.constants import AssetTypes\n\nmodel = Model(\n    name=\"my-model\",\n    version=\"1\",\n    path=\"./model/\",\n    type=AssetTypes.CUSTOM_MODEL,\n    description=\"My trained model\"\n)\n\nml_client.models.create_or_update(model)\n```\n\n### List Models\n\n```python\nfor model in ml_client.models.list(name=\"my-model\"):\n    print(f\"{model.name} v{model.version}\")\n```\n\n## Compute\n\n### Create Compute Cluster\n\n```python\nfrom azure.ai.ml.entities import AmlCompute\n\ncluster = AmlCompute(\n    name=\"cpu-cluster\",\n    type=\"amlcompute\",\n    size=\"Standard_DS3_v2\",\n    min_instances=0,\n    max_instances=4,\n    idle_time_before_scale_down=120\n)\n\nml_client.compute.begin_create_or_update(cluster).result()\n```\n\n### List Compute\n\n```python\nfor compute in ml_client.compute.list():\n    print(f\"{compute.name}: {compute.type}\")\n```\n\n## Jobs\n\n### Command Job\n\n```python\nfrom azure.ai.ml import command, Input\n\njob = command(\n    code=\"./src\",\n    command=\"python train.py --data ${{inputs.data}} --lr ${{inputs.learning_rate}}\",\n    inputs={\n        \"data\": Input(type=\"uri_folder\", path=\"azureml:my-dataset:1\"),\n        \"learning_rate\": 0.01\n    },\n    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n    compute=\"cpu-cluster\",\n    display_name=\"training-job\"\n)\n\nreturned_job = ml_client.jobs.create_or_update(job)\nprint(f\"Job URL: {returned_job.studio_url}\")\n```\n\n### Monitor Job\n\n```python\nml_client.jobs.stream(returned_job.name)\n```\n\n## Pipelines\n\n```python\nfrom azure.ai.ml import dsl, Input, Output\nfrom azure.ai.ml.entities import Pipeline\n\n@dsl.pipeline(\n    compute=\"cpu-cluster\",\n    description=\"Training pipeline\"\n)\ndef training_pipeline(data_input):\n    prep_step = prep_component(data=data_input)\n    train_step = train_component(\n        data=prep_step.outputs.output_data,\n        learning_rate=0.01\n    )\n    return {\"model\": train_step.outputs.model}\n\npipeline = training_pipeline(\n    data_input=Input(type=\"uri_folder\", path=\"azureml:my-dataset:1\")\n)\n\npipeline_job = ml_client.jobs.create_or_update(pipeline)\n```\n\n## Environments\n\n### Create Custom Environment\n\n```python\nfrom azure.ai.ml.entities import Environment\n\nenv = Environment(\n    name=\"my-env\",\n    version=\"1\",\n    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n    conda_file=\"./environment.yml\"\n)\n\nml_client.environments.create_or_update(env)\n```\n\n## Datastores\n\n### List Datastores\n\n```python\nfor ds in ml_client.datastores.list():\n    print(f\"{ds.name}: {ds.type}\")\n```\n\n### Get Default Datastore\n\n```python\ndefault_ds = ml_client.datastores.get_default()\nprint(f\"Default: {default_ds.name}\")\n```\n\n## MLClient Operations\n\n| Property | Operations |\n|----------|------------|\n| `workspaces` | create, get, list, delete |\n| `jobs` | create_or_update, get, list, stream, cancel |\n| `models` | create_or_update, get, list, archive |\n| `data` | create_or_update, get, list |\n",
  "tags": [
    "python",
    "ai",
    "workflow",
    "image",
    "azure",
    "cro"
  ],
  "useCases": [],
  "scrapedAt": "2026-02-12T07:15:32.111Z"
}