{
  "id": "antigravity-m365-agents-ts",
  "name": "m365-agents-ts",
  "slug": "m365-agents-ts",
  "description": "Microsoft 365 Agents SDK for TypeScript/Node.js. Build multichannel agents for Teams/M365/Copilot Studio with AgentApplication routing, Express hosting, streaming responses, and Copilot Studio client integration. Triggers: \"Microsoft 365 Agents SDK\", \"@microsoft/agents-hosting\", \"AgentApplication\", ",
  "category": "AI & Agents",
  "source": "antigravity",
  "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
  "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/m365-agents-ts",
  "content": "\n# Microsoft 365 Agents SDK (TypeScript)\n\nBuild enterprise agents for Microsoft 365, Teams, and Copilot Studio using the Microsoft 365 Agents SDK with Express hosting, AgentApplication routing, streaming responses, and Copilot Studio client integrations.\n\n## Before implementation\n- Use the microsoft-docs MCP to verify the latest API signatures for AgentApplication, startServer, and CopilotStudioClient.\n- Confirm package versions on npm before wiring up samples or templates.\n\n## Installation\n\n```bash\nnpm install @microsoft/agents-hosting @microsoft/agents-hosting-express @microsoft/agents-activity\nnpm install @microsoft/agents-copilotstudio-client\n```\n\n## Environment Variables\n\n```bash\nPORT=3978\nAZURE_RESOURCE_NAME=<azure-openai-resource>\nAZURE_API_KEY=<azure-openai-key>\nAZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o-mini\n\nTENANT_ID=<tenant-id>\nCLIENT_ID=<client-id>\nCLIENT_SECRET=<client-secret>\n\nCOPILOT_ENVIRONMENT_ID=<environment-id>\nCOPILOT_SCHEMA_NAME=<schema-name>\nCOPILOT_CLIENT_ID=<copilot-app-client-id>\nCOPILOT_BEARER_TOKEN=<copilot-jwt>\n```\n\n## Core Workflow: Express-hosted AgentApplication\n\n```typescript\nimport { AgentApplication, TurnContext, TurnState } from \"@microsoft/agents-hosting\";\nimport { startServer } from \"@microsoft/agents-hosting-express\";\n\nconst agent = new AgentApplication<TurnState>();\n\nagent.onConversationUpdate(\"membersAdded\", async (context: TurnContext) => {\n  await context.sendActivity(\"Welcome to the agent.\");\n});\n\nagent.onMessage(\"hello\", async (context: TurnContext) => {\n  await context.sendActivity(`Echo: ${context.activity.text}`);\n});\n\nstartServer(agent);\n```\n\n## Streaming responses with Azure OpenAI\n\n```typescript\nimport { azure } from \"@ai-sdk/azure\";\nimport { AgentApplication, TurnContext, TurnState } from \"@microsoft/agents-hosting\";\nimport { startServer } from \"@microsoft/agents-hosting-express\";\nimport { streamText } from \"ai\";\n\nconst agent = new AgentApplication<TurnState>();\n\nagent.onMessage(\"poem\", async (context: TurnContext) => {\n  context.streamingResponse.setFeedbackLoop(true);\n  context.streamingResponse.setGeneratedByAILabel(true);\n  context.streamingResponse.setSensitivityLabel({\n    type: \"https://schema.org/Message\",\n    \"@type\": \"CreativeWork\",\n    name: \"Internal\",\n  });\n\n  await context.streamingResponse.queueInformativeUpdate(\"starting a poem...\");\n\n  const { fullStream } = streamText({\n    model: azure(process.env.AZURE_OPENAI_DEPLOYMENT_NAME || \"gpt-4o-mini\"),\n    system: \"You are a creative assistant.\",\n    prompt: \"Write a poem about Apollo.\",\n  });\n\n  try {\n    for await (const part of fullStream) {\n      if (part.type === \"text-delta\" && part.text.length > 0) {\n        await context.streamingResponse.queueTextChunk(part.text);\n      }\n      if (part.type === \"error\") {\n        throw new Error(`Streaming error: ${part.error}`);\n      }\n    }\n  } finally {\n    await context.streamingResponse.endStream();\n  }\n});\n\nstartServer(agent);\n```\n\n## Invoke activity handling\n\n```typescript\nimport { Activity, ActivityTypes } from \"@microsoft/agents-activity\";\nimport { AgentApplication, TurnContext, TurnState } from \"@microsoft/agents-hosting\";\n\nconst agent = new AgentApplication<TurnState>();\n\nagent.onActivity(\"invoke\", async (context: TurnContext) => {\n  const invokeResponse = Activity.fromObject({\n    type: ActivityTypes.InvokeResponse,\n    value: { status: 200 },\n  });\n\n  await context.sendActivity(invokeResponse);\n  await context.sendActivity(\"Thanks for submitting your feedback.\");\n});\n```\n\n## Copilot Studio client (Direct to Engine)\n\n```typescript\nimport { CopilotStudioClient } from \"@microsoft/agents-copilotstudio-client\";\n\nconst settings = {\n  environmentId: process.env.COPILOT_ENVIRONMENT_ID!,\n  schemaName: process.env.COPILOT_SCHEMA_NAME!,\n  clientId: process.env.COPILOT_CLIENT_ID!,\n};\n\nconst tokenProvider = async (): Promise<string> => {\n  return process.env.COPILOT_BEARER_TOKEN!;\n};\n\nconst client = new CopilotStudioClient(settings, tokenProvider);\n\nconst conversation = await client.startConversationAsync();\nconst reply = await client.askQuestionAsync(\"Hello!\", conversation.id);\nconsole.log(reply);\n```\n\n## Copilot Studio WebChat integration\n\n```typescript\nimport { CopilotStudioWebChat } from \"@microsoft/agents-copilotstudio-client\";\n\nconst directLine = CopilotStudioWebChat.createConnection(client, {\n  showTyping: true,\n});\n\nwindow.WebChat.renderWebChat({\n  directLine,\n}, document.getElementById(\"webchat\")!);\n```\n\n## Best Practices\n\n1. Use AgentApplication for routing and keep handlers focused on one responsibility.\n2. Prefer streamingResponse for long-running completions and call endStream in finally blocks.\n3. Keep secrets out of source code; load tokens from environment variables or secure stores.\n4. Reuse CopilotStudioClient instances and cache tokens in your token provider.\n5. Validate invoke payloads before logging or persisting feedback.\n\n## Reference Files\n\n| File | Contents |\n| --- | --- |\n| [references/acceptance-criteria.md](references/acceptance-c",
  "tags": [
    "javascript",
    "typescript",
    "node",
    "api",
    "mcp",
    "ai",
    "agent",
    "gpt",
    "workflow",
    "template"
  ],
  "useCases": [],
  "scrapedAt": "2026-02-15T07:05:36.223Z"
}