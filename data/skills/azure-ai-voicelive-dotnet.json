{
  "id": "antigravity-azure-ai-voicelive-dotnet",
  "name": "azure-ai-voicelive-dotnet",
  "slug": "azure-ai-voicelive-dotnet",
  "description": "Azure AI Voice Live SDK for .NET. Build real-time voice AI applications with bidirectional WebSocket communication. Use for voice assistants, conversational AI, real-time speech-to-speech, and voice-enabled chatbots. Triggers: \"voice live\", \"real-time voice\", \"VoiceLiveClient\", \"VoiceLiveSession\", \"",
  "category": "AI & Agents",
  "source": "antigravity",
  "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
  "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/azure-ai-voicelive-dotnet",
  "content": "\n# Azure.AI.VoiceLive (.NET)\n\nReal-time voice AI SDK for building bidirectional voice assistants with Azure AI.\n\n## Installation\n\n```bash\ndotnet add package Azure.AI.VoiceLive\ndotnet add package Azure.Identity\ndotnet add package NAudio                    # For audio capture/playback\n```\n\n**Current Versions**: Stable v1.0.0, Preview v1.1.0-beta.1\n\n## Environment Variables\n\n```bash\nAZURE_VOICELIVE_ENDPOINT=https://<resource>.services.ai.azure.com/\nAZURE_VOICELIVE_MODEL=gpt-4o-realtime-preview\nAZURE_VOICELIVE_VOICE=en-US-AvaNeural\n# Optional: API key if not using Entra ID\nAZURE_VOICELIVE_API_KEY=<your-api-key>\n```\n\n## Authentication\n\n### Microsoft Entra ID (Recommended)\n\n```csharp\nusing Azure.Identity;\nusing Azure.AI.VoiceLive;\n\nUri endpoint = new Uri(\"https://your-resource.cognitiveservices.azure.com\");\nDefaultAzureCredential credential = new DefaultAzureCredential();\nVoiceLiveClient client = new VoiceLiveClient(endpoint, credential);\n```\n\n**Required Role**: `Cognitive Services User` (assign in Azure Portal → Access control)\n\n### API Key\n\n```csharp\nUri endpoint = new Uri(\"https://your-resource.cognitiveservices.azure.com\");\nAzureKeyCredential credential = new AzureKeyCredential(\"your-api-key\");\nVoiceLiveClient client = new VoiceLiveClient(endpoint, credential);\n```\n\n## Client Hierarchy\n\n```\nVoiceLiveClient\n└── VoiceLiveSession (WebSocket connection)\n    ├── ConfigureSessionAsync()\n    ├── GetUpdatesAsync() → SessionUpdate events\n    ├── AddItemAsync() → UserMessageItem, FunctionCallOutputItem\n    ├── SendAudioAsync()\n    └── StartResponseAsync()\n```\n\n## Core Workflow\n\n### 1. Start Session and Configure\n\n```csharp\nusing Azure.Identity;\nusing Azure.AI.VoiceLive;\n\nvar endpoint = new Uri(Environment.GetEnvironmentVariable(\"AZURE_VOICELIVE_ENDPOINT\"));\nvar client = new VoiceLiveClient(endpoint, new DefaultAzureCredential());\n\nvar model = \"gpt-4o-mini-realtime-preview\";\n\n// Start session\nusing VoiceLiveSession session = await client.StartSessionAsync(model);\n\n// Configure session\nVoiceLiveSessionOptions sessionOptions = new()\n{\n    Model = model,\n    Instructions = \"You are a helpful AI assistant. Respond naturally.\",\n    Voice = new AzureStandardVoice(\"en-US-AvaNeural\"),\n    TurnDetection = new AzureSemanticVadTurnDetection()\n    {\n        Threshold = 0.5f,\n        PrefixPadding = TimeSpan.FromMilliseconds(300),\n        SilenceDuration = TimeSpan.FromMilliseconds(500)\n    },\n    InputAudioFormat = InputAudioFormat.Pcm16,\n    OutputAudioFormat = OutputAudioFormat.Pcm16\n};\n\n// Set modalities (both text and audio for voice assistants)\nsessionOptions.Modalities.Clear();\nsessionOptions.Modalities.Add(InteractionModality.Text);\nsessionOptions.Modalities.Add(InteractionModality.Audio);\n\nawait session.ConfigureSessionAsync(sessionOptions);\n```\n\n### 2. Process Events\n\n```csharp\nawait foreach (SessionUpdate serverEvent in session.GetUpdatesAsync())\n{\n    switch (serverEvent)\n    {\n        case SessionUpdateResponseAudioDelta audioDelta:\n            byte[] audioData = audioDelta.Delta.ToArray();\n            // Play audio via NAudio or other audio library\n            break;\n            \n        case SessionUpdateResponseTextDelta textDelta:\n            Console.Write(textDelta.Delta);\n            break;\n            \n        case SessionUpdateResponseFunctionCallArgumentsDone functionCall:\n            // Handle function call (see Function Calling section)\n            break;\n            \n        case SessionUpdateError error:\n            Console.WriteLine($\"Error: {error.Error.Message}\");\n            break;\n            \n        case SessionUpdateResponseDone:\n            Console.WriteLine(\"\\n--- Response complete ---\");\n            break;\n    }\n}\n```\n\n### 3. Send User Message\n\n```csharp\nawait session.AddItemAsync(new UserMessageItem(\"Hello, can you help me?\"));\nawait session.StartResponseAsync();\n```\n\n### 4. Function Calling\n\n```csharp\n// Define function\nvar weatherFunction = new VoiceLiveFunctionDefinition(\"get_current_weather\")\n{\n    Description = \"Get the current weather for a given location\",\n    Parameters = BinaryData.FromString(\"\"\"\n        {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\n                    \"type\": \"string\",\n                    \"description\": \"The city and state or country\"\n                }\n            },\n            \"required\": [\"location\"]\n        }\n        \"\"\")\n};\n\n// Add to session options\nsessionOptions.Tools.Add(weatherFunction);\n\n// Handle function call in event loop\nif (serverEvent is SessionUpdateResponseFunctionCallArgumentsDone functionCall)\n{\n    if (functionCall.Name == \"get_current_weather\")\n    {\n        var parameters = JsonSerializer.Deserialize<Dictionary<string, string>>(functionCall.Arguments);\n        string location = parameters?[\"location\"] ?? \"\";\n        \n        // Call external service\n        string weatherInfo = $\"The weather in {location} is sunny, 75°F.\";\n        \n        // Send response\n        await session.AddItemAsync(new Functio",
  "tags": [
    "api",
    "ai",
    "gpt",
    "workflow",
    "azure",
    "rag",
    "cro"
  ],
  "useCases": [],
  "scrapedAt": "2026-02-12T07:15:35.882Z"
}