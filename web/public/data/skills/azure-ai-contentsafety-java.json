{
  "id": "antigravity-azure-ai-contentsafety-java",
  "name": "azure-ai-contentsafety-java",
  "slug": "azure-ai-contentsafety-java",
  "description": "Build content moderation applications with Azure AI Content Safety SDK for Java. Use when implementing text/image analysis, blocklist management, or harm detection for hate, violence, sexual content, and self-harm.",
  "category": "AI & Agents",
  "source": "antigravity",
  "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
  "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/azure-ai-contentsafety-java",
  "content": "\n# Azure AI Content Safety SDK for Java\n\nBuild content moderation applications using the Azure AI Content Safety SDK for Java.\n\n## Installation\n\n```xml\n<dependency>\n    <groupId>com.azure</groupId>\n    <artifactId>azure-ai-contentsafety</artifactId>\n    <version>1.1.0-beta.1</version>\n</dependency>\n```\n\n## Client Creation\n\n### With API Key\n\n```java\nimport com.azure.ai.contentsafety.ContentSafetyClient;\nimport com.azure.ai.contentsafety.ContentSafetyClientBuilder;\nimport com.azure.ai.contentsafety.BlocklistClient;\nimport com.azure.ai.contentsafety.BlocklistClientBuilder;\nimport com.azure.core.credential.KeyCredential;\n\nString endpoint = System.getenv(\"CONTENT_SAFETY_ENDPOINT\");\nString key = System.getenv(\"CONTENT_SAFETY_KEY\");\n\nContentSafetyClient contentSafetyClient = new ContentSafetyClientBuilder()\n    .credential(new KeyCredential(key))\n    .endpoint(endpoint)\n    .buildClient();\n\nBlocklistClient blocklistClient = new BlocklistClientBuilder()\n    .credential(new KeyCredential(key))\n    .endpoint(endpoint)\n    .buildClient();\n```\n\n### With DefaultAzureCredential\n\n```java\nimport com.azure.identity.DefaultAzureCredentialBuilder;\n\nContentSafetyClient client = new ContentSafetyClientBuilder()\n    .credential(new DefaultAzureCredentialBuilder().build())\n    .endpoint(endpoint)\n    .buildClient();\n```\n\n## Key Concepts\n\n### Harm Categories\n| Category | Description |\n|----------|-------------|\n| Hate | Discriminatory language based on identity groups |\n| Sexual | Sexual content, relationships, acts |\n| Violence | Physical harm, weapons, injury |\n| Self-harm | Self-injury, suicide-related content |\n\n### Severity Levels\n- Text: 0-7 scale (default outputs 0, 2, 4, 6)\n- Image: 0, 2, 4, 6 (trimmed scale)\n\n## Core Patterns\n\n### Analyze Text\n\n```java\nimport com.azure.ai.contentsafety.models.*;\n\nAnalyzeTextResult result = contentSafetyClient.analyzeText(\n    new AnalyzeTextOptions(\"This is text to analyze\"));\n\nfor (TextCategoriesAnalysis category : result.getCategoriesAnalysis()) {\n    System.out.printf(\"Category: %s, Severity: %d%n\",\n        category.getCategory(),\n        category.getSeverity());\n}\n```\n\n### Analyze Text with Options\n\n```java\nAnalyzeTextOptions options = new AnalyzeTextOptions(\"Text to analyze\")\n    .setCategories(Arrays.asList(\n        TextCategory.HATE,\n        TextCategory.VIOLENCE))\n    .setOutputType(AnalyzeTextOutputType.EIGHT_SEVERITY_LEVELS);\n\nAnalyzeTextResult result = contentSafetyClient.analyzeText(options);\n```\n\n### Analyze Text with Blocklist\n\n```java\nAnalyzeTextOptions options = new AnalyzeTextOptions(\"I h*te you and want to k*ll you\")\n    .setBlocklistNames(Arrays.asList(\"my-blocklist\"))\n    .setHaltOnBlocklistHit(true);\n\nAnalyzeTextResult result = contentSafetyClient.analyzeText(options);\n\nif (result.getBlocklistsMatch() != null) {\n    for (TextBlocklistMatch match : result.getBlocklistsMatch()) {\n        System.out.printf(\"Blocklist: %s, Item: %s, Text: %s%n\",\n            match.getBlocklistName(),\n            match.getBlocklistItemId(),\n            match.getBlocklistItemText());\n    }\n}\n```\n\n### Analyze Image\n\n```java\nimport com.azure.ai.contentsafety.models.*;\nimport com.azure.core.util.BinaryData;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\n\n// From file\nbyte[] imageBytes = Files.readAllBytes(Paths.get(\"image.png\"));\nContentSafetyImageData imageData = new ContentSafetyImageData()\n    .setContent(BinaryData.fromBytes(imageBytes));\n\nAnalyzeImageResult result = contentSafetyClient.analyzeImage(\n    new AnalyzeImageOptions(imageData));\n\nfor (ImageCategoriesAnalysis category : result.getCategoriesAnalysis()) {\n    System.out.printf(\"Category: %s, Severity: %d%n\",\n        category.getCategory(),\n        category.getSeverity());\n}\n```\n\n### Analyze Image from URL\n\n```java\nContentSafetyImageData imageData = new ContentSafetyImageData()\n    .setBlobUrl(\"https://example.com/image.jpg\");\n\nAnalyzeImageResult result = contentSafetyClient.analyzeImage(\n    new AnalyzeImageOptions(imageData));\n```\n\n## Blocklist Management\n\n### Create or Update Blocklist\n\n```java\nimport com.azure.core.http.rest.RequestOptions;\nimport com.azure.core.http.rest.Response;\nimport com.azure.core.util.BinaryData;\nimport java.util.Map;\n\nMap<String, String> description = Map.of(\"description\", \"Custom blocklist\");\nBinaryData resource = BinaryData.fromObject(description);\n\nResponse<BinaryData> response = blocklistClient.createOrUpdateTextBlocklistWithResponse(\n    \"my-blocklist\", resource, new RequestOptions());\n\nif (response.getStatusCode() == 201) {\n    System.out.println(\"Blocklist created\");\n} else if (response.getStatusCode() == 200) {\n    System.out.println(\"Blocklist updated\");\n}\n```\n\n### Add Block Items\n\n```java\nimport com.azure.ai.contentsafety.models.*;\nimport java.util.Arrays;\n\nList<TextBlocklistItem> items = Arrays.asList(\n    new TextBlocklistItem(\"badword1\").setDescription(\"Offensive term\"),\n    new TextBlocklistItem(\"badword2\").setDescription(\"Another term\")\n);\n\nAddOrUpdateTextBlocklistItemsResult resu",
  "tags": [
    "api",
    "ai",
    "image",
    "azure"
  ],
  "useCases": [
    "\"content safety Java\"",
    "\"content moderation Azure\"",
    "\"analyze text safety\"",
    "\"image moderation Java\"",
    "\"blocklist management\""
  ],
  "scrapedAt": "2026-02-12T07:15:30.100Z"
}