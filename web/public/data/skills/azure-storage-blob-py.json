{
  "id": "antigravity-azure-storage-blob-py",
  "name": "azure-storage-blob-py",
  "slug": "azure-storage-blob-py",
  "description": "Azure Blob Storage SDK for Python. Use for uploading, downloading, listing blobs, managing containers, and blob lifecycle.\nTriggers: \"blob storage\", \"BlobServiceClient\", \"ContainerClient\", \"BlobClient\", \"upload blob\", \"download blob\".\n",
  "category": "AI & Agents",
  "source": "antigravity",
  "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
  "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/azure-storage-blob-py",
  "content": "\n# Azure Blob Storage SDK for Python\n\nClient library for Azure Blob Storage â€” object storage for unstructured data.\n\n## Installation\n\n```bash\npip install azure-storage-blob azure-identity\n```\n\n## Environment Variables\n\n```bash\nAZURE_STORAGE_ACCOUNT_NAME=<your-storage-account>\n# Or use full URL\nAZURE_STORAGE_ACCOUNT_URL=https://<account>.blob.core.windows.net\n```\n\n## Authentication\n\n```python\nfrom azure.identity import DefaultAzureCredential\nfrom azure.storage.blob import BlobServiceClient\n\ncredential = DefaultAzureCredential()\naccount_url = \"https://<account>.blob.core.windows.net\"\n\nblob_service_client = BlobServiceClient(account_url, credential=credential)\n```\n\n## Client Hierarchy\n\n| Client | Purpose | Get From |\n|--------|---------|----------|\n| `BlobServiceClient` | Account-level operations | Direct instantiation |\n| `ContainerClient` | Container operations | `blob_service_client.get_container_client()` |\n| `BlobClient` | Single blob operations | `container_client.get_blob_client()` |\n\n## Core Workflow\n\n### Create Container\n\n```python\ncontainer_client = blob_service_client.get_container_client(\"mycontainer\")\ncontainer_client.create_container()\n```\n\n### Upload Blob\n\n```python\n# From file path\nblob_client = blob_service_client.get_blob_client(\n    container=\"mycontainer\",\n    blob=\"sample.txt\"\n)\n\nwith open(\"./local-file.txt\", \"rb\") as data:\n    blob_client.upload_blob(data, overwrite=True)\n\n# From bytes/string\nblob_client.upload_blob(b\"Hello, World!\", overwrite=True)\n\n# From stream\nimport io\nstream = io.BytesIO(b\"Stream content\")\nblob_client.upload_blob(stream, overwrite=True)\n```\n\n### Download Blob\n\n```python\nblob_client = blob_service_client.get_blob_client(\n    container=\"mycontainer\",\n    blob=\"sample.txt\"\n)\n\n# To file\nwith open(\"./downloaded.txt\", \"wb\") as file:\n    download_stream = blob_client.download_blob()\n    file.write(download_stream.readall())\n\n# To memory\ndownload_stream = blob_client.download_blob()\ncontent = download_stream.readall()  # bytes\n\n# Read into existing buffer\nstream = io.BytesIO()\nnum_bytes = blob_client.download_blob().readinto(stream)\n```\n\n### List Blobs\n\n```python\ncontainer_client = blob_service_client.get_container_client(\"mycontainer\")\n\n# List all blobs\nfor blob in container_client.list_blobs():\n    print(f\"{blob.name} - {blob.size} bytes\")\n\n# List with prefix (folder-like)\nfor blob in container_client.list_blobs(name_starts_with=\"logs/\"):\n    print(blob.name)\n\n# Walk blob hierarchy (virtual directories)\nfor item in container_client.walk_blobs(delimiter=\"/\"):\n    if item.get(\"prefix\"):\n        print(f\"Directory: {item['prefix']}\")\n    else:\n        print(f\"Blob: {item.name}\")\n```\n\n### Delete Blob\n\n```python\nblob_client.delete_blob()\n\n# Delete with snapshots\nblob_client.delete_blob(delete_snapshots=\"include\")\n```\n\n## Performance Tuning\n\n```python\n# Configure chunk sizes for large uploads/downloads\nblob_client = BlobClient(\n    account_url=account_url,\n    container_name=\"mycontainer\",\n    blob_name=\"large-file.zip\",\n    credential=credential,\n    max_block_size=4 * 1024 * 1024,  # 4 MiB blocks\n    max_single_put_size=64 * 1024 * 1024  # 64 MiB single upload limit\n)\n\n# Parallel upload\nblob_client.upload_blob(data, max_concurrency=4)\n\n# Parallel download\ndownload_stream = blob_client.download_blob(max_concurrency=4)\n```\n\n## SAS Tokens\n\n```python\nfrom datetime import datetime, timedelta, timezone\nfrom azure.storage.blob import generate_blob_sas, BlobSasPermissions\n\nsas_token = generate_blob_sas(\n    account_name=\"<account>\",\n    container_name=\"mycontainer\",\n    blob_name=\"sample.txt\",\n    account_key=\"<account-key>\",  # Or use user delegation key\n    permission=BlobSasPermissions(read=True),\n    expiry=datetime.now(timezone.utc) + timedelta(hours=1)\n)\n\n# Use SAS token\nblob_url = f\"https://<account>.blob.core.windows.net/mycontainer/sample.txt?{sas_token}\"\n```\n\n## Blob Properties and Metadata\n\n```python\n# Get properties\nproperties = blob_client.get_blob_properties()\nprint(f\"Size: {properties.size}\")\nprint(f\"Content-Type: {properties.content_settings.content_type}\")\nprint(f\"Last modified: {properties.last_modified}\")\n\n# Set metadata\nblob_client.set_blob_metadata(metadata={\"category\": \"logs\", \"year\": \"2024\"})\n\n# Set content type\nfrom azure.storage.blob import ContentSettings\nblob_client.set_http_headers(\n    content_settings=ContentSettings(content_type=\"application/json\")\n)\n```\n\n## Async Client\n\n```python\nfrom azure.identity.aio import DefaultAzureCredential\nfrom azure.storage.blob.aio import BlobServiceClient\n\nasync def upload_async():\n    credential = DefaultAzureCredential()\n    \n    async with BlobServiceClient(account_url, credential=credential) as client:\n        blob_client = client.get_blob_client(\"mycontainer\", \"sample.txt\")\n        \n        with open(\"./file.txt\", \"rb\") as data:\n            await blob_client.upload_blob(data, overwrite=True)\n\n# Download async\nasync def download_async():\n    async with BlobServiceClient(account_url, credential=credential) as client:\n  ",
  "tags": [
    "python",
    "ai",
    "workflow",
    "azure",
    "rag"
  ],
  "useCases": [],
  "scrapedAt": "2026-02-12T07:16:00.720Z"
}