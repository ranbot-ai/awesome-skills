{
  "id": "antigravity-machine-learning-ops-ml-pipeline",
  "name": "machine-learning-ops-ml-pipeline",
  "slug": "machine-learning-ops-ml-pipeline",
  "description": "Design and implement a complete ML pipeline for: $ARGUMENTS",
  "category": "AI & Agents",
  "source": "antigravity",
  "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
  "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/machine-learning-ops-ml-pipeline",
  "content": "\n# Machine Learning Pipeline - Multi-Agent MLOps Orchestration\n\nDesign and implement a complete ML pipeline for: $ARGUMENTS\n\n## Use this skill when\n\n- Working on machine learning pipeline - multi-agent mlops orchestration tasks or workflows\n- Needing guidance, best practices, or checklists for machine learning pipeline - multi-agent mlops orchestration\n\n## Do not use this skill when\n\n- The task is unrelated to machine learning pipeline - multi-agent mlops orchestration\n- You need a different domain or tool outside this scope\n\n## Instructions\n\n- Clarify goals, constraints, and required inputs.\n- Apply relevant best practices and validate outcomes.\n- Provide actionable steps and verification.\n- If detailed examples are required, open `resources/implementation-playbook.md`.\n\n## Thinking\n\nThis workflow orchestrates multiple specialized agents to build a production-ready ML pipeline following modern MLOps best practices. The approach emphasizes:\n\n- **Phase-based coordination**: Each phase builds upon previous outputs, with clear handoffs between agents\n- **Modern tooling integration**: MLflow/W&B for experiments, Feast/Tecton for features, KServe/Seldon for serving\n- **Production-first mindset**: Every component designed for scale, monitoring, and reliability\n- **Reproducibility**: Version control for data, models, and infrastructure\n- **Continuous improvement**: Automated retraining, A/B testing, and drift detection\n\nThe multi-agent approach ensures each aspect is handled by domain experts:\n- Data engineers handle ingestion and quality\n- Data scientists design features and experiments\n- ML engineers implement training pipelines\n- MLOps engineers handle production deployment\n- Observability engineers ensure monitoring\n\n## Phase 1: Data & Requirements Analysis\n\n<Task>\nsubagent_type: data-engineer\nprompt: |\n  Analyze and design data pipeline for ML system with requirements: $ARGUMENTS\n\n  Deliverables:\n  1. Data source audit and ingestion strategy:\n     - Source systems and connection patterns\n     - Schema validation using Pydantic/Great Expectations\n     - Data versioning with DVC or lakeFS\n     - Incremental loading and CDC strategies\n\n  2. Data quality framework:\n     - Profiling and statistics generation\n     - Anomaly detection rules\n     - Data lineage tracking\n     - Quality gates and SLAs\n\n  3. Storage architecture:\n     - Raw/processed/feature layers\n     - Partitioning strategy\n     - Retention policies\n     - Cost optimization\n\n  Provide implementation code for critical components and integration patterns.\n</Task>\n\n<Task>\nsubagent_type: data-scientist\nprompt: |\n  Design feature engineering and model requirements for: $ARGUMENTS\n  Using data architecture from: {phase1.data-engineer.output}\n\n  Deliverables:\n  1. Feature engineering pipeline:\n     - Transformation specifications\n     - Feature store schema (Feast/Tecton)\n     - Statistical validation rules\n     - Handling strategies for missing data/outliers\n\n  2. Model requirements:\n     - Algorithm selection rationale\n     - Performance metrics and baselines\n     - Training data requirements\n     - Evaluation criteria and thresholds\n\n  3. Experiment design:\n     - Hypothesis and success metrics\n     - A/B testing methodology\n     - Sample size calculations\n     - Bias detection approach\n\n  Include feature transformation code and statistical validation logic.\n</Task>\n\n## Phase 2: Model Development & Training\n\n<Task>\nsubagent_type: ml-engineer\nprompt: |\n  Implement training pipeline based on requirements: {phase1.data-scientist.output}\n  Using data pipeline: {phase1.data-engineer.output}\n\n  Build comprehensive training system:\n  1. Training pipeline implementation:\n     - Modular training code with clear interfaces\n     - Hyperparameter optimization (Optuna/Ray Tune)\n     - Distributed training support (Horovod/PyTorch DDP)\n     - Cross-validation and ensemble strategies\n\n  2. Experiment tracking setup:\n     - MLflow/Weights & Biases integration\n     - Metric logging and visualization\n     - Artifact management (models, plots, data samples)\n     - Experiment comparison and analysis tools\n\n  3. Model registry integration:\n     - Version control and tagging strategy\n     - Model metadata and lineage\n     - Promotion workflows (dev -> staging -> prod)\n     - Rollback procedures\n\n  Provide complete training code with configuration management.\n</Task>\n\n<Task>\nsubagent_type: python-pro\nprompt: |\n  Optimize and productionize ML code from: {phase2.ml-engineer.output}\n\n  Focus areas:\n  1. Code quality and structure:\n     - Refactor for production standards\n     - Add comprehensive error handling\n     - Implement proper logging with structured formats\n     - Create reusable components and utilities\n\n  2. Performance optimization:\n     - Profile and optimize bottlenecks\n     - Implement caching strategies\n     - Optimize data loading and preprocessing\n     - Memory management for large-scale training\n\n  3. Testing framework:\n     - Unit tests for data transformations",
  "tags": [
    "python",
    "api",
    "ai",
    "agent",
    "automation",
    "workflow",
    "design",
    "document",
    "docker",
    "kubernetes"
  ],
  "useCases": [],
  "scrapedAt": "2026-01-29T06:59:35.576Z"
}