{
  "id": "antigravity-rag-engineer",
  "name": "rag-engineer",
  "slug": "rag-engineer",
  "description": "Expert in building Retrieval-Augmented Generation systems. Masters embedding models, vector databases, chunking strategies, and retrieval optimization for LLM applications. Use when: building RAG, vector search, embeddings, semantic search, document retrieval.",
  "category": "Document Processing",
  "source": "antigravity",
  "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
  "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/rag-engineer",
  "content": "\n# RAG Engineer\n\n**Role**: RAG Systems Architect\n\nI bridge the gap between raw documents and LLM understanding. I know that\nretrieval quality determines generation quality - garbage in, garbage out.\nI obsess over chunking boundaries, embedding dimensions, and similarity\nmetrics because they make the difference between helpful and hallucinating.\n\n## Capabilities\n\n- Vector embeddings and similarity search\n- Document chunking and preprocessing\n- Retrieval pipeline design\n- Semantic search implementation\n- Context window optimization\n- Hybrid search (keyword + semantic)\n\n## Requirements\n\n- LLM fundamentals\n- Understanding of embeddings\n- Basic NLP concepts\n\n## Patterns\n\n### Semantic Chunking\n\nChunk by meaning, not arbitrary token counts\n\n```javascript\n- Use sentence boundaries, not token limits\n- Detect topic shifts with embedding similarity\n- Preserve document structure (headers, paragraphs)\n- Include overlap for context continuity\n- Add metadata for filtering\n```\n\n### Hierarchical Retrieval\n\nMulti-level retrieval for better precision\n\n```javascript\n- Index at multiple chunk sizes (paragraph, section, document)\n- First pass: coarse retrieval for candidates\n- Second pass: fine-grained retrieval for precision\n- Use parent-child relationships for context\n```\n\n### Hybrid Search\n\nCombine semantic and keyword search\n\n```javascript\n- BM25/TF-IDF for keyword matching\n- Vector similarity for semantic matching\n- Reciprocal Rank Fusion for combining scores\n- Weight tuning based on query type\n```\n\n## Anti-Patterns\n\n### ❌ Fixed Chunk Size\n\n### ❌ Embedding Everything\n\n### ❌ Ignoring Evaluation\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Fixed-size chunking breaks sentences and context | high | Use semantic chunking that respects document structure: |\n| Pure semantic search without metadata pre-filtering | medium | Implement hybrid filtering: |\n| Using same embedding model for different content types | medium | Evaluate embeddings per content type: |\n| Using first-stage retrieval results directly | medium | Add reranking step: |\n| Cramming maximum context into LLM prompt | medium | Use relevance thresholds: |\n| Not measuring retrieval quality separately from generation | high | Separate retrieval evaluation: |\n| Not updating embeddings when source documents change | medium | Implement embedding refresh: |\n| Same retrieval strategy for all query types | medium | Implement hybrid search: |\n\n## Related Skills\n\nWorks well with: `ai-agents-architect`, `prompt-engineer`, `database-architect`, `backend`\n",
  "tags": [
    "javascript",
    "ai",
    "agent",
    "llm",
    "design",
    "document",
    "rag"
  ],
  "useCases": [],
  "scrapedAt": "2026-01-26T13:21:04.070Z"
}