{
  "id": "antigravity-hugging-face-cli",
  "name": "hugging-face-cli",
  "slug": "hugging-face-cli",
  "description": "Execute Hugging Face Hub operations using the `hf` CLI. Use when the user needs to download models/datasets/spaces, upload files to Hub repositories, create repos, manage local cache, or run compute jobs on HF infrastructure. Covers authentication, file transfers, repository creation, cache operatio",
  "category": "AI & Agents",
  "source": "antigravity",
  "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
  "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/hugging-face-cli",
  "content": "\n# Hugging Face CLI\n\nThe `hf` CLI provides direct terminal access to the Hugging Face Hub for downloading, uploading, and managing repositories, cache, and compute resources.\n\n## When to Use This Skill\n\nUse this skill when:\n- User needs to download models, datasets, or spaces\n- Uploading files to Hub repositories\n- Creating Hugging Face repositories\n- Managing local cache\n- Running compute jobs on HF infrastructure\n- Working with Hugging Face Hub authentication\n\n## Quick Command Reference\n\n| Task | Command |\n|------|---------|\n| Login | `hf auth login` |\n| Download model | `hf download <repo_id>` |\n| Download to folder | `hf download <repo_id> --local-dir ./path` |\n| Upload folder | `hf upload <repo_id> . .` |\n| Create repo | `hf repo create <name>` |\n| Create tag | `hf repo tag create <repo_id> <tag>` |\n| Delete files | `hf repo-files delete <repo_id> <files>` |\n| List cache | `hf cache ls` |\n| Remove from cache | `hf cache rm <repo_or_revision>` |\n| List models | `hf models ls` |\n| Get model info | `hf models info <model_id>` |\n| List datasets | `hf datasets ls` |\n| Get dataset info | `hf datasets info <dataset_id>` |\n| List spaces | `hf spaces ls` |\n| Get space info | `hf spaces info <space_id>` |\n| List endpoints | `hf endpoints ls` |\n| Run GPU job | `hf jobs run --flavor a10g-small <image> <cmd>` |\n| Environment info | `hf env` |\n\n## Core Commands\n\n### Authentication\n```bash\nhf auth login                    # Interactive login\nhf auth login --token $HF_TOKEN  # Non-interactive\nhf auth whoami                   # Check current user\nhf auth list                     # List stored tokens\nhf auth switch                   # Switch between tokens\nhf auth logout                   # Log out\n```\n\n### Download\n```bash\nhf download <repo_id>                              # Full repo to cache\nhf download <repo_id> file.safetensors             # Specific file\nhf download <repo_id> --local-dir ./models         # To local directory\nhf download <repo_id> --include \"*.safetensors\"    # Filter by pattern\nhf download <repo_id> --repo-type dataset          # Dataset\nhf download <repo_id> --revision v1.0              # Specific version\n```\n\n### Upload\n```bash\nhf upload <repo_id> . .                            # Current dir to root\nhf upload <repo_id> ./models /weights              # Folder to path\nhf upload <repo_id> model.safetensors              # Single file\nhf upload <repo_id> . . --repo-type dataset        # Dataset\nhf upload <repo_id> . . --create-pr                # Create PR\nhf upload <repo_id> . . --commit-message=\"msg\"     # Custom message\n```\n\n### Repository Management\n```bash\nhf repo create <name>                              # Create model repo\nhf repo create <name> --repo-type dataset          # Create dataset\nhf repo create <name> --private                    # Private repo\nhf repo create <name> --repo-type space --space_sdk gradio  # Gradio space\nhf repo delete <repo_id>                           # Delete repo\nhf repo move <from_id> <to_id>                     # Move repo to new namespace\nhf repo settings <repo_id> --private true          # Update repo settings\nhf repo list --repo-type model                     # List repos\nhf repo branch create <repo_id> release-v1         # Create branch\nhf repo branch delete <repo_id> release-v1         # Delete branch\nhf repo tag create <repo_id> v1.0                  # Create tag\nhf repo tag list <repo_id>                         # List tags\nhf repo tag delete <repo_id> v1.0                  # Delete tag\n```\n\n### Delete Files from Repo\n```bash\nhf repo-files delete <repo_id> folder/             # Delete folder\nhf repo-files delete <repo_id> \"*.txt\"             # Delete with pattern\n```\n\n### Cache Management\n```bash\nhf cache ls                      # List cached repos\nhf cache ls --revisions          # Include individual revisions\nhf cache rm model/gpt2           # Remove cached repo\nhf cache rm <revision_hash>      # Remove cached revision\nhf cache prune                   # Remove detached revisions\nhf cache verify gpt2             # Verify checksums from cache\n```\n\n### Browse Hub\n```bash\n# Models\nhf models ls                                        # List top trending models\nhf models ls --search \"MiniMax\" --author MiniMaxAI  # Search models\nhf models ls --filter \"text-generation\" --limit 20  # Filter by task\nhf models info MiniMaxAI/MiniMax-M2.1               # Get model info\n\n# Datasets\nhf datasets ls                                      # List top trending datasets\nhf datasets ls --search \"finepdfs\" --sort downloads # Search datasets\nhf datasets info HuggingFaceFW/finepdfs             # Get dataset info\n\n# Spaces\nhf spaces ls                                        # List top trending spaces\nhf spaces ls --filter \"3d\" --limit 10               # Filter by 3D modeling spaces\nhf spaces info enzostvs/deepsite                    # Get space info\n```\n\n### Jobs (Cloud Compute)\n```bash\nhf jobs run python:3.12 python script.py           # Run on CPU\nhf jobs run --flavor a10g-small",
  "tags": [
    "python",
    "pdf",
    "ai",
    "llm",
    "gpt",
    "workflow",
    "image",
    "aws"
  ],
  "useCases": [
    "User needs to download models, datasets, or spaces",
    "Uploading files to Hub repositories",
    "Creating Hugging Face repositories",
    "Managing local cache",
    "Running compute jobs on HF infrastructure"
  ],
  "scrapedAt": "2026-01-31T06:52:35.136Z"
}