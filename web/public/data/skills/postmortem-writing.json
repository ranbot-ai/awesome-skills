{
  "id": "antigravity-postmortem-writing",
  "name": "postmortem-writing",
  "slug": "postmortem-writing",
  "description": "Write effective blameless postmortems with root cause analysis, timelines, and action items. Use when conducting incident reviews, writing postmortem documents, or improving incident response processes.",
  "category": "Document Processing",
  "source": "antigravity",
  "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
  "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/postmortem-writing",
  "content": "\n# Postmortem Writing\n\nComprehensive guide to writing effective, blameless postmortems that drive organizational learning and prevent incident recurrence.\n\n## Do not use this skill when\n\n- The task is unrelated to postmortem writing\n- You need a different domain or tool outside this scope\n\n## Instructions\n\n- Clarify goals, constraints, and required inputs.\n- Apply relevant best practices and validate outcomes.\n- Provide actionable steps and verification.\n- If detailed examples are required, open `resources/implementation-playbook.md`.\n\n## Use this skill when\n\n- Conducting post-incident reviews\n- Writing postmortem documents\n- Facilitating blameless postmortem meetings\n- Identifying root causes and contributing factors\n- Creating actionable follow-up items\n- Building organizational learning culture\n\n## Core Concepts\n\n### 1. Blameless Culture\n\n| Blame-Focused | Blameless |\n|---------------|-----------|\n| \"Who caused this?\" | \"What conditions allowed this?\" |\n| \"Someone made a mistake\" | \"The system allowed this mistake\" |\n| Punish individuals | Improve systems |\n| Hide information | Share learnings |\n| Fear of speaking up | Psychological safety |\n\n### 2. Postmortem Triggers\n\n- SEV1 or SEV2 incidents\n- Customer-facing outages > 15 minutes\n- Data loss or security incidents\n- Near-misses that could have been severe\n- Novel failure modes\n- Incidents requiring unusual intervention\n\n## Quick Start\n\n### Postmortem Timeline\n```\nDay 0: Incident occurs\nDay 1-2: Draft postmortem document\nDay 3-5: Postmortem meeting\nDay 5-7: Finalize document, create tickets\nWeek 2+: Action item completion\nQuarterly: Review patterns across incidents\n```\n\n## Templates\n\n### Template 1: Standard Postmortem\n\n```markdown\n# Postmortem: [Incident Title]\n\n**Date**: 2024-01-15\n**Authors**: @alice, @bob\n**Status**: Draft | In Review | Final\n**Incident Severity**: SEV2\n**Incident Duration**: 47 minutes\n\n## Executive Summary\n\nOn January 15, 2024, the payment processing service experienced a 47-minute outage affecting approximately 12,000 customers. The root cause was a database connection pool exhaustion triggered by a configuration change in deployment v2.3.4. The incident was resolved by rolling back to v2.3.3 and increasing connection pool limits.\n\n**Impact**:\n- 12,000 customers unable to complete purchases\n- Estimated revenue loss: $45,000\n- 847 support tickets created\n- No data loss or security implications\n\n## Timeline (All times UTC)\n\n| Time | Event |\n|------|-------|\n| 14:23 | Deployment v2.3.4 completed to production |\n| 14:31 | First alert: `payment_error_rate > 5%` |\n| 14:33 | On-call engineer @alice acknowledges alert |\n| 14:35 | Initial investigation begins, error rate at 23% |\n| 14:41 | Incident declared SEV2, @bob joins |\n| 14:45 | Database connection exhaustion identified |\n| 14:52 | Decision to rollback deployment |\n| 14:58 | Rollback to v2.3.3 initiated |\n| 15:10 | Rollback complete, error rate dropping |\n| 15:18 | Service fully recovered, incident resolved |\n\n## Root Cause Analysis\n\n### What Happened\n\nThe v2.3.4 deployment included a change to the database query pattern that inadvertently removed connection pooling for a frequently-called endpoint. Each request opened a new database connection instead of reusing pooled connections.\n\n### Why It Happened\n\n1. **Proximate Cause**: Code change in `PaymentRepository.java` replaced pooled `DataSource` with direct `DriverManager.getConnection()` calls.\n\n2. **Contributing Factors**:\n   - Code review did not catch the connection handling change\n   - No integration tests specifically for connection pool behavior\n   - Staging environment has lower traffic, masking the issue\n   - Database connection metrics alert threshold was too high (90%)\n\n3. **5 Whys Analysis**:\n   - Why did the service fail? → Database connections exhausted\n   - Why were connections exhausted? → Each request opened new connection\n   - Why did each request open new connection? → Code bypassed connection pool\n   - Why did code bypass connection pool? → Developer unfamiliar with codebase patterns\n   - Why was developer unfamiliar? → No documentation on connection management patterns\n\n### System Diagram\n\n```\n[Client] → [Load Balancer] → [Payment Service] → [Database]\n                                    ↓\n                            Connection Pool (broken)\n                                    ↓\n                            Direct connections (cause)\n```\n\n## Detection\n\n### What Worked\n- Error rate alert fired within 8 minutes of deployment\n- Grafana dashboard clearly showed connection spike\n- On-call response was swift (2 minute acknowledgment)\n\n### What Didn't Work\n- Database connection metric alert threshold too high\n- No deployment-correlated alerting\n- Canary deployment would have caught this earlier\n\n### Detection Gap\nThe deployment completed at 14:23, but the first alert didn't fire until 14:31 (8 minutes). A deployment-aware alert could have detected the issue faster.\n\n## Response\n\n### What Worked\n- On-call engineer quick",
  "tags": [
    "markdown",
    "api",
    "ai",
    "agent",
    "template",
    "document",
    "security",
    "rag",
    "cro"
  ],
  "useCases": [],
  "scrapedAt": "2026-01-29T07:00:00.608Z"
}