{
  "id": "antigravity-application-performance-performance-optimization",
  "name": "application-performance-performance-optimization",
  "slug": "application-performance-performance-optimization",
  "description": "Optimize end-to-end application performance with profiling, observability, and backend/frontend tuning. Use when coordinating performance optimization across the stack.",
  "category": "Document Processing",
  "source": "antigravity",
  "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
  "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/application-performance-performance-optimization",
  "content": "\nOptimize application performance end-to-end using specialized performance and optimization agents:\n\n[Extended thinking: This workflow orchestrates a comprehensive performance optimization process across the entire application stack. Starting with deep profiling and baseline establishment, the workflow progresses through targeted optimizations in each system layer, validates improvements through load testing, and establishes continuous monitoring for sustained performance. Each phase builds on insights from previous phases, creating a data-driven optimization strategy that addresses real bottlenecks rather than theoretical improvements. The workflow emphasizes modern observability practices, user-centric performance metrics, and cost-effective optimization strategies.]\n\n## Use this skill when\n\n- Coordinating performance optimization across backend, frontend, and infrastructure\n- Establishing baselines and profiling to identify bottlenecks\n- Designing load tests, performance budgets, or capacity plans\n- Building observability for performance and reliability targets\n\n## Do not use this skill when\n\n- The task is a small localized fix with no broader performance goals\n- There is no access to metrics, tracing, or profiling data\n- The request is unrelated to performance or scalability\n\n## Instructions\n\n1. Confirm performance goals, constraints, and target metrics.\n2. Establish baselines with profiling, tracing, and real-user data.\n3. Execute phased optimizations across the stack with measurable impact.\n4. Validate improvements and set guardrails to prevent regressions.\n\n## Safety\n\n- Avoid load testing production without approvals and safeguards.\n- Roll out performance changes gradually with rollback plans.\n\n## Phase 1: Performance Profiling & Baseline\n\n### 1. Comprehensive Performance Profiling\n\n- Use Task tool with subagent_type=\"performance-engineer\"\n- Prompt: \"Profile application performance comprehensively for: $ARGUMENTS. Generate flame graphs for CPU usage, heap dumps for memory analysis, trace I/O operations, and identify hot paths. Use APM tools like DataDog or New Relic if available. Include database query profiling, API response times, and frontend rendering metrics. Establish performance baselines for all critical user journeys.\"\n- Context: Initial performance investigation\n- Output: Detailed performance profile with flame graphs, memory analysis, bottleneck identification, baseline metrics\n\n### 2. Observability Stack Assessment\n\n- Use Task tool with subagent_type=\"observability-engineer\"\n- Prompt: \"Assess current observability setup for: $ARGUMENTS. Review existing monitoring, distributed tracing with OpenTelemetry, log aggregation, and metrics collection. Identify gaps in visibility, missing metrics, and areas needing better instrumentation. Recommend APM tool integration and custom metrics for business-critical operations.\"\n- Context: Performance profile from step 1\n- Output: Observability assessment report, instrumentation gaps, monitoring recommendations\n\n### 3. User Experience Analysis\n\n- Use Task tool with subagent_type=\"performance-engineer\"\n- Prompt: \"Analyze user experience metrics for: $ARGUMENTS. Measure Core Web Vitals (LCP, FID, CLS), page load times, time to interactive, and perceived performance. Use Real User Monitoring (RUM) data if available. Identify user journeys with poor performance and their business impact.\"\n- Context: Performance baselines from step 1\n- Output: UX performance report, Core Web Vitals analysis, user impact assessment\n\n## Phase 2: Database & Backend Optimization\n\n### 4. Database Performance Optimization\n\n- Use Task tool with subagent_type=\"database-cloud-optimization::database-optimizer\"\n- Prompt: \"Optimize database performance for: $ARGUMENTS based on profiling data: {context_from_phase_1}. Analyze slow query logs, create missing indexes, optimize execution plans, implement query result caching with Redis/Memcached. Review connection pooling, prepared statements, and batch processing opportunities. Consider read replicas and database sharding if needed.\"\n- Context: Performance bottlenecks from phase 1\n- Output: Optimized queries, new indexes, caching strategy, connection pool configuration\n\n### 5. Backend Code & API Optimization\n\n- Use Task tool with subagent_type=\"backend-development::backend-architect\"\n- Prompt: \"Optimize backend services for: $ARGUMENTS targeting bottlenecks: {context_from_phase_1}. Implement efficient algorithms, add application-level caching, optimize N+1 queries, use async/await patterns effectively. Implement pagination, response compression, GraphQL query optimization, and batch API operations. Add circuit breakers and bulkheads for resilience.\"\n- Context: Database optimizations from step 4, profiling data from phase 1\n- Output: Optimized backend code, caching implementation, API improvements, resilience patterns\n\n### 6. Microservices & Distributed System Optimization\n\n- Use Task tool with subagent_type=\"performance-engineer\"\n- Prompt: \"",
  "tags": [
    "javascript",
    "react",
    "api",
    "ai",
    "agent",
    "workflow",
    "design",
    "document",
    "image",
    "rag"
  ],
  "useCases": [],
  "scrapedAt": "2026-01-29T06:58:00.264Z"
}