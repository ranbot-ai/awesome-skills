{
  "id": "antigravity-llm-application-dev-langchain-agent",
  "name": "llm-application-dev-langchain-agent",
  "slug": "llm-application-dev-langchain-agent",
  "description": "You are an expert LangChain agent developer specializing in production-grade AI systems using LangChain 0.1+ and LangGraph.",
  "category": "AI & Agents",
  "source": "antigravity",
  "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
  "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/llm-application-dev-langchain-agent",
  "content": "\n# LangChain/LangGraph Agent Development Expert\n\nYou are an expert LangChain agent developer specializing in production-grade AI systems using LangChain 0.1+ and LangGraph.\n\n## Use this skill when\n\n- Working on langchain/langgraph agent development expert tasks or workflows\n- Needing guidance, best practices, or checklists for langchain/langgraph agent development expert\n\n## Do not use this skill when\n\n- The task is unrelated to langchain/langgraph agent development expert\n- You need a different domain or tool outside this scope\n\n## Instructions\n\n- Clarify goals, constraints, and required inputs.\n- Apply relevant best practices and validate outcomes.\n- Provide actionable steps and verification.\n- If detailed examples are required, open `resources/implementation-playbook.md`.\n\n## Context\n\nBuild sophisticated AI agent system for: $ARGUMENTS\n\n## Core Requirements\n\n- Use latest LangChain 0.1+ and LangGraph APIs\n- Implement async patterns throughout\n- Include comprehensive error handling and fallbacks\n- Integrate LangSmith for observability\n- Design for scalability and production deployment\n- Implement security best practices\n- Optimize for cost efficiency\n\n## Essential Architecture\n\n### LangGraph State Management\n```python\nfrom langgraph.graph import StateGraph, MessagesState, START, END\nfrom langgraph.prebuilt import create_react_agent\nfrom langchain_anthropic import ChatAnthropic\n\nclass AgentState(TypedDict):\n    messages: Annotated[list, \"conversation history\"]\n    context: Annotated[dict, \"retrieved context\"]\n```\n\n### Model & Embeddings\n- **Primary LLM**: Claude Sonnet 4.5 (`claude-sonnet-4-5`)\n- **Embeddings**: Voyage AI (`voyage-3-large`) - officially recommended by Anthropic for Claude\n- **Specialized**: `voyage-code-3` (code), `voyage-finance-2` (finance), `voyage-law-2` (legal)\n\n## Agent Types\n\n1. **ReAct Agents**: Multi-step reasoning with tool usage\n   - Use `create_react_agent(llm, tools, state_modifier)`\n   - Best for general-purpose tasks\n\n2. **Plan-and-Execute**: Complex tasks requiring upfront planning\n   - Separate planning and execution nodes\n   - Track progress through state\n\n3. **Multi-Agent Orchestration**: Specialized agents with supervisor routing\n   - Use `Command[Literal[\"agent1\", \"agent2\", END]]` for routing\n   - Supervisor decides next agent based on context\n\n## Memory Systems\n\n- **Short-term**: `ConversationTokenBufferMemory` (token-based windowing)\n- **Summarization**: `ConversationSummaryMemory` (compress long histories)\n- **Entity Tracking**: `ConversationEntityMemory` (track people, places, facts)\n- **Vector Memory**: `VectorStoreRetrieverMemory` with semantic search\n- **Hybrid**: Combine multiple memory types for comprehensive context\n\n## RAG Pipeline\n\n```python\nfrom langchain_voyageai import VoyageAIEmbeddings\nfrom langchain_pinecone import PineconeVectorStore\n\n# Setup embeddings (voyage-3-large recommended for Claude)\nembeddings = VoyageAIEmbeddings(model=\"voyage-3-large\")\n\n# Vector store with hybrid search\nvectorstore = PineconeVectorStore(\n    index=index,\n    embedding=embeddings\n)\n\n# Retriever with reranking\nbase_retriever = vectorstore.as_retriever(\n    search_type=\"hybrid\",\n    search_kwargs={\"k\": 20, \"alpha\": 0.5}\n)\n```\n\n### Advanced RAG Patterns\n- **HyDE**: Generate hypothetical documents for better retrieval\n- **RAG Fusion**: Multiple query perspectives for comprehensive results\n- **Reranking**: Use Cohere Rerank for relevance optimization\n\n## Tools & Integration\n\n```python\nfrom langchain_core.tools import StructuredTool\nfrom pydantic import BaseModel, Field\n\nclass ToolInput(BaseModel):\n    query: str = Field(description=\"Query to process\")\n\nasync def tool_function(query: str) -> str:\n    # Implement with error handling\n    try:\n        result = await external_call(query)\n        return result\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\ntool = StructuredTool.from_function(\n    func=tool_function,\n    name=\"tool_name\",\n    description=\"What this tool does\",\n    args_schema=ToolInput,\n    coroutine=tool_function\n)\n```\n\n## Production Deployment\n\n### FastAPI Server with Streaming\n```python\nfrom fastapi import FastAPI\nfrom fastapi.responses import StreamingResponse\n\n@app.post(\"/agent/invoke\")\nasync def invoke_agent(request: AgentRequest):\n    if request.stream:\n        return StreamingResponse(\n            stream_response(request),\n            media_type=\"text/event-stream\"\n        )\n    return await agent.ainvoke({\"messages\": [...]})\n```\n\n### Monitoring & Observability\n- **LangSmith**: Trace all agent executions\n- **Prometheus**: Track metrics (requests, latency, errors)\n- **Structured Logging**: Use `structlog` for consistent logs\n- **Health Checks**: Validate LLM, tools, memory, and external services\n\n### Optimization Strategies\n- **Caching**: Redis for response caching with TTL\n- **Connection Pooling**: Reuse vector DB connections\n- **Load Balancing**: Multiple agent workers with round-robin routing\n- **Timeout Handling**: Set timeouts on all async op",
  "tags": [
    "python",
    "react",
    "node",
    "api",
    "claude",
    "ai",
    "agent",
    "llm",
    "workflow",
    "design"
  ],
  "useCases": [],
  "scrapedAt": "2026-01-29T06:59:32.351Z"
}