{
  "id": "antigravity-computer-use-agents",
  "name": "computer-use-agents",
  "slug": "computer-use-agents",
  "description": "Build AI agents that interact with computers like humans do - viewing screens, moving cursors, clicking buttons, and typing text. Covers Anthropic's Computer Use, OpenAI's Operator/CUA, and open-source alternatives. Critical focus on sandboxing, security, and handling the unique challenges of vision",
  "category": "AI & Agents",
  "source": "antigravity",
  "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
  "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/computer-use-agents",
  "content": "\n# Computer Use Agents\n\n## Patterns\n\n### Perception-Reasoning-Action Loop\n\nThe fundamental architecture of computer use agents: observe screen,\nreason about next action, execute action, repeat. This loop integrates\nvision models with action execution through an iterative pipeline.\n\nKey components:\n1. PERCEPTION: Screenshot captures current screen state\n2. REASONING: Vision-language model analyzes and plans\n3. ACTION: Execute mouse/keyboard operations\n4. FEEDBACK: Observe result, continue or correct\n\nCritical insight: Vision agents are completely still during \"thinking\"\nphase (1-5 seconds), creating a detectable pause pattern.\n\n\n**When to use**: ['Building any computer use agent from scratch', 'Integrating vision models with desktop control', 'Understanding agent behavior patterns']\n\n```python\nfrom anthropic import Anthropic\nfrom PIL import Image\nimport base64\nimport pyautogui\nimport time\n\nclass ComputerUseAgent:\n    \"\"\"\n    Perception-Reasoning-Action loop implementation.\n    Based on Anthropic Computer Use patterns.\n    \"\"\"\n\n    def __init__(self, client: Anthropic, model: str = \"claude-sonnet-4-20250514\"):\n        self.client = client\n        self.model = model\n        self.max_steps = 50  # Prevent runaway loops\n        self.action_delay = 0.5  # Seconds between actions\n\n    def capture_screenshot(self) -> str:\n        \"\"\"Capture screen and return base64 encoded image.\"\"\"\n        screenshot = pyautogui.screenshot()\n        # Resize for token efficiency (1280x800 is good balance)\n        screenshot = screenshot.resize((1280, 800), Image.LANCZOS)\n\n        import io\n        buffer = io.BytesIO()\n        screenshot.save(buffer, format=\"PNG\")\n        return base64.b64encode(buffer.getvalue()).decode()\n\n    def execute_action(self, action: dict) -> dict:\n        \"\"\"Execute mouse/keyboard action on the computer.\"\"\"\n        action_type = action.get(\"type\")\n\n        if action_type == \"click\":\n            x, y = action[\"x\"], action[\"y\"]\n            button = action.get(\"button\", \"left\")\n            pyautogui.click(x, y, button=button)\n            return {\"success\": True, \"action\": f\"clicked at ({x}, {y})\"}\n\n        elif action_type == \"type\":\n            text = action[\"text\"]\n            pyautogui.typewrite(text, interval=0.02)\n            return {\"success\": True, \"action\": f\"typed {len(text)} chars\"}\n\n        elif action_type == \"key\":\n            key = action[\"key\"]\n            pyautogui.press(key)\n            return {\"success\": True, \"action\": f\"pressed {key}\"}\n\n        elif action_type == \"scroll\":\n            direction = action.get(\"direction\", \"down\")\n            amount = action.get(\"amount\", 3)\n            scroll = -amount if direction == \"down\" else amount\n            pyautogui.scroll(scroll)\n            return {\"success\": True, \"action\": f\"scrolled {dir\n```\n\n### Sandboxed Environment Pattern\n\nComputer use agents MUST run in isolated, sandboxed environments.\nNever give agents direct access to your main system - the security\nrisks are too high. Use Docker containers with virtual desktops.\n\nKey isolation requirements:\n1. NETWORK: Restrict to necessary endpoints only\n2. FILESYSTEM: Read-only or scoped to temp directories\n3. CREDENTIALS: No access to host credentials\n4. SYSCALLS: Filter dangerous system calls\n5. RESOURCES: Limit CPU, memory, time\n\nThe goal is \"blast radius minimization\" - if the agent goes wrong,\ndamage is contained to the sandbox.\n\n\n**When to use**: ['Deploying any computer use agent', 'Testing agent behavior safely', 'Running untrusted automation tasks']\n\n```python\n# Dockerfile for sandboxed computer use environment\n# Based on Anthropic's reference implementation pattern\n\nFROM ubuntu:22.04\n\n# Install desktop environment\nRUN apt-get update && apt-get install -y \\\n    xvfb \\\n    x11vnc \\\n    fluxbox \\\n    xterm \\\n    firefox \\\n    python3 \\\n    python3-pip \\\n    supervisor\n\n# Security: Create non-root user\nRUN useradd -m -s /bin/bash agent && \\\n    mkdir -p /home/agent/.vnc\n\n# Install Python dependencies\nCOPY requirements.txt /tmp/\nRUN pip3 install -r /tmp/requirements.txt\n\n# Security: Drop capabilities\nRUN apt-get install -y --no-install-recommends libcap2-bin && \\\n    setcap -r /usr/bin/python3 || true\n\n# Copy agent code\nCOPY --chown=agent:agent . /app\nWORKDIR /app\n\n# Supervisor config for virtual display + VNC\nCOPY supervisord.conf /etc/supervisor/conf.d/\n\n# Expose VNC port only (not desktop directly)\nEXPOSE 5900\n\n# Run as non-root\nUSER agent\n\nCMD [\"/usr/bin/supervisord\", \"-c\", \"/etc/supervisor/conf.d/supervisord.conf\"]\n\n---\n\n# docker-compose.yml with security constraints\nversion: '3.8'\n\nservices:\n  computer-use-agent:\n    build: .\n    ports:\n      - \"5900:5900\"  # VNC for observation\n      - \"8080:8080\"  # API for control\n\n    # Security constraints\n    security_opt:\n      - no-new-privileges:true\n      - seccomp:seccomp-profile.json\n\n    # Resource limits\n    deploy:\n      resources:\n        limits:\n          cpus: '2'\n          memory: 4G\n        reservations:\n          cpus: '0.5'\n      ",
  "tags": [
    "python",
    "api",
    "claude",
    "ai",
    "agent",
    "automation",
    "image",
    "security",
    "docker",
    "rag"
  ],
  "useCases": [],
  "scrapedAt": "2026-01-26T13:17:42.565Z"
}