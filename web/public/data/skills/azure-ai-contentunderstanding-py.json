{
  "id": "antigravity-azure-ai-contentunderstanding-py",
  "name": "azure-ai-contentunderstanding-py",
  "slug": "azure-ai-contentunderstanding-py",
  "description": "Azure AI Content Understanding SDK for Python. Use for multimodal content extraction from documents, images, audio, and video.\nTriggers: \"azure-ai-contentunderstanding\", \"ContentUnderstandingClient\", \"multimodal analysis\", \"document extraction\", \"video analysis\", \"audio transcription\".\n",
  "category": "Document Processing",
  "source": "antigravity",
  "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
  "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/azure-ai-contentunderstanding-py",
  "content": "\n# Azure AI Content Understanding SDK for Python\n\nMultimodal AI service that extracts semantic content from documents, video, audio, and image files for RAG and automated workflows.\n\n## Installation\n\n```bash\npip install azure-ai-contentunderstanding\n```\n\n## Environment Variables\n\n```bash\nCONTENTUNDERSTANDING_ENDPOINT=https://<resource>.cognitiveservices.azure.com/\n```\n\n## Authentication\n\n```python\nimport os\nfrom azure.ai.contentunderstanding import ContentUnderstandingClient\nfrom azure.identity import DefaultAzureCredential\n\nendpoint = os.environ[\"CONTENTUNDERSTANDING_ENDPOINT\"]\ncredential = DefaultAzureCredential()\nclient = ContentUnderstandingClient(endpoint=endpoint, credential=credential)\n```\n\n## Core Workflow\n\nContent Understanding operations are asynchronous long-running operations:\n\n1. **Begin Analysis** — Start the analysis operation with `begin_analyze()` (returns a poller)\n2. **Poll for Results** — Poll until analysis completes (SDK handles this with `.result()`)\n3. **Process Results** — Extract structured results from `AnalyzeResult.contents`\n\n## Prebuilt Analyzers\n\n| Analyzer | Content Type | Purpose |\n|----------|--------------|---------|\n| `prebuilt-documentSearch` | Documents | Extract markdown for RAG applications |\n| `prebuilt-imageSearch` | Images | Extract content from images |\n| `prebuilt-audioSearch` | Audio | Transcribe audio with timing |\n| `prebuilt-videoSearch` | Video | Extract frames, transcripts, summaries |\n| `prebuilt-invoice` | Documents | Extract invoice fields |\n\n## Analyze Document\n\n```python\nimport os\nfrom azure.ai.contentunderstanding import ContentUnderstandingClient\nfrom azure.ai.contentunderstanding.models import AnalyzeInput\nfrom azure.identity import DefaultAzureCredential\n\nendpoint = os.environ[\"CONTENTUNDERSTANDING_ENDPOINT\"]\nclient = ContentUnderstandingClient(\n    endpoint=endpoint,\n    credential=DefaultAzureCredential()\n)\n\n# Analyze document from URL\npoller = client.begin_analyze(\n    analyzer_id=\"prebuilt-documentSearch\",\n    inputs=[AnalyzeInput(url=\"https://example.com/document.pdf\")]\n)\n\nresult = poller.result()\n\n# Access markdown content (contents is a list)\ncontent = result.contents[0]\nprint(content.markdown)\n```\n\n## Access Document Content Details\n\n```python\nfrom azure.ai.contentunderstanding.models import MediaContentKind, DocumentContent\n\ncontent = result.contents[0]\nif content.kind == MediaContentKind.DOCUMENT:\n    document_content: DocumentContent = content  # type: ignore\n    print(document_content.start_page_number)\n```\n\n## Analyze Image\n\n```python\nfrom azure.ai.contentunderstanding.models import AnalyzeInput\n\npoller = client.begin_analyze(\n    analyzer_id=\"prebuilt-imageSearch\",\n    inputs=[AnalyzeInput(url=\"https://example.com/image.jpg\")]\n)\nresult = poller.result()\ncontent = result.contents[0]\nprint(content.markdown)\n```\n\n## Analyze Video\n\n```python\nfrom azure.ai.contentunderstanding.models import AnalyzeInput\n\npoller = client.begin_analyze(\n    analyzer_id=\"prebuilt-videoSearch\",\n    inputs=[AnalyzeInput(url=\"https://example.com/video.mp4\")]\n)\n\nresult = poller.result()\n\n# Access video content (AudioVisualContent)\ncontent = result.contents[0]\n\n# Get transcript phrases with timing\nfor phrase in content.transcript_phrases:\n    print(f\"[{phrase.start_time} - {phrase.end_time}]: {phrase.text}\")\n\n# Get key frames (for video)\nfor frame in content.key_frames:\n    print(f\"Frame at {frame.time}: {frame.description}\")\n```\n\n## Analyze Audio\n\n```python\nfrom azure.ai.contentunderstanding.models import AnalyzeInput\n\npoller = client.begin_analyze(\n    analyzer_id=\"prebuilt-audioSearch\",\n    inputs=[AnalyzeInput(url=\"https://example.com/audio.mp3\")]\n)\n\nresult = poller.result()\n\n# Access audio transcript\ncontent = result.contents[0]\nfor phrase in content.transcript_phrases:\n    print(f\"[{phrase.start_time}] {phrase.text}\")\n```\n\n## Custom Analyzers\n\nCreate custom analyzers with field schemas for specialized extraction:\n\n```python\n# Create custom analyzer\nanalyzer = client.create_analyzer(\n    analyzer_id=\"my-invoice-analyzer\",\n    analyzer={\n        \"description\": \"Custom invoice analyzer\",\n        \"base_analyzer_id\": \"prebuilt-documentSearch\",\n        \"field_schema\": {\n            \"fields\": {\n                \"vendor_name\": {\"type\": \"string\"},\n                \"invoice_total\": {\"type\": \"number\"},\n                \"line_items\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"description\": {\"type\": \"string\"},\n                            \"amount\": {\"type\": \"number\"}\n                        }\n                    }\n                }\n            }\n        }\n    }\n)\n\n# Use custom analyzer\nfrom azure.ai.contentunderstanding.models import AnalyzeInput\n\npoller = client.begin_analyze(\n    analyzer_id=\"my-invoice-analyzer\",\n    inputs=[AnalyzeInput(url=\"https://example.com/invoice.pdf\")]\n)\n\nresult = poller.result()\n\n# Access extracted fields\nprint",
  "tags": [
    "python",
    "pdf",
    "markdown",
    "ai",
    "workflow",
    "document",
    "presentation",
    "image",
    "azure",
    "rag"
  ],
  "useCases": [],
  "scrapedAt": "2026-02-12T07:15:30.979Z"
}